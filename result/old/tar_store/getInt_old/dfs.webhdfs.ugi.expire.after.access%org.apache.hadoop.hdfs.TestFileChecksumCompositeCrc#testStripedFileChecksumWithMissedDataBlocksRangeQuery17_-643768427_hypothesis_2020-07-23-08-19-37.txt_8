reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523157595-172.17.0.19-1595492394217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-367605f2-d4d2-4fb8-a37c-1c581a389f90,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-e1c3da0a-6307-4672-bd9a-d0b2016bb6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-34ee163a-1ffd-4563-bd77-6b8e5090c709,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-3a6e7d3e-1f68-44a1-941b-fc542c89683f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-75cefe93-3e75-4ced-8d35-670283ff7883,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-ad1d06c4-b96a-4a39-acc1-eee87fefdc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-b7654c50-2387-40c6-b7f0-f2e1703f1e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-24e0e91a-b27c-45e2-93a2-238a08746b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523157595-172.17.0.19-1595492394217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-367605f2-d4d2-4fb8-a37c-1c581a389f90,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-e1c3da0a-6307-4672-bd9a-d0b2016bb6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-34ee163a-1ffd-4563-bd77-6b8e5090c709,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-3a6e7d3e-1f68-44a1-941b-fc542c89683f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-75cefe93-3e75-4ced-8d35-670283ff7883,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-ad1d06c4-b96a-4a39-acc1-eee87fefdc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-b7654c50-2387-40c6-b7f0-f2e1703f1e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-24e0e91a-b27c-45e2-93a2-238a08746b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510827294-172.17.0.19-1595492545763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-639c865c-53e0-4e98-8b24-fca975662461,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-f5c64b12-01f5-449e-8c53-7b83a0b7fd14,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-a716adc7-ad4e-4615-8c59-712a63851bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-d2111e87-f6d7-4131-95d0-db9aa91927d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-90746afd-9d96-4812-bcdc-03aff0ab7a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-5e12d274-75bd-441e-b969-6fdca02e8ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-9984c2b4-8c41-4e80-8a3a-91d3a7155d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-2ebc8222-70d3-4283-96ff-3fa539dfa9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510827294-172.17.0.19-1595492545763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-639c865c-53e0-4e98-8b24-fca975662461,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-f5c64b12-01f5-449e-8c53-7b83a0b7fd14,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-a716adc7-ad4e-4615-8c59-712a63851bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-d2111e87-f6d7-4131-95d0-db9aa91927d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-90746afd-9d96-4812-bcdc-03aff0ab7a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-5e12d274-75bd-441e-b969-6fdca02e8ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-9984c2b4-8c41-4e80-8a3a-91d3a7155d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-2ebc8222-70d3-4283-96ff-3fa539dfa9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117612731-172.17.0.19-1595492584186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-9a66ac15-2854-4245-a0d7-b9b2b10362f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-bd7ec295-5abd-41ff-9f50-09dc72116b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-689e144f-128a-4cea-81c8-9375b9ada43d,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-12341587-9e32-40fa-ad01-da647f370d03,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-46317753-8029-4053-b033-ecf25e9ba55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-6c3b7f17-8556-48cc-9e79-ff4955129565,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-13ccbcac-5227-4c16-b9fc-91a3db9f5c95,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-1ac58903-31c3-4f5e-8207-69ea6c204c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117612731-172.17.0.19-1595492584186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-9a66ac15-2854-4245-a0d7-b9b2b10362f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-bd7ec295-5abd-41ff-9f50-09dc72116b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-689e144f-128a-4cea-81c8-9375b9ada43d,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-12341587-9e32-40fa-ad01-da647f370d03,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-46317753-8029-4053-b033-ecf25e9ba55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-6c3b7f17-8556-48cc-9e79-ff4955129565,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-13ccbcac-5227-4c16-b9fc-91a3db9f5c95,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-1ac58903-31c3-4f5e-8207-69ea6c204c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844422567-172.17.0.19-1595492820096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35522,DS-d3c185a7-8e96-429e-9e60-d9a62096c423,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-63485e29-d0ab-4ddc-857b-b6e44c80f9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-3d93c4cc-c4ca-4741-9da6-edeff3470f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-8fce9e0f-3053-4a00-9d18-ec500feea9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-d920861d-2264-4995-be99-ec3e1a8d2828,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-017834de-68e3-4d98-a92e-9c5a5dbbb2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-18da2f9c-292f-42b1-abb3-017c6b85d7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-5ac5ddef-175a-4262-836d-19748424ece2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844422567-172.17.0.19-1595492820096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35522,DS-d3c185a7-8e96-429e-9e60-d9a62096c423,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-63485e29-d0ab-4ddc-857b-b6e44c80f9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-3d93c4cc-c4ca-4741-9da6-edeff3470f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-8fce9e0f-3053-4a00-9d18-ec500feea9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-d920861d-2264-4995-be99-ec3e1a8d2828,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-017834de-68e3-4d98-a92e-9c5a5dbbb2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-18da2f9c-292f-42b1-abb3-017c6b85d7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-5ac5ddef-175a-4262-836d-19748424ece2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327717870-172.17.0.19-1595492927097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35200,DS-bd977986-21fa-4b27-8004-28c239515a95,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-095596be-5f57-45ba-926b-638b29aee0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-1f67e55d-47d5-41e5-9f33-2a9c3bb597a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-b7ea3b31-385a-4812-86fd-774347383043,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-3fba05f0-e801-48b4-9ebd-a4ccbbeea081,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-f95eff08-cd2e-492c-8760-77ab4639d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-b34e2397-f46a-4aed-9721-5d9a292977a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-23f05385-eb5c-48d2-a7b0-02f33142e5e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327717870-172.17.0.19-1595492927097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35200,DS-bd977986-21fa-4b27-8004-28c239515a95,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-095596be-5f57-45ba-926b-638b29aee0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-1f67e55d-47d5-41e5-9f33-2a9c3bb597a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-b7ea3b31-385a-4812-86fd-774347383043,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-3fba05f0-e801-48b4-9ebd-a4ccbbeea081,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-f95eff08-cd2e-492c-8760-77ab4639d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-b34e2397-f46a-4aed-9721-5d9a292977a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-23f05385-eb5c-48d2-a7b0-02f33142e5e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48127912-172.17.0.19-1595493078370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-82e05742-7566-446d-a605-58b30586634f,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-8f8eeec1-4b32-443e-9267-e6c1a467497c,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-9c33616d-4537-4ee6-acca-9b85ce0fc679,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-369748e8-576e-4b5a-9ea8-d92980a84f81,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-79da8bb1-9a1a-4d90-bb22-612e032278a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-52951aa5-bb80-4403-8a8d-6554dac9a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-2cb9287d-6bf9-45d1-8925-9338243fd84b,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-4c7a4e98-6bdb-4245-b3d8-204c780d896f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48127912-172.17.0.19-1595493078370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-82e05742-7566-446d-a605-58b30586634f,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-8f8eeec1-4b32-443e-9267-e6c1a467497c,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-9c33616d-4537-4ee6-acca-9b85ce0fc679,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-369748e8-576e-4b5a-9ea8-d92980a84f81,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-79da8bb1-9a1a-4d90-bb22-612e032278a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-52951aa5-bb80-4403-8a8d-6554dac9a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-2cb9287d-6bf9-45d1-8925-9338243fd84b,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-4c7a4e98-6bdb-4245-b3d8-204c780d896f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252471141-172.17.0.19-1595493419293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-a04e2bf3-9b63-4b74-b46f-39d58dcee638,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-bb29db20-5b86-49df-9494-8d3aa1d5ba4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-e5282746-d31d-411b-b6f5-1b82b609a12d,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-62f2de45-7e20-4095-b106-e14395ec486d,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-fb04710a-2694-44f3-8243-0443ca5d73a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-e13d6dae-f804-466a-846b-7621134ce747,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-08a0ccf6-9475-4241-bd5a-4448cd77e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-9e8237e1-0f84-4906-9a26-d7655234578f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252471141-172.17.0.19-1595493419293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-a04e2bf3-9b63-4b74-b46f-39d58dcee638,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-bb29db20-5b86-49df-9494-8d3aa1d5ba4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-e5282746-d31d-411b-b6f5-1b82b609a12d,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-62f2de45-7e20-4095-b106-e14395ec486d,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-fb04710a-2694-44f3-8243-0443ca5d73a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-e13d6dae-f804-466a-846b-7621134ce747,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-08a0ccf6-9475-4241-bd5a-4448cd77e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-9e8237e1-0f84-4906-9a26-d7655234578f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532238975-172.17.0.19-1595493534884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-a67597f6-5c41-45eb-9fdb-61af2c6011b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-7c3841be-344f-4150-87ad-68c18dd5ee41,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-1b212b65-34da-440d-bf71-31d5c75505e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-da2ac7eb-d83b-42a9-a40a-d0e842a97194,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-1f2e3574-b6ec-4096-ad34-c807b9c838b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-dec95e74-66f9-4a75-adac-e25be8f9a80f,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-b27f8480-a893-4c58-ba06-38d6de5da6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-40195398-0812-4a93-8883-c53c9550dcbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532238975-172.17.0.19-1595493534884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-a67597f6-5c41-45eb-9fdb-61af2c6011b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-7c3841be-344f-4150-87ad-68c18dd5ee41,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-1b212b65-34da-440d-bf71-31d5c75505e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-da2ac7eb-d83b-42a9-a40a-d0e842a97194,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-1f2e3574-b6ec-4096-ad34-c807b9c838b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-dec95e74-66f9-4a75-adac-e25be8f9a80f,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-b27f8480-a893-4c58-ba06-38d6de5da6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-40195398-0812-4a93-8883-c53c9550dcbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035854322-172.17.0.19-1595493614458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-27953911-d123-4bd7-ab3e-0f5cca7c3537,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-53e52380-f7de-45ba-a08d-3c8f2260fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-b0d2bb51-7be2-488f-bf82-eadd373cf1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-a4af832a-b1c4-40f9-9465-0917e48799a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-3491fdd1-51cf-4684-9f4f-436a3639fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-4a493272-97ea-4e67-a432-0cab42a63c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-412d7fd0-ee53-436e-a49e-f4e91fccaf90,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-1ccb4004-157c-4ef6-a4a8-58b6c8ae5599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035854322-172.17.0.19-1595493614458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-27953911-d123-4bd7-ab3e-0f5cca7c3537,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-53e52380-f7de-45ba-a08d-3c8f2260fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-b0d2bb51-7be2-488f-bf82-eadd373cf1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-a4af832a-b1c4-40f9-9465-0917e48799a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-3491fdd1-51cf-4684-9f4f-436a3639fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-4a493272-97ea-4e67-a432-0cab42a63c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-412d7fd0-ee53-436e-a49e-f4e91fccaf90,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-1ccb4004-157c-4ef6-a4a8-58b6c8ae5599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055373498-172.17.0.19-1595493935798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-a6debe53-5864-48db-850f-3f1181ae2a20,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-fc1ec3f5-4b17-4376-ad6c-4d5cebdca9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-78f59fe4-2a69-4718-9dd3-5c6e54df7b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-f6ba1069-126c-46c4-8f5b-70f441759a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-6b44725b-e94c-43ff-879f-21ac4dabfabe,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-c3fb01d2-8484-447e-bfdc-328f11191799,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-e2073a27-d604-4af0-ae75-dc81e69b2280,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-8ef77120-6d66-4b7a-9312-9b2b9c2101c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055373498-172.17.0.19-1595493935798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-a6debe53-5864-48db-850f-3f1181ae2a20,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-fc1ec3f5-4b17-4376-ad6c-4d5cebdca9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-78f59fe4-2a69-4718-9dd3-5c6e54df7b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-f6ba1069-126c-46c4-8f5b-70f441759a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-6b44725b-e94c-43ff-879f-21ac4dabfabe,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-c3fb01d2-8484-447e-bfdc-328f11191799,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-e2073a27-d604-4af0-ae75-dc81e69b2280,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-8ef77120-6d66-4b7a-9312-9b2b9c2101c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137607084-172.17.0.19-1595493972529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-055b3ceb-f0b3-4194-9762-6053a738ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-4ccf154c-f1bc-4a4f-941a-f3113719b539,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-340093ca-0ce8-49fc-9ca1-35cee44bcef2,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-50b68b49-97f6-4381-904a-bc3b601dac43,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-57165c41-0146-4b0f-9d8f-5f01f38b2a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-5ac551d7-5e32-4e01-9f66-71e49361237a,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-6a0f0126-2943-4b99-9c20-168dda297ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-b98783ce-fe6e-4ba5-835e-827dae390884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137607084-172.17.0.19-1595493972529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-055b3ceb-f0b3-4194-9762-6053a738ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-4ccf154c-f1bc-4a4f-941a-f3113719b539,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-340093ca-0ce8-49fc-9ca1-35cee44bcef2,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-50b68b49-97f6-4381-904a-bc3b601dac43,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-57165c41-0146-4b0f-9d8f-5f01f38b2a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-5ac551d7-5e32-4e01-9f66-71e49361237a,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-6a0f0126-2943-4b99-9c20-168dda297ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-b98783ce-fe6e-4ba5-835e-827dae390884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307938312-172.17.0.19-1595494686523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-4192e36d-1248-4008-b2e6-2d6bd4afc9be,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-4105602c-6adf-44bb-b7f7-3e88f6775945,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-7eaea3ba-7971-481a-9588-ef6ecd8e2aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-8569aab7-8415-4476-a6aa-bb1388b830cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-ca300b55-3e04-4078-8ab1-dc247552ea12,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-067f2b28-432a-4e41-b094-965c02999564,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-a62f3b1f-782a-4fc7-af90-0e8e2c26acc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-353c331e-05ce-49f1-9380-63242fafd504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307938312-172.17.0.19-1595494686523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-4192e36d-1248-4008-b2e6-2d6bd4afc9be,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-4105602c-6adf-44bb-b7f7-3e88f6775945,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-7eaea3ba-7971-481a-9588-ef6ecd8e2aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-8569aab7-8415-4476-a6aa-bb1388b830cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-ca300b55-3e04-4078-8ab1-dc247552ea12,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-067f2b28-432a-4e41-b094-965c02999564,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-a62f3b1f-782a-4fc7-af90-0e8e2c26acc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-353c331e-05ce-49f1-9380-63242fafd504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089284361-172.17.0.19-1595494797915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-39d444b5-d53f-4518-aacd-d7a678c7dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-4731752f-b573-4309-b315-dd4e717bc956,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-d9f23e12-4f58-438d-b090-8000f6435e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-f40af2c3-49ee-47a9-a28b-559ed353bd75,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-6797eb18-fe29-4b40-a53b-0fc2c9594f96,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-e7045577-721f-4b59-aba8-538272289ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-b4ef1a0c-4a99-4acb-8e14-9e9c4f4367f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-6b05571a-4a1f-4854-98bf-2b370feb3842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089284361-172.17.0.19-1595494797915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-39d444b5-d53f-4518-aacd-d7a678c7dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-4731752f-b573-4309-b315-dd4e717bc956,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-d9f23e12-4f58-438d-b090-8000f6435e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-f40af2c3-49ee-47a9-a28b-559ed353bd75,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-6797eb18-fe29-4b40-a53b-0fc2c9594f96,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-e7045577-721f-4b59-aba8-538272289ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-b4ef1a0c-4a99-4acb-8e14-9e9c4f4367f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-6b05571a-4a1f-4854-98bf-2b370feb3842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553985087-172.17.0.19-1595495461722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33290,DS-29b0cd86-5007-4aa0-a06d-840524e096d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-1fb5978a-30c6-47ad-b3c6-38a2aeb44d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-89fac0a1-e56b-480d-9d89-b1c098fafd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-6dfe2710-d719-4203-9590-c618ee76b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-3825a92a-3623-435a-aa8b-84b694b4f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-63a6e2c9-eace-48c2-8d00-23e3277631b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-cdb7d282-30cd-4377-ae44-c57baaadc446,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-64977bbb-7b51-4154-b618-bdadbfb2d72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553985087-172.17.0.19-1595495461722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33290,DS-29b0cd86-5007-4aa0-a06d-840524e096d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-1fb5978a-30c6-47ad-b3c6-38a2aeb44d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-89fac0a1-e56b-480d-9d89-b1c098fafd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-6dfe2710-d719-4203-9590-c618ee76b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-3825a92a-3623-435a-aa8b-84b694b4f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-63a6e2c9-eace-48c2-8d00-23e3277631b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-cdb7d282-30cd-4377-ae44-c57baaadc446,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-64977bbb-7b51-4154-b618-bdadbfb2d72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461567887-172.17.0.19-1595495496884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37463,DS-d47d2387-d21b-40e2-b991-9ceeb23cfaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-3728c9f6-3256-486f-9a48-1239050276f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-24d7bb23-6478-4bb7-9a2d-1493ac80c5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-2990168d-88d7-4fa8-b46c-67e147c9514d,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-96c8667b-ed9a-4c77-b858-5ac08dd44b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-fa18b4ee-f650-41ca-b5b3-e31f53eb0d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-4b652847-a164-4c48-8d18-679ea90ea570,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-47794e02-0026-4352-aa4d-913b37f63994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461567887-172.17.0.19-1595495496884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37463,DS-d47d2387-d21b-40e2-b991-9ceeb23cfaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-3728c9f6-3256-486f-9a48-1239050276f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-24d7bb23-6478-4bb7-9a2d-1493ac80c5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-2990168d-88d7-4fa8-b46c-67e147c9514d,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-96c8667b-ed9a-4c77-b858-5ac08dd44b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-fa18b4ee-f650-41ca-b5b3-e31f53eb0d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-4b652847-a164-4c48-8d18-679ea90ea570,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-47794e02-0026-4352-aa4d-913b37f63994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760285127-172.17.0.19-1595496009518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-b7aa587a-2230-4a30-a9ae-e8df9980f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-ad9afb55-bccc-4e89-a7d7-d465db8540b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-9472e831-8da4-452f-ab9c-044af757206f,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-a794dc1b-f063-404d-aa1e-79f282b3be82,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-4cb9ee31-0188-47c9-999a-543a47ff526f,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-0809bdcc-5cd9-4990-b67d-e99aea219608,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-731413d2-e514-40a1-ab4f-6ebad2a4554b,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-d3796e5a-f2ae-44cd-98c9-7c0fffa05aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760285127-172.17.0.19-1595496009518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-b7aa587a-2230-4a30-a9ae-e8df9980f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-ad9afb55-bccc-4e89-a7d7-d465db8540b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-9472e831-8da4-452f-ab9c-044af757206f,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-a794dc1b-f063-404d-aa1e-79f282b3be82,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-4cb9ee31-0188-47c9-999a-543a47ff526f,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-0809bdcc-5cd9-4990-b67d-e99aea219608,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-731413d2-e514-40a1-ab4f-6ebad2a4554b,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-d3796e5a-f2ae-44cd-98c9-7c0fffa05aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759588806-172.17.0.19-1595496526519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-e98f97c7-cd37-4125-baab-f92b09015e69,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-e922f162-0e3e-4c28-a91b-6c87d4fd9afb,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-d6eb4b2c-b812-45ec-a8a4-4cad6fa5efbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-f19f214b-27a2-46b1-9f96-2bd375dc3a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-79f48e0e-a568-4941-83ab-7cf0a8636361,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-46fec833-0211-42a4-9527-02fba85a309f,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-0791bbef-7f21-4102-87f5-bbda7ad69a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-b9bc7423-2d5c-4e07-8d80-decfa9b87345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759588806-172.17.0.19-1595496526519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-e98f97c7-cd37-4125-baab-f92b09015e69,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-e922f162-0e3e-4c28-a91b-6c87d4fd9afb,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-d6eb4b2c-b812-45ec-a8a4-4cad6fa5efbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-f19f214b-27a2-46b1-9f96-2bd375dc3a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-79f48e0e-a568-4941-83ab-7cf0a8636361,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-46fec833-0211-42a4-9527-02fba85a309f,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-0791bbef-7f21-4102-87f5-bbda7ad69a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-b9bc7423-2d5c-4e07-8d80-decfa9b87345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6901499-172.17.0.19-1595496918098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46399,DS-2d0808a7-5b79-485f-9146-b3a427acb579,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-83bb360b-cd44-4f39-95fb-da7ab9cbe9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-87101d68-8062-42ee-9044-dedc27a74a96,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-682433bd-0a8b-438b-819b-ca7d8a72fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-ae595d61-9c3e-42af-9d09-f83a3179f770,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-5c02dc2b-d4d9-4f7f-9850-ea5cf7e683d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-f397b63f-3612-41d1-bc18-f190f713343a,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-6482c2ff-a20c-4111-b83b-dd0ba14480e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6901499-172.17.0.19-1595496918098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46399,DS-2d0808a7-5b79-485f-9146-b3a427acb579,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-83bb360b-cd44-4f39-95fb-da7ab9cbe9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-87101d68-8062-42ee-9044-dedc27a74a96,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-682433bd-0a8b-438b-819b-ca7d8a72fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-ae595d61-9c3e-42af-9d09-f83a3179f770,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-5c02dc2b-d4d9-4f7f-9850-ea5cf7e683d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-f397b63f-3612-41d1-bc18-f190f713343a,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-6482c2ff-a20c-4111-b83b-dd0ba14480e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297129663-172.17.0.19-1595497200214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39732,DS-1b300f5e-dea0-45ed-a66b-9d5b4cca083b,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-614e302b-c5e4-49b9-8648-e98ee459dc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-8dd7ee6a-1f9a-4759-b08a-ff54ae458d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-dcf7a99b-b699-4019-b915-7776860d932f,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-a8d258ac-21d6-47de-afb1-7547285f8df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-454bcc5e-a61f-42a1-80aa-413fef4e060a,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-412bedb8-3c96-42d7-afdb-494fc2653025,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-39df685c-1e20-410b-b0a2-7331c724f2bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297129663-172.17.0.19-1595497200214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39732,DS-1b300f5e-dea0-45ed-a66b-9d5b4cca083b,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-614e302b-c5e4-49b9-8648-e98ee459dc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-8dd7ee6a-1f9a-4759-b08a-ff54ae458d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-dcf7a99b-b699-4019-b915-7776860d932f,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-a8d258ac-21d6-47de-afb1-7547285f8df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-454bcc5e-a61f-42a1-80aa-413fef4e060a,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-412bedb8-3c96-42d7-afdb-494fc2653025,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-39df685c-1e20-410b-b0a2-7331c724f2bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950733697-172.17.0.19-1595497346153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43728,DS-0b3e528d-4687-42d6-ab03-498b2293715e,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-aee47cf4-c40e-4596-baaf-ad0a10e32fab,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-8ab90883-eebf-471c-b80b-56af9b8330ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-d6720142-a988-449a-8522-0294849c174a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-6ad39c8d-a629-454c-9bcd-69eee4fde576,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-58828a50-a187-4b88-8cde-9d9ceee9669c,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-894d7637-b2c1-41e1-9e75-f399602b6cad,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-b1cd23fc-3cf0-4e73-9351-0a1f9840d91e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950733697-172.17.0.19-1595497346153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43728,DS-0b3e528d-4687-42d6-ab03-498b2293715e,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-aee47cf4-c40e-4596-baaf-ad0a10e32fab,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-8ab90883-eebf-471c-b80b-56af9b8330ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-d6720142-a988-449a-8522-0294849c174a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-6ad39c8d-a629-454c-9bcd-69eee4fde576,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-58828a50-a187-4b88-8cde-9d9ceee9669c,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-894d7637-b2c1-41e1-9e75-f399602b6cad,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-b1cd23fc-3cf0-4e73-9351-0a1f9840d91e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928878309-172.17.0.19-1595497654203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37682,DS-d477be85-ac3a-499d-b6a9-388760a41d94,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-3285abd2-f831-44a9-9535-5c952a80515e,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-208fc05c-0c84-44b2-96f1-e2c471cb8b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-52ede888-4c23-4329-8cd0-75350f9e19b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-54719d12-fdd6-454f-9c3c-348f917a0ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-9bac3b3f-55b3-4dda-8008-9493f54cc09a,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-9684ca5f-f4fc-46b1-a1ec-5729a7d6ff78,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-99d3a66f-2633-4adc-b264-91013db691dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928878309-172.17.0.19-1595497654203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37682,DS-d477be85-ac3a-499d-b6a9-388760a41d94,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-3285abd2-f831-44a9-9535-5c952a80515e,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-208fc05c-0c84-44b2-96f1-e2c471cb8b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-52ede888-4c23-4329-8cd0-75350f9e19b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-54719d12-fdd6-454f-9c3c-348f917a0ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-9bac3b3f-55b3-4dda-8008-9493f54cc09a,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-9684ca5f-f4fc-46b1-a1ec-5729a7d6ff78,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-99d3a66f-2633-4adc-b264-91013db691dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5488
