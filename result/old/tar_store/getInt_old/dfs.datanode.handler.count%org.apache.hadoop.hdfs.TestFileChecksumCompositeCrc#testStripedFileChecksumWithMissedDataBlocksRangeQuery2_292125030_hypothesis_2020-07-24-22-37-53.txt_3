reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684388267-172.17.0.18-1595630732183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-b8c593b0-d227-422e-9d95-2270c18c4421,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-adcbb7e3-a393-4cd5-83e9-a4269552016e,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-b52d8482-203a-44fe-b479-ba5a2f02e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-6fbd2148-f62b-4465-98b2-c8d34d9c7c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-9ab7139d-5e6e-45c0-8b06-ab913517b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-10668179-1cc2-4b08-ac53-faf967fba696,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-3ffe1f15-225f-4be8-9bb2-fab4a81bf256,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-ef9780e5-76d2-4970-871d-049d45db37dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684388267-172.17.0.18-1595630732183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-b8c593b0-d227-422e-9d95-2270c18c4421,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-adcbb7e3-a393-4cd5-83e9-a4269552016e,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-b52d8482-203a-44fe-b479-ba5a2f02e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-6fbd2148-f62b-4465-98b2-c8d34d9c7c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-9ab7139d-5e6e-45c0-8b06-ab913517b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-10668179-1cc2-4b08-ac53-faf967fba696,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-3ffe1f15-225f-4be8-9bb2-fab4a81bf256,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-ef9780e5-76d2-4970-871d-049d45db37dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630339733-172.17.0.18-1595631111040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-dfd77fb3-30b3-4f2a-874a-2d0987098654,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-61edf001-575f-40ef-8814-339aac3b62e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-af8cbf36-eef3-48fb-82dd-2576c59bb942,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-7aa8a141-c8c2-429e-bcf7-925186628379,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-06afe00f-ff9f-4d0a-921a-62218e51cc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-b2aa5281-3f4e-4628-9c59-dbb58a066dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-003d9eba-9992-467c-8d76-502b7c59a607,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-42fe0f0e-2f9b-4b0d-b12a-5a2f4a986122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630339733-172.17.0.18-1595631111040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-dfd77fb3-30b3-4f2a-874a-2d0987098654,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-61edf001-575f-40ef-8814-339aac3b62e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-af8cbf36-eef3-48fb-82dd-2576c59bb942,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-7aa8a141-c8c2-429e-bcf7-925186628379,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-06afe00f-ff9f-4d0a-921a-62218e51cc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-b2aa5281-3f4e-4628-9c59-dbb58a066dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-003d9eba-9992-467c-8d76-502b7c59a607,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-42fe0f0e-2f9b-4b0d-b12a-5a2f4a986122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297769373-172.17.0.18-1595632227818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46330,DS-7bed2206-1145-4640-ae6b-61b1c6cb00dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-b2a5e13c-7730-4720-92fa-a660a08eec1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-1ab11347-efc8-40d6-bc0f-e18b860087be,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-6176dbad-47f2-413b-b1fa-b142a8f5b9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-226d8bf0-7887-4b71-b1ec-5b135348d67e,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-dadc8890-f18a-4491-aca7-f70c17ca614f,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-fce6edb3-c41f-4bb6-bfc1-0b597809d352,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-f598356e-fd4f-4b47-a48a-a08c47126bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297769373-172.17.0.18-1595632227818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46330,DS-7bed2206-1145-4640-ae6b-61b1c6cb00dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-b2a5e13c-7730-4720-92fa-a660a08eec1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-1ab11347-efc8-40d6-bc0f-e18b860087be,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-6176dbad-47f2-413b-b1fa-b142a8f5b9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-226d8bf0-7887-4b71-b1ec-5b135348d67e,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-dadc8890-f18a-4491-aca7-f70c17ca614f,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-fce6edb3-c41f-4bb6-bfc1-0b597809d352,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-f598356e-fd4f-4b47-a48a-a08c47126bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684030549-172.17.0.18-1595632343796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-b8db506e-48f0-4e7b-84bc-31f76bb7e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-24010327-7304-430e-a4cf-13ae98af5bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-4b4e4748-6adb-470c-9581-b373a13d4b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-8b4c968d-52fd-48aa-acc3-2118f4f49414,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-17e08cbe-7e05-4d3b-8608-ba9ac9703fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-d4fb20cd-207c-41a4-8b71-85b037224bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-ec86d9c8-3caf-47b0-a51a-00636f079a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-7366b3f5-eee0-4b64-bcef-963b407c3e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684030549-172.17.0.18-1595632343796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-b8db506e-48f0-4e7b-84bc-31f76bb7e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-24010327-7304-430e-a4cf-13ae98af5bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-4b4e4748-6adb-470c-9581-b373a13d4b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-8b4c968d-52fd-48aa-acc3-2118f4f49414,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-17e08cbe-7e05-4d3b-8608-ba9ac9703fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-d4fb20cd-207c-41a4-8b71-85b037224bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-ec86d9c8-3caf-47b0-a51a-00636f079a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-7366b3f5-eee0-4b64-bcef-963b407c3e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317340259-172.17.0.18-1595632833812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-f03fbf18-11d4-45b5-99d8-f06d037056ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-c98dda3c-e42e-488b-9f6f-f5cc9d0dfcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-f2ca62cb-7383-4564-906f-49d8b4675a24,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-1194f9f1-18a8-4686-959b-e6103d66d14d,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-734dacd9-00da-445c-b423-0b5ca40c4ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-68f9e72e-7716-4fe5-9145-87fd6e0c4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-578b71e4-db85-47f5-9217-5237a3e39a90,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-ed9b4895-2bad-4181-816b-e383c7965184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317340259-172.17.0.18-1595632833812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-f03fbf18-11d4-45b5-99d8-f06d037056ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-c98dda3c-e42e-488b-9f6f-f5cc9d0dfcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-f2ca62cb-7383-4564-906f-49d8b4675a24,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-1194f9f1-18a8-4686-959b-e6103d66d14d,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-734dacd9-00da-445c-b423-0b5ca40c4ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-68f9e72e-7716-4fe5-9145-87fd6e0c4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-578b71e4-db85-47f5-9217-5237a3e39a90,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-ed9b4895-2bad-4181-816b-e383c7965184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199307322-172.17.0.18-1595633880882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-ef231ae8-8704-41bb-8581-776afd9d60f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-4571b0fc-79d3-4135-a313-6146ed882e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-96312f4f-5255-4234-a432-970753a156f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-99f7716e-a8c9-4e4b-a59d-012aa53b05e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-55555705-eae4-4130-af80-f4f37f0b5c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-b93d4208-ba06-420f-9b60-48f6981a774f,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-afe856b6-011f-4c01-be04-c8f43ec421bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-74390058-34b3-47ac-8603-4c9c6d6796c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199307322-172.17.0.18-1595633880882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-ef231ae8-8704-41bb-8581-776afd9d60f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-4571b0fc-79d3-4135-a313-6146ed882e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-96312f4f-5255-4234-a432-970753a156f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-99f7716e-a8c9-4e4b-a59d-012aa53b05e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-55555705-eae4-4130-af80-f4f37f0b5c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-b93d4208-ba06-420f-9b60-48f6981a774f,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-afe856b6-011f-4c01-be04-c8f43ec421bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-74390058-34b3-47ac-8603-4c9c6d6796c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300574808-172.17.0.18-1595634190058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42634,DS-044af663-91ca-4440-8a83-cdc441835e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-8aeda75e-e3b1-451c-8fe5-7cbc86e646ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-d6d2e5c3-b095-42f7-afec-a695b96d28d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-1d6c1836-e4af-43e8-b859-062f3a7c79a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-88135f22-51e0-44bb-bae4-6654767708f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-d4249ab2-2509-485d-83b8-4e83204534b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-4e622050-4592-42de-88fb-4b2a08a1d340,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-f8a38495-c277-4c5a-b041-6a649c23c30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300574808-172.17.0.18-1595634190058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42634,DS-044af663-91ca-4440-8a83-cdc441835e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-8aeda75e-e3b1-451c-8fe5-7cbc86e646ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-d6d2e5c3-b095-42f7-afec-a695b96d28d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-1d6c1836-e4af-43e8-b859-062f3a7c79a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-88135f22-51e0-44bb-bae4-6654767708f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-d4249ab2-2509-485d-83b8-4e83204534b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-4e622050-4592-42de-88fb-4b2a08a1d340,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-f8a38495-c277-4c5a-b041-6a649c23c30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997503690-172.17.0.18-1595635094677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36220,DS-121e17f5-7e26-46cf-b578-2ec935155b00,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-392710ef-f094-46c4-b358-e2c50eff7bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-52c8bc9a-b5d4-4c67-88be-36550b04ca15,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-2dc232c7-1117-480f-b674-2dc92a72e5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-f9f36f5d-7769-4925-818a-8868233c38b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-cc9c64a8-b377-4c16-a77c-70fd02b5ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-1960c85b-4973-40cf-a155-6346b136a017,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-8976430b-4648-4111-a9c0-adeba366aeaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997503690-172.17.0.18-1595635094677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36220,DS-121e17f5-7e26-46cf-b578-2ec935155b00,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-392710ef-f094-46c4-b358-e2c50eff7bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-52c8bc9a-b5d4-4c67-88be-36550b04ca15,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-2dc232c7-1117-480f-b674-2dc92a72e5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-f9f36f5d-7769-4925-818a-8868233c38b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-cc9c64a8-b377-4c16-a77c-70fd02b5ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-1960c85b-4973-40cf-a155-6346b136a017,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-8976430b-4648-4111-a9c0-adeba366aeaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373208133-172.17.0.18-1595635274294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46602,DS-c366cf47-cf3b-4b50-9dff-59dc40f9f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-d2e1bcc0-49cc-47d1-9d73-fa9535acc630,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-81d451e3-9049-4d88-b702-bfafcfb6afc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-8244340d-528e-4322-a775-0a52ece5316d,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-22768a06-b159-4937-b706-9befbe074b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-d6442696-c0d2-45c2-9bda-723b77506bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-ac1a3f83-01e3-46ef-87ab-8661fbe9adb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-697ea7d3-42a2-4c47-8813-60805e93cb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373208133-172.17.0.18-1595635274294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46602,DS-c366cf47-cf3b-4b50-9dff-59dc40f9f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-d2e1bcc0-49cc-47d1-9d73-fa9535acc630,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-81d451e3-9049-4d88-b702-bfafcfb6afc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-8244340d-528e-4322-a775-0a52ece5316d,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-22768a06-b159-4937-b706-9befbe074b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-d6442696-c0d2-45c2-9bda-723b77506bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-ac1a3f83-01e3-46ef-87ab-8661fbe9adb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-697ea7d3-42a2-4c47-8813-60805e93cb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124460788-172.17.0.18-1595635420710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-ec146662-80ef-4740-9583-fe2d4502e310,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-2e81fbf1-f8cd-44ad-b9b8-5d82a5bd8857,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-392027a6-e036-46fd-94fa-361ac363b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-b51e730b-3bc2-4f41-9695-186429e4d071,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-452a9609-6181-4ab2-a402-67ead27f41a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-d0bae64d-4b3b-46db-a3c9-6f3f843e3ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-c582f810-1a4a-44b3-bb6e-55bbf78d336f,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-efa54b29-b992-4024-9fc3-112313c0a704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124460788-172.17.0.18-1595635420710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-ec146662-80ef-4740-9583-fe2d4502e310,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-2e81fbf1-f8cd-44ad-b9b8-5d82a5bd8857,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-392027a6-e036-46fd-94fa-361ac363b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-b51e730b-3bc2-4f41-9695-186429e4d071,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-452a9609-6181-4ab2-a402-67ead27f41a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-d0bae64d-4b3b-46db-a3c9-6f3f843e3ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-c582f810-1a4a-44b3-bb6e-55bbf78d336f,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-efa54b29-b992-4024-9fc3-112313c0a704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5595
