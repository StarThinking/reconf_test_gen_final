reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793039168-172.17.0.21-1595700336036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36751,DS-d5b6d973-d811-4ced-a224-6783d080779d,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-f3e6ee10-fc01-48a4-9b8c-3359599e5746,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-bb3703d5-3209-446c-9357-d862c948e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-ea689559-b570-4630-98e7-0d432600d864,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-a0707261-617b-47df-abcc-406ab4cea517,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-b8ec33f0-d2dc-4745-9f8a-447fcb1db55b,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-74c55104-86b5-4663-8aaf-ef90aaf57034,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-a05eb5f2-6a65-48b4-95d7-727914aa769c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793039168-172.17.0.21-1595700336036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36751,DS-d5b6d973-d811-4ced-a224-6783d080779d,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-f3e6ee10-fc01-48a4-9b8c-3359599e5746,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-bb3703d5-3209-446c-9357-d862c948e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-ea689559-b570-4630-98e7-0d432600d864,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-a0707261-617b-47df-abcc-406ab4cea517,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-b8ec33f0-d2dc-4745-9f8a-447fcb1db55b,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-74c55104-86b5-4663-8aaf-ef90aaf57034,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-a05eb5f2-6a65-48b4-95d7-727914aa769c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478878520-172.17.0.21-1595700372341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32818,DS-1eee22a4-e1c5-4bb0-bb4e-700aade640c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-08dd19ac-8da1-4288-b0f1-c885d09e5868,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-472b28ae-875b-457c-927d-fee5964474fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-a9baec5a-2495-4f81-97dd-4c7a39d72417,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-1bb396f7-083e-461e-a9b3-4346d95ef6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-f2ca8c63-00a7-43ff-8d82-ea92c142a057,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-f09e9942-a760-42d7-b044-4501685205c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-aa8ed79f-920e-40a1-adc5-8f20b9bb7e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478878520-172.17.0.21-1595700372341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32818,DS-1eee22a4-e1c5-4bb0-bb4e-700aade640c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-08dd19ac-8da1-4288-b0f1-c885d09e5868,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-472b28ae-875b-457c-927d-fee5964474fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-a9baec5a-2495-4f81-97dd-4c7a39d72417,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-1bb396f7-083e-461e-a9b3-4346d95ef6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-f2ca8c63-00a7-43ff-8d82-ea92c142a057,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-f09e9942-a760-42d7-b044-4501685205c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-aa8ed79f-920e-40a1-adc5-8f20b9bb7e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298705307-172.17.0.21-1595700616038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40325,DS-b6ffaafe-20f1-4dce-a94b-86bd71b4e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-228893c6-56be-4b94-896a-5269475cf49e,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-b9f128a2-1bb6-4512-867b-4f08ab20ac82,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-46bee117-7261-4ab6-b20a-07ff720432f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-f428fb9c-fc92-4321-b95f-788faec38f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-6222d58b-ea18-4431-be37-f50b6a0c9a01,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-3f6caa2b-247e-445c-8078-37b53154b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-7f42f1ec-bd51-4f2e-b69f-f04461821589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298705307-172.17.0.21-1595700616038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40325,DS-b6ffaafe-20f1-4dce-a94b-86bd71b4e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-228893c6-56be-4b94-896a-5269475cf49e,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-b9f128a2-1bb6-4512-867b-4f08ab20ac82,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-46bee117-7261-4ab6-b20a-07ff720432f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-f428fb9c-fc92-4321-b95f-788faec38f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-6222d58b-ea18-4431-be37-f50b6a0c9a01,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-3f6caa2b-247e-445c-8078-37b53154b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-7f42f1ec-bd51-4f2e-b69f-f04461821589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826103245-172.17.0.21-1595701009192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-bed20d39-0b3a-4ca0-9a33-84c0d3b435ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-6f12298d-f5d7-4baa-8a1f-205dcc690974,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-f6278c6e-c703-4786-b42d-cd4666cdcc28,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-67599832-f2d6-4c50-af88-c5b1f86ba219,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-5e97a094-69e3-4783-8718-9e5775b72eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-d51e5b0e-785f-46f1-88c7-1840bbc90bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-17fe0bf4-3f08-461e-b4c9-314300daff98,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-2791c59c-b512-4f4d-b8ac-962b10c684b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826103245-172.17.0.21-1595701009192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-bed20d39-0b3a-4ca0-9a33-84c0d3b435ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-6f12298d-f5d7-4baa-8a1f-205dcc690974,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-f6278c6e-c703-4786-b42d-cd4666cdcc28,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-67599832-f2d6-4c50-af88-c5b1f86ba219,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-5e97a094-69e3-4783-8718-9e5775b72eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-d51e5b0e-785f-46f1-88c7-1840bbc90bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-17fe0bf4-3f08-461e-b4c9-314300daff98,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-2791c59c-b512-4f4d-b8ac-962b10c684b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149573311-172.17.0.21-1595701081490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45672,DS-7c2140a4-c631-4597-a510-bf37e8b11b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-f4054b2d-b3eb-4299-8a1c-728e3bcea1da,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-0ad22a33-37d6-49c3-bccc-6ac0350384df,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-00e8b35a-92c3-4d3d-b1b4-1c1ea867bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-806300ab-95cc-42db-bfd6-6d6da1ae563c,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-a22d7c46-276c-426f-94d2-86cb56e96962,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-377478c2-6d08-4b92-b26e-787c53d21d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-3a3d05ea-f26a-4c40-99ef-7bf081ab3e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149573311-172.17.0.21-1595701081490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45672,DS-7c2140a4-c631-4597-a510-bf37e8b11b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-f4054b2d-b3eb-4299-8a1c-728e3bcea1da,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-0ad22a33-37d6-49c3-bccc-6ac0350384df,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-00e8b35a-92c3-4d3d-b1b4-1c1ea867bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-806300ab-95cc-42db-bfd6-6d6da1ae563c,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-a22d7c46-276c-426f-94d2-86cb56e96962,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-377478c2-6d08-4b92-b26e-787c53d21d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-3a3d05ea-f26a-4c40-99ef-7bf081ab3e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445407628-172.17.0.21-1595701234884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36164,DS-334d717e-543c-4472-a7b2-3a63c6ed72cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-2881c61b-a30b-45ea-bc7e-b96d77db1b21,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-70aace8b-b6df-4fdc-9236-a1343ad26ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-b9dd67fb-8e9f-40f5-a5fe-9de318d0feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-b3581b32-287f-413a-b924-4fa8c6df44f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-7a7bc57f-026b-4ab7-bddd-8cb8ccf68e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-5dd2c7f2-e1d2-4bca-8799-3ed1e7afb1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-4175c911-48bf-4d96-84fc-4e1119df0bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445407628-172.17.0.21-1595701234884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36164,DS-334d717e-543c-4472-a7b2-3a63c6ed72cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-2881c61b-a30b-45ea-bc7e-b96d77db1b21,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-70aace8b-b6df-4fdc-9236-a1343ad26ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-b9dd67fb-8e9f-40f5-a5fe-9de318d0feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-b3581b32-287f-413a-b924-4fa8c6df44f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-7a7bc57f-026b-4ab7-bddd-8cb8ccf68e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-5dd2c7f2-e1d2-4bca-8799-3ed1e7afb1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-4175c911-48bf-4d96-84fc-4e1119df0bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20812744-172.17.0.21-1595701677563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-c00f81b4-dd78-415a-b743-d8d34848d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-f74af4a5-50f3-420b-a8bd-61f32a2810f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-66c4b6fb-51f6-432b-91a5-3583498fa07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-1b4603b5-293b-40bb-94d8-6a592e6a38fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-e17afe89-87bf-4f61-91b7-e4225cf34f30,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-646e3634-6fd3-4b58-9ce0-4c9a122a411c,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-0c088e1c-292e-452c-a46d-147a5a48648e,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-244f5038-6d74-4bc2-8580-81e613271a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20812744-172.17.0.21-1595701677563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-c00f81b4-dd78-415a-b743-d8d34848d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-f74af4a5-50f3-420b-a8bd-61f32a2810f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-66c4b6fb-51f6-432b-91a5-3583498fa07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-1b4603b5-293b-40bb-94d8-6a592e6a38fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-e17afe89-87bf-4f61-91b7-e4225cf34f30,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-646e3634-6fd3-4b58-9ce0-4c9a122a411c,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-0c088e1c-292e-452c-a46d-147a5a48648e,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-244f5038-6d74-4bc2-8580-81e613271a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377131096-172.17.0.21-1595702012638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-911f4f30-4027-462e-8cff-a4e386d5e8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-cd552e8b-eedb-481b-ae9d-fecbebcd3cde,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-5843aa42-924d-411f-b6b3-13ef8a41da66,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-08590745-82b6-4920-8f97-2b8150e62cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-87837f62-5541-45ce-ab22-b7e588cfecf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-01a07653-bc22-4b1a-8dfe-5905099814f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-7de70281-f1ff-4041-a166-28f168b5039c,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-66841c11-b32f-472e-859d-0db92febc4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377131096-172.17.0.21-1595702012638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-911f4f30-4027-462e-8cff-a4e386d5e8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-cd552e8b-eedb-481b-ae9d-fecbebcd3cde,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-5843aa42-924d-411f-b6b3-13ef8a41da66,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-08590745-82b6-4920-8f97-2b8150e62cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-87837f62-5541-45ce-ab22-b7e588cfecf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-01a07653-bc22-4b1a-8dfe-5905099814f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-7de70281-f1ff-4041-a166-28f168b5039c,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-66841c11-b32f-472e-859d-0db92febc4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372641398-172.17.0.21-1595702836985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37341,DS-d3055af7-0195-4235-9a1a-13bc1197c52c,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-32cc8aca-495c-4660-ac71-56a416db6b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-0f5233d9-815f-41e0-81d6-e7b1b8e27a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-3944493a-be29-466e-ba9d-a0253f48fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-5c5575ee-91c5-4e1c-b576-0c0c52b678dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-0ea4e3f5-1590-4ee0-8c63-fffecfd36f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-dc8a0797-8a62-4cb6-96a4-7ddf52c73559,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-8e5d773e-e2ef-43f0-9ec9-1a2d262b728c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372641398-172.17.0.21-1595702836985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37341,DS-d3055af7-0195-4235-9a1a-13bc1197c52c,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-32cc8aca-495c-4660-ac71-56a416db6b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-0f5233d9-815f-41e0-81d6-e7b1b8e27a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-3944493a-be29-466e-ba9d-a0253f48fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-5c5575ee-91c5-4e1c-b576-0c0c52b678dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-0ea4e3f5-1590-4ee0-8c63-fffecfd36f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-dc8a0797-8a62-4cb6-96a4-7ddf52c73559,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-8e5d773e-e2ef-43f0-9ec9-1a2d262b728c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985030186-172.17.0.21-1595703065807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-449dc91f-647a-46f9-8ec8-c0b343d664c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-a1f6ab3d-6d8c-42f2-8a25-e6448377ddc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-d466ca29-0139-43a4-bdd1-477224f1849c,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-0f6906de-7224-415b-8b34-b6c9b0cb0077,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-3a3dfaa2-0701-496c-8160-d171ef585c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-5a6465a0-6a30-494b-b2da-d97ab785f558,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-d22dc6d5-e7cf-4911-b88d-9b0ab65e4786,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-34030467-55dd-4627-9483-827b2745409b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985030186-172.17.0.21-1595703065807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-449dc91f-647a-46f9-8ec8-c0b343d664c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-a1f6ab3d-6d8c-42f2-8a25-e6448377ddc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-d466ca29-0139-43a4-bdd1-477224f1849c,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-0f6906de-7224-415b-8b34-b6c9b0cb0077,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-3a3dfaa2-0701-496c-8160-d171ef585c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-5a6465a0-6a30-494b-b2da-d97ab785f558,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-d22dc6d5-e7cf-4911-b88d-9b0ab65e4786,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-34030467-55dd-4627-9483-827b2745409b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039282524-172.17.0.21-1595703115520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-dde036af-6549-4f8b-b826-fc566fe7d19d,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-6c30c849-af6e-478e-8293-2c91acef6413,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-498c21d9-5475-425d-96e3-0d37929b07a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-35bbab92-44ec-4ba9-8690-4683a9a87277,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-1de52094-c83c-4807-954e-f297645f8767,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-cd370067-089b-4bba-b23d-95a64e08e5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-a3faf45b-1852-4c96-b04a-2b4eaa8ccdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-0fffbc4f-3b77-479f-96d1-343935de535d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039282524-172.17.0.21-1595703115520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-dde036af-6549-4f8b-b826-fc566fe7d19d,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-6c30c849-af6e-478e-8293-2c91acef6413,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-498c21d9-5475-425d-96e3-0d37929b07a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-35bbab92-44ec-4ba9-8690-4683a9a87277,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-1de52094-c83c-4807-954e-f297645f8767,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-cd370067-089b-4bba-b23d-95a64e08e5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-a3faf45b-1852-4c96-b04a-2b4eaa8ccdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-0fffbc4f-3b77-479f-96d1-343935de535d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044383420-172.17.0.21-1595703246144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43634,DS-95b9702e-b1dd-4859-8f7e-49ac944e2ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-079e46e7-5f1a-4646-b453-afc7601cc5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-640ed8f2-d647-40e0-b50f-0fc6a8dbb9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-9a49f96a-f2a8-4691-a328-7df77c69c554,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-e32c50a8-9a7f-4e6e-8884-74640a77a6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-0f7357e1-588e-442b-a014-91797df788c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-75d92b46-ba91-4f11-bed6-100e01e97137,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-c73b62e7-43c0-4889-bc20-56c2fcd65c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044383420-172.17.0.21-1595703246144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43634,DS-95b9702e-b1dd-4859-8f7e-49ac944e2ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-079e46e7-5f1a-4646-b453-afc7601cc5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-640ed8f2-d647-40e0-b50f-0fc6a8dbb9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-9a49f96a-f2a8-4691-a328-7df77c69c554,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-e32c50a8-9a7f-4e6e-8884-74640a77a6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-0f7357e1-588e-442b-a014-91797df788c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-75d92b46-ba91-4f11-bed6-100e01e97137,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-c73b62e7-43c0-4889-bc20-56c2fcd65c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825889976-172.17.0.21-1595703376406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36562,DS-a0281c37-55ed-4445-9234-4dbf1bab7b80,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-b108c1c2-8456-4b3f-868f-61d28cf21ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-f1840692-632f-4c6b-b1ff-17aada4c490f,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-c04aced4-50f6-4b7c-a285-d9df17faf991,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-b452e196-145f-4fbb-a8f1-f3faf11471e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-d74e820e-bdf5-4c03-8a5f-5e213c192388,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-ccfb00b1-17f4-4a18-99d2-789f77b5a5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-aa0fc02a-df6d-4940-81f8-cd57acbb9476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825889976-172.17.0.21-1595703376406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36562,DS-a0281c37-55ed-4445-9234-4dbf1bab7b80,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-b108c1c2-8456-4b3f-868f-61d28cf21ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-f1840692-632f-4c6b-b1ff-17aada4c490f,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-c04aced4-50f6-4b7c-a285-d9df17faf991,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-b452e196-145f-4fbb-a8f1-f3faf11471e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-d74e820e-bdf5-4c03-8a5f-5e213c192388,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-ccfb00b1-17f4-4a18-99d2-789f77b5a5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-aa0fc02a-df6d-4940-81f8-cd57acbb9476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4009
