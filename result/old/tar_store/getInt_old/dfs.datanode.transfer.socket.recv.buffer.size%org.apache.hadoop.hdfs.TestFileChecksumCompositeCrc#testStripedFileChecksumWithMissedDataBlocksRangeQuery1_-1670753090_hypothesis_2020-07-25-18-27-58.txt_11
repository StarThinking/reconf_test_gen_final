reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360573102-172.17.0.10-1595701932759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-8d994417-2c64-490f-a1f7-47c76dd765ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-87c16e45-eef5-48c7-aad9-299824eaf903,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-7d2813c2-d683-4451-bc32-e34394d0a35a,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-d5ff5776-dc8c-4ec1-93b0-6ed4938093e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-5f0579a3-aaec-4ea7-8f9a-69d9cfc187dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-d73c7f29-4924-4421-b189-35025b9ce341,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-495a463a-2b67-4f3e-8514-975d38caad34,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-70e92ae2-da75-4788-834f-d035f5fdf32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360573102-172.17.0.10-1595701932759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-8d994417-2c64-490f-a1f7-47c76dd765ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-87c16e45-eef5-48c7-aad9-299824eaf903,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-7d2813c2-d683-4451-bc32-e34394d0a35a,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-d5ff5776-dc8c-4ec1-93b0-6ed4938093e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-5f0579a3-aaec-4ea7-8f9a-69d9cfc187dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-d73c7f29-4924-4421-b189-35025b9ce341,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-495a463a-2b67-4f3e-8514-975d38caad34,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-70e92ae2-da75-4788-834f-d035f5fdf32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614669870-172.17.0.10-1595702041802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43184,DS-46b5cb8f-5a6e-41ce-a0cf-868cbce567cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-2a135782-2b26-4de3-9a2f-5d7ac35c7a99,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-1d09e471-cf4b-4a8b-8ff6-af36ed2a98ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-03a8d722-bf1a-4bd0-998f-9015e6825da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-ac515c77-452d-4165-896b-d2e75e6bb220,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-e0de8850-7b3f-4c34-b706-ca9ba7761155,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-eeaf40e1-3299-4d02-b39e-451a693026fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-a12c723e-9f19-4ffb-8723-3ab60e7e120b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614669870-172.17.0.10-1595702041802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43184,DS-46b5cb8f-5a6e-41ce-a0cf-868cbce567cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-2a135782-2b26-4de3-9a2f-5d7ac35c7a99,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-1d09e471-cf4b-4a8b-8ff6-af36ed2a98ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-03a8d722-bf1a-4bd0-998f-9015e6825da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-ac515c77-452d-4165-896b-d2e75e6bb220,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-e0de8850-7b3f-4c34-b706-ca9ba7761155,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-eeaf40e1-3299-4d02-b39e-451a693026fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-a12c723e-9f19-4ffb-8723-3ab60e7e120b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104007892-172.17.0.10-1595702263452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38671,DS-20f87127-7eee-4d26-9edd-89c95ce203bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-bacb9e45-9e5a-4613-89e2-26980b4d1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-938c5605-3d4c-41d6-9ecc-4300e427afa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-bf34869b-db2a-4f9e-84af-e4f3b71a430c,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-eaa80323-b956-4381-85fc-7ad02f9896b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-6decbc2d-e210-4406-8569-4c6dde9c88a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-fca2a57a-ce79-4d73-bbbf-015493c1653f,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-e8e91b32-5f73-4fc3-bce5-1b7136ddc54e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104007892-172.17.0.10-1595702263452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38671,DS-20f87127-7eee-4d26-9edd-89c95ce203bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-bacb9e45-9e5a-4613-89e2-26980b4d1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-938c5605-3d4c-41d6-9ecc-4300e427afa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-bf34869b-db2a-4f9e-84af-e4f3b71a430c,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-eaa80323-b956-4381-85fc-7ad02f9896b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-6decbc2d-e210-4406-8569-4c6dde9c88a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-fca2a57a-ce79-4d73-bbbf-015493c1653f,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-e8e91b32-5f73-4fc3-bce5-1b7136ddc54e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157824521-172.17.0.10-1595702514771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35826,DS-bcdc28b9-efc0-49da-a38b-46350dff5b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-797d3019-3748-42c8-afba-b888015ecfde,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-8943898d-5fe5-4a73-b6ec-8d03d7b616a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-dadc0873-9c18-4cf6-ae3b-e5bcd61d5eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-6f8fa437-1ee7-47fa-9833-72f5c92bcc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-bdc735ea-c628-49d7-8e3b-c6a530708f51,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-1d07423a-0457-45bc-a4df-492f0be4c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-05f33e89-f708-4245-bad9-c05b971e8a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157824521-172.17.0.10-1595702514771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35826,DS-bcdc28b9-efc0-49da-a38b-46350dff5b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-797d3019-3748-42c8-afba-b888015ecfde,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-8943898d-5fe5-4a73-b6ec-8d03d7b616a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-dadc0873-9c18-4cf6-ae3b-e5bcd61d5eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-6f8fa437-1ee7-47fa-9833-72f5c92bcc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-bdc735ea-c628-49d7-8e3b-c6a530708f51,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-1d07423a-0457-45bc-a4df-492f0be4c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-05f33e89-f708-4245-bad9-c05b971e8a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775704052-172.17.0.10-1595702838392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-e6c66f01-b288-4e7f-9b8c-391c2c90a379,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-137df1c7-390d-4626-8d62-ac9fd1b53b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-e24e1dc7-9a6f-41e0-be6b-854703231fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-b5a9117e-8574-4714-83e0-4c8f806053d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-888fc836-fbcd-4365-b2d2-2c17f411046b,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-f5baaee3-1a11-498c-8c51-c71a8ae3dbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-6ecd590f-69ce-4ca4-9c9a-c7b14c7b24b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-eb40b3d7-4209-4afe-9f85-ae9f9f3c794e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775704052-172.17.0.10-1595702838392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-e6c66f01-b288-4e7f-9b8c-391c2c90a379,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-137df1c7-390d-4626-8d62-ac9fd1b53b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-e24e1dc7-9a6f-41e0-be6b-854703231fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-b5a9117e-8574-4714-83e0-4c8f806053d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-888fc836-fbcd-4365-b2d2-2c17f411046b,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-f5baaee3-1a11-498c-8c51-c71a8ae3dbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-6ecd590f-69ce-4ca4-9c9a-c7b14c7b24b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-eb40b3d7-4209-4afe-9f85-ae9f9f3c794e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111394869-172.17.0.10-1595703373850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41712,DS-28bad684-901e-41d1-9680-9c3cc694d421,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-fec296c3-e620-457e-a002-6ccae8165271,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-55910bd5-ca49-4dd7-9f51-beeb0d411218,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-ce466300-872e-437b-ba25-dc0e562cc9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-de3f2592-9134-4fee-8322-167e1607066e,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-b8220785-da27-4f57-bb5c-571497717a22,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-609015a3-fd17-4b30-85be-41c91a1d1e33,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-9c951038-42d3-457d-aa5c-81061080c81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111394869-172.17.0.10-1595703373850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41712,DS-28bad684-901e-41d1-9680-9c3cc694d421,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-fec296c3-e620-457e-a002-6ccae8165271,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-55910bd5-ca49-4dd7-9f51-beeb0d411218,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-ce466300-872e-437b-ba25-dc0e562cc9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-de3f2592-9134-4fee-8322-167e1607066e,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-b8220785-da27-4f57-bb5c-571497717a22,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-609015a3-fd17-4b30-85be-41c91a1d1e33,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-9c951038-42d3-457d-aa5c-81061080c81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633965901-172.17.0.10-1595703762574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-70f0b735-0924-48b5-863d-2d0a30d0cab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-d84a3749-9b45-43e9-82ed-4fe147ed1ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-43505cbd-256e-44c7-9828-d93d0028e014,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-20eb4b95-0d13-4320-a7d5-7eba21ef6b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-e8ec4558-0e2b-4708-a33f-6c91d4de25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-cb64e4f6-603f-43ba-99bb-f2f1990ad8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-0f719953-7937-442b-bedd-6e59f96be83a,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-22291112-09f1-4879-a49e-5f98fefbda94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633965901-172.17.0.10-1595703762574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-70f0b735-0924-48b5-863d-2d0a30d0cab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-d84a3749-9b45-43e9-82ed-4fe147ed1ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-43505cbd-256e-44c7-9828-d93d0028e014,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-20eb4b95-0d13-4320-a7d5-7eba21ef6b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-e8ec4558-0e2b-4708-a33f-6c91d4de25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-cb64e4f6-603f-43ba-99bb-f2f1990ad8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-0f719953-7937-442b-bedd-6e59f96be83a,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-22291112-09f1-4879-a49e-5f98fefbda94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099160710-172.17.0.10-1595703915315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41085,DS-f51468d2-3e3e-4347-b9aa-01c590ab2329,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-b738c717-bbab-43a1-8acc-4341d1d3eae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-5d756b75-77a3-4679-bc80-145bdfc0f650,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-57352d66-8cc1-4e06-8c58-fcb450af2447,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-f1355fd5-c82c-4b96-a556-e41cdeb64d98,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-6f2aae08-d4eb-4ba9-8666-7dd3487aebb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-f016ea16-9bc8-4f31-85d0-7b5e68cb3f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-560d1001-9550-4a40-989c-196dc699066c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099160710-172.17.0.10-1595703915315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41085,DS-f51468d2-3e3e-4347-b9aa-01c590ab2329,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-b738c717-bbab-43a1-8acc-4341d1d3eae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-5d756b75-77a3-4679-bc80-145bdfc0f650,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-57352d66-8cc1-4e06-8c58-fcb450af2447,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-f1355fd5-c82c-4b96-a556-e41cdeb64d98,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-6f2aae08-d4eb-4ba9-8666-7dd3487aebb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-f016ea16-9bc8-4f31-85d0-7b5e68cb3f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-560d1001-9550-4a40-989c-196dc699066c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886039025-172.17.0.10-1595703992192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36543,DS-b42bfc37-2c47-477e-8cb5-84ccccc4e697,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-f18a29b4-f017-4e1f-8acf-c88f846991da,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-bc6c9627-1e54-4d1b-b91c-c7254520b80a,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-3995a1a5-c6e5-48a9-a02f-27888b090f37,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-8738ca89-3832-4e54-9cc1-00b980941ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-9fc0133e-e434-41c2-9c94-d7d44c13b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-66dd26ce-6bc3-4f67-9876-117ed4e17ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-afedd049-71d4-457a-a1bf-b578ccd48a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886039025-172.17.0.10-1595703992192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36543,DS-b42bfc37-2c47-477e-8cb5-84ccccc4e697,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-f18a29b4-f017-4e1f-8acf-c88f846991da,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-bc6c9627-1e54-4d1b-b91c-c7254520b80a,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-3995a1a5-c6e5-48a9-a02f-27888b090f37,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-8738ca89-3832-4e54-9cc1-00b980941ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-9fc0133e-e434-41c2-9c94-d7d44c13b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-66dd26ce-6bc3-4f67-9876-117ed4e17ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-afedd049-71d4-457a-a1bf-b578ccd48a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295985283-172.17.0.10-1595704264467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37769,DS-4c187732-900b-478c-a2da-cfc791daa400,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-8f12e098-436f-44b0-8d4d-4494158dde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-42d6bc3b-dfa4-4237-ba8f-6213c1d63879,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-43d79cdc-7995-4942-a13c-b37c3a8d55e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-ac7e5d81-321a-4444-a4f3-680b324af9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-a619fdb3-f5d9-48eb-b792-137400840a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-ed448657-08cd-456b-839f-100fa6eed9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-e2572d39-2c2b-4d07-8e15-b8ed77c9df7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295985283-172.17.0.10-1595704264467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37769,DS-4c187732-900b-478c-a2da-cfc791daa400,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-8f12e098-436f-44b0-8d4d-4494158dde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-42d6bc3b-dfa4-4237-ba8f-6213c1d63879,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-43d79cdc-7995-4942-a13c-b37c3a8d55e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-ac7e5d81-321a-4444-a4f3-680b324af9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-a619fdb3-f5d9-48eb-b792-137400840a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-ed448657-08cd-456b-839f-100fa6eed9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-e2572d39-2c2b-4d07-8e15-b8ed77c9df7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948184535-172.17.0.10-1595705055680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-9f5d48a3-93f8-4970-9154-7fd39745581d,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-cc101f32-c7de-4aaf-b6aa-08eab604012f,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-8dad7259-cad6-4804-a8a8-f701268a3160,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-3c46cb4c-7f5f-4803-93d6-afa5c0a0a232,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-249c7f91-e32f-4cac-932d-9e47731c22d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-9f34f658-ed3d-4894-8a30-5c1c89d5c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-9052b99d-faa2-4edc-830e-67a9814a5b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-86ee8664-b3bd-46ac-abec-9f45a64d863c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948184535-172.17.0.10-1595705055680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-9f5d48a3-93f8-4970-9154-7fd39745581d,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-cc101f32-c7de-4aaf-b6aa-08eab604012f,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-8dad7259-cad6-4804-a8a8-f701268a3160,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-3c46cb4c-7f5f-4803-93d6-afa5c0a0a232,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-249c7f91-e32f-4cac-932d-9e47731c22d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-9f34f658-ed3d-4894-8a30-5c1c89d5c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-9052b99d-faa2-4edc-830e-67a9814a5b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-86ee8664-b3bd-46ac-abec-9f45a64d863c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427506840-172.17.0.10-1595705485014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37442,DS-2127eeac-c626-4154-9446-7d2f7339cc97,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-cd052d11-8f5a-4191-b483-c95ce959eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-62e92155-ed32-4d2e-97d2-0a452fc37897,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-bef5abaf-1d5a-4fef-a8a7-6fbf30888fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-2b0b2954-1926-46eb-b713-88da37f7879e,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-6333e4b2-2252-4c9e-823e-dc0bdb57fa47,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-02a72972-7c73-4a90-9d04-48878b153e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-0b96f3d2-d643-46fc-943b-d4ad5cd1ffec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427506840-172.17.0.10-1595705485014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37442,DS-2127eeac-c626-4154-9446-7d2f7339cc97,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-cd052d11-8f5a-4191-b483-c95ce959eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-62e92155-ed32-4d2e-97d2-0a452fc37897,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-bef5abaf-1d5a-4fef-a8a7-6fbf30888fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-2b0b2954-1926-46eb-b713-88da37f7879e,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-6333e4b2-2252-4c9e-823e-dc0bdb57fa47,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-02a72972-7c73-4a90-9d04-48878b153e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-0b96f3d2-d643-46fc-943b-d4ad5cd1ffec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1024
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219913610-172.17.0.10-1595706168387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43099,DS-5847d214-8a70-44bd-99ea-9736602f88fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-0d36d501-d496-42c3-9783-6b86175d84b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-a8cd6a92-2627-451a-a04d-c301871e60d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-09360834-914a-4cd9-8663-f2d2857f87e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-7d205887-5180-4af9-857b-113d6ce91888,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-658406d1-4789-413b-9905-7919af91478f,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-1f672f8a-5ad6-4e24-a889-b2dffcf3493c,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-9e37eff7-ae6c-4d0d-9546-c41893e333a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219913610-172.17.0.10-1595706168387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43099,DS-5847d214-8a70-44bd-99ea-9736602f88fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-0d36d501-d496-42c3-9783-6b86175d84b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-a8cd6a92-2627-451a-a04d-c301871e60d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-09360834-914a-4cd9-8663-f2d2857f87e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-7d205887-5180-4af9-857b-113d6ce91888,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-658406d1-4789-413b-9905-7919af91478f,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-1f672f8a-5ad6-4e24-a889-b2dffcf3493c,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-9e37eff7-ae6c-4d0d-9546-c41893e333a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5438
