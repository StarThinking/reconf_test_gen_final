reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370081670-172.17.0.19-1595526458680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-13cf2a15-c04a-4d8f-8cd2-564fefb6dbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-5415df8d-4e72-43a6-98e3-8142924f89ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-e6490e40-cfaa-4f0f-98bb-4dde5dcd1456,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-bbe0ce94-76cf-4c8a-8afb-6b6589c4563d,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-d44fcb16-746c-4d00-b433-924308b2f063,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-bf0f6c4b-3a07-484f-84b5-1460114e06df,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-b9757d95-5852-41d7-8db7-6bc79d875fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-32683f34-bc43-4403-9cb9-c2b0454f1038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370081670-172.17.0.19-1595526458680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-13cf2a15-c04a-4d8f-8cd2-564fefb6dbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-5415df8d-4e72-43a6-98e3-8142924f89ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-e6490e40-cfaa-4f0f-98bb-4dde5dcd1456,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-bbe0ce94-76cf-4c8a-8afb-6b6589c4563d,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-d44fcb16-746c-4d00-b433-924308b2f063,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-bf0f6c4b-3a07-484f-84b5-1460114e06df,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-b9757d95-5852-41d7-8db7-6bc79d875fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-32683f34-bc43-4403-9cb9-c2b0454f1038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383988400-172.17.0.19-1595526560402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-a292a98a-a58d-41b1-b7fa-13862c8e7c14,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-66bba447-8af1-4b02-b4fb-9950e8b3f088,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-2e0c1a1c-b776-4166-8bd8-574311fa25de,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-54020014-1ca8-4204-9052-bb1e34a468e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-17d216e2-d49e-4ded-8830-c4e784881018,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-16f8770a-19e5-4fae-a1e8-fcf821a4b749,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-6d53d4a0-5dc1-455e-9902-e9084be25dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-19bbb368-b982-4aaa-ae9e-94abfc527a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383988400-172.17.0.19-1595526560402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-a292a98a-a58d-41b1-b7fa-13862c8e7c14,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-66bba447-8af1-4b02-b4fb-9950e8b3f088,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-2e0c1a1c-b776-4166-8bd8-574311fa25de,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-54020014-1ca8-4204-9052-bb1e34a468e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-17d216e2-d49e-4ded-8830-c4e784881018,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-16f8770a-19e5-4fae-a1e8-fcf821a4b749,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-6d53d4a0-5dc1-455e-9902-e9084be25dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-19bbb368-b982-4aaa-ae9e-94abfc527a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626614434-172.17.0.19-1595526819723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-947b430f-0011-415e-b52e-f1dcad5f61de,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-180c2edb-e493-454a-8886-3316858c9298,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-3f574a85-7539-4b76-a34f-b38510f79ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-39e0a331-2bc7-49c7-bbc9-bf11a93e6319,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-a58c9999-015d-45de-a4a4-344dfc53b405,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-06eecf42-30e1-40ca-9219-7095f703c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-cf1c5e48-994e-4171-b7e7-0040a45d0647,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-add4ada2-16d6-44a1-8c09-9efb8f167f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626614434-172.17.0.19-1595526819723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-947b430f-0011-415e-b52e-f1dcad5f61de,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-180c2edb-e493-454a-8886-3316858c9298,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-3f574a85-7539-4b76-a34f-b38510f79ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-39e0a331-2bc7-49c7-bbc9-bf11a93e6319,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-a58c9999-015d-45de-a4a4-344dfc53b405,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-06eecf42-30e1-40ca-9219-7095f703c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-cf1c5e48-994e-4171-b7e7-0040a45d0647,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-add4ada2-16d6-44a1-8c09-9efb8f167f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3125255-172.17.0.19-1595526926668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-30d349ca-1e5a-4f12-a258-892310525dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-febda6cf-6faf-437e-a90a-63f2e59d17f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-e8b93d06-bbd9-4e57-acae-f97e3db88a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-adcce617-435e-4ab1-9528-7f36eaf08f56,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-68233dd8-8e50-4221-b36d-b5fe4ebd8168,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-2c0e71a3-eaf2-49cc-aafc-56d790c899f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-dc3d16c8-0257-472d-84b4-e42af996ce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-6dbe1a71-24e2-448e-9f44-00d63b0eb2c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3125255-172.17.0.19-1595526926668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-30d349ca-1e5a-4f12-a258-892310525dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-febda6cf-6faf-437e-a90a-63f2e59d17f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-e8b93d06-bbd9-4e57-acae-f97e3db88a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-adcce617-435e-4ab1-9528-7f36eaf08f56,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-68233dd8-8e50-4221-b36d-b5fe4ebd8168,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-2c0e71a3-eaf2-49cc-aafc-56d790c899f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-dc3d16c8-0257-472d-84b4-e42af996ce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-6dbe1a71-24e2-448e-9f44-00d63b0eb2c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222191449-172.17.0.19-1595527028337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-4aca639f-c48f-4982-a3ed-60d1e67737fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-f9bafe7c-3b60-44f9-b957-711791e0dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-8c6f251d-b8f1-4006-9a83-d6f8e1a6edcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-cb5bc7f7-5ac1-4fb7-88c1-79ae1639136d,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-0a3bc865-174e-4e4b-b06e-6f1f9c03a532,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-40f8faa7-362c-497f-a5ba-933b59f53c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-ac80881c-c6c9-4d48-997d-2bf6436f6fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-1d0af2c1-f430-448c-be36-c1c8b658cde2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222191449-172.17.0.19-1595527028337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-4aca639f-c48f-4982-a3ed-60d1e67737fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-f9bafe7c-3b60-44f9-b957-711791e0dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-8c6f251d-b8f1-4006-9a83-d6f8e1a6edcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-cb5bc7f7-5ac1-4fb7-88c1-79ae1639136d,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-0a3bc865-174e-4e4b-b06e-6f1f9c03a532,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-40f8faa7-362c-497f-a5ba-933b59f53c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-ac80881c-c6c9-4d48-997d-2bf6436f6fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-1d0af2c1-f430-448c-be36-c1c8b658cde2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462374659-172.17.0.19-1595527360221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39084,DS-4c2ea300-1376-44bc-a1ea-475c0c655821,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-941e7663-1535-4205-9e0f-7112e0678183,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-b659b7fa-4a51-4e62-b26f-b62b46a35409,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-aee254e1-485f-481c-abdd-3ec9581c4998,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-4dd6b212-2723-4720-a8e1-a2bbf6daeb34,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-f8bedcd4-fc0f-4597-b4fc-c4ccaba705e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-33b57a7e-54a1-4ac2-8c8b-f773e8f07b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-58f1e496-037b-4fe6-afbf-61b210430cf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462374659-172.17.0.19-1595527360221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39084,DS-4c2ea300-1376-44bc-a1ea-475c0c655821,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-941e7663-1535-4205-9e0f-7112e0678183,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-b659b7fa-4a51-4e62-b26f-b62b46a35409,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-aee254e1-485f-481c-abdd-3ec9581c4998,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-4dd6b212-2723-4720-a8e1-a2bbf6daeb34,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-f8bedcd4-fc0f-4597-b4fc-c4ccaba705e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-33b57a7e-54a1-4ac2-8c8b-f773e8f07b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-58f1e496-037b-4fe6-afbf-61b210430cf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877800053-172.17.0.19-1595527469746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43920,DS-4dc610bd-b525-4fc6-be50-69c63014e1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-961fe489-9c49-4419-9aa7-9323bb972e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-28a550be-da49-40fe-ade6-3876ce60ce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-f79635b1-3d64-421b-9020-de532dbf1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-d7bc3b43-fa21-4aa8-a81e-b76f6653f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-9f6dad9b-cb95-4062-b30c-fe1221b37e26,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-5874e925-5b33-41c4-9750-12440e973599,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-1ab129ed-a035-4425-89bf-0b44ac487332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877800053-172.17.0.19-1595527469746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43920,DS-4dc610bd-b525-4fc6-be50-69c63014e1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-961fe489-9c49-4419-9aa7-9323bb972e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-28a550be-da49-40fe-ade6-3876ce60ce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-f79635b1-3d64-421b-9020-de532dbf1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-d7bc3b43-fa21-4aa8-a81e-b76f6653f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-9f6dad9b-cb95-4062-b30c-fe1221b37e26,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-5874e925-5b33-41c4-9750-12440e973599,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-1ab129ed-a035-4425-89bf-0b44ac487332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493204680-172.17.0.19-1595527650762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-543664ca-a7d8-417c-8592-b059e3d83826,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-8eebb65b-cded-4dc1-9bdd-deb9f7afffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-2443b17f-75ec-4abd-9589-6c7dfbc6b997,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-4f20bc26-b6e3-467a-ac4e-23517c217a48,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-4ae4c591-eecd-4b91-bc11-7f43a9a37759,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-5944b761-007b-4fbd-a253-253c322ac1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-3d86251f-8063-4a25-a97a-3ac992715797,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-9511206c-5d31-4d1d-ab69-1c92fd24397b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493204680-172.17.0.19-1595527650762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-543664ca-a7d8-417c-8592-b059e3d83826,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-8eebb65b-cded-4dc1-9bdd-deb9f7afffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-2443b17f-75ec-4abd-9589-6c7dfbc6b997,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-4f20bc26-b6e3-467a-ac4e-23517c217a48,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-4ae4c591-eecd-4b91-bc11-7f43a9a37759,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-5944b761-007b-4fbd-a253-253c322ac1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-3d86251f-8063-4a25-a97a-3ac992715797,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-9511206c-5d31-4d1d-ab69-1c92fd24397b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786019198-172.17.0.19-1595527716994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38453,DS-89df8abd-f6f4-494d-b705-ec0896c14cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-fa34bf06-770a-4424-bdcf-47afc9e91c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-740e9864-6240-4572-b9d9-a984b82cb081,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-2fe99bc2-30bd-45c2-92ff-e254ea0f0bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-69110c2b-4267-47f3-b9e1-0ab19400f41c,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-86410db6-1ac6-4b73-ae1d-245c425d256f,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-5f114196-2dad-471c-b69e-b5ba23ade02c,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-d4532e02-2f9c-43fc-abf3-ca342f77f38a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786019198-172.17.0.19-1595527716994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38453,DS-89df8abd-f6f4-494d-b705-ec0896c14cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-fa34bf06-770a-4424-bdcf-47afc9e91c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-740e9864-6240-4572-b9d9-a984b82cb081,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-2fe99bc2-30bd-45c2-92ff-e254ea0f0bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-69110c2b-4267-47f3-b9e1-0ab19400f41c,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-86410db6-1ac6-4b73-ae1d-245c425d256f,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-5f114196-2dad-471c-b69e-b5ba23ade02c,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-d4532e02-2f9c-43fc-abf3-ca342f77f38a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548304812-172.17.0.19-1595527793447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-ca2d0c5a-eaed-4775-b513-9be35ec35d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-d01d8525-6740-4db2-843e-a6fe95dc40ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-c748d5c4-c883-4e29-bf44-19fbf663df7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-90894af1-daf3-4f15-a2b1-8e908bd62bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-b501bd64-f206-474e-9031-63e078ec8f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-2a7584eb-d386-4d95-88e2-b322928903c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-cea0ad5b-9e45-4728-b01a-515d3508e751,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-7e550f43-903c-4014-94f6-724d925b8d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548304812-172.17.0.19-1595527793447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-ca2d0c5a-eaed-4775-b513-9be35ec35d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-d01d8525-6740-4db2-843e-a6fe95dc40ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-c748d5c4-c883-4e29-bf44-19fbf663df7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-90894af1-daf3-4f15-a2b1-8e908bd62bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-b501bd64-f206-474e-9031-63e078ec8f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-2a7584eb-d386-4d95-88e2-b322928903c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-cea0ad5b-9e45-4728-b01a-515d3508e751,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-7e550f43-903c-4014-94f6-724d925b8d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440431807-172.17.0.19-1595527865249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-8816716f-a35b-4e6b-a1c4-d1f8b9e94ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-83f63b58-0608-4abe-81ef-6e9d1ae62bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-0dc34307-3e0d-4efc-8ecc-24e3fc09ff56,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-cac5bcbb-d8b5-4273-8036-f931dd53fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-63bc4fe3-bece-4342-9362-55a32592d0be,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-3d969afa-fece-41f6-bb63-88db303c3510,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-5ac44505-331e-49ee-96d1-7941400d62c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-dfd87e23-7533-4e76-9f07-c1a6ecd8443f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440431807-172.17.0.19-1595527865249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-8816716f-a35b-4e6b-a1c4-d1f8b9e94ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-83f63b58-0608-4abe-81ef-6e9d1ae62bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-0dc34307-3e0d-4efc-8ecc-24e3fc09ff56,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-cac5bcbb-d8b5-4273-8036-f931dd53fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-63bc4fe3-bece-4342-9362-55a32592d0be,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-3d969afa-fece-41f6-bb63-88db303c3510,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-5ac44505-331e-49ee-96d1-7941400d62c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-dfd87e23-7533-4e76-9f07-c1a6ecd8443f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675763382-172.17.0.19-1595528058791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32783,DS-3ba5b594-58d3-4041-9b7b-710069b46301,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-fa83b374-4746-4bb2-943a-e3b37fd28115,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-099888e8-f6bd-47a2-9b74-2f37182de21a,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-b3e949de-42d3-4fa1-a033-0b6b40467fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-bd146429-8d43-4321-b25a-1633c477e399,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-568a4b9b-f1de-4e75-b4f2-15781f1fac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-02d8ffa6-51e6-4861-aa7b-e80dd86f1c14,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-1f31d08d-108f-4244-8b07-18fb5a1f8d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675763382-172.17.0.19-1595528058791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32783,DS-3ba5b594-58d3-4041-9b7b-710069b46301,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-fa83b374-4746-4bb2-943a-e3b37fd28115,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-099888e8-f6bd-47a2-9b74-2f37182de21a,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-b3e949de-42d3-4fa1-a033-0b6b40467fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-bd146429-8d43-4321-b25a-1633c477e399,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-568a4b9b-f1de-4e75-b4f2-15781f1fac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-02d8ffa6-51e6-4861-aa7b-e80dd86f1c14,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-1f31d08d-108f-4244-8b07-18fb5a1f8d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763987208-172.17.0.19-1595528291723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-a301683b-0759-49c6-b936-19befc2ee69a,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-3f25d130-bd7f-4f7d-baff-5fec59b0b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-6d78dcf3-bc07-47f9-af75-f4d4d8fbbb33,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-a874ec24-7f19-4ac9-b09f-302e7b901ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-30fd75e4-b5c2-491e-83b2-bc518ebebde5,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-5fcba44d-d464-4df6-a975-9b94588803e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-a89ddf48-61b3-48ca-8ad7-83d388720740,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-c059cbfe-478f-4ab1-8388-034e0ec9bc47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763987208-172.17.0.19-1595528291723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-a301683b-0759-49c6-b936-19befc2ee69a,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-3f25d130-bd7f-4f7d-baff-5fec59b0b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-6d78dcf3-bc07-47f9-af75-f4d4d8fbbb33,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-a874ec24-7f19-4ac9-b09f-302e7b901ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-30fd75e4-b5c2-491e-83b2-bc518ebebde5,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-5fcba44d-d464-4df6-a975-9b94588803e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-a89ddf48-61b3-48ca-8ad7-83d388720740,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-c059cbfe-478f-4ab1-8388-034e0ec9bc47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392158488-172.17.0.19-1595528361689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34136,DS-1eb96f78-49f2-48ee-8e0a-dd67e6731dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-9f47b8a5-dde3-4c44-99cc-f2e96899bf59,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-89a9a43c-efb4-46e1-b135-8264580b2df8,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-0b16ebea-badf-4141-9a67-cf3a5264df79,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-e695fdc1-6133-4135-b662-56cc65e3f88b,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-87b008b8-4049-4e76-b526-22bcfa683f58,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-bb7f566f-7d1d-43fc-9b34-56515aa267ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-e3a4dd03-866d-4f52-8982-56d1c8022242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392158488-172.17.0.19-1595528361689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34136,DS-1eb96f78-49f2-48ee-8e0a-dd67e6731dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-9f47b8a5-dde3-4c44-99cc-f2e96899bf59,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-89a9a43c-efb4-46e1-b135-8264580b2df8,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-0b16ebea-badf-4141-9a67-cf3a5264df79,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-e695fdc1-6133-4135-b662-56cc65e3f88b,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-87b008b8-4049-4e76-b526-22bcfa683f58,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-bb7f566f-7d1d-43fc-9b34-56515aa267ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-e3a4dd03-866d-4f52-8982-56d1c8022242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703615832-172.17.0.19-1595528832525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35253,DS-7a611c45-6d9f-4a19-a1d8-789a1a20466a,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-93c57e8f-c45a-49f4-85cd-df3568437a57,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-a6d4a34b-97cf-40c1-a279-4949d59ac8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-eb828239-1f8f-4cfc-b892-d24fdc40de72,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-4678669f-5577-4acc-8a11-62a98d0d0c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-8d66fbc2-e159-418e-9111-bc6be673f992,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-79b8b1a1-2fa5-4b8f-b3ec-4b30cd1f4139,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-6c6e844d-b1c9-4e4d-992a-534230bc9d44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703615832-172.17.0.19-1595528832525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35253,DS-7a611c45-6d9f-4a19-a1d8-789a1a20466a,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-93c57e8f-c45a-49f4-85cd-df3568437a57,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-a6d4a34b-97cf-40c1-a279-4949d59ac8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-eb828239-1f8f-4cfc-b892-d24fdc40de72,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-4678669f-5577-4acc-8a11-62a98d0d0c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-8d66fbc2-e159-418e-9111-bc6be673f992,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-79b8b1a1-2fa5-4b8f-b3ec-4b30cd1f4139,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-6c6e844d-b1c9-4e4d-992a-534230bc9d44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056172922-172.17.0.19-1595529076193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-6766bf1d-5bb1-4975-b196-a2c522494a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-d06324fa-85bb-41c3-89a5-b7b10427c8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-1f72432c-bfde-423c-9bb7-04a4d98dc298,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-96213afe-c76d-4a2d-8e46-19659c0ff1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-75e2d31e-fd4b-492f-942a-9aedf13a6576,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-1879c936-7c69-4f60-b590-4e42065dd76a,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-bcdd7453-08a7-43d5-8a5b-e9079d1032aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-d2eb7067-a6f2-498e-abf9-aed38ffd74ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056172922-172.17.0.19-1595529076193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-6766bf1d-5bb1-4975-b196-a2c522494a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-d06324fa-85bb-41c3-89a5-b7b10427c8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-1f72432c-bfde-423c-9bb7-04a4d98dc298,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-96213afe-c76d-4a2d-8e46-19659c0ff1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-75e2d31e-fd4b-492f-942a-9aedf13a6576,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-1879c936-7c69-4f60-b590-4e42065dd76a,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-bcdd7453-08a7-43d5-8a5b-e9079d1032aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-d2eb7067-a6f2-498e-abf9-aed38ffd74ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303994666-172.17.0.19-1595529371729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33963,DS-55410db2-ed83-4c79-b35a-1ced457d4420,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-540b12c3-847f-4e0b-bf82-629b805ba0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-ab32c3a8-c7e5-4208-a61e-67234479c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-98922a4d-d867-413d-85f6-17d004378cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-631ddbc4-fc0c-4d73-8731-3accdb056b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-16c176eb-a8ca-4e24-a1b3-03503220cf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-50e1b454-1103-4cb5-88f4-9e5aec5ebd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-31d1ec12-17d6-4a7a-8d01-1b020b215091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303994666-172.17.0.19-1595529371729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33963,DS-55410db2-ed83-4c79-b35a-1ced457d4420,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-540b12c3-847f-4e0b-bf82-629b805ba0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-ab32c3a8-c7e5-4208-a61e-67234479c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-98922a4d-d867-413d-85f6-17d004378cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-631ddbc4-fc0c-4d73-8731-3accdb056b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-16c176eb-a8ca-4e24-a1b3-03503220cf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-50e1b454-1103-4cb5-88f4-9e5aec5ebd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-31d1ec12-17d6-4a7a-8d01-1b020b215091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443817396-172.17.0.19-1595529433150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-8bddba7e-ef2b-4f60-aabb-4ad06e2983f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-63d0a003-e7e1-4d23-b333-c64451dec5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-a30a141e-b475-47ac-938a-b63fbe47092b,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-4533ab60-5f07-46e0-b6b6-56d6a99e94ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-858845a0-9f83-4e08-a7d5-060f54797607,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-bb2b7b4d-b68a-41c2-9ef8-7eac407ca1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-91dd2631-362b-4dcc-ba7c-0610306bc2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-eb8f07d6-502b-4be6-9869-768c60875542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443817396-172.17.0.19-1595529433150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-8bddba7e-ef2b-4f60-aabb-4ad06e2983f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-63d0a003-e7e1-4d23-b333-c64451dec5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-a30a141e-b475-47ac-938a-b63fbe47092b,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-4533ab60-5f07-46e0-b6b6-56d6a99e94ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-858845a0-9f83-4e08-a7d5-060f54797607,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-bb2b7b4d-b68a-41c2-9ef8-7eac407ca1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-91dd2631-362b-4dcc-ba7c-0610306bc2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-eb8f07d6-502b-4be6-9869-768c60875542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139036913-172.17.0.19-1595529797275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40018,DS-14d0bbb6-a2d8-4104-83fd-3c11a8a45059,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-47cfb97c-e2fd-427d-ae3b-23087651f7db,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-e4caa6fe-8d26-44cb-8b74-06b10198c7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-c50f000e-3ae3-479d-bc81-57fa37ba2448,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-c1d089b4-ef7a-4e52-9173-f4bd21a2bede,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-69d4aef5-732b-4079-96db-3ab386491259,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-e303d67e-efc9-40cc-b3a6-33137b71a707,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-3fe72363-190f-4796-82e3-17e9f0638ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139036913-172.17.0.19-1595529797275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40018,DS-14d0bbb6-a2d8-4104-83fd-3c11a8a45059,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-47cfb97c-e2fd-427d-ae3b-23087651f7db,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-e4caa6fe-8d26-44cb-8b74-06b10198c7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-c50f000e-3ae3-479d-bc81-57fa37ba2448,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-c1d089b4-ef7a-4e52-9173-f4bd21a2bede,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-69d4aef5-732b-4079-96db-3ab386491259,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-e303d67e-efc9-40cc-b3a6-33137b71a707,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-3fe72363-190f-4796-82e3-17e9f0638ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472211476-172.17.0.19-1595529841776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-b9848f3f-3289-4cf5-8e11-ebe96b7473b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-424eebb8-8390-45f3-b70a-7e71ced47b88,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-790e52d5-38ee-43ba-8e7d-62c621d8690b,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-f6784979-d144-40f3-b73b-2754d24ba4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-5e55ab95-3582-4223-8505-37984eb496ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-2c0c60bf-d732-4fc9-9c72-3d3ceec787e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-037e2332-855a-4fe6-8701-d0327cdd78f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-86b7413f-e25a-49fb-8dba-d884e45b3b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472211476-172.17.0.19-1595529841776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-b9848f3f-3289-4cf5-8e11-ebe96b7473b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-424eebb8-8390-45f3-b70a-7e71ced47b88,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-790e52d5-38ee-43ba-8e7d-62c621d8690b,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-f6784979-d144-40f3-b73b-2754d24ba4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-5e55ab95-3582-4223-8505-37984eb496ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-2c0c60bf-d732-4fc9-9c72-3d3ceec787e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-037e2332-855a-4fe6-8701-d0327cdd78f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-86b7413f-e25a-49fb-8dba-d884e45b3b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149792606-172.17.0.19-1595530150688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36307,DS-35bca4d8-99aa-478d-aeb5-afca96004437,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-4f30307a-d2ca-4417-9e27-131e6e24ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-23aa620b-3cc8-4ab4-bd77-285cd019693e,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-47b2f219-4fd9-4bcb-bd86-c77ad7fa1c91,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-5b0a7e32-5425-4661-a81b-520a200e88af,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-559186aa-df59-41e4-a7ad-aa5218d758ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-428cc25a-f8dd-481b-b40a-90403caf4858,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-ebb6ee9f-dbe8-4a16-8c91-62b3003d7243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149792606-172.17.0.19-1595530150688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36307,DS-35bca4d8-99aa-478d-aeb5-afca96004437,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-4f30307a-d2ca-4417-9e27-131e6e24ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-23aa620b-3cc8-4ab4-bd77-285cd019693e,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-47b2f219-4fd9-4bcb-bd86-c77ad7fa1c91,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-5b0a7e32-5425-4661-a81b-520a200e88af,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-559186aa-df59-41e4-a7ad-aa5218d758ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-428cc25a-f8dd-481b-b40a-90403caf4858,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-ebb6ee9f-dbe8-4a16-8c91-62b3003d7243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214273619-172.17.0.19-1595530403119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-45673351-8069-40c2-909a-94305bbf1480,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-8416ce69-bf38-429c-98e2-3e5f12c8cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-6e88eb66-f96d-4cf1-b2a1-3985b9239ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-cfefdb82-77e7-42ff-bdcb-51f030ee5420,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-f3e83459-7ff9-4f19-8b50-c731a55f214e,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-b3c49c9f-7c2a-49ea-ad9f-7191b7645a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-3cb368dd-b53f-4e20-b228-d4ff3f700332,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-cffb349b-f252-4902-a335-e5d15444bf65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214273619-172.17.0.19-1595530403119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-45673351-8069-40c2-909a-94305bbf1480,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-8416ce69-bf38-429c-98e2-3e5f12c8cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-6e88eb66-f96d-4cf1-b2a1-3985b9239ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-cfefdb82-77e7-42ff-bdcb-51f030ee5420,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-f3e83459-7ff9-4f19-8b50-c731a55f214e,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-b3c49c9f-7c2a-49ea-ad9f-7191b7645a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-3cb368dd-b53f-4e20-b228-d4ff3f700332,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-cffb349b-f252-4902-a335-e5d15444bf65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925732837-172.17.0.19-1595530437259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-658936fc-6d53-46b0-92eb-1b8d653865d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-6461e92e-ee30-44b3-b958-dabcc3bdf551,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-6880dbca-7fed-4640-aeb4-b02d41b9c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-7a82aa22-37e4-42ad-a1c1-0c97ae7b16a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-195614f4-3757-4a48-9808-c6eb8001efa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-69ae90b8-bb6f-47da-986d-dfb593a18e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-bfb4289d-28c7-42e5-a4c2-3f631baa0a66,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-df63adb4-9baf-4ad3-9891-31b402b4c3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925732837-172.17.0.19-1595530437259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-658936fc-6d53-46b0-92eb-1b8d653865d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-6461e92e-ee30-44b3-b958-dabcc3bdf551,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-6880dbca-7fed-4640-aeb4-b02d41b9c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-7a82aa22-37e4-42ad-a1c1-0c97ae7b16a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-195614f4-3757-4a48-9808-c6eb8001efa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-69ae90b8-bb6f-47da-986d-dfb593a18e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-bfb4289d-28c7-42e5-a4c2-3f631baa0a66,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-df63adb4-9baf-4ad3-9891-31b402b4c3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773517803-172.17.0.19-1595530658851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-cf37a867-3956-491f-94ea-398b27c1a376,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-0dcb2994-ac1d-4dc7-9ea7-f036c62f6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-ffaa9dea-1ae5-47f4-8064-55c2ed88cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-43a1f680-7535-47ed-8853-fca207912640,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-aaec8b03-26ef-49aa-a631-525eb0fdce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-dfb60409-f6b2-46f9-a0b8-05ce8cebc09f,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-2d3d1c63-3441-4ebd-b8b7-a33d6ac134f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-de8db2ad-3485-43ab-b22a-0880bc61701b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773517803-172.17.0.19-1595530658851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-cf37a867-3956-491f-94ea-398b27c1a376,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-0dcb2994-ac1d-4dc7-9ea7-f036c62f6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-ffaa9dea-1ae5-47f4-8064-55c2ed88cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-43a1f680-7535-47ed-8853-fca207912640,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-aaec8b03-26ef-49aa-a631-525eb0fdce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-dfb60409-f6b2-46f9-a0b8-05ce8cebc09f,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-2d3d1c63-3441-4ebd-b8b7-a33d6ac134f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-de8db2ad-3485-43ab-b22a-0880bc61701b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225443719-172.17.0.19-1595530796526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-794caa48-79bf-4df3-9b70-9098ee883cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-8f52fd9a-ae51-42b0-a09e-9013637cfb34,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-ffb5c763-4825-4f00-9fae-465c6f8aa430,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-5e689259-74b9-4889-a104-14a89622f575,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-21f687d6-6dfd-4a49-a79a-6f81ec8b744c,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-42c2b090-f105-4183-a09c-3be163958516,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-ee51bae2-3280-40a1-b7fc-0e952c5798a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-29acca6d-e412-495f-a735-f3e2937aca9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225443719-172.17.0.19-1595530796526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-794caa48-79bf-4df3-9b70-9098ee883cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-8f52fd9a-ae51-42b0-a09e-9013637cfb34,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-ffb5c763-4825-4f00-9fae-465c6f8aa430,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-5e689259-74b9-4889-a104-14a89622f575,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-21f687d6-6dfd-4a49-a79a-6f81ec8b744c,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-42c2b090-f105-4183-a09c-3be163958516,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-ee51bae2-3280-40a1-b7fc-0e952c5798a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-29acca6d-e412-495f-a735-f3e2937aca9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696017319-172.17.0.19-1595531252062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-5cfab431-706e-4c40-af53-7bbdd5a8e234,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-79df4250-fedb-494e-9186-c63fb3300c43,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-0b6d7f15-7ae3-48e1-bb7e-8d03e9684ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-7bf31d27-2ab5-4c31-9d27-946e1aae2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-99709308-8c89-434d-be1a-caeb657b8864,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-eefeb3ad-40e9-4695-9eca-3b5349a6b57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-0d4da50e-509a-431f-a000-b3dfd414759c,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-6a20f006-5908-41d7-8cbd-b23e2ef56281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696017319-172.17.0.19-1595531252062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-5cfab431-706e-4c40-af53-7bbdd5a8e234,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-79df4250-fedb-494e-9186-c63fb3300c43,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-0b6d7f15-7ae3-48e1-bb7e-8d03e9684ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-7bf31d27-2ab5-4c31-9d27-946e1aae2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-99709308-8c89-434d-be1a-caeb657b8864,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-eefeb3ad-40e9-4695-9eca-3b5349a6b57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-0d4da50e-509a-431f-a000-b3dfd414759c,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-6a20f006-5908-41d7-8cbd-b23e2ef56281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417871413-172.17.0.19-1595531360647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45179,DS-6dbefa5e-b9f5-4320-b9f3-6c3b1697be9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-8219d3a4-6daa-44e5-a5ea-69900d9ffd55,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-cef0f2d3-f231-4f8b-a6f9-30d2adce0a67,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-c7b18d68-41a1-4084-b6af-14f366fb3eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-16212c31-4386-4865-8b21-018665438bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-26278ec6-5e75-4d63-bb13-1a54303487af,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-3369590a-d74c-4a12-aa10-087fc7f46e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-3f7c890f-6458-46b2-9b90-9d4af393f673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417871413-172.17.0.19-1595531360647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45179,DS-6dbefa5e-b9f5-4320-b9f3-6c3b1697be9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-8219d3a4-6daa-44e5-a5ea-69900d9ffd55,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-cef0f2d3-f231-4f8b-a6f9-30d2adce0a67,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-c7b18d68-41a1-4084-b6af-14f366fb3eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-16212c31-4386-4865-8b21-018665438bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-26278ec6-5e75-4d63-bb13-1a54303487af,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-3369590a-d74c-4a12-aa10-087fc7f46e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-3f7c890f-6458-46b2-9b90-9d4af393f673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390644875-172.17.0.19-1595531514465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-2518bf58-004b-4c46-baa0-bb7043c14659,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-3e286ed2-1ba1-4fac-8d4b-2fd678e8dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-3d541576-a4df-4c9d-8476-5de6f15c843d,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-5efa1390-826f-4ace-98ef-46c09125c838,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-08f5f5ab-a8f4-4600-840a-9ce52a55c7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-a66c7aaa-18b4-4a6b-8b24-5a3e9213216f,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-2948efbe-f2f0-410a-821f-573418df9b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-d4f684ec-d981-48a3-9d17-32a92ebc9807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390644875-172.17.0.19-1595531514465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-2518bf58-004b-4c46-baa0-bb7043c14659,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-3e286ed2-1ba1-4fac-8d4b-2fd678e8dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-3d541576-a4df-4c9d-8476-5de6f15c843d,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-5efa1390-826f-4ace-98ef-46c09125c838,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-08f5f5ab-a8f4-4600-840a-9ce52a55c7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-a66c7aaa-18b4-4a6b-8b24-5a3e9213216f,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-2948efbe-f2f0-410a-821f-573418df9b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-d4f684ec-d981-48a3-9d17-32a92ebc9807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751829672-172.17.0.19-1595531593618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41499,DS-45bcbe3d-5d1a-4fe7-a9ae-2a1ae6bb1498,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-c931dc5e-7872-4d13-a706-91bccce07eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-c7c884bc-48af-46cd-936c-f9cf8c709e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-87b829f9-849b-4620-96f8-40127930e196,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-0ed1c4eb-9ee7-47c7-9d65-5982abdd4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-f6c5b65a-850f-4ffc-a7e2-7fc21a9549e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-56a55b1b-6ae6-40c2-8e01-2097c7a9be82,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-ee27cbbd-632b-438b-8aef-aa3836e5033a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751829672-172.17.0.19-1595531593618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41499,DS-45bcbe3d-5d1a-4fe7-a9ae-2a1ae6bb1498,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-c931dc5e-7872-4d13-a706-91bccce07eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-c7c884bc-48af-46cd-936c-f9cf8c709e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-87b829f9-849b-4620-96f8-40127930e196,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-0ed1c4eb-9ee7-47c7-9d65-5982abdd4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-f6c5b65a-850f-4ffc-a7e2-7fc21a9549e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-56a55b1b-6ae6-40c2-8e01-2097c7a9be82,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-ee27cbbd-632b-438b-8aef-aa3836e5033a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.interval-ms.get-last-block-length
component: hdfs:NameNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333265555-172.17.0.19-1595531706979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36081,DS-3e58d014-06a0-4d38-ab4a-de43602f557e,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-e307ca95-45d4-434a-b87b-c03b009fcc12,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-ca88671a-3a36-4afc-9205-9eef36bf823a,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-2a7a31b9-70e3-4d27-9e9a-5375e921cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-5568824e-5fb6-413b-beb7-344420417f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-2e5d5c3c-6b60-4ca1-8443-b340c3ccd425,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-0a3fa736-31f7-4a9e-a292-1bf185c4f67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-9bc15ae3-498f-4e0a-bf4b-ef3dd358ddac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333265555-172.17.0.19-1595531706979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36081,DS-3e58d014-06a0-4d38-ab4a-de43602f557e,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-e307ca95-45d4-434a-b87b-c03b009fcc12,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-ca88671a-3a36-4afc-9205-9eef36bf823a,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-2a7a31b9-70e3-4d27-9e9a-5375e921cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-5568824e-5fb6-413b-beb7-344420417f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-2e5d5c3c-6b60-4ca1-8443-b340c3ccd425,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-0a3fa736-31f7-4a9e-a292-1bf185c4f67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-9bc15ae3-498f-4e0a-bf4b-ef3dd358ddac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5480
