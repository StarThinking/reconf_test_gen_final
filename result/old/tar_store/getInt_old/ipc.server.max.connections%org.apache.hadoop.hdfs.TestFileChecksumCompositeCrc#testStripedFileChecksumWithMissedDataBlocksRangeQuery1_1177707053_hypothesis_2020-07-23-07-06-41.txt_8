reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155678370-172.17.0.11-1595488461742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-4d7afd48-9f6c-46b7-a2c9-7ee8e089138e,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-9dd7db0d-6d3d-47ad-8348-ff6b793e62a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-25623b9e-813e-4014-904a-9f99b0eff26c,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-fa1196ad-622f-4f66-bc4a-8dc10d90fc35,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-d1efdfeb-4d37-4d09-afd3-82638ea6c337,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-d11fc93b-730d-4b15-bef9-e223a1e6344d,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-27163ad0-abca-438e-8141-237300d6d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-c138f678-2506-4c30-8826-bdd027ea2afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155678370-172.17.0.11-1595488461742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-4d7afd48-9f6c-46b7-a2c9-7ee8e089138e,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-9dd7db0d-6d3d-47ad-8348-ff6b793e62a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-25623b9e-813e-4014-904a-9f99b0eff26c,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-fa1196ad-622f-4f66-bc4a-8dc10d90fc35,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-d1efdfeb-4d37-4d09-afd3-82638ea6c337,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-d11fc93b-730d-4b15-bef9-e223a1e6344d,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-27163ad0-abca-438e-8141-237300d6d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-c138f678-2506-4c30-8826-bdd027ea2afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66052243-172.17.0.11-1595488993207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40769,DS-ea1c1c3e-a9ec-40e5-81f6-fb3d39546864,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-03adf372-e818-4c77-8248-179e34cd8140,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-1b343262-5cfb-44cc-a874-b9a69d168e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-0a2b9c4e-e09c-4fab-8614-9cc9ce879591,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-86c4f154-479e-4915-acc2-9d6a56c7b5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-738d529c-4fd8-4258-9f48-a9a21b4fce23,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-056f0212-394b-4ed8-9cd4-4bba5032345b,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-13a0497e-f696-40a8-992d-2d547f9bd42f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66052243-172.17.0.11-1595488993207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40769,DS-ea1c1c3e-a9ec-40e5-81f6-fb3d39546864,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-03adf372-e818-4c77-8248-179e34cd8140,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-1b343262-5cfb-44cc-a874-b9a69d168e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-0a2b9c4e-e09c-4fab-8614-9cc9ce879591,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-86c4f154-479e-4915-acc2-9d6a56c7b5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-738d529c-4fd8-4258-9f48-a9a21b4fce23,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-056f0212-394b-4ed8-9cd4-4bba5032345b,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-13a0497e-f696-40a8-992d-2d547f9bd42f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519891961-172.17.0.11-1595489061582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44399,DS-b988f328-5ce4-4be1-b56b-bca7f56522b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-4575ecb7-1e3e-495a-9c89-88a8a5d2c580,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-bca77887-07a9-4314-bd84-c1ff91220eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-5f009f13-fe76-4cea-b299-b1d20855bff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-4ee59033-735d-4887-a21c-4a02ae3dc368,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-e00b6427-ce32-4239-9789-82c1eeb780e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-663b6842-a54f-47e0-bc9e-b67dfa00644a,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-893d9ca6-1ba4-44fb-9950-1652b6ccb3a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519891961-172.17.0.11-1595489061582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44399,DS-b988f328-5ce4-4be1-b56b-bca7f56522b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-4575ecb7-1e3e-495a-9c89-88a8a5d2c580,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-bca77887-07a9-4314-bd84-c1ff91220eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-5f009f13-fe76-4cea-b299-b1d20855bff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-4ee59033-735d-4887-a21c-4a02ae3dc368,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-e00b6427-ce32-4239-9789-82c1eeb780e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-663b6842-a54f-47e0-bc9e-b67dfa00644a,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-893d9ca6-1ba4-44fb-9950-1652b6ccb3a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276075022-172.17.0.11-1595489093810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45957,DS-9e385f1c-c8f6-483d-8043-4722217e5e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-d58d8311-d52f-4a87-a801-57a9273111c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-ed7f118e-2bc1-414c-b6ba-0d576a699de1,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-cac8f331-1835-4bc5-91f4-1120ca9e1ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-037e9b0a-546a-48ab-bdb6-2754100ba3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-1604b0a2-c638-41ec-ae7d-ae4e7d65d5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-0061073f-1967-4cf1-9070-475a567fb308,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-282e2d96-9eeb-4795-9d12-c2f715661b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276075022-172.17.0.11-1595489093810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45957,DS-9e385f1c-c8f6-483d-8043-4722217e5e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-d58d8311-d52f-4a87-a801-57a9273111c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-ed7f118e-2bc1-414c-b6ba-0d576a699de1,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-cac8f331-1835-4bc5-91f4-1120ca9e1ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-037e9b0a-546a-48ab-bdb6-2754100ba3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-1604b0a2-c638-41ec-ae7d-ae4e7d65d5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-0061073f-1967-4cf1-9070-475a567fb308,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-282e2d96-9eeb-4795-9d12-c2f715661b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518539528-172.17.0.11-1595489504190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36191,DS-88f7fd54-ad37-460a-8270-27bb8a6ac518,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-0a777af9-b675-454d-906c-f82d171f824b,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-9195587f-86d4-45ca-b955-7b17b82d36d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-e1cacdc7-e4c1-4322-8522-62aa305db6be,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-4f7b55b9-8c49-41f3-9e39-fd44bb636e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-e626f1de-11ae-47bf-941a-429d603ec0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-e3519bd8-b423-4db9-88f3-89ffbed88ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-bdf574cd-92ec-4fa0-8aea-0ef6abfd4fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518539528-172.17.0.11-1595489504190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36191,DS-88f7fd54-ad37-460a-8270-27bb8a6ac518,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-0a777af9-b675-454d-906c-f82d171f824b,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-9195587f-86d4-45ca-b955-7b17b82d36d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-e1cacdc7-e4c1-4322-8522-62aa305db6be,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-4f7b55b9-8c49-41f3-9e39-fd44bb636e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-e626f1de-11ae-47bf-941a-429d603ec0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-e3519bd8-b423-4db9-88f3-89ffbed88ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-bdf574cd-92ec-4fa0-8aea-0ef6abfd4fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071833197-172.17.0.11-1595489543136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33457,DS-612f30e3-2513-4465-ae2b-2fcf384cc5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-7ab61e56-954e-4aef-adb9-e4a90cac081f,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-dcef4f1b-1187-4bc8-a04b-f5db51559db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-3941d23e-a611-4a04-b8ad-67e6a09c414d,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-62293c79-0040-4823-b1d8-a12b949f9757,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-ebf01927-91a9-429e-a10c-24b7cec4db43,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-68230f38-d7b8-462e-9f24-0fff0f1597ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-30f2550f-eb57-4388-8b33-ee2ecda3376a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071833197-172.17.0.11-1595489543136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33457,DS-612f30e3-2513-4465-ae2b-2fcf384cc5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-7ab61e56-954e-4aef-adb9-e4a90cac081f,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-dcef4f1b-1187-4bc8-a04b-f5db51559db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-3941d23e-a611-4a04-b8ad-67e6a09c414d,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-62293c79-0040-4823-b1d8-a12b949f9757,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-ebf01927-91a9-429e-a10c-24b7cec4db43,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-68230f38-d7b8-462e-9f24-0fff0f1597ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-30f2550f-eb57-4388-8b33-ee2ecda3376a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870888971-172.17.0.11-1595489688053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42508,DS-ab1d475d-264f-4fae-945e-3b0080732d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-db2c5009-cfa9-4423-9ef3-3f17953cc6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-e0a55b0a-d549-48fd-866d-0c69b39c4815,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-e15f9889-0057-475c-9ff6-745b90580b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-2cf1751d-6d8e-4646-a6f4-d61aea666e95,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-12ae1497-d4cc-4ceb-abda-9f9e360b2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-9f3ef7ad-eca1-4b6e-ad2c-6d02b5cf6f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-7da973fe-c550-442f-ae29-951bf23bbe69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870888971-172.17.0.11-1595489688053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42508,DS-ab1d475d-264f-4fae-945e-3b0080732d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-db2c5009-cfa9-4423-9ef3-3f17953cc6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-e0a55b0a-d549-48fd-866d-0c69b39c4815,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-e15f9889-0057-475c-9ff6-745b90580b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-2cf1751d-6d8e-4646-a6f4-d61aea666e95,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-12ae1497-d4cc-4ceb-abda-9f9e360b2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-9f3ef7ad-eca1-4b6e-ad2c-6d02b5cf6f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-7da973fe-c550-442f-ae29-951bf23bbe69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84443618-172.17.0.11-1595489892083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40848,DS-0b4bcfb8-f63d-48e0-8879-49b9db626340,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-cb66ee1b-45d4-4450-8917-1d5088cf9fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-aed40175-fa65-448e-acb9-fc4a4ba5a867,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-5034aff6-146d-407d-b162-f9ad5e11e983,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-c52858cc-6804-47c9-b2e2-94fa28e6ce45,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-905cbd6e-0503-478b-aac3-b5942b6e7f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-556adf1a-3c6a-4229-b082-97b6e6ba49ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-42fe5d1b-9821-43b8-9ae8-9b41a054a72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84443618-172.17.0.11-1595489892083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40848,DS-0b4bcfb8-f63d-48e0-8879-49b9db626340,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-cb66ee1b-45d4-4450-8917-1d5088cf9fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-aed40175-fa65-448e-acb9-fc4a4ba5a867,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-5034aff6-146d-407d-b162-f9ad5e11e983,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-c52858cc-6804-47c9-b2e2-94fa28e6ce45,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-905cbd6e-0503-478b-aac3-b5942b6e7f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-556adf1a-3c6a-4229-b082-97b6e6ba49ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-42fe5d1b-9821-43b8-9ae8-9b41a054a72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185824944-172.17.0.11-1595490566079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-3fb76c67-a13c-40bd-895f-df26ffb4888c,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-59a91754-0eb5-476a-8e73-ce38733b9acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-c2e386d8-3324-421b-9a45-17e6e6d56ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-89c02d0b-461f-4576-bd4b-0d00f5908195,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-3ba621b2-9179-49c1-84f1-9960ee9aace9,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-c600983a-af1f-4f79-9e55-932fbb5bea19,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-7f2556d7-236b-483d-99e1-0db47d755b03,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-90508a3c-3183-4a6b-b8a7-1c72afb5767b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185824944-172.17.0.11-1595490566079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-3fb76c67-a13c-40bd-895f-df26ffb4888c,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-59a91754-0eb5-476a-8e73-ce38733b9acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-c2e386d8-3324-421b-9a45-17e6e6d56ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-89c02d0b-461f-4576-bd4b-0d00f5908195,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-3ba621b2-9179-49c1-84f1-9960ee9aace9,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-c600983a-af1f-4f79-9e55-932fbb5bea19,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-7f2556d7-236b-483d-99e1-0db47d755b03,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-90508a3c-3183-4a6b-b8a7-1c72afb5767b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028484503-172.17.0.11-1595491206550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-70ba9845-e54a-4998-9f47-593881a52559,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-88c2f1cc-b16c-4fb7-a85f-2011d6f7aeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-de12139b-f369-40b4-a882-0aaf94cc8a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-043bcf66-5b94-4cdd-b809-df31860143f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-d924abf4-074d-4e9c-a2cf-59e7955e54b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-5a6038cf-a162-489e-bd64-ebc5412aa70b,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-3d5cecd5-006b-4e6c-92c8-8982243991ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-7692d7fa-1406-4784-a6c0-e09d9608991f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028484503-172.17.0.11-1595491206550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-70ba9845-e54a-4998-9f47-593881a52559,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-88c2f1cc-b16c-4fb7-a85f-2011d6f7aeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-de12139b-f369-40b4-a882-0aaf94cc8a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-043bcf66-5b94-4cdd-b809-df31860143f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-d924abf4-074d-4e9c-a2cf-59e7955e54b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-5a6038cf-a162-489e-bd64-ebc5412aa70b,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-3d5cecd5-006b-4e6c-92c8-8982243991ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-7692d7fa-1406-4784-a6c0-e09d9608991f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350024336-172.17.0.11-1595491273820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-6a6175cf-23df-4ec6-a4aa-8e3df5aaf4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-fc87ed78-96ec-40f1-b2fe-5a1e2e852882,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-a8db8554-54db-4ce5-9689-d17b13a68878,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-41d63a08-8ad4-4779-8282-916b63db7b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-f8ac8171-b9c4-466a-849d-9b8c0c8c26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-39170fed-c384-4f43-bb04-70821998fe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-b9168535-0afb-4b1e-b2a8-1ecf12c35551,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-23cec5d6-542e-43aa-80e3-c29713fe526b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350024336-172.17.0.11-1595491273820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-6a6175cf-23df-4ec6-a4aa-8e3df5aaf4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-fc87ed78-96ec-40f1-b2fe-5a1e2e852882,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-a8db8554-54db-4ce5-9689-d17b13a68878,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-41d63a08-8ad4-4779-8282-916b63db7b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-f8ac8171-b9c4-466a-849d-9b8c0c8c26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-39170fed-c384-4f43-bb04-70821998fe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-b9168535-0afb-4b1e-b2a8-1ecf12c35551,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-23cec5d6-542e-43aa-80e3-c29713fe526b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263417180-172.17.0.11-1595491543703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-cfc655cd-7e1a-4dee-8013-2c9d9ad7837c,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-895d941d-a75c-46b5-a05f-77e2dccfaf32,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-efd4d00a-53cf-4ce7-b2ff-f67b0fba9c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-a9a6ef56-1910-4567-a7a0-cfec476fae46,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-983d9343-6da9-473f-87b3-0ae7f91eedbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-98ef744f-8055-4e12-aa92-9e4a8dd61721,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-b9304e47-ce32-420d-8d4e-386b6c4bed04,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-82a4a932-e7ab-442e-8c90-3db624f8a529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263417180-172.17.0.11-1595491543703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-cfc655cd-7e1a-4dee-8013-2c9d9ad7837c,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-895d941d-a75c-46b5-a05f-77e2dccfaf32,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-efd4d00a-53cf-4ce7-b2ff-f67b0fba9c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-a9a6ef56-1910-4567-a7a0-cfec476fae46,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-983d9343-6da9-473f-87b3-0ae7f91eedbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-98ef744f-8055-4e12-aa92-9e4a8dd61721,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-b9304e47-ce32-420d-8d4e-386b6c4bed04,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-82a4a932-e7ab-442e-8c90-3db624f8a529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197944670-172.17.0.11-1595491737708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39827,DS-6f73a1f5-0d97-497e-ae17-5f3e3be7a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-5be7bbb4-b5af-4a2e-9e3c-fc2f0ff84542,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-783197aa-c0dd-43a9-8877-2e02336f31ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-d520f9ea-120d-4b68-99aa-6f3c33e952ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-eda9caad-d271-4a82-be51-25eedae63c63,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-125e915f-51b3-4ccd-9b66-08be01bd7815,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-fc254e5e-0c14-4647-8322-811bbad66d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-9b9e6da8-3621-4247-99e5-158a116cf1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197944670-172.17.0.11-1595491737708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39827,DS-6f73a1f5-0d97-497e-ae17-5f3e3be7a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-5be7bbb4-b5af-4a2e-9e3c-fc2f0ff84542,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-783197aa-c0dd-43a9-8877-2e02336f31ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-d520f9ea-120d-4b68-99aa-6f3c33e952ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-eda9caad-d271-4a82-be51-25eedae63c63,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-125e915f-51b3-4ccd-9b66-08be01bd7815,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-fc254e5e-0c14-4647-8322-811bbad66d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-9b9e6da8-3621-4247-99e5-158a116cf1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237631881-172.17.0.11-1595493446907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-4604caa8-a218-4fb6-bc14-0d5e3873c136,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-b452c21a-26d8-46ff-be98-467cb78d113b,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-2385321a-53e2-462c-af40-7eed4117a69f,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-6d1f9d06-620d-47b7-85b4-93b78b759256,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-70d959f1-8bc3-4e26-8ddd-705a4da62b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-a6a0d8b7-0a76-4882-88c8-5aabae4f12a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-b0805466-403a-403a-8934-e99bffa6b506,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-8d647115-e068-4144-af1d-95a7631f2192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237631881-172.17.0.11-1595493446907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-4604caa8-a218-4fb6-bc14-0d5e3873c136,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-b452c21a-26d8-46ff-be98-467cb78d113b,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-2385321a-53e2-462c-af40-7eed4117a69f,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-6d1f9d06-620d-47b7-85b4-93b78b759256,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-70d959f1-8bc3-4e26-8ddd-705a4da62b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-a6a0d8b7-0a76-4882-88c8-5aabae4f12a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-b0805466-403a-403a-8934-e99bffa6b506,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-8d647115-e068-4144-af1d-95a7631f2192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810409406-172.17.0.11-1595493485770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41711,DS-b7d6f8a8-e4ba-4623-add4-ca4bd2c74c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-05b62480-eba9-46f5-b5ef-93c61a8182a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-c3b683aa-e4a8-4c14-bb3f-db5edfbb37f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-ff844d71-ca80-460a-a4fc-0c11141dd41e,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-e7c88c2a-d3af-4708-a455-20b2ddf0e451,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-974dbeb6-6d76-4e75-b92d-1b8d5fa7fbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-d62a0a43-bc33-41bf-9160-be6a092a8d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-40296442-43ca-4fa2-ad95-83dbc997fc03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810409406-172.17.0.11-1595493485770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41711,DS-b7d6f8a8-e4ba-4623-add4-ca4bd2c74c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-05b62480-eba9-46f5-b5ef-93c61a8182a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-c3b683aa-e4a8-4c14-bb3f-db5edfbb37f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-ff844d71-ca80-460a-a4fc-0c11141dd41e,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-e7c88c2a-d3af-4708-a455-20b2ddf0e451,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-974dbeb6-6d76-4e75-b92d-1b8d5fa7fbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-d62a0a43-bc33-41bf-9160-be6a092a8d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-40296442-43ca-4fa2-ad95-83dbc997fc03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418591943-172.17.0.11-1595493602609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-019e64a7-5c7c-4923-afdc-adb84b964192,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-34e2adc3-19b2-4a74-8804-ae6ba7595950,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-5ab30308-0537-4595-964a-01786ce712c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-69d81650-f81d-4b9e-9dd1-7f41b0931696,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-99aba0c8-deaa-4e4a-9fea-0f11097f1aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-2d9504ee-4185-44ee-ab89-6ea4a382b1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-c2780d63-63ae-4035-a487-e3535d742678,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-845baeac-c19e-4a8f-880f-cee0ffeea82c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418591943-172.17.0.11-1595493602609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-019e64a7-5c7c-4923-afdc-adb84b964192,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-34e2adc3-19b2-4a74-8804-ae6ba7595950,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-5ab30308-0537-4595-964a-01786ce712c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-69d81650-f81d-4b9e-9dd1-7f41b0931696,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-99aba0c8-deaa-4e4a-9fea-0f11097f1aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-2d9504ee-4185-44ee-ab89-6ea4a382b1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-c2780d63-63ae-4035-a487-e3535d742678,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-845baeac-c19e-4a8f-880f-cee0ffeea82c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5705
