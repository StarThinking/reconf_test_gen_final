reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416287080-172.17.0.10-1595520499355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-b111ba42-c68a-4d71-897b-6d40d6a27dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-f2ece3c6-8a18-4882-a3c9-88414b413c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-1ffc7f87-a5de-4a58-a4bb-f7d5e534da25,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-852d0837-772f-4dfe-8ec0-eb071e6c18d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-e6b9b412-eca4-4d56-a808-e91f6633e516,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-88455611-05b6-4afb-a202-e0de64f9f5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-eb9df49e-9a36-42a0-b7bb-2e86989c9b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-fb0ec84e-b40e-4ab0-9945-9aad1dc87e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416287080-172.17.0.10-1595520499355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-b111ba42-c68a-4d71-897b-6d40d6a27dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-f2ece3c6-8a18-4882-a3c9-88414b413c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-1ffc7f87-a5de-4a58-a4bb-f7d5e534da25,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-852d0837-772f-4dfe-8ec0-eb071e6c18d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-e6b9b412-eca4-4d56-a808-e91f6633e516,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-88455611-05b6-4afb-a202-e0de64f9f5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-eb9df49e-9a36-42a0-b7bb-2e86989c9b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-fb0ec84e-b40e-4ab0-9945-9aad1dc87e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54098408-172.17.0.10-1595521474397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37834,DS-5f54713b-eb0a-4a98-bd5a-b7b6a6e2992e,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-3717d170-1a90-4e29-802f-fe31b98ec17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-6152836b-af27-467e-b6fd-7607113810cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-609c1f7c-f973-4ee1-873c-35a1cb85844c,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-1f17274a-2b83-46e6-9d6e-21b3aa984140,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-6da8d399-98db-4001-8811-92efdbcaa7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-46723cd7-cfa5-467d-9e60-7177ba2731da,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-f2ff3f24-dce3-4c58-9347-5cedd10313ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54098408-172.17.0.10-1595521474397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37834,DS-5f54713b-eb0a-4a98-bd5a-b7b6a6e2992e,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-3717d170-1a90-4e29-802f-fe31b98ec17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-6152836b-af27-467e-b6fd-7607113810cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-609c1f7c-f973-4ee1-873c-35a1cb85844c,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-1f17274a-2b83-46e6-9d6e-21b3aa984140,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-6da8d399-98db-4001-8811-92efdbcaa7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-46723cd7-cfa5-467d-9e60-7177ba2731da,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-f2ff3f24-dce3-4c58-9347-5cedd10313ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21788434-172.17.0.10-1595521542334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35291,DS-54507c9d-d8ce-48a4-b72f-73538758254f,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-f65695e1-2d3c-46d3-a995-25bab6204900,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-6d0710bb-ea4a-43d5-a1e4-8b29bbe7c0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-67b372f7-fe24-4944-b6f4-aa02f444f35f,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-444aebfe-1291-46d4-a941-d69812d6a1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-5217c060-27f5-4a54-a9cb-cc10e32585de,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-3f6ac96d-b53b-4c18-9252-793c9f3a8ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-6ba69c23-41d0-4e71-93e8-b78ed7cddcc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21788434-172.17.0.10-1595521542334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35291,DS-54507c9d-d8ce-48a4-b72f-73538758254f,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-f65695e1-2d3c-46d3-a995-25bab6204900,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-6d0710bb-ea4a-43d5-a1e4-8b29bbe7c0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-67b372f7-fe24-4944-b6f4-aa02f444f35f,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-444aebfe-1291-46d4-a941-d69812d6a1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-5217c060-27f5-4a54-a9cb-cc10e32585de,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-3f6ac96d-b53b-4c18-9252-793c9f3a8ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-6ba69c23-41d0-4e71-93e8-b78ed7cddcc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068107633-172.17.0.10-1595521611927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37091,DS-8642d5a4-903b-47b9-ac26-9520583748b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-e36e5cd6-e75c-44e5-b391-db8f7a9f2907,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-99e2ea81-7be5-4c62-8d7d-23d44552e0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-9434ee8e-e6e3-4c98-a769-ca74c3b66c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-3f0900a9-7083-4de4-8e88-faa7f09e181a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-8d55f6b5-e057-4bdf-8001-b77adecdd4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-bd1c9a65-6d03-4fe2-92b3-73d7b422d1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-f6a004da-44b5-4e52-b3eb-ebf7885c579b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068107633-172.17.0.10-1595521611927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37091,DS-8642d5a4-903b-47b9-ac26-9520583748b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-e36e5cd6-e75c-44e5-b391-db8f7a9f2907,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-99e2ea81-7be5-4c62-8d7d-23d44552e0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-9434ee8e-e6e3-4c98-a769-ca74c3b66c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-3f0900a9-7083-4de4-8e88-faa7f09e181a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-8d55f6b5-e057-4bdf-8001-b77adecdd4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-bd1c9a65-6d03-4fe2-92b3-73d7b422d1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-f6a004da-44b5-4e52-b3eb-ebf7885c579b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378877658-172.17.0.10-1595521683971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34072,DS-04143ace-4d7a-4044-811e-5cc279c24cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-65a41d57-d5f4-404c-a6d2-c83c27756b99,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-ff256e5d-b8bb-4ba3-bd7b-30fc6ec003d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-7c0d7745-f04b-4955-b96d-a2017094c6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-2750cc72-b6c6-4b27-aa60-570f937e8147,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-983ebc9a-8f63-46c1-b911-9118f21d38ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-729789a0-df13-4043-af40-55e8feb187b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-498ba930-3680-48c4-a0dc-b2f07aca49b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378877658-172.17.0.10-1595521683971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34072,DS-04143ace-4d7a-4044-811e-5cc279c24cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-65a41d57-d5f4-404c-a6d2-c83c27756b99,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-ff256e5d-b8bb-4ba3-bd7b-30fc6ec003d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-7c0d7745-f04b-4955-b96d-a2017094c6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-2750cc72-b6c6-4b27-aa60-570f937e8147,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-983ebc9a-8f63-46c1-b911-9118f21d38ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-729789a0-df13-4043-af40-55e8feb187b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-498ba930-3680-48c4-a0dc-b2f07aca49b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763976403-172.17.0.10-1595522531476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-a42c5ea8-9bb6-47bb-b13d-6160d22895c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-b3855177-45bb-4eb5-9870-41e444575d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-a78024ce-6136-4983-89ea-ed7ec98f0315,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-763ff57b-0299-492e-af50-1e6b9c1aad55,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-0d5bfa9d-73e9-4e37-9578-021d1f20e801,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-7efd01ed-60c2-45ee-9ece-8d4a0f3f3d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-50ac3e3e-1681-4f4c-97ad-2d1f84b63a77,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-eb59b7a1-c9ff-4f8e-94d4-86955154593e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763976403-172.17.0.10-1595522531476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-a42c5ea8-9bb6-47bb-b13d-6160d22895c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-b3855177-45bb-4eb5-9870-41e444575d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-a78024ce-6136-4983-89ea-ed7ec98f0315,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-763ff57b-0299-492e-af50-1e6b9c1aad55,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-0d5bfa9d-73e9-4e37-9578-021d1f20e801,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-7efd01ed-60c2-45ee-9ece-8d4a0f3f3d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-50ac3e3e-1681-4f4c-97ad-2d1f84b63a77,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-eb59b7a1-c9ff-4f8e-94d4-86955154593e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577611944-172.17.0.10-1595522570689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-dba9bd0b-5f7c-4b6f-9487-090aab18a093,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-57db5925-def0-42a5-9a2f-1f616818d6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-e434e41b-e05a-40ba-a4f3-8019114eed3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-1bb1d522-c916-4add-afba-a06b83b6874d,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-1e23f7a1-ed24-4cbd-90a4-74f7572ba3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-2ee009ea-ef2d-46af-80f7-de31b3b79374,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-7ce4170a-2179-4f07-8d11-87cf07fb2e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-4f924ce6-eed1-4cef-b7b0-105bf9a80bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577611944-172.17.0.10-1595522570689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-dba9bd0b-5f7c-4b6f-9487-090aab18a093,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-57db5925-def0-42a5-9a2f-1f616818d6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-e434e41b-e05a-40ba-a4f3-8019114eed3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-1bb1d522-c916-4add-afba-a06b83b6874d,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-1e23f7a1-ed24-4cbd-90a4-74f7572ba3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-2ee009ea-ef2d-46af-80f7-de31b3b79374,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-7ce4170a-2179-4f07-8d11-87cf07fb2e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-4f924ce6-eed1-4cef-b7b0-105bf9a80bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691722138-172.17.0.10-1595522754427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-39aa284c-95c7-48d3-a5b4-6590fb30f21a,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-35645666-501a-4da1-a8ba-0502782510c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-f1230fa7-8ef5-44f7-9146-d67ce898f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-5ca1f19a-e5f3-44e8-85ff-0ced18d446d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-122b0c1e-6954-4b88-bc69-7048b5bc129a,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-c39216bb-cbd8-4995-b77c-78544b1bc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-1d92c92e-9a05-45b8-938f-6ab5495e05d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-29528995-039f-4710-b280-db558aacb734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691722138-172.17.0.10-1595522754427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-39aa284c-95c7-48d3-a5b4-6590fb30f21a,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-35645666-501a-4da1-a8ba-0502782510c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-f1230fa7-8ef5-44f7-9146-d67ce898f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-5ca1f19a-e5f3-44e8-85ff-0ced18d446d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-122b0c1e-6954-4b88-bc69-7048b5bc129a,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-c39216bb-cbd8-4995-b77c-78544b1bc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-1d92c92e-9a05-45b8-938f-6ab5495e05d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-29528995-039f-4710-b280-db558aacb734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492078492-172.17.0.10-1595523883093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-d4172737-ac1f-4e4b-9c1e-039cd9e870b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-cfe2f25f-64af-4d45-a263-a7ec3bf4bd94,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-923e667b-7b4b-4fe3-9d12-b80378b2c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-632c8547-1c53-4aed-ac45-ae64f504a93b,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-1a304944-b952-4419-86e3-051810b27784,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-4bfa9e7c-0b60-4827-bec0-2206a0082d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-d140fa18-567d-4132-ba4a-441547a4b45c,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-687c3416-d6c6-4896-84bb-de617cee0ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492078492-172.17.0.10-1595523883093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-d4172737-ac1f-4e4b-9c1e-039cd9e870b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-cfe2f25f-64af-4d45-a263-a7ec3bf4bd94,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-923e667b-7b4b-4fe3-9d12-b80378b2c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-632c8547-1c53-4aed-ac45-ae64f504a93b,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-1a304944-b952-4419-86e3-051810b27784,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-4bfa9e7c-0b60-4827-bec0-2206a0082d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-d140fa18-567d-4132-ba4a-441547a4b45c,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-687c3416-d6c6-4896-84bb-de617cee0ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581276464-172.17.0.10-1595524583833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33158,DS-f6c7a78e-33a0-4179-85d8-af9710ac6836,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-01d19c2d-cf3d-4ee5-8fce-b3b411687f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-127341c2-d9a0-40fa-a662-e0a2aa5d5585,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-ef33adbf-e401-4476-aab7-525c24aeafb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-587ac2fe-9b9c-472b-b9a8-cf9b36909b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-ddf4d1ff-49c7-46ac-b8c5-9af491252083,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-05b4e9fa-ef2c-485b-b7ed-f4b90de56522,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-83907f7c-0f46-48e9-aafc-763e059a1a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581276464-172.17.0.10-1595524583833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33158,DS-f6c7a78e-33a0-4179-85d8-af9710ac6836,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-01d19c2d-cf3d-4ee5-8fce-b3b411687f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-127341c2-d9a0-40fa-a662-e0a2aa5d5585,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-ef33adbf-e401-4476-aab7-525c24aeafb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-587ac2fe-9b9c-472b-b9a8-cf9b36909b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-ddf4d1ff-49c7-46ac-b8c5-9af491252083,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-05b4e9fa-ef2c-485b-b7ed-f4b90de56522,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-83907f7c-0f46-48e9-aafc-763e059a1a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782624288-172.17.0.10-1595525159525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41115,DS-70040ef7-2a1e-4942-ac3c-9737ef410939,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-2e546052-c754-4048-8592-6006fee3d166,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-1c42ecf7-e083-44f5-88b8-6c6782281ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-ad62a170-5c69-41ff-ada8-5fda50897bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-11858f65-2cec-49f2-be05-bd085ead0b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-97249e92-e247-4047-9ba7-4b48cf9ab2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-134a494d-0206-4480-8695-8cb5a64b1167,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-562ba502-3d2a-41cc-8911-5ac00e225b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782624288-172.17.0.10-1595525159525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41115,DS-70040ef7-2a1e-4942-ac3c-9737ef410939,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-2e546052-c754-4048-8592-6006fee3d166,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-1c42ecf7-e083-44f5-88b8-6c6782281ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-ad62a170-5c69-41ff-ada8-5fda50897bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-11858f65-2cec-49f2-be05-bd085ead0b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-97249e92-e247-4047-9ba7-4b48cf9ab2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-134a494d-0206-4480-8695-8cb5a64b1167,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-562ba502-3d2a-41cc-8911-5ac00e225b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5382
