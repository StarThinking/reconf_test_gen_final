reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963610833-172.17.0.17-1595593735348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-7a66ea39-2c9e-4765-a936-11be7ccb05d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-2db245ff-b0bb-4c8a-b97b-a26abbe5f305,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-a609028d-2410-4d9f-8700-4a4661c5e899,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-f2ff1728-aab5-48d5-90b8-b2257e582127,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-1ff690fc-3856-46b1-b91a-7d92c5a3c105,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-a8bedac2-7738-4627-b69c-a28bf1b0c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-363d66fd-ae55-431a-8ae5-26f4c02e4720,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-57a4e50d-814a-4e89-8c98-98252ff3e451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963610833-172.17.0.17-1595593735348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-7a66ea39-2c9e-4765-a936-11be7ccb05d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-2db245ff-b0bb-4c8a-b97b-a26abbe5f305,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-a609028d-2410-4d9f-8700-4a4661c5e899,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-f2ff1728-aab5-48d5-90b8-b2257e582127,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-1ff690fc-3856-46b1-b91a-7d92c5a3c105,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-a8bedac2-7738-4627-b69c-a28bf1b0c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-363d66fd-ae55-431a-8ae5-26f4c02e4720,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-57a4e50d-814a-4e89-8c98-98252ff3e451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107927883-172.17.0.17-1595593771753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40893,DS-f5d13e8e-aa99-4fb6-9d26-a97941288779,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-5208c5b0-c186-43e4-97fc-bce7de4aee58,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-a794ed98-0421-4609-bee8-78f168aab192,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-bd8c180e-e932-41fc-a44a-e477ca140edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-e1985da0-0c7a-4b91-b85b-4cacc2bc2834,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-97e23b39-9a8a-46f3-8aba-02ea2e847665,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-ecf40f36-3178-4bda-af35-f1a5ab47f891,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-a61b3e8a-c8d6-40fa-a0e4-4fa5d8fd5020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107927883-172.17.0.17-1595593771753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40893,DS-f5d13e8e-aa99-4fb6-9d26-a97941288779,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-5208c5b0-c186-43e4-97fc-bce7de4aee58,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-a794ed98-0421-4609-bee8-78f168aab192,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-bd8c180e-e932-41fc-a44a-e477ca140edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-e1985da0-0c7a-4b91-b85b-4cacc2bc2834,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-97e23b39-9a8a-46f3-8aba-02ea2e847665,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-ecf40f36-3178-4bda-af35-f1a5ab47f891,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-a61b3e8a-c8d6-40fa-a0e4-4fa5d8fd5020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587884539-172.17.0.17-1595593836617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41926,DS-959ab10c-84ff-4e93-8b14-c61ee0aa5064,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-203dd7e7-d7c4-406b-a885-dc4be82d2582,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-75f37166-cd66-4534-9981-fc91dcd2a28a,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-7764cb11-1a55-44d7-a085-703c441b1ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-bb8f5ae3-d883-4771-bc64-0d48eff48b09,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-3c1475e4-802c-4c4b-94ff-a2322c8748d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-1c3e4b6e-f662-4337-84c2-f022e93b8813,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-63929005-c8e8-4ead-8c04-f357d866db1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587884539-172.17.0.17-1595593836617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41926,DS-959ab10c-84ff-4e93-8b14-c61ee0aa5064,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-203dd7e7-d7c4-406b-a885-dc4be82d2582,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-75f37166-cd66-4534-9981-fc91dcd2a28a,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-7764cb11-1a55-44d7-a085-703c441b1ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-bb8f5ae3-d883-4771-bc64-0d48eff48b09,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-3c1475e4-802c-4c4b-94ff-a2322c8748d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-1c3e4b6e-f662-4337-84c2-f022e93b8813,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-63929005-c8e8-4ead-8c04-f357d866db1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84874076-172.17.0.17-1595594595690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45502,DS-80398d24-be38-4d3c-9112-435f245b0513,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-cc72255d-d7aa-4cf7-918a-2957e0316856,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-c1f75341-8840-4ff3-8e13-edaead968993,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-da05300b-b89b-4491-a436-64870bc3eca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-33849b43-e36b-42e4-8f39-f4af8a9a3c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-32859997-2ef5-49df-a3f0-bf6b6dba7275,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-a18ff4c9-51ba-472c-9c74-ac78d0254cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-17f93eaa-f733-49fc-a439-d571cd6b07fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84874076-172.17.0.17-1595594595690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45502,DS-80398d24-be38-4d3c-9112-435f245b0513,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-cc72255d-d7aa-4cf7-918a-2957e0316856,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-c1f75341-8840-4ff3-8e13-edaead968993,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-da05300b-b89b-4491-a436-64870bc3eca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-33849b43-e36b-42e4-8f39-f4af8a9a3c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-32859997-2ef5-49df-a3f0-bf6b6dba7275,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-a18ff4c9-51ba-472c-9c74-ac78d0254cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-17f93eaa-f733-49fc-a439-d571cd6b07fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589277067-172.17.0.17-1595594805032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38753,DS-9b0aecdb-48b2-4ce6-9c51-432e705a1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-5fda10be-3373-4116-930d-d8bce5ac4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-25f7d76b-20ab-436b-a6ed-eeeb7c5f6530,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-dbef9da2-4e1c-4182-9edb-edc2a56e503e,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-6ebae350-e6fa-4364-94a6-13033fd23347,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-ebe86712-39e5-4840-b12f-1b6026978156,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-ad100163-a681-481b-a91b-ad313ac7d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-3407fbed-ea8e-48f0-aade-1ca3fdcde781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589277067-172.17.0.17-1595594805032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38753,DS-9b0aecdb-48b2-4ce6-9c51-432e705a1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-5fda10be-3373-4116-930d-d8bce5ac4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-25f7d76b-20ab-436b-a6ed-eeeb7c5f6530,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-dbef9da2-4e1c-4182-9edb-edc2a56e503e,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-6ebae350-e6fa-4364-94a6-13033fd23347,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-ebe86712-39e5-4840-b12f-1b6026978156,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-ad100163-a681-481b-a91b-ad313ac7d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-3407fbed-ea8e-48f0-aade-1ca3fdcde781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2769408-172.17.0.17-1595594974143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32988,DS-ffbacee1-ffe8-41d0-84bc-23d165b3fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d4ec1fa2-d2b3-4589-91f6-7fab67e90404,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-4d075032-698c-495b-b15f-811c6f9806d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-fc83eef4-2228-4750-a7a8-e677178e44d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-dc54fb76-ed5f-44e6-a1d2-5133f241aa23,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-13391cbf-ed03-41a5-ae2b-1fb9cb2b8df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-f97deca0-e0dd-42b8-8b19-12861b83b254,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-e810ad29-c80d-4f5e-ac4d-dd57a5141058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2769408-172.17.0.17-1595594974143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32988,DS-ffbacee1-ffe8-41d0-84bc-23d165b3fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d4ec1fa2-d2b3-4589-91f6-7fab67e90404,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-4d075032-698c-495b-b15f-811c6f9806d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-fc83eef4-2228-4750-a7a8-e677178e44d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-dc54fb76-ed5f-44e6-a1d2-5133f241aa23,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-13391cbf-ed03-41a5-ae2b-1fb9cb2b8df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-f97deca0-e0dd-42b8-8b19-12861b83b254,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-e810ad29-c80d-4f5e-ac4d-dd57a5141058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91764317-172.17.0.17-1595595411766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-7b3dd36a-a1b0-44ea-ad72-0cd6a3e45855,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-bc53ef41-28f9-4680-b1b1-485873f3b706,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-0fb9ca5e-1b39-49b2-b24f-88b53c95af57,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-f77cd244-e05b-4417-b6f2-0b2f62b72649,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-34446c95-7956-4c21-86d9-68e38cfeeceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-1edc4ee1-adfb-4a0c-9b49-417b5582abeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-367fcf83-afaa-40bf-98fb-df05f1645b65,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-ae7e042b-7855-455a-be6c-3106bf27941d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91764317-172.17.0.17-1595595411766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-7b3dd36a-a1b0-44ea-ad72-0cd6a3e45855,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-bc53ef41-28f9-4680-b1b1-485873f3b706,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-0fb9ca5e-1b39-49b2-b24f-88b53c95af57,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-f77cd244-e05b-4417-b6f2-0b2f62b72649,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-34446c95-7956-4c21-86d9-68e38cfeeceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-1edc4ee1-adfb-4a0c-9b49-417b5582abeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-367fcf83-afaa-40bf-98fb-df05f1645b65,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-ae7e042b-7855-455a-be6c-3106bf27941d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999948843-172.17.0.17-1595596500790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42978,DS-2296b7ee-8a92-4d1f-9bba-72f52db89894,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-76f1298c-23f5-42e7-b0ef-528197799b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-19fd472b-2d83-4b28-8319-1f7f7bb4b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-75acc5ca-6f1c-44a5-8848-04faa3bd14b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-559411c6-399d-4074-961c-903f33dd7cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-4d0a26ad-67d9-4835-95a7-f97eed158cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-0803f5fb-7020-4586-a8fc-46693dd53579,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-9d4c68cf-d34c-477e-ba08-b14b47a6f979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999948843-172.17.0.17-1595596500790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42978,DS-2296b7ee-8a92-4d1f-9bba-72f52db89894,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-76f1298c-23f5-42e7-b0ef-528197799b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-19fd472b-2d83-4b28-8319-1f7f7bb4b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-75acc5ca-6f1c-44a5-8848-04faa3bd14b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-559411c6-399d-4074-961c-903f33dd7cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-4d0a26ad-67d9-4835-95a7-f97eed158cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-0803f5fb-7020-4586-a8fc-46693dd53579,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-9d4c68cf-d34c-477e-ba08-b14b47a6f979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001535838-172.17.0.17-1595596604794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-5e83e7a1-a5d9-473c-ac7e-df58729cf089,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-36354268-1bee-4d48-8d78-7d65b01381a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-a4a05e49-d860-4934-ab96-d91042700427,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-a8872ea9-9160-4ef3-a30b-5c66e5f6f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-405ca57e-64d2-4b83-bb92-b1e0b8500201,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-7fe2b9af-2303-4aac-9774-81c1e6f6e7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-ca198a00-66b2-4180-bdc6-94497ff68af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-090ccc70-5127-44a6-9ad2-158d22501124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001535838-172.17.0.17-1595596604794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-5e83e7a1-a5d9-473c-ac7e-df58729cf089,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-36354268-1bee-4d48-8d78-7d65b01381a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-a4a05e49-d860-4934-ab96-d91042700427,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-a8872ea9-9160-4ef3-a30b-5c66e5f6f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-405ca57e-64d2-4b83-bb92-b1e0b8500201,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-7fe2b9af-2303-4aac-9774-81c1e6f6e7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-ca198a00-66b2-4180-bdc6-94497ff68af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-090ccc70-5127-44a6-9ad2-158d22501124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103608337-172.17.0.17-1595596818918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34463,DS-ec15a906-a82c-4601-b964-0dd9921bbe08,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-2c2f1204-295c-4c59-b2dd-76d13119df7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-8c0a7786-5cc3-48d4-9632-2383b894cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-2df98524-c860-40cf-9098-9df459ac6442,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-d4b65f39-0e4e-422a-8dbf-33404e5e1c64,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-53fc4d02-7aa1-4cfc-b83b-99919a3f2a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-257bd4d8-10b7-4d93-8d79-9dc37f5f97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-2025daf5-fadf-4f62-9e0d-45de8ec3a476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103608337-172.17.0.17-1595596818918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34463,DS-ec15a906-a82c-4601-b964-0dd9921bbe08,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-2c2f1204-295c-4c59-b2dd-76d13119df7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-8c0a7786-5cc3-48d4-9632-2383b894cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-2df98524-c860-40cf-9098-9df459ac6442,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-d4b65f39-0e4e-422a-8dbf-33404e5e1c64,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-53fc4d02-7aa1-4cfc-b83b-99919a3f2a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-257bd4d8-10b7-4d93-8d79-9dc37f5f97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-2025daf5-fadf-4f62-9e0d-45de8ec3a476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576160166-172.17.0.17-1595596860124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-b7f558aa-980b-4941-9044-6176f0cac649,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-d7fbea84-78ac-4cf8-a545-f7089070444a,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-c0479fbd-9ace-4334-8661-00847cbade8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-b64cf514-bee0-43cb-9c11-3d28106ede55,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-2635c4a6-4f74-4756-ac38-0996949a0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-a4f74d57-bc74-4502-9e4a-9c73dce51321,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-894efa8a-2544-43c5-aaba-56c95493784a,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-a6a9084f-366d-44b5-9fcb-7ea80b08d2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576160166-172.17.0.17-1595596860124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-b7f558aa-980b-4941-9044-6176f0cac649,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-d7fbea84-78ac-4cf8-a545-f7089070444a,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-c0479fbd-9ace-4334-8661-00847cbade8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-b64cf514-bee0-43cb-9c11-3d28106ede55,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-2635c4a6-4f74-4756-ac38-0996949a0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-a4f74d57-bc74-4502-9e4a-9c73dce51321,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-894efa8a-2544-43c5-aaba-56c95493784a,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-a6a9084f-366d-44b5-9fcb-7ea80b08d2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523368292-172.17.0.17-1595596992327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41924,DS-91ed673d-94d0-433a-a75f-594696fc85fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-3f55d370-3c29-481f-9935-f6e41089da49,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-22e900f8-d8f4-4b63-953c-b0c28c68d6de,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-e1e3d973-7445-45a8-bbe8-ce6d005572e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-fe9026a7-f821-4e43-adff-29560679f5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-b349782b-befa-4bf4-9e1b-155d0e53f1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-dbe2dce8-3100-47ff-afc2-c53fce81b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-262b104c-8590-4a7a-8874-6dbba7493d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523368292-172.17.0.17-1595596992327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41924,DS-91ed673d-94d0-433a-a75f-594696fc85fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-3f55d370-3c29-481f-9935-f6e41089da49,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-22e900f8-d8f4-4b63-953c-b0c28c68d6de,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-e1e3d973-7445-45a8-bbe8-ce6d005572e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-fe9026a7-f821-4e43-adff-29560679f5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-b349782b-befa-4bf4-9e1b-155d0e53f1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-dbe2dce8-3100-47ff-afc2-c53fce81b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-262b104c-8590-4a7a-8874-6dbba7493d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459350039-172.17.0.17-1595597057100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46085,DS-1bf70ba0-df23-4c69-a692-1b1e0c52d267,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-196d0330-cb98-49b5-a5c4-41a3a890bf58,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-6f5fab20-20b1-4387-92bc-6b1a613a3d50,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-9761407b-d2bb-4d04-b554-c6a7d4d5b698,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-ab7dbf8e-74f6-4c27-949d-e1c5a30cdd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-c503cd71-ba18-43a4-bbd3-fa953f09fc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-884980a5-991e-4699-b30d-9552e2ecf48d,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-9f0880b2-8628-4529-95fb-d0523bf45f36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459350039-172.17.0.17-1595597057100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46085,DS-1bf70ba0-df23-4c69-a692-1b1e0c52d267,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-196d0330-cb98-49b5-a5c4-41a3a890bf58,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-6f5fab20-20b1-4387-92bc-6b1a613a3d50,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-9761407b-d2bb-4d04-b554-c6a7d4d5b698,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-ab7dbf8e-74f6-4c27-949d-e1c5a30cdd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-c503cd71-ba18-43a4-bbd3-fa953f09fc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-884980a5-991e-4699-b30d-9552e2ecf48d,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-9f0880b2-8628-4529-95fb-d0523bf45f36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38870838-172.17.0.17-1595597323617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34722,DS-9d57e0eb-11dd-4e35-bbbb-7896e7b0a583,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-d47a610b-ee4d-47cf-a363-8508c4be6eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-30efea86-3a5c-4198-b86f-44404e8c51fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-7daadb68-7a9b-4bfa-b525-3fe5e580330c,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-c5c4f5af-0759-4ec8-a31e-d44341a673bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-2671de91-0eed-41e7-bc3d-7fbca56adcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-81ca713b-d090-4cd7-beac-3cdf6a276b77,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-4c6168ec-71ed-441d-8016-acaed10590fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38870838-172.17.0.17-1595597323617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34722,DS-9d57e0eb-11dd-4e35-bbbb-7896e7b0a583,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-d47a610b-ee4d-47cf-a363-8508c4be6eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-30efea86-3a5c-4198-b86f-44404e8c51fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-7daadb68-7a9b-4bfa-b525-3fe5e580330c,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-c5c4f5af-0759-4ec8-a31e-d44341a673bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-2671de91-0eed-41e7-bc3d-7fbca56adcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-81ca713b-d090-4cd7-beac-3cdf6a276b77,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-4c6168ec-71ed-441d-8016-acaed10590fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359462916-172.17.0.17-1595597357272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44277,DS-856b8b3d-b6d0-400e-ad0f-3079a0ec1e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-d955ef09-91c7-42e0-a812-328388051e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-5f974a86-119f-4900-8a4d-2971aca87879,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-9128f4a8-90c9-4e91-a78b-da18e7551ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-02d4382c-b13b-4bdf-81d7-06147b35572b,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-c21c5044-675a-4a56-ac01-e409a1682f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-27bc1b49-6960-4f5b-88fb-b314b66b64e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-dbe8550b-adf1-4640-baf4-f58f1a214cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359462916-172.17.0.17-1595597357272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44277,DS-856b8b3d-b6d0-400e-ad0f-3079a0ec1e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-d955ef09-91c7-42e0-a812-328388051e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-5f974a86-119f-4900-8a4d-2971aca87879,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-9128f4a8-90c9-4e91-a78b-da18e7551ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-02d4382c-b13b-4bdf-81d7-06147b35572b,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-c21c5044-675a-4a56-ac01-e409a1682f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-27bc1b49-6960-4f5b-88fb-b314b66b64e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-dbe8550b-adf1-4640-baf4-f58f1a214cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947116975-172.17.0.17-1595597492663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-2e194598-e9e7-4f3a-972e-17014a2bd65a,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-134a8de9-33ef-4196-a3a8-f7c0ea846192,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-160184a9-ca44-43f7-86f4-2f753b3b0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-244e4c61-919b-4210-8c8b-150ae511dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-8de48f48-abf7-4d51-b4a9-507e2bbbf9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-ecf121c5-1ab9-4da2-b78b-105d4b6a04f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-5582820b-9f46-41d5-94cd-5d689714fe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-651d552a-326c-4f10-9357-30c745e50f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947116975-172.17.0.17-1595597492663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-2e194598-e9e7-4f3a-972e-17014a2bd65a,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-134a8de9-33ef-4196-a3a8-f7c0ea846192,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-160184a9-ca44-43f7-86f4-2f753b3b0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-244e4c61-919b-4210-8c8b-150ae511dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-8de48f48-abf7-4d51-b4a9-507e2bbbf9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-ecf121c5-1ab9-4da2-b78b-105d4b6a04f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-5582820b-9f46-41d5-94cd-5d689714fe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-651d552a-326c-4f10-9357-30c745e50f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571775989-172.17.0.17-1595598083326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-793df96c-f94e-4fb9-91d8-8f6d3fc160a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-696fdd7b-6ddc-4cbb-b210-a80677086200,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-9208b310-28a3-4cb5-840e-8e49cb84a990,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-83450372-9843-4ede-a41c-3e87e910d96f,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-d1ca9b1f-27a8-4f8b-822c-9bf50ee82f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-741ac24d-bff7-4467-a52c-72c74ff9b785,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-f5223ad6-858e-4e6c-b33d-8ab1c19a8b66,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-79403b40-f641-4cc2-a43e-191b2fdc3ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571775989-172.17.0.17-1595598083326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-793df96c-f94e-4fb9-91d8-8f6d3fc160a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-696fdd7b-6ddc-4cbb-b210-a80677086200,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-9208b310-28a3-4cb5-840e-8e49cb84a990,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-83450372-9843-4ede-a41c-3e87e910d96f,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-d1ca9b1f-27a8-4f8b-822c-9bf50ee82f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-741ac24d-bff7-4467-a52c-72c74ff9b785,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-f5223ad6-858e-4e6c-b33d-8ab1c19a8b66,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-79403b40-f641-4cc2-a43e-191b2fdc3ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707772695-172.17.0.17-1595598118308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44963,DS-ac4367cc-d904-46bf-819a-60f32274bea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-3859a167-7880-4874-bcb8-3ca62013dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-fcee11f9-077f-4cac-b0a6-b52c58770e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-7effa452-2e78-47e0-97d3-f29e254ea042,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-e98aa3d4-336d-427c-b0ee-17dcf4422f06,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-0651840c-081b-4536-a683-4cc4e0e1dc65,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-0a9da254-2a85-4050-9ff8-7f3dfc1c2fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-142c00b2-7179-4aa1-bf8f-cd3419dfcf76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707772695-172.17.0.17-1595598118308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44963,DS-ac4367cc-d904-46bf-819a-60f32274bea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-3859a167-7880-4874-bcb8-3ca62013dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-fcee11f9-077f-4cac-b0a6-b52c58770e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-7effa452-2e78-47e0-97d3-f29e254ea042,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-e98aa3d4-336d-427c-b0ee-17dcf4422f06,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-0651840c-081b-4536-a683-4cc4e0e1dc65,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-0a9da254-2a85-4050-9ff8-7f3dfc1c2fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-142c00b2-7179-4aa1-bf8f-cd3419dfcf76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5171
