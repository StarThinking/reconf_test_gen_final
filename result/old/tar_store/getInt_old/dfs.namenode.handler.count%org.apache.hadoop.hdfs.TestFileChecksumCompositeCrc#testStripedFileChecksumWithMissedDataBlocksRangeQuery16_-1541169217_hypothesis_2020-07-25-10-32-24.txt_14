reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423923002-172.17.0.16-1595673159547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39049,DS-8e2c0770-8cfc-413f-963b-096e94a0d7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-28a1c24c-3c83-475f-ba67-f535c1cf910e,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-b873b628-0ebb-47a9-8afc-34fc2720a140,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-1c2ed352-16dc-43b4-81ce-25ea72458d31,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-6de12a01-b23e-40ff-8918-e55dad7d48db,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-8071c1f5-5c48-4188-9ba6-f2e2171ee0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-f1f2afdf-4956-49db-9d42-3a658b07ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-bd5cb9e5-8fd3-42ba-b5b8-f2ef4c45c97c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423923002-172.17.0.16-1595673159547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39049,DS-8e2c0770-8cfc-413f-963b-096e94a0d7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-28a1c24c-3c83-475f-ba67-f535c1cf910e,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-b873b628-0ebb-47a9-8afc-34fc2720a140,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-1c2ed352-16dc-43b4-81ce-25ea72458d31,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-6de12a01-b23e-40ff-8918-e55dad7d48db,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-8071c1f5-5c48-4188-9ba6-f2e2171ee0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-f1f2afdf-4956-49db-9d42-3a658b07ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-bd5cb9e5-8fd3-42ba-b5b8-f2ef4c45c97c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530110563-172.17.0.16-1595673709190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-762d6379-83ac-448c-8660-d6654fb61006,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-eb84786c-c5a4-48de-8b9a-a1189a0e0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-e9f45722-f7e8-4b6b-ba33-77b01ca408f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-ce7fbdf3-08fc-4121-8cc8-6d9e149b87f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-fae98f41-9166-4ca3-9050-376fb29f203b,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-7ad899bb-ed87-46a6-9469-e0338b31813d,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-be8f7b82-23c1-49ed-8178-b4191dcc1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-4968ac17-c85c-4bae-a4a6-f084bee4dd0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530110563-172.17.0.16-1595673709190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-762d6379-83ac-448c-8660-d6654fb61006,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-eb84786c-c5a4-48de-8b9a-a1189a0e0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-e9f45722-f7e8-4b6b-ba33-77b01ca408f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-ce7fbdf3-08fc-4121-8cc8-6d9e149b87f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-fae98f41-9166-4ca3-9050-376fb29f203b,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-7ad899bb-ed87-46a6-9469-e0338b31813d,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-be8f7b82-23c1-49ed-8178-b4191dcc1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-4968ac17-c85c-4bae-a4a6-f084bee4dd0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363458520-172.17.0.16-1595674010769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-898a7644-9268-4e36-b8fd-95e650893120,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-e7e9597c-1e15-4995-ae77-ce542de70257,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-09a599a6-1612-4b6e-917c-6fffd4587ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-3b7d242e-f0d3-4792-a554-11aec5c878e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-d888cc9a-c3fb-4c1f-9bb5-01c1e68599ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-987c435b-ff43-41f0-a694-7b620167cb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-62a46da3-441b-4b66-808b-f01542f5170b,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-de800e2f-3fec-4cf9-877c-70a355105de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363458520-172.17.0.16-1595674010769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-898a7644-9268-4e36-b8fd-95e650893120,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-e7e9597c-1e15-4995-ae77-ce542de70257,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-09a599a6-1612-4b6e-917c-6fffd4587ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-3b7d242e-f0d3-4792-a554-11aec5c878e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-d888cc9a-c3fb-4c1f-9bb5-01c1e68599ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-987c435b-ff43-41f0-a694-7b620167cb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-62a46da3-441b-4b66-808b-f01542f5170b,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-de800e2f-3fec-4cf9-877c-70a355105de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808752336-172.17.0.16-1595674195686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-d8e2fcd9-cd2b-4a3c-b3b6-a7798457ccca,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-7b04da36-14e3-4c5b-8025-f15792c3b2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-18822877-216e-4e86-931c-19489eca73f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-101b97ba-5235-4d2f-8fa0-a42ea9a9a749,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-a917b7c6-2169-45d4-9991-a954b36eac4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-0742a737-3f83-40d0-a110-bb06b5c3bb18,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-7e7196ed-57f3-4851-915b-581ba05726b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-d2149c46-a29f-431f-8134-81afc4c40a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808752336-172.17.0.16-1595674195686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-d8e2fcd9-cd2b-4a3c-b3b6-a7798457ccca,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-7b04da36-14e3-4c5b-8025-f15792c3b2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-18822877-216e-4e86-931c-19489eca73f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-101b97ba-5235-4d2f-8fa0-a42ea9a9a749,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-a917b7c6-2169-45d4-9991-a954b36eac4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-0742a737-3f83-40d0-a110-bb06b5c3bb18,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-7e7196ed-57f3-4851-915b-581ba05726b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-d2149c46-a29f-431f-8134-81afc4c40a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532388281-172.17.0.16-1595675161275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-32d7f0c1-5894-4ba3-82c4-51edb8c2bc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-322e84b0-c381-4b88-bab4-6333cadb4353,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-ba44f944-df31-4e12-b7a7-3b37ca07e652,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-3b15a91a-f182-4714-a111-4eb10c5c8ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-2e51ee91-2ffd-4b0a-9a39-c768598930ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-feeabf43-9610-44e5-af7d-94c07f5b7170,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-807d8ee2-a963-4d1e-9966-5d7516cf9723,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-973e91f0-7aaf-4fb7-a287-cd0962470d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532388281-172.17.0.16-1595675161275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-32d7f0c1-5894-4ba3-82c4-51edb8c2bc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-322e84b0-c381-4b88-bab4-6333cadb4353,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-ba44f944-df31-4e12-b7a7-3b37ca07e652,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-3b15a91a-f182-4714-a111-4eb10c5c8ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-2e51ee91-2ffd-4b0a-9a39-c768598930ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-feeabf43-9610-44e5-af7d-94c07f5b7170,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-807d8ee2-a963-4d1e-9966-5d7516cf9723,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-973e91f0-7aaf-4fb7-a287-cd0962470d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666844996-172.17.0.16-1595675500833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33220,DS-ea644940-7d42-4746-8283-cda124f07cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-d5e8e080-1eb9-45be-b3a4-7ded1a3f314e,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-811e7017-e569-412a-b648-eed13f49be42,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-4f979eba-6f60-4cf6-abd2-94c80108af54,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-7de0a6f4-b857-47fc-9d3d-ccad837643f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-1a3c6cfa-3ef8-4e30-a720-39c3c45d2ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-07adf4ae-c6d5-4e0c-a339-37cb136bf13d,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-0133d359-9d5b-4d92-b9fb-3ece17d34286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666844996-172.17.0.16-1595675500833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33220,DS-ea644940-7d42-4746-8283-cda124f07cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-d5e8e080-1eb9-45be-b3a4-7ded1a3f314e,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-811e7017-e569-412a-b648-eed13f49be42,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-4f979eba-6f60-4cf6-abd2-94c80108af54,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-7de0a6f4-b857-47fc-9d3d-ccad837643f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-1a3c6cfa-3ef8-4e30-a720-39c3c45d2ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-07adf4ae-c6d5-4e0c-a339-37cb136bf13d,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-0133d359-9d5b-4d92-b9fb-3ece17d34286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991323544-172.17.0.16-1595675636269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45286,DS-14c201aa-aa33-4cf8-abca-7013fbe3e686,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-5d176f9b-ca50-4491-a589-4deec452198e,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-db3d7a9e-5596-4f15-9917-4d41b59f61dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-52b589d7-78f6-4b8c-a6ee-4ea6386ee59c,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-d379c9e1-1677-41af-8f77-e002f8a822eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-d1152cb9-7c49-4386-904a-a5f2e43555e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-7053ad58-0e64-41c2-aa9f-c228788e97da,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-3ae07ce4-1552-4eda-b766-2757fcb9e79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991323544-172.17.0.16-1595675636269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45286,DS-14c201aa-aa33-4cf8-abca-7013fbe3e686,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-5d176f9b-ca50-4491-a589-4deec452198e,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-db3d7a9e-5596-4f15-9917-4d41b59f61dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-52b589d7-78f6-4b8c-a6ee-4ea6386ee59c,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-d379c9e1-1677-41af-8f77-e002f8a822eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-d1152cb9-7c49-4386-904a-a5f2e43555e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-7053ad58-0e64-41c2-aa9f-c228788e97da,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-3ae07ce4-1552-4eda-b766-2757fcb9e79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234645818-172.17.0.16-1595676025997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-82317d05-f765-47f6-acb2-439ea5399798,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-e92506bf-8681-4b37-ae48-92718e58d405,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-799c32b8-a9ae-4f7b-8db0-9f527649c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-4330d2a3-b1f6-4cfc-aa67-c866f5098f26,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-ba2ce1bc-218e-4434-b22f-8b8c364e37f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-a51e862a-c7a3-4758-be26-10a5510e56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-6a6bb7f3-c74b-4a1a-9a3f-5a6ab6688146,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-64db1248-3a0b-497b-bf10-8326069ae6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234645818-172.17.0.16-1595676025997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-82317d05-f765-47f6-acb2-439ea5399798,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-e92506bf-8681-4b37-ae48-92718e58d405,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-799c32b8-a9ae-4f7b-8db0-9f527649c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-4330d2a3-b1f6-4cfc-aa67-c866f5098f26,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-ba2ce1bc-218e-4434-b22f-8b8c364e37f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-a51e862a-c7a3-4758-be26-10a5510e56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-6a6bb7f3-c74b-4a1a-9a3f-5a6ab6688146,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-64db1248-3a0b-497b-bf10-8326069ae6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302631803-172.17.0.16-1595676159061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34623,DS-8ddbb191-4880-480e-8382-1c14129cbe4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-e8ba5c0b-a793-4b00-9511-fde15d36e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-bd20d893-dba9-4952-b505-6ac4d1fca800,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-cb2664cc-3894-4e40-bf6b-362b018d72dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-323430a2-bb2d-4d85-a551-9a8d6659ece0,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-088c7d04-d800-4fa6-9955-754dd5de1551,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-9add3713-d986-48b5-82c9-3bd6f498d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-541523b8-5b93-442c-a553-5ec3991ea250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302631803-172.17.0.16-1595676159061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34623,DS-8ddbb191-4880-480e-8382-1c14129cbe4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-e8ba5c0b-a793-4b00-9511-fde15d36e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-bd20d893-dba9-4952-b505-6ac4d1fca800,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-cb2664cc-3894-4e40-bf6b-362b018d72dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-323430a2-bb2d-4d85-a551-9a8d6659ece0,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-088c7d04-d800-4fa6-9955-754dd5de1551,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-9add3713-d986-48b5-82c9-3bd6f498d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-541523b8-5b93-442c-a553-5ec3991ea250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544667213-172.17.0.16-1595676555271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37096,DS-5f160bce-477a-4a96-a1ac-e7ca4311ae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-39f2235b-3536-453b-b2e5-92557a0a9cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-7f800884-0cb7-4bc3-9d24-48c799bf4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-d2c06718-b907-46fd-9cd3-9fae9a0403cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-13c37705-4e51-4634-ab51-40df99efc0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-e18f6058-5988-4ef1-91c4-af9eb875ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-372afd74-7e25-4597-98f9-94506330112a,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-d2c9aff5-70b3-4720-883e-88c9da4d3f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544667213-172.17.0.16-1595676555271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37096,DS-5f160bce-477a-4a96-a1ac-e7ca4311ae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-39f2235b-3536-453b-b2e5-92557a0a9cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-7f800884-0cb7-4bc3-9d24-48c799bf4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-d2c06718-b907-46fd-9cd3-9fae9a0403cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-13c37705-4e51-4634-ab51-40df99efc0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-e18f6058-5988-4ef1-91c4-af9eb875ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-372afd74-7e25-4597-98f9-94506330112a,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-d2c9aff5-70b3-4720-883e-88c9da4d3f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381080581-172.17.0.16-1595676588325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43511,DS-8a876882-9b40-4597-96b3-fb13f84aa60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-9c9ae192-9204-48be-9771-6ec3ef95f961,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-b9d50262-ed26-45c4-b986-9f43868dbbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-7a3f7563-b841-46f7-ac4d-b896e7455b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-c4069347-65fa-45ba-9205-3866dafc9682,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-f1e1b2b3-c5e3-497d-aef5-c66e143c9326,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-75c943a9-182b-436f-bd9d-8e71a83cadd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-81d24df8-2b9d-4b82-a7f4-a1ac8306c47f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381080581-172.17.0.16-1595676588325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43511,DS-8a876882-9b40-4597-96b3-fb13f84aa60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-9c9ae192-9204-48be-9771-6ec3ef95f961,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-b9d50262-ed26-45c4-b986-9f43868dbbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-7a3f7563-b841-46f7-ac4d-b896e7455b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-c4069347-65fa-45ba-9205-3866dafc9682,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-f1e1b2b3-c5e3-497d-aef5-c66e143c9326,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-75c943a9-182b-436f-bd9d-8e71a83cadd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-81d24df8-2b9d-4b82-a7f4-a1ac8306c47f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496336676-172.17.0.16-1595677186837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-a0988d75-86df-472d-a1c4-b5279a9c490d,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-9f338e9f-2102-4705-8599-3cd76c80a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-7db7a15d-c102-4d0c-a631-d9f9d555405d,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-f1f50702-bf92-4c98-b9f6-f8b68f0d9080,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-0a85e01d-67ab-4bab-9bd0-f5733bdb476e,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-e0d411be-84b9-4c98-849b-b9cc4bf38d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-2b361971-e27c-4e6e-952a-fc3e415026dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-3993bdf8-9217-4791-9327-0670e4bee2d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496336676-172.17.0.16-1595677186837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-a0988d75-86df-472d-a1c4-b5279a9c490d,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-9f338e9f-2102-4705-8599-3cd76c80a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-7db7a15d-c102-4d0c-a631-d9f9d555405d,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-f1f50702-bf92-4c98-b9f6-f8b68f0d9080,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-0a85e01d-67ab-4bab-9bd0-f5733bdb476e,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-e0d411be-84b9-4c98-849b-b9cc4bf38d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-2b361971-e27c-4e6e-952a-fc3e415026dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-3993bdf8-9217-4791-9327-0670e4bee2d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454514363-172.17.0.16-1595677657390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-1c12ebaf-1970-4291-9c37-54f9aed8e62e,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-45c63b9f-c02a-426b-8af9-efa8d340aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-5e086968-4a7e-418d-830b-9387bab07fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-97603438-09c1-4d6c-8636-c361cffab59c,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-c3a27b97-1499-4036-9fdf-8da0efb4f6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-7572c523-f3b5-40ec-85f9-3fa53a0e6311,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-21412590-699e-4a10-9c54-4a556dace491,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-f7d78fb1-0994-4da8-a627-a7c6a6e4c916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454514363-172.17.0.16-1595677657390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-1c12ebaf-1970-4291-9c37-54f9aed8e62e,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-45c63b9f-c02a-426b-8af9-efa8d340aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-5e086968-4a7e-418d-830b-9387bab07fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-97603438-09c1-4d6c-8636-c361cffab59c,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-c3a27b97-1499-4036-9fdf-8da0efb4f6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-7572c523-f3b5-40ec-85f9-3fa53a0e6311,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-21412590-699e-4a10-9c54-4a556dace491,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-f7d78fb1-0994-4da8-a627-a7c6a6e4c916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393959538-172.17.0.16-1595677691052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46323,DS-4ff84705-6a01-4c45-812c-c628f9444e79,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-96bdae35-3f78-4b73-80cd-79e9855b7e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-2eae7a6d-2f35-42b5-ad69-bdca07a684c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-c15fd6b3-9a23-40bc-b095-418a6fa7d704,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-38fa3075-ed8e-4cca-807b-336190a86381,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-f5d20872-e258-4412-b572-79637e987d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-014f75bd-c1f7-4acf-9f2a-82cf96adc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-26b2075a-111f-4430-9c53-368d2c02a8ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393959538-172.17.0.16-1595677691052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46323,DS-4ff84705-6a01-4c45-812c-c628f9444e79,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-96bdae35-3f78-4b73-80cd-79e9855b7e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-2eae7a6d-2f35-42b5-ad69-bdca07a684c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-c15fd6b3-9a23-40bc-b095-418a6fa7d704,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-38fa3075-ed8e-4cca-807b-336190a86381,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-f5d20872-e258-4412-b572-79637e987d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-014f75bd-c1f7-4acf-9f2a-82cf96adc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-26b2075a-111f-4430-9c53-368d2c02a8ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471453528-172.17.0.16-1595677754746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-9c76a5b1-2a7f-42a3-ae77-8b2d4de02568,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-f36f35e1-84a4-42d5-94af-f8db50290bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-5ddaa02b-5d8d-4d20-85b1-95d90f285731,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-cba74887-1e07-4d5d-9d73-9d170be7a2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-18d6a200-0682-4cd7-93a1-4671143f00d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-4f3453e0-8b93-4a6a-b5fd-b45622ffd19e,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-0131f228-1c19-4cca-b95c-b44699dda899,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-3cf379c6-592f-47de-a8c2-98aae037bd89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471453528-172.17.0.16-1595677754746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-9c76a5b1-2a7f-42a3-ae77-8b2d4de02568,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-f36f35e1-84a4-42d5-94af-f8db50290bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-5ddaa02b-5d8d-4d20-85b1-95d90f285731,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-cba74887-1e07-4d5d-9d73-9d170be7a2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-18d6a200-0682-4cd7-93a1-4671143f00d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-4f3453e0-8b93-4a6a-b5fd-b45622ffd19e,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-0131f228-1c19-4cca-b95c-b44699dda899,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-3cf379c6-592f-47de-a8c2-98aae037bd89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428354903-172.17.0.16-1595677818663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-10f51422-eb5c-41cb-9179-bc9c1074cf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-5e3e3abc-6d5d-4b26-95c4-0dc720c0d59c,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-244ffe07-adbd-4680-9004-8bf215786ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-331d3614-cd1c-4458-aa07-086932eb6d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-3229bf01-9767-4465-90ae-985453943994,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-a4d4a386-5dfa-480f-ab71-6d43f4a991ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-3516ea14-fb15-467a-8e3e-46b40763dba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-4cbeca49-0991-4b42-9e13-4fcec8a333e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428354903-172.17.0.16-1595677818663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-10f51422-eb5c-41cb-9179-bc9c1074cf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-5e3e3abc-6d5d-4b26-95c4-0dc720c0d59c,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-244ffe07-adbd-4680-9004-8bf215786ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-331d3614-cd1c-4458-aa07-086932eb6d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-3229bf01-9767-4465-90ae-985453943994,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-a4d4a386-5dfa-480f-ab71-6d43f4a991ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-3516ea14-fb15-467a-8e3e-46b40763dba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-4cbeca49-0991-4b42-9e13-4fcec8a333e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156110575-172.17.0.16-1595677880121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33460,DS-249c3db8-d582-460c-84c0-a71b95a9a787,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-7c236788-d115-4e93-b60e-5b691062cb55,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-b89e94d8-dd1c-405a-bc65-1998088697ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-8e401544-7e7f-49ea-9490-f171a2f6ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-0e334051-ff51-48a5-8a4e-9be60b4b09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-5b9c5d82-dd8f-44e2-8a35-d7e11761fb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-8d65e075-1d05-4f06-b740-1e6ba887ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-9814e457-c415-444e-b608-9b3c1f8bbe67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156110575-172.17.0.16-1595677880121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33460,DS-249c3db8-d582-460c-84c0-a71b95a9a787,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-7c236788-d115-4e93-b60e-5b691062cb55,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-b89e94d8-dd1c-405a-bc65-1998088697ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-8e401544-7e7f-49ea-9490-f171a2f6ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-0e334051-ff51-48a5-8a4e-9be60b4b09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-5b9c5d82-dd8f-44e2-8a35-d7e11761fb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-8d65e075-1d05-4f06-b740-1e6ba887ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-9814e457-c415-444e-b608-9b3c1f8bbe67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066277814-172.17.0.16-1595677973298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-da67178b-c60e-4c1b-beb1-d78ac9d66e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-2e692d4d-ccda-4b59-b28b-bd6a04b725cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-f28e6a2a-510f-4f19-8229-fb0165159ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-9836eef2-39d0-40ae-b5ac-2392f8e42eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-669158ca-18e8-4c10-82e9-f5e860839443,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-1fa8a3ef-57f3-4778-8573-b3ddceae2c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-0a1c6fa0-0564-4f6e-882a-fef66da7cb70,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-ce6b3923-a0d9-4b2f-9336-896fa56a9585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066277814-172.17.0.16-1595677973298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-da67178b-c60e-4c1b-beb1-d78ac9d66e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-2e692d4d-ccda-4b59-b28b-bd6a04b725cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-f28e6a2a-510f-4f19-8229-fb0165159ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-9836eef2-39d0-40ae-b5ac-2392f8e42eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-669158ca-18e8-4c10-82e9-f5e860839443,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-1fa8a3ef-57f3-4778-8573-b3ddceae2c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-0a1c6fa0-0564-4f6e-882a-fef66da7cb70,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-ce6b3923-a0d9-4b2f-9336-896fa56a9585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5191
