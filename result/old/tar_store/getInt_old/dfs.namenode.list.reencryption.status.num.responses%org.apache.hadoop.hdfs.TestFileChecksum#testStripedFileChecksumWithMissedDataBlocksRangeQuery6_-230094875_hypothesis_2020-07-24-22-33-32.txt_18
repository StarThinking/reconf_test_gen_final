reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632861969-172.17.0.19-1595630109731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38427,DS-24d63b68-d8c4-4bd2-a33e-6f59864be1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-e21e48b1-04b7-4291-b17d-15e9e754c959,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-16fee3d1-5112-4073-b11f-f2f4db95ca70,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-f2641486-b302-4da3-91fd-07ffd952d185,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-c28038aa-c054-4bbe-bcac-60473353166e,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-4d34d4a8-4498-4f38-b0c9-e3879bccfbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-6fef2a5c-49c6-4efe-b8f8-ea98eb003303,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-f256eb1c-78c4-4557-8e83-61b3c3791a3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632861969-172.17.0.19-1595630109731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38427,DS-24d63b68-d8c4-4bd2-a33e-6f59864be1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-e21e48b1-04b7-4291-b17d-15e9e754c959,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-16fee3d1-5112-4073-b11f-f2f4db95ca70,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-f2641486-b302-4da3-91fd-07ffd952d185,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-c28038aa-c054-4bbe-bcac-60473353166e,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-4d34d4a8-4498-4f38-b0c9-e3879bccfbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-6fef2a5c-49c6-4efe-b8f8-ea98eb003303,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-f256eb1c-78c4-4557-8e83-61b3c3791a3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526894152-172.17.0.19-1595630238340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42385,DS-1ae956ef-8a75-42ca-9897-489de2f63e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-7dce669c-9090-4d17-8d69-ea62375a635a,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-442cade1-634a-4f68-87fe-ece5f7d41b86,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-aceeda85-f957-4e3c-a133-80bbe907d56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-bdcda879-1ee1-49d8-8eff-5ae06cdfe3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-46196c73-7154-4cc0-ae92-d5ee074ed258,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-babc4673-59d1-4014-8db8-fda1c7523353,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-e6329528-e43a-4e1a-924c-657db68dbce7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526894152-172.17.0.19-1595630238340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42385,DS-1ae956ef-8a75-42ca-9897-489de2f63e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-7dce669c-9090-4d17-8d69-ea62375a635a,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-442cade1-634a-4f68-87fe-ece5f7d41b86,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-aceeda85-f957-4e3c-a133-80bbe907d56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-bdcda879-1ee1-49d8-8eff-5ae06cdfe3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-46196c73-7154-4cc0-ae92-d5ee074ed258,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-babc4673-59d1-4014-8db8-fda1c7523353,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-e6329528-e43a-4e1a-924c-657db68dbce7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188132769-172.17.0.19-1595630283042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-7ed7cd4e-e55d-457e-a56f-86a1a53f3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-2c3bec4f-ba9a-442d-b575-7da1d6405b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-bf3cd37e-0878-4fde-8183-cf0334e35fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-a83470d2-9073-48a6-af3c-70bf14850443,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-b9fec978-adab-4bdf-a31c-4c4aa21889a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-4cf0d16d-0f88-4bd3-a976-e04569e461ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-9a639029-2b4e-4cb7-a051-c95d5f12a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-e250f263-e47e-4b2d-b95e-3a6d56ebf59b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188132769-172.17.0.19-1595630283042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-7ed7cd4e-e55d-457e-a56f-86a1a53f3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-2c3bec4f-ba9a-442d-b575-7da1d6405b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-bf3cd37e-0878-4fde-8183-cf0334e35fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-a83470d2-9073-48a6-af3c-70bf14850443,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-b9fec978-adab-4bdf-a31c-4c4aa21889a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-4cf0d16d-0f88-4bd3-a976-e04569e461ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-9a639029-2b4e-4cb7-a051-c95d5f12a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-e250f263-e47e-4b2d-b95e-3a6d56ebf59b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119497116-172.17.0.19-1595630576096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-cc02cf37-8024-455a-a579-13271d5f62ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-3c5ebb9f-ef13-42e3-8fb7-579b67fda586,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-e63d8414-18dc-430b-92b5-758201b61578,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-96104ed9-16ed-4432-9068-e346ef4b5807,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-447128fc-9549-410e-b190-5ab77aa51043,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-d037d3d5-708a-4112-bf06-2760773b954c,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-de398a15-5984-4de0-8bce-6038d7162c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-c9fd4d73-8441-433b-b302-3417754062cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119497116-172.17.0.19-1595630576096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-cc02cf37-8024-455a-a579-13271d5f62ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-3c5ebb9f-ef13-42e3-8fb7-579b67fda586,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-e63d8414-18dc-430b-92b5-758201b61578,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-96104ed9-16ed-4432-9068-e346ef4b5807,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-447128fc-9549-410e-b190-5ab77aa51043,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-d037d3d5-708a-4112-bf06-2760773b954c,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-de398a15-5984-4de0-8bce-6038d7162c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-c9fd4d73-8441-433b-b302-3417754062cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293478459-172.17.0.19-1595630809928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36222,DS-c569ee1f-6641-415f-a09a-52cf9feb4dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-6744a747-dbeb-4967-96f7-23523ad8e87e,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-c17face9-2a5d-45f3-b014-ceed8e188c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-e8e12457-03ef-4030-be16-0c170308e1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-7ba3511c-3573-460d-97a2-b3f3aef8827c,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-e10201c3-375c-4d20-88ed-100d91f7e1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-52c768c5-16ce-4bb1-afb4-05825063d274,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-2e631066-3eca-4483-b79d-5a94ec6a227a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293478459-172.17.0.19-1595630809928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36222,DS-c569ee1f-6641-415f-a09a-52cf9feb4dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-6744a747-dbeb-4967-96f7-23523ad8e87e,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-c17face9-2a5d-45f3-b014-ceed8e188c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-e8e12457-03ef-4030-be16-0c170308e1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-7ba3511c-3573-460d-97a2-b3f3aef8827c,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-e10201c3-375c-4d20-88ed-100d91f7e1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-52c768c5-16ce-4bb1-afb4-05825063d274,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-2e631066-3eca-4483-b79d-5a94ec6a227a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039335466-172.17.0.19-1595631035535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42561,DS-f6ffe5fd-741d-464f-a9a7-763202d6018e,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-a8095e9f-09de-4f6e-af8a-20c897fb513e,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-662c6d3f-2350-40ef-9477-6d560db0d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-d7d79690-4b2e-4cec-9088-57d566236b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-3f365a5e-93bc-4cc0-aad8-7d6dbfa01911,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-72c355f0-3e36-4cae-8bff-699eb75c6ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-ba99c242-e1e7-4a01-aacd-757aa7a3386d,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-be270119-7c70-40b5-abb0-904e5313e981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039335466-172.17.0.19-1595631035535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42561,DS-f6ffe5fd-741d-464f-a9a7-763202d6018e,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-a8095e9f-09de-4f6e-af8a-20c897fb513e,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-662c6d3f-2350-40ef-9477-6d560db0d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-d7d79690-4b2e-4cec-9088-57d566236b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-3f365a5e-93bc-4cc0-aad8-7d6dbfa01911,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-72c355f0-3e36-4cae-8bff-699eb75c6ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-ba99c242-e1e7-4a01-aacd-757aa7a3386d,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-be270119-7c70-40b5-abb0-904e5313e981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122187754-172.17.0.19-1595631352403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-5b7c1db3-1ce0-4c65-8af4-f284415122a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-fed22858-c54b-48e0-906c-d12f02ea0e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-066cfcc9-0f76-44a1-9745-0017be27d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-4ff5cd4b-fb14-44fb-bbec-0fe813685abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-e7a5ad0c-a668-4e31-8e39-e862555bfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-bf312b00-d404-4cf2-a93e-bbfb1a66534f,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-5ff02501-f798-460f-844e-140e47d2c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-83d61a65-b4e8-48f1-937b-902301774da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122187754-172.17.0.19-1595631352403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-5b7c1db3-1ce0-4c65-8af4-f284415122a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-fed22858-c54b-48e0-906c-d12f02ea0e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-066cfcc9-0f76-44a1-9745-0017be27d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-4ff5cd4b-fb14-44fb-bbec-0fe813685abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-e7a5ad0c-a668-4e31-8e39-e862555bfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-bf312b00-d404-4cf2-a93e-bbfb1a66534f,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-5ff02501-f798-460f-844e-140e47d2c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-83d61a65-b4e8-48f1-937b-902301774da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575888874-172.17.0.19-1595631737964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32839,DS-f5c13aa6-de39-4f3c-8b13-b0874391d772,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-43991684-b2cf-4ab2-849e-7614e7730235,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-685e4998-ef50-4695-aec0-9f3b3d94cef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-b7606509-1a97-41f5-8e4e-76deb68deae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-6461b689-6a3d-4e12-bec6-bf974b6dbe68,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-22ce919f-694a-4f47-86a3-856a4b14da53,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-c170039d-8116-44a8-ac9c-ea0a3aec38e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-f2fed42c-2a57-4889-a20e-cbcabf25270b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575888874-172.17.0.19-1595631737964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32839,DS-f5c13aa6-de39-4f3c-8b13-b0874391d772,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-43991684-b2cf-4ab2-849e-7614e7730235,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-685e4998-ef50-4695-aec0-9f3b3d94cef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-b7606509-1a97-41f5-8e4e-76deb68deae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-6461b689-6a3d-4e12-bec6-bf974b6dbe68,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-22ce919f-694a-4f47-86a3-856a4b14da53,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-c170039d-8116-44a8-ac9c-ea0a3aec38e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-f2fed42c-2a57-4889-a20e-cbcabf25270b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977278736-172.17.0.19-1595632040859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43723,DS-9fcfdb72-a13b-417b-8741-f81a1595c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-2a1fb1fe-ab84-4204-9af6-7d465219544d,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-b91522b5-c80b-4438-b3f8-3a7d96e36852,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-c134b6b1-a7c2-4d49-86bc-7ef156a660c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-d2b2c719-dd4d-43aa-b3ea-492e733e2c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-38ecf0cf-43d3-4c92-ab3b-e3d923ea30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-991b38a2-7204-4f45-a774-e0cc6ba65af6,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-f4df3ab6-0dc1-4a4a-bf31-7cc10c2dfdf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977278736-172.17.0.19-1595632040859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43723,DS-9fcfdb72-a13b-417b-8741-f81a1595c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-2a1fb1fe-ab84-4204-9af6-7d465219544d,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-b91522b5-c80b-4438-b3f8-3a7d96e36852,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-c134b6b1-a7c2-4d49-86bc-7ef156a660c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-d2b2c719-dd4d-43aa-b3ea-492e733e2c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-38ecf0cf-43d3-4c92-ab3b-e3d923ea30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-991b38a2-7204-4f45-a774-e0cc6ba65af6,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-f4df3ab6-0dc1-4a4a-bf31-7cc10c2dfdf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374772883-172.17.0.19-1595632139325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-50fe53b6-f2db-47a7-b1dc-8bf0f49d1920,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-da87247c-794a-433f-84b0-59656a6d48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-19b79d83-f282-4269-bb97-d408c42b61d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-c587a414-203b-4ab1-942b-293bba6bd561,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-6cec261a-e004-44fd-a0d6-50c5071210bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-7845dc21-8cdc-4274-b4cb-86a5f7734a81,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-637fd960-791e-48b3-b78c-b3f2c1867bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-f946f13c-5d94-47f2-b18d-a443b0e2325e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374772883-172.17.0.19-1595632139325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-50fe53b6-f2db-47a7-b1dc-8bf0f49d1920,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-da87247c-794a-433f-84b0-59656a6d48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-19b79d83-f282-4269-bb97-d408c42b61d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-c587a414-203b-4ab1-942b-293bba6bd561,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-6cec261a-e004-44fd-a0d6-50c5071210bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-7845dc21-8cdc-4274-b4cb-86a5f7734a81,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-637fd960-791e-48b3-b78c-b3f2c1867bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-f946f13c-5d94-47f2-b18d-a443b0e2325e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835463079-172.17.0.19-1595632818662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-8bb7a186-6657-4863-9cac-a0aadff09da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-e5dd654f-2c1a-400a-9b5d-7405ecb44643,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-12e78c4c-ca3b-4482-bed4-f0238090b922,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-b9046394-3b79-4e3c-bba5-81745f6108cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-4a537a98-04db-43fe-a74d-31eee8033d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-0beae8c1-2027-4215-a3f1-12f81a8794da,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-8bae31b4-70a1-433d-8d50-37dcf1b2052e,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-5069f3d2-ba54-4918-8180-1dd65f1a64c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835463079-172.17.0.19-1595632818662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-8bb7a186-6657-4863-9cac-a0aadff09da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-e5dd654f-2c1a-400a-9b5d-7405ecb44643,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-12e78c4c-ca3b-4482-bed4-f0238090b922,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-b9046394-3b79-4e3c-bba5-81745f6108cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-4a537a98-04db-43fe-a74d-31eee8033d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-0beae8c1-2027-4215-a3f1-12f81a8794da,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-8bae31b4-70a1-433d-8d50-37dcf1b2052e,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-5069f3d2-ba54-4918-8180-1dd65f1a64c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018893256-172.17.0.19-1595633095173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-59753bff-cc00-407b-9911-fb5ce1d34472,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-61f75fa7-ee78-416f-8cbe-56f9a8962620,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-4d3087b9-7f5f-4281-829c-a73ac1b4e949,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-658e28f3-a7e1-43d3-9d9d-8ccfc4b50073,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-6e276fbd-068b-401a-9978-faef6704922f,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-71d1814a-4d0c-41db-a5fd-290377a00d06,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-36e8760f-4cd9-4c83-891c-4f7f4af419ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-30cf7aa9-0c00-4b2b-9c98-9620a062ba26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018893256-172.17.0.19-1595633095173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-59753bff-cc00-407b-9911-fb5ce1d34472,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-61f75fa7-ee78-416f-8cbe-56f9a8962620,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-4d3087b9-7f5f-4281-829c-a73ac1b4e949,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-658e28f3-a7e1-43d3-9d9d-8ccfc4b50073,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-6e276fbd-068b-401a-9978-faef6704922f,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-71d1814a-4d0c-41db-a5fd-290377a00d06,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-36e8760f-4cd9-4c83-891c-4f7f4af419ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-30cf7aa9-0c00-4b2b-9c98-9620a062ba26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9189240-172.17.0.19-1595633287316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39420,DS-330b04c2-3774-4c60-a8ff-6386e7ba05f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-c97e94fe-8d8a-474b-bb4d-a382f04de467,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-4c169a6e-ac14-4c87-8bfc-f20e4aa40f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-957a89d7-bd3b-4478-9b4c-33193df7bea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-0a8443df-7a2d-40cc-9947-7ffcbb61e099,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-86131045-9281-4734-95ac-7e6f51fecdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-bda3e358-6363-4ca6-b01e-b863a9cff4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-16c781ad-7067-4213-9f41-52c8d5cf07ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9189240-172.17.0.19-1595633287316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39420,DS-330b04c2-3774-4c60-a8ff-6386e7ba05f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-c97e94fe-8d8a-474b-bb4d-a382f04de467,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-4c169a6e-ac14-4c87-8bfc-f20e4aa40f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-957a89d7-bd3b-4478-9b4c-33193df7bea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-0a8443df-7a2d-40cc-9947-7ffcbb61e099,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-86131045-9281-4734-95ac-7e6f51fecdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-bda3e358-6363-4ca6-b01e-b863a9cff4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-16c781ad-7067-4213-9f41-52c8d5cf07ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834100382-172.17.0.19-1595633370361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-4e7da3fd-1b99-4b4d-a602-ed8c22827f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-2025c493-13df-4473-88b8-3ddf3b0ce251,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-39333edd-b78e-4aa0-8bf5-c8b0d1dd3042,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-971ce063-9908-4a04-ae77-c052d1d4baa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-18ac4d1c-8578-4c15-8586-e40c5c2587e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-56ba7a7f-2496-47ee-b471-c5632f305bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-605a3271-d165-4d64-a05d-1c06614991d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-cab08916-d03a-49b4-8756-1b0efd6a776f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834100382-172.17.0.19-1595633370361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-4e7da3fd-1b99-4b4d-a602-ed8c22827f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-2025c493-13df-4473-88b8-3ddf3b0ce251,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-39333edd-b78e-4aa0-8bf5-c8b0d1dd3042,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-971ce063-9908-4a04-ae77-c052d1d4baa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-18ac4d1c-8578-4c15-8586-e40c5c2587e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-56ba7a7f-2496-47ee-b471-c5632f305bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-605a3271-d165-4d64-a05d-1c06614991d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-cab08916-d03a-49b4-8756-1b0efd6a776f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114475337-172.17.0.19-1595633419356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38989,DS-1700811c-6cd4-489a-872e-21daaee3ab5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-8e4e8fe1-2c61-4e7e-acd3-aafb0948eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-8d61ebf1-4107-492f-ab03-96c22e09d4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-003593d2-4173-4ade-bbfd-e1702a697e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-fec0d3a5-a8c3-4055-bf97-3adb97fef485,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-a2f1c52e-13f9-4f1c-88d9-3d5c654600aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-9f6183a9-71e6-46cf-a3bf-548ea692ede7,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-17ce56d3-d009-4a0c-976e-000103e58a90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114475337-172.17.0.19-1595633419356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38989,DS-1700811c-6cd4-489a-872e-21daaee3ab5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-8e4e8fe1-2c61-4e7e-acd3-aafb0948eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-8d61ebf1-4107-492f-ab03-96c22e09d4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-003593d2-4173-4ade-bbfd-e1702a697e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-fec0d3a5-a8c3-4055-bf97-3adb97fef485,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-a2f1c52e-13f9-4f1c-88d9-3d5c654600aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-9f6183a9-71e6-46cf-a3bf-548ea692ede7,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-17ce56d3-d009-4a0c-976e-000103e58a90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083191707-172.17.0.19-1595633608721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37027,DS-e00303b1-7b2b-4811-ad26-e88edc634e76,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-673f5634-1678-4822-ba22-6a28472eb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-6313365c-9a79-471f-9210-c2721e77489e,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-a01f6926-8cb7-4c41-9b92-4762b8744761,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-df30b83b-5a74-4d5c-b3c0-f6ed9a8230ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-0b0994df-d4e7-4743-a704-953168debb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-1fabdf72-6af0-458b-b4af-8294a95615ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-dea14c20-8683-48fa-a6fc-d2426e66a824,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083191707-172.17.0.19-1595633608721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37027,DS-e00303b1-7b2b-4811-ad26-e88edc634e76,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-673f5634-1678-4822-ba22-6a28472eb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-6313365c-9a79-471f-9210-c2721e77489e,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-a01f6926-8cb7-4c41-9b92-4762b8744761,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-df30b83b-5a74-4d5c-b3c0-f6ed9a8230ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-0b0994df-d4e7-4743-a704-953168debb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-1fabdf72-6af0-458b-b4af-8294a95615ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-dea14c20-8683-48fa-a6fc-d2426e66a824,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054121859-172.17.0.19-1595633784997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33881,DS-aaccd00c-ece1-4ab5-b658-8346afc56409,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-784b7a37-6650-4ad3-9e3b-020c1ac9c9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-74f0b966-8f8e-474d-ae4b-6cdce55a386a,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-44fb5578-abae-40d0-b5e6-66812c5b4d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-b786e654-69c1-413f-acc7-967b8b6db61f,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-c610ff04-8305-433a-9573-a72b1aad550c,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-871907a8-1f6c-479f-9303-24d96f58fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-47b90b1c-cf0d-4616-ad03-84453778b89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054121859-172.17.0.19-1595633784997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33881,DS-aaccd00c-ece1-4ab5-b658-8346afc56409,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-784b7a37-6650-4ad3-9e3b-020c1ac9c9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-74f0b966-8f8e-474d-ae4b-6cdce55a386a,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-44fb5578-abae-40d0-b5e6-66812c5b4d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-b786e654-69c1-413f-acc7-967b8b6db61f,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-c610ff04-8305-433a-9573-a72b1aad550c,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-871907a8-1f6c-479f-9303-24d96f58fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-47b90b1c-cf0d-4616-ad03-84453778b89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499548990-172.17.0.19-1595634151086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38072,DS-bcddd199-60eb-4e38-9cba-9617200bc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-cbb2c183-c462-4f76-b7dc-8122c5b73f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-efe311ad-726a-4e8e-9554-6e79071fa3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-876360a0-6d7c-4288-98c7-6befbb7e7d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-877948fb-c57d-4bb6-98f1-7652c764237a,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-77e554ff-004c-4670-925e-5cbeacc09eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-c56338a7-198c-4172-9d72-09d84b4a6531,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-38b9608b-1552-44ad-868a-95d12c7c1688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499548990-172.17.0.19-1595634151086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38072,DS-bcddd199-60eb-4e38-9cba-9617200bc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-cbb2c183-c462-4f76-b7dc-8122c5b73f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-efe311ad-726a-4e8e-9554-6e79071fa3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-876360a0-6d7c-4288-98c7-6befbb7e7d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-877948fb-c57d-4bb6-98f1-7652c764237a,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-77e554ff-004c-4670-925e-5cbeacc09eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-c56338a7-198c-4172-9d72-09d84b4a6531,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-38b9608b-1552-44ad-868a-95d12c7c1688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168196470-172.17.0.19-1595634636140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-2c50da9c-c1d5-4932-b702-9bec6fc37333,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-6431ebb6-18b9-46ac-8031-76dec423a387,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-9240dfd6-8fda-4184-8032-5636a7751ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-cbe49c44-2e57-417d-900b-99e2a5565042,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-e027a2f5-bfbf-4549-908f-ef95ba0416d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-1cfc8f54-a1e0-41d6-aaa0-a0830f44721d,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-a86848c2-9a22-4beb-9c53-ac6d1309b0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-aae4273a-6f0d-4d20-8055-37d1b94c1e72,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168196470-172.17.0.19-1595634636140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-2c50da9c-c1d5-4932-b702-9bec6fc37333,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-6431ebb6-18b9-46ac-8031-76dec423a387,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-9240dfd6-8fda-4184-8032-5636a7751ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-cbe49c44-2e57-417d-900b-99e2a5565042,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-e027a2f5-bfbf-4549-908f-ef95ba0416d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-1cfc8f54-a1e0-41d6-aaa0-a0830f44721d,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-a86848c2-9a22-4beb-9c53-ac6d1309b0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-aae4273a-6f0d-4d20-8055-37d1b94c1e72,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644028405-172.17.0.19-1595634675443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46438,DS-4ddf4dc1-a6b3-4ff0-b9be-11e7c134d832,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-bb80cd9f-a56f-4792-a7d2-e4a83d190afa,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-a11c57a3-a56a-44a3-9659-cc367818e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-e3d35544-471e-46fd-86d4-04e56a3e3737,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-3f7bc1ff-2187-456a-b01f-fa66c65b293a,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-4812aec9-e358-4911-8c6f-d7c39bc14be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-dd8958ff-7c65-45f3-b9c6-bd6fafd68121,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-be95687d-7575-41ec-8859-63ba9afeb275,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644028405-172.17.0.19-1595634675443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46438,DS-4ddf4dc1-a6b3-4ff0-b9be-11e7c134d832,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-bb80cd9f-a56f-4792-a7d2-e4a83d190afa,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-a11c57a3-a56a-44a3-9659-cc367818e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-e3d35544-471e-46fd-86d4-04e56a3e3737,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-3f7bc1ff-2187-456a-b01f-fa66c65b293a,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-4812aec9-e358-4911-8c6f-d7c39bc14be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-dd8958ff-7c65-45f3-b9c6-bd6fafd68121,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-be95687d-7575-41ec-8859-63ba9afeb275,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851390251-172.17.0.19-1595634768399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43292,DS-c3ebec94-361f-4283-9afd-54990f6ec2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d660402c-b566-4bba-a7f6-0bcf3e623ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-b9e04fa8-1475-4978-9d59-058144b2018f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-deb7d25a-3e36-40f9-b812-6a76381387f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-7e750d81-4470-45b0-9af4-f5562de21188,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-d7b1685b-f12e-4858-b079-a61ccb3db4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-13573e46-f529-4620-958b-fd5217ba6c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-adfaf793-9087-4881-9acd-7260f34078ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851390251-172.17.0.19-1595634768399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43292,DS-c3ebec94-361f-4283-9afd-54990f6ec2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d660402c-b566-4bba-a7f6-0bcf3e623ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-b9e04fa8-1475-4978-9d59-058144b2018f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-deb7d25a-3e36-40f9-b812-6a76381387f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-7e750d81-4470-45b0-9af4-f5562de21188,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-d7b1685b-f12e-4858-b079-a61ccb3db4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-13573e46-f529-4620-958b-fd5217ba6c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-adfaf793-9087-4881-9acd-7260f34078ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665440632-172.17.0.19-1595634910438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42923,DS-27c1f51f-2b35-45f3-9054-c8d63831cdab,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-63cfbc52-a90e-4e55-8d26-196849e51a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-d79b16be-fe95-4588-be2d-27f7350c5cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-72ffe993-08ba-4739-b7d7-3494ac30ec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-6981f91d-9bd7-4339-8b75-31162fcc65f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-e5b35067-7124-4435-af9e-38b71b014c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-150b128c-2dad-4da5-b217-61fd00e277f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-2d6dcd25-36b1-4e3b-8cae-62a370eb571b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665440632-172.17.0.19-1595634910438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42923,DS-27c1f51f-2b35-45f3-9054-c8d63831cdab,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-63cfbc52-a90e-4e55-8d26-196849e51a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-d79b16be-fe95-4588-be2d-27f7350c5cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-72ffe993-08ba-4739-b7d7-3494ac30ec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-6981f91d-9bd7-4339-8b75-31162fcc65f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-e5b35067-7124-4435-af9e-38b71b014c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-150b128c-2dad-4da5-b217-61fd00e277f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-2d6dcd25-36b1-4e3b-8cae-62a370eb571b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982022830-172.17.0.19-1595635047933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-83836ce3-e7c6-4de5-9b4b-56763f13bccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-843f4460-e494-4b54-afee-5c828999a901,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-2f874476-dc91-4620-84a2-735758d8fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-06b67905-329e-4d99-accd-c52a07c38f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-73570076-3666-483a-a6f5-c9dbe9a81338,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-277592cd-f2fe-48af-8dfe-76e129c4ba52,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-622ec474-e046-4f15-aa57-2b07a15dc94b,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-db4ca0c7-d8da-4ed3-ae75-2bba06f67540,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982022830-172.17.0.19-1595635047933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-83836ce3-e7c6-4de5-9b4b-56763f13bccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-843f4460-e494-4b54-afee-5c828999a901,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-2f874476-dc91-4620-84a2-735758d8fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-06b67905-329e-4d99-accd-c52a07c38f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-73570076-3666-483a-a6f5-c9dbe9a81338,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-277592cd-f2fe-48af-8dfe-76e129c4ba52,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-622ec474-e046-4f15-aa57-2b07a15dc94b,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-db4ca0c7-d8da-4ed3-ae75-2bba06f67540,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634909899-172.17.0.19-1595635136016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46585,DS-a8cf619d-439a-4439-993a-4d4fe718e422,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-c417e8ee-cb54-4dbb-ada4-42dc867461fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-988887b7-24ad-4060-8135-28b2a0ad74fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-1f69eea0-fdaa-4b5f-83d4-8974fcfeb038,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-a6b8d47f-8a6a-48fb-ac2a-1dd153d3d433,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-470866dc-7b90-41ef-a176-c2c78f23cc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-d188912f-fb8d-4d18-a4bc-57708a3f533f,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-250d4a7e-e575-4d19-99d6-4a44a451e5c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634909899-172.17.0.19-1595635136016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46585,DS-a8cf619d-439a-4439-993a-4d4fe718e422,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-c417e8ee-cb54-4dbb-ada4-42dc867461fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-988887b7-24ad-4060-8135-28b2a0ad74fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-1f69eea0-fdaa-4b5f-83d4-8974fcfeb038,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-a6b8d47f-8a6a-48fb-ac2a-1dd153d3d433,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-470866dc-7b90-41ef-a176-c2c78f23cc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-d188912f-fb8d-4d18-a4bc-57708a3f533f,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-250d4a7e-e575-4d19-99d6-4a44a451e5c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522842232-172.17.0.19-1595635402434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-fbbb73d2-eb50-46a8-9966-58182e9f254b,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-85cdbdf5-c7e9-47a0-8f4b-0ca7ff69608f,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-cb0302c7-81e6-42e8-955d-7e6accc69f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-83f33151-9920-4138-bd9a-c38ad4255e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-29ba8f69-78c1-49da-ae59-1a3ac6616d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-8b7af0e7-7cbb-425b-b7c8-f2740e1a36c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-4270e008-2257-442e-8db7-e59c8a195cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-6e0fc760-0e1f-4410-b42a-30d592edcbdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522842232-172.17.0.19-1595635402434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-fbbb73d2-eb50-46a8-9966-58182e9f254b,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-85cdbdf5-c7e9-47a0-8f4b-0ca7ff69608f,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-cb0302c7-81e6-42e8-955d-7e6accc69f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-83f33151-9920-4138-bd9a-c38ad4255e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-29ba8f69-78c1-49da-ae59-1a3ac6616d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-8b7af0e7-7cbb-425b-b7c8-f2740e1a36c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-4270e008-2257-442e-8db7-e59c8a195cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-6e0fc760-0e1f-4410-b42a-30d592edcbdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691150096-172.17.0.19-1595635451777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38429,DS-baa776ab-61e0-4af8-a471-63c8998ffdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-e6397860-b87f-407c-b63d-166c62e07269,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-2e220610-0097-4e08-892c-95d1cfd93a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-3ad15bab-8ead-4734-837d-2f56d61a8554,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-4d8714eb-7c39-4436-99d9-0263127ddae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-55aba54c-2e25-4424-ba2a-0197ff4bc1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-8c1644e0-e989-4433-bc19-0058137032b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-ef88822c-742f-446c-a4bc-80dfd4b2130b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691150096-172.17.0.19-1595635451777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38429,DS-baa776ab-61e0-4af8-a471-63c8998ffdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-e6397860-b87f-407c-b63d-166c62e07269,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-2e220610-0097-4e08-892c-95d1cfd93a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-3ad15bab-8ead-4734-837d-2f56d61a8554,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-4d8714eb-7c39-4436-99d9-0263127ddae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-55aba54c-2e25-4424-ba2a-0197ff4bc1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-8c1644e0-e989-4433-bc19-0058137032b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-ef88822c-742f-446c-a4bc-80dfd4b2130b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598244145-172.17.0.19-1595635717635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44873,DS-9d3da9bd-0abe-4059-ac7e-74d2ea615ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-4366bf16-30d5-4f16-b13d-67d5c388b83b,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-0490c8ba-19b2-4a7f-a1e4-523d1ab9d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-46d8c1a4-4321-4f45-b907-f926e51c803c,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-4def6524-3a40-45a2-bcb9-a344a4ce8d02,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-633fcc21-44f3-4c60-b325-c633f9a17b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-a0349197-f5a1-45e2-af9d-849ddfa8998f,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-e801def6-f650-434f-9fde-6c6e7c820fb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598244145-172.17.0.19-1595635717635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44873,DS-9d3da9bd-0abe-4059-ac7e-74d2ea615ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-4366bf16-30d5-4f16-b13d-67d5c388b83b,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-0490c8ba-19b2-4a7f-a1e4-523d1ab9d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-46d8c1a4-4321-4f45-b907-f926e51c803c,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-4def6524-3a40-45a2-bcb9-a344a4ce8d02,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-633fcc21-44f3-4c60-b325-c633f9a17b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-a0349197-f5a1-45e2-af9d-849ddfa8998f,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-e801def6-f650-434f-9fde-6c6e7c820fb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529008619-172.17.0.19-1595635797570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36543,DS-c936655d-cdcb-4fcc-8149-25933409bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-1df0ce7f-dd18-47f4-bb97-a081c79713d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-cc3502c5-9b43-435b-a485-dde61dd5ea30,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-01c37981-76aa-4d1a-9edc-7bb8459d55c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-324d6bfa-b293-497c-b598-381fffea410b,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-6505e69e-e33c-467f-babe-1650c74b5faf,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-5febfed0-0ced-4080-815e-b8b4e4e1c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-6b9c09d4-effc-470c-942a-2c25eba57168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529008619-172.17.0.19-1595635797570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36543,DS-c936655d-cdcb-4fcc-8149-25933409bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-1df0ce7f-dd18-47f4-bb97-a081c79713d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-cc3502c5-9b43-435b-a485-dde61dd5ea30,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-01c37981-76aa-4d1a-9edc-7bb8459d55c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-324d6bfa-b293-497c-b598-381fffea410b,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-6505e69e-e33c-467f-babe-1650c74b5faf,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-5febfed0-0ced-4080-815e-b8b4e4e1c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-6b9c09d4-effc-470c-942a-2c25eba57168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218199417-172.17.0.19-1595636089372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42416,DS-6b3daa93-ca52-43c3-9600-322e9a4519a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-165dc7d6-a308-4ed7-8f60-fdb86429c945,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-3af7979d-9df0-4e25-924b-e018bf1a3414,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-6fbe7892-4458-4675-a1a2-d7f5d98cba45,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-ec88efd4-60e8-40f8-a07c-918d79e52254,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-4ee51c26-0080-4bfb-9625-5fa3dfff4f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-7aae5858-acac-45b0-b69a-ac817437ed7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-8465af72-45d4-488e-bbf6-bb8fc12c4ec9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218199417-172.17.0.19-1595636089372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42416,DS-6b3daa93-ca52-43c3-9600-322e9a4519a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-165dc7d6-a308-4ed7-8f60-fdb86429c945,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-3af7979d-9df0-4e25-924b-e018bf1a3414,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-6fbe7892-4458-4675-a1a2-d7f5d98cba45,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-ec88efd4-60e8-40f8-a07c-918d79e52254,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-4ee51c26-0080-4bfb-9625-5fa3dfff4f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-7aae5858-acac-45b0-b69a-ac817437ed7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-8465af72-45d4-488e-bbf6-bb8fc12c4ec9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133327955-172.17.0.19-1595636174190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38109,DS-19e65558-d2a6-4f87-a267-f8db03fc194a,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-524970d2-62d3-40d3-9653-e921362409b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-91200477-a43f-4300-b334-faa5fec6b89c,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-5d23bbfd-dbc2-4ed2-81f3-231022c248ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-d0250179-95a6-4ed6-9525-51ee38c9b7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-5b09c51c-7757-4bbf-8d20-f6654d262c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-f4c9f174-dc78-4a19-8156-4c68938eed3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-ebf41a91-3164-4310-b314-50342c1d6951,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133327955-172.17.0.19-1595636174190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38109,DS-19e65558-d2a6-4f87-a267-f8db03fc194a,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-524970d2-62d3-40d3-9653-e921362409b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-91200477-a43f-4300-b334-faa5fec6b89c,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-5d23bbfd-dbc2-4ed2-81f3-231022c248ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-d0250179-95a6-4ed6-9525-51ee38c9b7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-5b09c51c-7757-4bbf-8d20-f6654d262c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-f4c9f174-dc78-4a19-8156-4c68938eed3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-ebf41a91-3164-4310-b314-50342c1d6951,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894163515-172.17.0.19-1595636488301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43397,DS-e82447fe-7f94-4906-a8ea-ad56f8d6844c,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-ccb88bed-d417-480b-9435-327269ae0b07,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-45f2e82d-9ff6-4a2d-b450-1f37e4f1968f,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-d74ef2b5-403c-4ec9-8f7c-cb36e435fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-e834fa15-87c4-45a1-b740-b6eb1b526da6,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-9bc153ba-d36d-4523-a97a-6c95cacfd1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-97064a12-60b5-4ed6-894b-1fb6f7862dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-eb002d79-d4d8-4cad-8b3c-5fd89cc089ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894163515-172.17.0.19-1595636488301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43397,DS-e82447fe-7f94-4906-a8ea-ad56f8d6844c,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-ccb88bed-d417-480b-9435-327269ae0b07,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-45f2e82d-9ff6-4a2d-b450-1f37e4f1968f,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-d74ef2b5-403c-4ec9-8f7c-cb36e435fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-e834fa15-87c4-45a1-b740-b6eb1b526da6,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-9bc153ba-d36d-4523-a97a-6c95cacfd1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-97064a12-60b5-4ed6-894b-1fb6f7862dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-eb002d79-d4d8-4cad-8b3c-5fd89cc089ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 6774
