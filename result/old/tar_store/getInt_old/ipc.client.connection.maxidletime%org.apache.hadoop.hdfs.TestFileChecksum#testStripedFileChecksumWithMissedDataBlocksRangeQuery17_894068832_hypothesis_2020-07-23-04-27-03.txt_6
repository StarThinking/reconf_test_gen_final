reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365168516-172.17.0.6-1595478635952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-3d945112-8e40-43eb-9fae-f1332de29037,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-57d0dd63-e6f9-448e-be5b-5c5c7db1d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-bb70d47b-4477-4052-a16d-f326e93c7931,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-637371d7-3529-4d31-9066-c2e3eb3d4b66,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-e5ddc460-d152-46c7-a9e3-571ef04a7dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-8e1efc14-b6f1-462a-a85e-a3e30f0bd80d,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-ca163485-96cc-4078-80b6-f1376f9b123d,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-ffaa7475-6746-4bcd-a357-872ef90d7e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365168516-172.17.0.6-1595478635952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-3d945112-8e40-43eb-9fae-f1332de29037,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-57d0dd63-e6f9-448e-be5b-5c5c7db1d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-bb70d47b-4477-4052-a16d-f326e93c7931,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-637371d7-3529-4d31-9066-c2e3eb3d4b66,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-e5ddc460-d152-46c7-a9e3-571ef04a7dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-8e1efc14-b6f1-462a-a85e-a3e30f0bd80d,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-ca163485-96cc-4078-80b6-f1376f9b123d,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-ffaa7475-6746-4bcd-a357-872ef90d7e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108046520-172.17.0.6-1595478778545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36978,DS-7f63a8ee-874e-491e-b79d-72c1efab6465,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-612d852c-f7e1-4f6e-b3cf-04ade9064c95,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-b805ef05-4224-4edc-b6a5-a4a91dac3acb,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-c811bcc3-9955-4f1b-b3ae-534d1ace53c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-e75b25c2-9c95-4500-86bf-8134419c3a48,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-f547f94a-3156-4c0c-98d9-25d62c5e223a,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-d9424cc5-1c73-40f9-bf2b-e959c5bc553a,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-17fbbcab-b058-418b-b1f1-bd027005c7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108046520-172.17.0.6-1595478778545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36978,DS-7f63a8ee-874e-491e-b79d-72c1efab6465,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-612d852c-f7e1-4f6e-b3cf-04ade9064c95,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-b805ef05-4224-4edc-b6a5-a4a91dac3acb,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-c811bcc3-9955-4f1b-b3ae-534d1ace53c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-e75b25c2-9c95-4500-86bf-8134419c3a48,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-f547f94a-3156-4c0c-98d9-25d62c5e223a,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-d9424cc5-1c73-40f9-bf2b-e959c5bc553a,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-17fbbcab-b058-418b-b1f1-bd027005c7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946389282-172.17.0.6-1595479298602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-96194bad-0876-4bcd-b806-594e719f8afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-7ddccdac-d02f-4e0b-b54e-4b4659d86e83,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-9362577d-ab83-4d70-8d39-a7ac5096a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-568e18fd-4633-4ba5-9526-83dad278be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-b787f071-d491-450b-a98d-a6776f999d75,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-d268fca6-a50b-47d7-a390-0d967c483ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-b97ab5c6-200e-4497-839b-64484a630c06,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-2b528421-a69c-4e68-9593-ee2be8de2253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946389282-172.17.0.6-1595479298602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-96194bad-0876-4bcd-b806-594e719f8afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-7ddccdac-d02f-4e0b-b54e-4b4659d86e83,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-9362577d-ab83-4d70-8d39-a7ac5096a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-568e18fd-4633-4ba5-9526-83dad278be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-b787f071-d491-450b-a98d-a6776f999d75,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-d268fca6-a50b-47d7-a390-0d967c483ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-b97ab5c6-200e-4497-839b-64484a630c06,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-2b528421-a69c-4e68-9593-ee2be8de2253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669865053-172.17.0.6-1595479535040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-89ba75ba-3ae0-4f2c-820a-a7c22f34aecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-35e61f10-d9d6-4e0c-a29c-45708398ba6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-45434189-9ec6-4c95-a2d2-ecdb1758aafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-421ea9ec-e870-4f7c-a5ac-fdbf3d50ddee,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-3cce5e3e-644a-470a-8fc5-3e298e95d7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-7ec71ab3-8d8b-44f2-8f4a-52729079f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-b0da8fef-c751-4503-a83b-9513ece55235,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-94cd4ec5-2f77-4b63-a4ac-034f1b1885ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669865053-172.17.0.6-1595479535040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-89ba75ba-3ae0-4f2c-820a-a7c22f34aecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-35e61f10-d9d6-4e0c-a29c-45708398ba6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-45434189-9ec6-4c95-a2d2-ecdb1758aafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-421ea9ec-e870-4f7c-a5ac-fdbf3d50ddee,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-3cce5e3e-644a-470a-8fc5-3e298e95d7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-7ec71ab3-8d8b-44f2-8f4a-52729079f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-b0da8fef-c751-4503-a83b-9513ece55235,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-94cd4ec5-2f77-4b63-a4ac-034f1b1885ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358040937-172.17.0.6-1595480096541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-6b7ec9e1-497f-4b27-b421-142c5be44d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-8e6a70f6-7de7-4632-9fca-9929173ea579,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-f2d8736b-34e7-44a2-821c-bfdec05e20b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-9227f355-37f2-4d83-b43b-fddcf401be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-fbb5e1a4-c10d-4168-a91e-9a10b5380658,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-41581eb9-7c9a-4dbb-b04a-669295b64e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-f516c4a0-f173-4a6e-b635-30bd510c9851,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-1851e8ae-a89f-44a9-ac88-21f126b28d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358040937-172.17.0.6-1595480096541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-6b7ec9e1-497f-4b27-b421-142c5be44d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-8e6a70f6-7de7-4632-9fca-9929173ea579,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-f2d8736b-34e7-44a2-821c-bfdec05e20b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-9227f355-37f2-4d83-b43b-fddcf401be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-fbb5e1a4-c10d-4168-a91e-9a10b5380658,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-41581eb9-7c9a-4dbb-b04a-669295b64e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-f516c4a0-f173-4a6e-b635-30bd510c9851,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-1851e8ae-a89f-44a9-ac88-21f126b28d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435063235-172.17.0.6-1595480384433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-0cad0526-2fb0-4e78-b65e-c4b11d1297ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-fe0c8913-25d2-438a-9875-c951902f0527,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-57161c7d-ce92-4c56-b8ed-7a0d86719e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-15e5b5bd-0abe-4e56-99c4-1ecb13529e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-322f8079-6db6-4b3b-b99a-7983559f5a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-c81ea67d-62e8-4239-ae4f-2d2e104a6787,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-d7cf0025-4aa0-4c99-8284-4fd78c77e6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-b675fb51-65d2-4362-bd2e-5cdab56b472e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435063235-172.17.0.6-1595480384433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-0cad0526-2fb0-4e78-b65e-c4b11d1297ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-fe0c8913-25d2-438a-9875-c951902f0527,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-57161c7d-ce92-4c56-b8ed-7a0d86719e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-15e5b5bd-0abe-4e56-99c4-1ecb13529e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-322f8079-6db6-4b3b-b99a-7983559f5a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-c81ea67d-62e8-4239-ae4f-2d2e104a6787,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-d7cf0025-4aa0-4c99-8284-4fd78c77e6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-b675fb51-65d2-4362-bd2e-5cdab56b472e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124847062-172.17.0.6-1595480424713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-99408186-0728-4c82-b813-f679090418d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-4e99e58e-b804-4106-8a81-6915b0a9bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-8e9d8642-d266-4637-8ee7-17781b48fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-c1263511-c41a-43f5-9f24-4df54bd4f24f,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-b1aced45-7781-41c7-ac28-7f2bc4401f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-a024b577-5500-4a8c-a6c2-9150433f536d,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-679a9a86-0a85-47a5-8621-73e0f62ddf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-27fc5a28-fbcd-4c75-881b-9953576620a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124847062-172.17.0.6-1595480424713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-99408186-0728-4c82-b813-f679090418d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-4e99e58e-b804-4106-8a81-6915b0a9bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-8e9d8642-d266-4637-8ee7-17781b48fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-c1263511-c41a-43f5-9f24-4df54bd4f24f,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-b1aced45-7781-41c7-ac28-7f2bc4401f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-a024b577-5500-4a8c-a6c2-9150433f536d,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-679a9a86-0a85-47a5-8621-73e0f62ddf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-27fc5a28-fbcd-4c75-881b-9953576620a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291201698-172.17.0.6-1595480950888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44614,DS-15920ff9-60d3-42a5-a728-e9843496c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-63fb2b4b-cb83-4fdc-af6d-952a2ba0090c,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-c7ac4a4e-7d21-4a13-8f6c-587be164dd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-3fa79dea-581f-44ed-8a84-6de9083f65ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-98694e98-50c0-4bbc-b04a-9e6ab12c58e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-ed6dc810-a3b2-430b-8fe5-573320acf5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-614adc24-23eb-4a32-9a81-6b68627cc6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-54336c44-6e6f-4041-b5fc-2dc8823dafe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291201698-172.17.0.6-1595480950888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44614,DS-15920ff9-60d3-42a5-a728-e9843496c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-63fb2b4b-cb83-4fdc-af6d-952a2ba0090c,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-c7ac4a4e-7d21-4a13-8f6c-587be164dd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-3fa79dea-581f-44ed-8a84-6de9083f65ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-98694e98-50c0-4bbc-b04a-9e6ab12c58e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-ed6dc810-a3b2-430b-8fe5-573320acf5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-614adc24-23eb-4a32-9a81-6b68627cc6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-54336c44-6e6f-4041-b5fc-2dc8823dafe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558157655-172.17.0.6-1595481243429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-1ec07242-c985-44fe-8095-b52dd9c57dde,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-15087ebd-f1ea-41a0-8a6f-bdf67bec19e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-c3b8cdf3-7fe2-46fd-96a5-b07d781901ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-3a4cec33-d5ee-4e44-ada9-df77230e2557,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-a3137047-2c53-455b-91da-ed12eb208bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-8dcd6e84-457a-42cc-a2a1-40235be954cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-89fe86dc-aba2-4fe6-a0e6-8020d4f9da0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-7fe7849b-6aa7-493a-ab51-bcd8d25c2ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558157655-172.17.0.6-1595481243429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-1ec07242-c985-44fe-8095-b52dd9c57dde,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-15087ebd-f1ea-41a0-8a6f-bdf67bec19e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-c3b8cdf3-7fe2-46fd-96a5-b07d781901ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-3a4cec33-d5ee-4e44-ada9-df77230e2557,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-a3137047-2c53-455b-91da-ed12eb208bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-8dcd6e84-457a-42cc-a2a1-40235be954cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-89fe86dc-aba2-4fe6-a0e6-8020d4f9da0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-7fe7849b-6aa7-493a-ab51-bcd8d25c2ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615074877-172.17.0.6-1595481503713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-c9bfb220-24ed-480e-8bca-5acbd26644e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-eb0a9fd9-51f9-4eeb-9c5b-6991e9b8312b,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-1f7f9367-45a1-4bb4-8fc8-af1a64035c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-1bce225b-5d49-4645-970d-f8d3f822deea,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-a65fd833-848f-4a90-b03f-c934a43041de,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-841ba988-88b5-4e71-a1df-ea5b3766e010,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-afe631da-8e07-47e8-985f-6e5446cbe917,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-efa5baec-597c-402e-8fec-2ae33d83aa9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615074877-172.17.0.6-1595481503713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-c9bfb220-24ed-480e-8bca-5acbd26644e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-eb0a9fd9-51f9-4eeb-9c5b-6991e9b8312b,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-1f7f9367-45a1-4bb4-8fc8-af1a64035c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-1bce225b-5d49-4645-970d-f8d3f822deea,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-a65fd833-848f-4a90-b03f-c934a43041de,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-841ba988-88b5-4e71-a1df-ea5b3766e010,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-afe631da-8e07-47e8-985f-6e5446cbe917,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-efa5baec-597c-402e-8fec-2ae33d83aa9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398866683-172.17.0.6-1595481577398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36966,DS-f343ec04-95c1-4380-b505-aff29de710d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-5aaae97d-08ac-4838-b54c-6915e60cd2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-2b7a2ce6-c3b7-45a1-be5e-79a22e8e8bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-544121ab-f61c-4617-adac-6da596e02614,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-6ff7d617-b4d3-4526-a3c8-d5d5451dabae,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-dc31a50e-b0b0-4fdd-aabb-5feb95fed4db,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-36d0e69e-a366-4cce-93db-0cb3d30249f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-7f89e0af-fdf9-44cc-b9a7-bfee4a236ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398866683-172.17.0.6-1595481577398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36966,DS-f343ec04-95c1-4380-b505-aff29de710d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-5aaae97d-08ac-4838-b54c-6915e60cd2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-2b7a2ce6-c3b7-45a1-be5e-79a22e8e8bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-544121ab-f61c-4617-adac-6da596e02614,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-6ff7d617-b4d3-4526-a3c8-d5d5451dabae,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-dc31a50e-b0b0-4fdd-aabb-5feb95fed4db,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-36d0e69e-a366-4cce-93db-0cb3d30249f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-7f89e0af-fdf9-44cc-b9a7-bfee4a236ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1857623281-172.17.0.6-1595481714821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-3164ca0a-c581-45b9-96ae-b2a6a733a6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-65062ad8-1793-4a6b-9aaf-9037ddeee1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-fd082b3c-4a1c-46c9-9d49-85a9dfcab0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-efc4619e-5672-4178-8a32-9aa75000b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-540e07ba-4bc1-40b5-ba33-f1d9020e285a,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-eec7ade5-9a55-48fc-b789-208901fe0a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-2983d6e7-37c2-48d1-adfa-75927cd2d285,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-404c8de0-e821-4d23-a1de-2a1ecd2c5b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1857623281-172.17.0.6-1595481714821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-3164ca0a-c581-45b9-96ae-b2a6a733a6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-65062ad8-1793-4a6b-9aaf-9037ddeee1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-fd082b3c-4a1c-46c9-9d49-85a9dfcab0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-efc4619e-5672-4178-8a32-9aa75000b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-540e07ba-4bc1-40b5-ba33-f1d9020e285a,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-eec7ade5-9a55-48fc-b789-208901fe0a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-2983d6e7-37c2-48d1-adfa-75927cd2d285,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-404c8de0-e821-4d23-a1de-2a1ecd2c5b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245823675-172.17.0.6-1595481865838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38793,DS-83d316e1-6460-45ae-a41d-49af230683f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-cf3b2cb2-3f16-4bc2-b97b-d4275b85825d,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-95f1699c-f357-460f-97b5-e83f40fcc2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-ae54d4d0-63b6-406b-90aa-acec1d3c133c,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-ff8840e6-515b-4d53-bb6b-9cccf21b3908,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-4da1c70b-214d-4c46-b9fc-5ec2244b18f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-b17e9f08-0389-4539-8399-bd0455ccf81f,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-b1d187e5-6a9a-4518-ba13-1631aa81b777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245823675-172.17.0.6-1595481865838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38793,DS-83d316e1-6460-45ae-a41d-49af230683f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-cf3b2cb2-3f16-4bc2-b97b-d4275b85825d,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-95f1699c-f357-460f-97b5-e83f40fcc2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-ae54d4d0-63b6-406b-90aa-acec1d3c133c,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-ff8840e6-515b-4d53-bb6b-9cccf21b3908,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-4da1c70b-214d-4c46-b9fc-5ec2244b18f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-b17e9f08-0389-4539-8399-bd0455ccf81f,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-b1d187e5-6a9a-4518-ba13-1631aa81b777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510101665-172.17.0.6-1595481966169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-feaed00a-fb80-4ed8-a5c2-e32202cf3dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-2f117e1e-fd31-421f-8df3-2f0d8026572c,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-c5ae6e46-42a3-4e4e-aa5a-a09d32981210,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-d4e5e571-5961-439e-b788-602670c73625,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-8da45f3a-f575-4f1e-a356-4617489b207b,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-01a3a967-e14b-4ecc-8c63-fa1a3c8dc2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-5acf06bb-76e7-4fc1-943a-48969260abfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-60af1de9-faf4-481c-a67c-dc6c44fda260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510101665-172.17.0.6-1595481966169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-feaed00a-fb80-4ed8-a5c2-e32202cf3dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-2f117e1e-fd31-421f-8df3-2f0d8026572c,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-c5ae6e46-42a3-4e4e-aa5a-a09d32981210,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-d4e5e571-5961-439e-b788-602670c73625,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-8da45f3a-f575-4f1e-a356-4617489b207b,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-01a3a967-e14b-4ecc-8c63-fa1a3c8dc2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-5acf06bb-76e7-4fc1-943a-48969260abfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-60af1de9-faf4-481c-a67c-dc6c44fda260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294229382-172.17.0.6-1595482182550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38159,DS-e6fd8e63-0f7b-46d3-bae4-d39915d3191e,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-fb1560d4-479a-4c89-87c7-f1abd8b43a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-60589c72-e3aa-4eac-b181-4ebe188bfecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-ab91086c-9bfa-49a6-b5a9-30cbea66e834,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-6c24a089-0603-42bc-a140-716a0d895970,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-e288b11a-fcb3-46c6-b755-a4d42b7d4dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-a20ccc3e-e7f8-426c-bd07-00d2f6177ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-0bce1c70-ec60-4bfc-9642-2e3343593c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294229382-172.17.0.6-1595482182550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38159,DS-e6fd8e63-0f7b-46d3-bae4-d39915d3191e,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-fb1560d4-479a-4c89-87c7-f1abd8b43a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-60589c72-e3aa-4eac-b181-4ebe188bfecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-ab91086c-9bfa-49a6-b5a9-30cbea66e834,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-6c24a089-0603-42bc-a140-716a0d895970,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-e288b11a-fcb3-46c6-b755-a4d42b7d4dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-a20ccc3e-e7f8-426c-bd07-00d2f6177ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-0bce1c70-ec60-4bfc-9642-2e3343593c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712231107-172.17.0.6-1595482288070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-1c6b3a1b-7066-44b0-8b7a-f884d5dbcabf,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-4385a31e-a97e-403b-991c-2c69b8edd9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-65a03469-15cb-415f-8851-ff3ad46e622d,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-c9c9403e-cbc8-42e8-9fbd-842fdf36de5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-23dddb45-2841-4071-acf3-56a526a8c0be,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-58a881da-5f56-4965-ab6e-48039877587a,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-164c5a0c-71b4-4a67-b522-c06d2d49d571,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-c1ff4fb4-87cc-4dbd-a139-cb08340c9ec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712231107-172.17.0.6-1595482288070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-1c6b3a1b-7066-44b0-8b7a-f884d5dbcabf,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-4385a31e-a97e-403b-991c-2c69b8edd9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-65a03469-15cb-415f-8851-ff3ad46e622d,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-c9c9403e-cbc8-42e8-9fbd-842fdf36de5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-23dddb45-2841-4071-acf3-56a526a8c0be,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-58a881da-5f56-4965-ab6e-48039877587a,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-164c5a0c-71b4-4a67-b522-c06d2d49d571,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-c1ff4fb4-87cc-4dbd-a139-cb08340c9ec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355977928-172.17.0.6-1595482327779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-5496d6cd-aee4-43eb-b1ae-53b39dafd929,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-2b33eaa3-9a96-4120-a670-3cb7e6bb860c,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-89eea4f3-9c72-459c-8a13-3a961d36d829,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-102ed63b-27e2-47c2-b893-e8c2126e12cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-7e21b31d-84cb-48d3-a480-3adc8cf68f61,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-e39b5bb9-2001-43e2-93fc-2c2d09abba85,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-ab1e009b-5666-40bb-80b9-6be286e36cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-fb4bcbb9-0a29-4853-81e5-d6f62636d004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355977928-172.17.0.6-1595482327779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-5496d6cd-aee4-43eb-b1ae-53b39dafd929,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-2b33eaa3-9a96-4120-a670-3cb7e6bb860c,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-89eea4f3-9c72-459c-8a13-3a961d36d829,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-102ed63b-27e2-47c2-b893-e8c2126e12cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-7e21b31d-84cb-48d3-a480-3adc8cf68f61,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-e39b5bb9-2001-43e2-93fc-2c2d09abba85,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-ab1e009b-5666-40bb-80b9-6be286e36cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-fb4bcbb9-0a29-4853-81e5-d6f62636d004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517234079-172.17.0.6-1595483454254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43013,DS-a6e93baf-9576-499a-ae7f-a438e4dbca17,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-3f76b536-42ef-44e8-a81d-0ecaf00e8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-fd7c2c67-59a3-4519-afd6-f744213a0cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-2d88f4fc-9977-4aeb-9e49-2a2802f9bf11,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-fd33a02a-7bcc-42b6-95b2-c9df5bf6600f,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-fc247e6f-8458-4d52-a4e3-e3a16b161a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-d7271bdc-e329-4c8a-8fb7-10a95dd4e28a,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-a425c228-b255-4d17-bd08-d7bd28a20025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517234079-172.17.0.6-1595483454254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43013,DS-a6e93baf-9576-499a-ae7f-a438e4dbca17,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-3f76b536-42ef-44e8-a81d-0ecaf00e8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-fd7c2c67-59a3-4519-afd6-f744213a0cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-2d88f4fc-9977-4aeb-9e49-2a2802f9bf11,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-fd33a02a-7bcc-42b6-95b2-c9df5bf6600f,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-fc247e6f-8458-4d52-a4e3-e3a16b161a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-d7271bdc-e329-4c8a-8fb7-10a95dd4e28a,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-a425c228-b255-4d17-bd08-d7bd28a20025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048866122-172.17.0.6-1595483494894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45780,DS-df20d332-344e-40f0-98f0-3b97806226d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-b243ab22-c9ab-4186-8ba7-9e45828dad99,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-3760712c-82b1-4dc8-af91-53f4af1fc5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-af9fd876-e8f8-4750-b2b9-10d54b840edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-8c812cdc-c653-4f6b-a340-e4acdc15cb26,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-37cf6db3-3ef6-4a5b-92a2-963ef5300c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-1009c6c6-4a22-4c66-be1e-391618875821,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-75142cc5-8d14-4581-9f69-d4eba20ef450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048866122-172.17.0.6-1595483494894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45780,DS-df20d332-344e-40f0-98f0-3b97806226d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-b243ab22-c9ab-4186-8ba7-9e45828dad99,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-3760712c-82b1-4dc8-af91-53f4af1fc5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-af9fd876-e8f8-4750-b2b9-10d54b840edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-8c812cdc-c653-4f6b-a340-e4acdc15cb26,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-37cf6db3-3ef6-4a5b-92a2-963ef5300c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-1009c6c6-4a22-4c66-be1e-391618875821,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-75142cc5-8d14-4581-9f69-d4eba20ef450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5359
