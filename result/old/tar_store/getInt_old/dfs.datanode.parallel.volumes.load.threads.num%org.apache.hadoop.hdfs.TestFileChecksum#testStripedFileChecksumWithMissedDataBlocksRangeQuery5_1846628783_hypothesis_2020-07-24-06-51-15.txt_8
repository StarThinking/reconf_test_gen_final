reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123303191-172.17.0.18-1595573775524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43411,DS-d75b2da0-1914-4b6f-abbe-efa8274de67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-13e85c68-7846-41bf-90e6-a32c743816c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-cdb1545e-1da9-47d4-85fe-091a0c711002,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-af832792-434a-4597-9d8b-f7eb443886dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-4b1c7d9a-82e2-4874-9ceb-a0d1e3ee3de3,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-61d42764-7768-4c22-bb5e-25ed851fa0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-a7019140-24f3-4c87-bcd8-4724f2b17399,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-f7618cdb-d648-4a5d-b533-727b526e13ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123303191-172.17.0.18-1595573775524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43411,DS-d75b2da0-1914-4b6f-abbe-efa8274de67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-13e85c68-7846-41bf-90e6-a32c743816c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-cdb1545e-1da9-47d4-85fe-091a0c711002,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-af832792-434a-4597-9d8b-f7eb443886dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-4b1c7d9a-82e2-4874-9ceb-a0d1e3ee3de3,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-61d42764-7768-4c22-bb5e-25ed851fa0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-a7019140-24f3-4c87-bcd8-4724f2b17399,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-f7618cdb-d648-4a5d-b533-727b526e13ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52781628-172.17.0.18-1595575753967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-adda9957-cd8b-43f2-a064-cd87725c8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-1517dac4-2c64-4800-b225-4ed4a920ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-3571de22-4dbc-4b93-bb7e-bcad43faa523,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-66e8693a-e9b9-4de5-bc95-4e63b90aa689,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-71afd23d-a9ad-4597-89bb-ce024b07d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-f6705a4b-edbc-4162-b432-48744d22e8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-31065641-5593-4e9a-a5a7-4857dca48ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-ad5db016-13ba-4cde-913a-bbec40f95734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52781628-172.17.0.18-1595575753967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-adda9957-cd8b-43f2-a064-cd87725c8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-1517dac4-2c64-4800-b225-4ed4a920ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-3571de22-4dbc-4b93-bb7e-bcad43faa523,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-66e8693a-e9b9-4de5-bc95-4e63b90aa689,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-71afd23d-a9ad-4597-89bb-ce024b07d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-f6705a4b-edbc-4162-b432-48744d22e8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-31065641-5593-4e9a-a5a7-4857dca48ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-ad5db016-13ba-4cde-913a-bbec40f95734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098744276-172.17.0.18-1595576061591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-45c87a18-aba5-4246-99d3-9ccb299713b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-0897d742-1c7f-48d2-b330-bced720df744,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-088c0e80-c1e0-4e76-a899-42c915f2416c,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-09b22f05-5484-4ab5-887e-b9d53cad9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-34128b7b-1a01-4da3-92a9-687ccd866cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-2d4a2256-6c15-43f0-beac-bfa8ce0d8081,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-24da16bd-c473-4f13-a9aa-ac8bfdbe500a,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-f4944b44-7ce5-4fb0-95f4-0226226e5105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098744276-172.17.0.18-1595576061591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-45c87a18-aba5-4246-99d3-9ccb299713b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-0897d742-1c7f-48d2-b330-bced720df744,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-088c0e80-c1e0-4e76-a899-42c915f2416c,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-09b22f05-5484-4ab5-887e-b9d53cad9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-34128b7b-1a01-4da3-92a9-687ccd866cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-2d4a2256-6c15-43f0-beac-bfa8ce0d8081,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-24da16bd-c473-4f13-a9aa-ac8bfdbe500a,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-f4944b44-7ce5-4fb0-95f4-0226226e5105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191843632-172.17.0.18-1595577513683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45039,DS-6b55bd96-d74a-4798-bd19-40867546a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-30932cea-08f1-4dae-a86f-76795497698b,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-3c214b1d-5c74-4744-9587-3d8eca149ace,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-e7c76382-1b3c-4d7f-af46-a18684583d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-4b595723-8168-46fd-aed7-bb9cf9cb8fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-7cc6526d-1041-4687-8b09-cbab26914bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-72514993-28da-4114-ba63-45564be1a856,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-7ab91485-aa13-48ec-8c31-ff280f8d29f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191843632-172.17.0.18-1595577513683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45039,DS-6b55bd96-d74a-4798-bd19-40867546a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-30932cea-08f1-4dae-a86f-76795497698b,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-3c214b1d-5c74-4744-9587-3d8eca149ace,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-e7c76382-1b3c-4d7f-af46-a18684583d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-4b595723-8168-46fd-aed7-bb9cf9cb8fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-7cc6526d-1041-4687-8b09-cbab26914bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-72514993-28da-4114-ba63-45564be1a856,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-7ab91485-aa13-48ec-8c31-ff280f8d29f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302145502-172.17.0.18-1595577907711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-e8b49095-e47f-43ba-a62c-a7644723a619,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-22e0c728-50a7-4106-8712-5ff966e1bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-a54ad6c3-3493-4f31-9b06-b3d6e71e7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-7bc09bc8-357c-4799-947f-f2fef14e6f84,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-8a32a2ef-445a-46b9-851d-a19ef5def68a,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-8686aaea-726d-4394-8f05-a949be8ebfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-9be40f3e-bfa1-446d-8343-93bac51f2f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-e03fa5f3-f921-4171-9cd6-02d94fc5fd90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302145502-172.17.0.18-1595577907711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-e8b49095-e47f-43ba-a62c-a7644723a619,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-22e0c728-50a7-4106-8712-5ff966e1bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-a54ad6c3-3493-4f31-9b06-b3d6e71e7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-7bc09bc8-357c-4799-947f-f2fef14e6f84,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-8a32a2ef-445a-46b9-851d-a19ef5def68a,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-8686aaea-726d-4394-8f05-a949be8ebfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-9be40f3e-bfa1-446d-8343-93bac51f2f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-e03fa5f3-f921-4171-9cd6-02d94fc5fd90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356318013-172.17.0.18-1595577941660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46147,DS-d768f2c7-1256-45df-b744-307da7500572,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-2c541345-3f6b-4a9e-aee0-bc3fbf44b222,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-a5745cec-3ad0-4e31-b0f0-3404da327f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-8470da58-b72e-4e72-919e-555b588ed64d,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-3fa693ae-8d0c-4a14-a45e-9dbe4ac74faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-9f59ca8c-9f9a-40b3-a2f9-e2340feec4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-9ac8661d-8a96-41ad-bc54-8af5ce4d7d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-8430aa8b-2e87-4ed1-84e5-dda8b4c2888a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356318013-172.17.0.18-1595577941660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46147,DS-d768f2c7-1256-45df-b744-307da7500572,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-2c541345-3f6b-4a9e-aee0-bc3fbf44b222,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-a5745cec-3ad0-4e31-b0f0-3404da327f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-8470da58-b72e-4e72-919e-555b588ed64d,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-3fa693ae-8d0c-4a14-a45e-9dbe4ac74faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-9f59ca8c-9f9a-40b3-a2f9-e2340feec4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-9ac8661d-8a96-41ad-bc54-8af5ce4d7d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-8430aa8b-2e87-4ed1-84e5-dda8b4c2888a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398439101-172.17.0.18-1595577997560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39422,DS-1cbdb52a-2ffc-42ff-a182-054ea5ad1676,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-220c8278-3c9e-4af6-85e6-b6001db5d677,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-60330160-1f9f-464e-8ec7-b12af1a71fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-00c24b50-bbe2-4709-8320-4241cc6e2553,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-89c8a646-87db-43c3-907f-de5733bbfb85,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-de708a1c-2020-4c5d-b62f-0913abb6115f,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-dbb0461c-0188-47ac-a830-c27a3f18671a,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-f5c291f9-47f4-4f86-b1c6-3062d3aba2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398439101-172.17.0.18-1595577997560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39422,DS-1cbdb52a-2ffc-42ff-a182-054ea5ad1676,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-220c8278-3c9e-4af6-85e6-b6001db5d677,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-60330160-1f9f-464e-8ec7-b12af1a71fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-00c24b50-bbe2-4709-8320-4241cc6e2553,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-89c8a646-87db-43c3-907f-de5733bbfb85,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-de708a1c-2020-4c5d-b62f-0913abb6115f,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-dbb0461c-0188-47ac-a830-c27a3f18671a,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-f5c291f9-47f4-4f86-b1c6-3062d3aba2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304436555-172.17.0.18-1595578448243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-317529cd-e68f-4048-8cd6-13f606fb7d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-3b51f5ff-02ea-4ce8-9c35-846a28fc6390,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-ac353997-9cdd-478d-a81a-079a20aae7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-2d63ed52-546b-4237-bb8b-1b731d25cd69,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-f4bcbef6-74aa-4ff7-b3b1-f712538bc4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-23984a33-93a5-4f8a-96cd-5c06340076df,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-737a6d83-7b96-40f5-bbf4-c7e8d8029599,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-b570756b-430d-4f73-b136-0107d62b5109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304436555-172.17.0.18-1595578448243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-317529cd-e68f-4048-8cd6-13f606fb7d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-3b51f5ff-02ea-4ce8-9c35-846a28fc6390,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-ac353997-9cdd-478d-a81a-079a20aae7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-2d63ed52-546b-4237-bb8b-1b731d25cd69,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-f4bcbef6-74aa-4ff7-b3b1-f712538bc4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-23984a33-93a5-4f8a-96cd-5c06340076df,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-737a6d83-7b96-40f5-bbf4-c7e8d8029599,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-b570756b-430d-4f73-b136-0107d62b5109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856372461-172.17.0.18-1595578615685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34712,DS-58489bb3-2f7f-48ac-8b6e-2048edbbc78a,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-e252f497-c7d3-4b34-a40f-9009f82349c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-23d714b6-2473-451d-9273-05e102e22f53,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-630d3c61-50c5-4434-a514-c6172d9ed652,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-0a296b61-eedc-4eaa-8272-a36351bf4346,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-5fca3e78-a169-4cb1-8511-937bd87e2b58,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-8c772a22-eb7c-4d46-a330-9468aa7438e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-84698eae-d5bd-4123-af82-05955dd845d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856372461-172.17.0.18-1595578615685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34712,DS-58489bb3-2f7f-48ac-8b6e-2048edbbc78a,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-e252f497-c7d3-4b34-a40f-9009f82349c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-23d714b6-2473-451d-9273-05e102e22f53,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-630d3c61-50c5-4434-a514-c6172d9ed652,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-0a296b61-eedc-4eaa-8272-a36351bf4346,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-5fca3e78-a169-4cb1-8511-937bd87e2b58,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-8c772a22-eb7c-4d46-a330-9468aa7438e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-84698eae-d5bd-4123-af82-05955dd845d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863444318-172.17.0.18-1595579542342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-e156fe02-9cd2-4f20-b1e4-76765a6e2774,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-ebc75881-96fe-47a6-be0c-ab33291fc969,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-bb32108d-f0d2-4c7e-9e94-20584c5a3b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-09bfd939-3d99-4901-b00d-fc739569f90c,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-d54b3d36-80ae-4c89-ab70-641e57107f52,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-dcfb3fbe-43b1-44ac-903e-7d4513b6bcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-cf14ded1-c13d-4f6c-ad40-06e61579077e,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-c8edb37d-fb8a-4540-bf36-4f3b78c7fb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863444318-172.17.0.18-1595579542342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-e156fe02-9cd2-4f20-b1e4-76765a6e2774,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-ebc75881-96fe-47a6-be0c-ab33291fc969,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-bb32108d-f0d2-4c7e-9e94-20584c5a3b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-09bfd939-3d99-4901-b00d-fc739569f90c,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-d54b3d36-80ae-4c89-ab70-641e57107f52,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-dcfb3fbe-43b1-44ac-903e-7d4513b6bcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-cf14ded1-c13d-4f6c-ad40-06e61579077e,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-c8edb37d-fb8a-4540-bf36-4f3b78c7fb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6472
