reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609036411-172.17.0.15-1595529636655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-55465cc0-04d4-4618-87e0-8fe989099070,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-a48fac64-7f45-41ac-b3fa-eb3c229dab86,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-6318cde6-9065-4616-9c9d-e18892d90ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-ab4b0b87-ba3a-4065-a00a-f14c91348fee,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-754d1e81-a80f-45aa-984a-955ceeb7f307,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-d8b5b8ac-bc47-482a-8fc7-df181907e164,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-3a06bd3a-0d3a-41d2-b8c9-2b06a4ede732,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-4ff11881-d498-4c3b-98e5-67707d32db60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609036411-172.17.0.15-1595529636655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-55465cc0-04d4-4618-87e0-8fe989099070,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-a48fac64-7f45-41ac-b3fa-eb3c229dab86,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-6318cde6-9065-4616-9c9d-e18892d90ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-ab4b0b87-ba3a-4065-a00a-f14c91348fee,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-754d1e81-a80f-45aa-984a-955ceeb7f307,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-d8b5b8ac-bc47-482a-8fc7-df181907e164,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-3a06bd3a-0d3a-41d2-b8c9-2b06a4ede732,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-4ff11881-d498-4c3b-98e5-67707d32db60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231378360-172.17.0.15-1595530052378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-8caac8f5-3bc5-4963-b004-6ecf3ab2cf40,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-64b4b03f-ea9a-40de-ab1d-a7d5acd7674d,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-c487362d-1120-4338-914c-fc25c5615796,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-65a52384-3325-457c-b938-b776da3b63ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-da63f7bf-9b60-4e5a-81be-33fa9266b538,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-267cc0d1-a31b-4a9f-95f4-33a6efc9b351,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-ba1abbf9-6939-4acf-a7c3-e565910aa6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-2b4a2e3e-fbb7-4ded-89af-54f457eeaca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231378360-172.17.0.15-1595530052378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-8caac8f5-3bc5-4963-b004-6ecf3ab2cf40,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-64b4b03f-ea9a-40de-ab1d-a7d5acd7674d,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-c487362d-1120-4338-914c-fc25c5615796,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-65a52384-3325-457c-b938-b776da3b63ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-da63f7bf-9b60-4e5a-81be-33fa9266b538,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-267cc0d1-a31b-4a9f-95f4-33a6efc9b351,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-ba1abbf9-6939-4acf-a7c3-e565910aa6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-2b4a2e3e-fbb7-4ded-89af-54f457eeaca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804242355-172.17.0.15-1595530093167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41482,DS-e87f1e23-d985-4345-95d5-acc65cacfd92,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-cccf0259-bbe6-413f-b959-f341552e45fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-b0f2e5cb-cb35-40c2-81f7-5d4557fabc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-2cc2f130-1177-4275-8ade-a251b1b13dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-1b5c16f0-c5ff-428e-9a5d-ff6360da1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-037c9656-e32d-4670-95d4-793d9b84385a,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-ee89b113-0fb6-4614-ab4b-344ad1f12e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-75eefd04-7dc5-407d-9f29-60b54f2b9d3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804242355-172.17.0.15-1595530093167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41482,DS-e87f1e23-d985-4345-95d5-acc65cacfd92,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-cccf0259-bbe6-413f-b959-f341552e45fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-b0f2e5cb-cb35-40c2-81f7-5d4557fabc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-2cc2f130-1177-4275-8ade-a251b1b13dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-1b5c16f0-c5ff-428e-9a5d-ff6360da1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-037c9656-e32d-4670-95d4-793d9b84385a,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-ee89b113-0fb6-4614-ab4b-344ad1f12e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-75eefd04-7dc5-407d-9f29-60b54f2b9d3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160872528-172.17.0.15-1595530455437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40336,DS-0598f48d-e728-49d0-b9a6-ba0a292d06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-52e60d93-1b3a-4fb4-8b30-a755e6e38870,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-72d8e473-c2ed-4c90-a204-4150bea4425c,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-20eb2e34-99b0-4a43-bca7-8aa0a142b180,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-7dbd48e2-5f51-4616-9fed-5f7e414f2fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-d321daa5-6afa-414b-8519-64a799e53cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-40e71aa7-55a2-4153-ad86-858e1fd32f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-4c496950-126c-48fe-a5e2-38335505ef12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160872528-172.17.0.15-1595530455437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40336,DS-0598f48d-e728-49d0-b9a6-ba0a292d06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-52e60d93-1b3a-4fb4-8b30-a755e6e38870,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-72d8e473-c2ed-4c90-a204-4150bea4425c,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-20eb2e34-99b0-4a43-bca7-8aa0a142b180,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-7dbd48e2-5f51-4616-9fed-5f7e414f2fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-d321daa5-6afa-414b-8519-64a799e53cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-40e71aa7-55a2-4153-ad86-858e1fd32f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-4c496950-126c-48fe-a5e2-38335505ef12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415851744-172.17.0.15-1595530787986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36198,DS-984687dd-7621-4bfc-b5cd-666a7ea62f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-0e405b8c-9994-45d4-938a-5fec1e190163,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-96c899b8-16f3-4d83-8823-2dc1f15e86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-e1119bad-2a9d-42b7-a57d-d279be943840,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-c8a23399-36dc-4f0e-b92d-72c814517a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-cc6afdb2-f198-4fb4-8ebd-61a34dd22bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-2a0a0068-0c49-48e9-9dc2-23c628622653,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-9ad8f795-f822-4502-a089-636de51ebccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415851744-172.17.0.15-1595530787986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36198,DS-984687dd-7621-4bfc-b5cd-666a7ea62f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-0e405b8c-9994-45d4-938a-5fec1e190163,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-96c899b8-16f3-4d83-8823-2dc1f15e86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-e1119bad-2a9d-42b7-a57d-d279be943840,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-c8a23399-36dc-4f0e-b92d-72c814517a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-cc6afdb2-f198-4fb4-8ebd-61a34dd22bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-2a0a0068-0c49-48e9-9dc2-23c628622653,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-9ad8f795-f822-4502-a089-636de51ebccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534148294-172.17.0.15-1595531125204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-9c6f5ab1-59d2-4e8e-a6c9-9fbf48457b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-a8d660fa-16a5-4f5f-833d-ac509a861bab,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-118eb0f5-fa57-4f7f-aa9d-4c5e3dc18078,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-046799ae-fc2d-441f-8894-8ab6f9e17871,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-c36c93ae-3c67-4d28-a070-7c947421622f,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-9b84beeb-576a-4365-8e24-70f79e0bd1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-4effd7d1-c525-42e2-8fa6-6ccf58ff604d,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-28a61df9-7203-4afd-bc7f-4a3d25172d5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534148294-172.17.0.15-1595531125204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-9c6f5ab1-59d2-4e8e-a6c9-9fbf48457b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-a8d660fa-16a5-4f5f-833d-ac509a861bab,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-118eb0f5-fa57-4f7f-aa9d-4c5e3dc18078,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-046799ae-fc2d-441f-8894-8ab6f9e17871,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-c36c93ae-3c67-4d28-a070-7c947421622f,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-9b84beeb-576a-4365-8e24-70f79e0bd1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-4effd7d1-c525-42e2-8fa6-6ccf58ff604d,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-28a61df9-7203-4afd-bc7f-4a3d25172d5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309249446-172.17.0.15-1595531321180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45646,DS-74c6c864-75be-427d-8ad4-0830843c7159,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-eaf2903a-478f-4a24-a652-6f9b8b3eaf94,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-4eb3f30d-155f-42a1-a775-16aedfb60b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-99d17e6f-7296-4d0a-97fe-1c8da9e82b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-096f2914-0293-4469-b155-d55ef537bc36,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-651d1cf3-0a1c-4efd-94ba-7e2dc210cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-80c6da4e-b9cb-4dd8-bba6-48f8ae8b7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-9bb3fd28-68d3-4ea9-a585-abe5e400c073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309249446-172.17.0.15-1595531321180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45646,DS-74c6c864-75be-427d-8ad4-0830843c7159,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-eaf2903a-478f-4a24-a652-6f9b8b3eaf94,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-4eb3f30d-155f-42a1-a775-16aedfb60b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-99d17e6f-7296-4d0a-97fe-1c8da9e82b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-096f2914-0293-4469-b155-d55ef537bc36,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-651d1cf3-0a1c-4efd-94ba-7e2dc210cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-80c6da4e-b9cb-4dd8-bba6-48f8ae8b7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-9bb3fd28-68d3-4ea9-a585-abe5e400c073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530103150-172.17.0.15-1595531740069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-2a9add90-5cdc-4ca5-acb5-014b712adca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-3614f990-588f-428d-bee2-b02a52e101e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-ca1c8a61-4bca-4e32-8c69-282e8811b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-f2a676ff-7d1b-4f70-a81f-c19979193630,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-78c39592-47c3-42da-8056-63486536cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-1401aa70-616b-452d-91ca-3438f5529dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-82983d9f-2b95-470f-8d46-317985ecb869,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-81de44c2-1a40-431e-b682-74415c1cae2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530103150-172.17.0.15-1595531740069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-2a9add90-5cdc-4ca5-acb5-014b712adca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-3614f990-588f-428d-bee2-b02a52e101e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-ca1c8a61-4bca-4e32-8c69-282e8811b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-f2a676ff-7d1b-4f70-a81f-c19979193630,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-78c39592-47c3-42da-8056-63486536cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-1401aa70-616b-452d-91ca-3438f5529dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-82983d9f-2b95-470f-8d46-317985ecb869,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-81de44c2-1a40-431e-b682-74415c1cae2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594234286-172.17.0.15-1595531938238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40121,DS-e7999c73-8f2f-48da-a1a2-9775cc87f624,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-9a4bab03-ddec-4f09-a0dd-faaea189f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-ce49465a-b636-4089-b600-5a1283eddd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-09a5a823-c41e-498d-89ff-727b1bcfe312,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-4eafc285-8c1f-468f-8847-01efd0a4402c,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-c11e7267-1d31-4db7-aef4-5c041a37970c,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-53a07622-dc8f-462a-86e7-c7842d62229a,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-894d2be3-e96d-49f0-bf85-b99a2a8c9451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594234286-172.17.0.15-1595531938238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40121,DS-e7999c73-8f2f-48da-a1a2-9775cc87f624,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-9a4bab03-ddec-4f09-a0dd-faaea189f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-ce49465a-b636-4089-b600-5a1283eddd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-09a5a823-c41e-498d-89ff-727b1bcfe312,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-4eafc285-8c1f-468f-8847-01efd0a4402c,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-c11e7267-1d31-4db7-aef4-5c041a37970c,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-53a07622-dc8f-462a-86e7-c7842d62229a,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-894d2be3-e96d-49f0-bf85-b99a2a8c9451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835764550-172.17.0.15-1595532018915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-b4c95b09-6bba-4d74-8c21-c3fd0df3a315,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-31e3d4f8-6b73-4baa-bb8c-9cbe7f579e66,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-13f3d910-fcd6-494d-aba4-09d757bd8503,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-55712a78-914a-4e89-93ee-3111e20e6327,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-0426fedd-ffbb-4549-aac7-9a68da9641da,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-180fc90d-5c14-4928-a585-55b26e10b589,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-3d4729aa-f44a-4871-b3ec-5414a917a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-9d41159d-b79e-4b3f-84d8-6704e1b882d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835764550-172.17.0.15-1595532018915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-b4c95b09-6bba-4d74-8c21-c3fd0df3a315,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-31e3d4f8-6b73-4baa-bb8c-9cbe7f579e66,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-13f3d910-fcd6-494d-aba4-09d757bd8503,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-55712a78-914a-4e89-93ee-3111e20e6327,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-0426fedd-ffbb-4549-aac7-9a68da9641da,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-180fc90d-5c14-4928-a585-55b26e10b589,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-3d4729aa-f44a-4871-b3ec-5414a917a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-9d41159d-b79e-4b3f-84d8-6704e1b882d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58312873-172.17.0.15-1595532528248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38663,DS-d615570e-2e4a-4a89-ba92-74aa3c57ab8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-b0377212-1673-4e1d-a72c-17cf730d3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-79a85eb7-1c01-40ab-9fc0-9205963e57dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-89efd68e-d897-4ea6-819c-1ebe5ca6c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-2e763e9d-2fcb-4473-8ab1-bb960c1b57ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-221230b0-914c-43f2-973b-888d86b5870b,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-339e9b80-a25b-4b3a-8653-699d690b0cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-cba7895f-18d5-4697-a39b-eec3b9a54278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58312873-172.17.0.15-1595532528248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38663,DS-d615570e-2e4a-4a89-ba92-74aa3c57ab8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-b0377212-1673-4e1d-a72c-17cf730d3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-79a85eb7-1c01-40ab-9fc0-9205963e57dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-89efd68e-d897-4ea6-819c-1ebe5ca6c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-2e763e9d-2fcb-4473-8ab1-bb960c1b57ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-221230b0-914c-43f2-973b-888d86b5870b,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-339e9b80-a25b-4b3a-8653-699d690b0cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-cba7895f-18d5-4697-a39b-eec3b9a54278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252306033-172.17.0.15-1595532856509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46161,DS-73b14005-729a-4588-85e5-2751a3bcc955,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-34840e3c-20ff-4f0f-bf46-8aa590b984d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-7ac9e67f-4b44-4c05-9fac-cef8fa6d29f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-8b2ad9ff-b9fe-407b-a4ae-5ec941ebe2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-fe98a6c4-f260-4911-9ea6-be0ae2a3f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-19d95f59-5d45-4b3e-b383-589f4003a851,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-9ac8674d-a681-474b-8eb7-8bf75404b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-c608d5ca-4729-44ef-9c71-e7595d2980de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252306033-172.17.0.15-1595532856509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46161,DS-73b14005-729a-4588-85e5-2751a3bcc955,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-34840e3c-20ff-4f0f-bf46-8aa590b984d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-7ac9e67f-4b44-4c05-9fac-cef8fa6d29f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-8b2ad9ff-b9fe-407b-a4ae-5ec941ebe2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-fe98a6c4-f260-4911-9ea6-be0ae2a3f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-19d95f59-5d45-4b3e-b383-589f4003a851,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-9ac8674d-a681-474b-8eb7-8bf75404b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-c608d5ca-4729-44ef-9c71-e7595d2980de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581889504-172.17.0.15-1595532961220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-0677da58-93a1-4707-a081-455ae27f722d,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-2ce4aa4e-cf6b-46cf-b15b-8d560b63ef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-a0b99d50-13c0-4db2-8586-707382759990,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-c0e1b487-67e6-49ab-a3be-775f34798b85,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-022b69d2-2fd4-42b9-a162-a86828e9d530,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-8c70dd2f-189f-4274-8d36-49da60c83b50,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-5da17ced-b8cb-4701-9d0a-3dd8cfdfbe55,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-aeae2d39-3b51-4dd5-ab22-c119a54936dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581889504-172.17.0.15-1595532961220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-0677da58-93a1-4707-a081-455ae27f722d,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-2ce4aa4e-cf6b-46cf-b15b-8d560b63ef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-a0b99d50-13c0-4db2-8586-707382759990,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-c0e1b487-67e6-49ab-a3be-775f34798b85,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-022b69d2-2fd4-42b9-a162-a86828e9d530,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-8c70dd2f-189f-4274-8d36-49da60c83b50,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-5da17ced-b8cb-4701-9d0a-3dd8cfdfbe55,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-aeae2d39-3b51-4dd5-ab22-c119a54936dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574975619-172.17.0.15-1595533154613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-ede70f7d-be82-4357-a486-8aced028f7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-2e3d9446-be67-4859-9bf8-8931321c252d,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-6b4bcca1-fb2f-4054-93b7-d8fc1ae2de94,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-5f5f9284-8255-4398-8857-d4898291c3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-3697d988-427c-4a22-be26-c1c1682c5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-6af87fad-9eb6-4978-b19b-1152c0450e52,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-ef8b9d04-6ffa-4d66-a9fa-3230bd2bf247,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-1361c625-9c10-45c6-83e1-d3e03f48a68d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574975619-172.17.0.15-1595533154613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-ede70f7d-be82-4357-a486-8aced028f7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-2e3d9446-be67-4859-9bf8-8931321c252d,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-6b4bcca1-fb2f-4054-93b7-d8fc1ae2de94,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-5f5f9284-8255-4398-8857-d4898291c3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-3697d988-427c-4a22-be26-c1c1682c5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-6af87fad-9eb6-4978-b19b-1152c0450e52,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-ef8b9d04-6ffa-4d66-a9fa-3230bd2bf247,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-1361c625-9c10-45c6-83e1-d3e03f48a68d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5474
