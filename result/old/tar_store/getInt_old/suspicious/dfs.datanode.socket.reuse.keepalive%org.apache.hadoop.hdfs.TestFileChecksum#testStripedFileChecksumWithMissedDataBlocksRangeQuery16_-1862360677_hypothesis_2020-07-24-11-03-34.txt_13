reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879272067-172.17.0.20-1595588855424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-617c8ddb-5adc-4327-8bc2-003bd375e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-eb329355-1808-4a87-9c3d-61ace7674140,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-b08b6845-7e3f-4244-8abb-1e6a00256037,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-82caff2e-4cd9-465f-b6ef-385d18c7b69d,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5c831430-65f8-4c6a-8539-4308157e26f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-4720fa23-49a0-4ba1-88d2-80041b07a4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-414a7670-0b64-4fd8-83d2-c3f0016dca69,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-6b009d29-6acc-4a5a-bb7d-436aeedbfc07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879272067-172.17.0.20-1595588855424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-617c8ddb-5adc-4327-8bc2-003bd375e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-eb329355-1808-4a87-9c3d-61ace7674140,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-b08b6845-7e3f-4244-8abb-1e6a00256037,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-82caff2e-4cd9-465f-b6ef-385d18c7b69d,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5c831430-65f8-4c6a-8539-4308157e26f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-4720fa23-49a0-4ba1-88d2-80041b07a4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-414a7670-0b64-4fd8-83d2-c3f0016dca69,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-6b009d29-6acc-4a5a-bb7d-436aeedbfc07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995047764-172.17.0.20-1595588966202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43053,DS-23033495-5959-494e-b10d-7c3d89d105f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-7a7769f8-8fd5-40ca-804f-893ea88e3017,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-a4f86321-78df-4193-a422-36f9138139bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-27739386-cccc-4f04-9a2a-3c2a3d53a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-94cc39ce-2a3d-4916-a289-22500fcb1ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-88a2d88d-f266-4435-8cf6-3f621e502187,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-09ec79af-3f35-4371-a73b-e43eb90b797d,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-2f2afbbf-31f3-4f42-854d-04e03001bb14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995047764-172.17.0.20-1595588966202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43053,DS-23033495-5959-494e-b10d-7c3d89d105f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-7a7769f8-8fd5-40ca-804f-893ea88e3017,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-a4f86321-78df-4193-a422-36f9138139bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-27739386-cccc-4f04-9a2a-3c2a3d53a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-94cc39ce-2a3d-4916-a289-22500fcb1ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-88a2d88d-f266-4435-8cf6-3f621e502187,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-09ec79af-3f35-4371-a73b-e43eb90b797d,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-2f2afbbf-31f3-4f42-854d-04e03001bb14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752514412-172.17.0.20-1595589106360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41893,DS-1b2acac3-7698-4a2d-8bb1-505df2d3a592,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-b0db6db0-84de-42af-b88b-bfc3edb1087d,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-2077d73d-eb29-412a-8236-3881de350e92,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-2ea648db-7081-429a-8c18-70cf2101fff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-67077ede-975c-4ba7-9264-e85ad3f16d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-0bdf654c-fa01-46a5-8efe-a248543bc015,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-e7e1b365-cef2-4018-936e-23e25206d7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-9da74305-d2cb-4910-8278-b277d3468898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752514412-172.17.0.20-1595589106360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41893,DS-1b2acac3-7698-4a2d-8bb1-505df2d3a592,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-b0db6db0-84de-42af-b88b-bfc3edb1087d,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-2077d73d-eb29-412a-8236-3881de350e92,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-2ea648db-7081-429a-8c18-70cf2101fff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-67077ede-975c-4ba7-9264-e85ad3f16d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-0bdf654c-fa01-46a5-8efe-a248543bc015,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-e7e1b365-cef2-4018-936e-23e25206d7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-9da74305-d2cb-4910-8278-b277d3468898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849680219-172.17.0.20-1595589711302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35336,DS-306bb163-fc44-46b1-926a-ba47e4bddcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-f6db9e02-11c9-47fd-b99f-03705b00703f,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-3ce7947c-1ecb-47c3-bae9-b56ede316084,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-d9029968-64f9-4e8d-b370-8bd2232669ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-5ff7e4e2-de53-4b91-8f42-4a136da0b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-a61bd089-5ca5-4710-b9a4-b51fb9abc258,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-1c99af91-5f1f-4a88-9fb1-aa18efc6969c,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-ea9a32c2-d564-43a7-98c4-0637baaedf2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849680219-172.17.0.20-1595589711302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35336,DS-306bb163-fc44-46b1-926a-ba47e4bddcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-f6db9e02-11c9-47fd-b99f-03705b00703f,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-3ce7947c-1ecb-47c3-bae9-b56ede316084,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-d9029968-64f9-4e8d-b370-8bd2232669ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-5ff7e4e2-de53-4b91-8f42-4a136da0b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-a61bd089-5ca5-4710-b9a4-b51fb9abc258,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-1c99af91-5f1f-4a88-9fb1-aa18efc6969c,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-ea9a32c2-d564-43a7-98c4-0637baaedf2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125366127-172.17.0.20-1595589817317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36506,DS-13d1ada3-9053-4e79-8612-11528a2daa99,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-baf17da9-d3af-4ad4-b383-b51075cd13f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-109455d7-766e-440c-aecb-d111c6c529c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-91acdf67-fc15-41dc-aa18-1fdf0208aa80,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-0ce38cf1-8a50-4216-b399-26601966909c,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-a3df0077-f554-4dd6-8913-542ecb850c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-2145e7a9-f05e-4998-86f9-be71ffcec2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-0c9692fd-2e88-423b-8e34-dcd820610075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125366127-172.17.0.20-1595589817317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36506,DS-13d1ada3-9053-4e79-8612-11528a2daa99,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-baf17da9-d3af-4ad4-b383-b51075cd13f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-109455d7-766e-440c-aecb-d111c6c529c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-91acdf67-fc15-41dc-aa18-1fdf0208aa80,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-0ce38cf1-8a50-4216-b399-26601966909c,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-a3df0077-f554-4dd6-8913-542ecb850c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-2145e7a9-f05e-4998-86f9-be71ffcec2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-0c9692fd-2e88-423b-8e34-dcd820610075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33197028-172.17.0.20-1595589956989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33236,DS-5c163352-b084-4831-b3c9-5e9d9441f290,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-d2e4dc21-b0fd-4196-9269-536a4ca20c41,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-4ffcf757-0d80-424a-bcba-629fe420f385,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-f7a62601-8f0d-4146-abad-9cb0dc3dfb74,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-259ce1fb-c0e4-4fc3-927a-449a2b1d04e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-c9aeb9c8-1e95-422e-b3dd-d1d6f8dc8b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-13191ccd-6e62-48c4-8d4f-ae2666c46d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-f72ada9f-acb0-4424-b2fe-a755468a0512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33197028-172.17.0.20-1595589956989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33236,DS-5c163352-b084-4831-b3c9-5e9d9441f290,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-d2e4dc21-b0fd-4196-9269-536a4ca20c41,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-4ffcf757-0d80-424a-bcba-629fe420f385,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-f7a62601-8f0d-4146-abad-9cb0dc3dfb74,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-259ce1fb-c0e4-4fc3-927a-449a2b1d04e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-c9aeb9c8-1e95-422e-b3dd-d1d6f8dc8b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-13191ccd-6e62-48c4-8d4f-ae2666c46d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-f72ada9f-acb0-4424-b2fe-a755468a0512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922819698-172.17.0.20-1595590144735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35451,DS-93f0a359-9204-4c3b-a277-811232e45b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-36962cf2-673d-497a-ae17-7f81fb8a078e,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-b896a0fa-dbff-48f1-8fe7-8d83feec35fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-85d0df7f-11d2-47f9-b243-b41b11279b45,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-32a9660c-d66f-4fd2-a512-4cd4af0ba8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-f19a9bfe-fb54-474e-bb4e-3a05127ffee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-240efd93-5464-4101-9094-30cf372dd2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-5bbe2c78-d1d8-46ff-92de-57ee8f17a392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922819698-172.17.0.20-1595590144735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35451,DS-93f0a359-9204-4c3b-a277-811232e45b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-36962cf2-673d-497a-ae17-7f81fb8a078e,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-b896a0fa-dbff-48f1-8fe7-8d83feec35fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-85d0df7f-11d2-47f9-b243-b41b11279b45,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-32a9660c-d66f-4fd2-a512-4cd4af0ba8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-f19a9bfe-fb54-474e-bb4e-3a05127ffee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-240efd93-5464-4101-9094-30cf372dd2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-5bbe2c78-d1d8-46ff-92de-57ee8f17a392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804544763-172.17.0.20-1595590708638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42452,DS-d7497a1d-7bd9-4158-8fb0-00f573ec1685,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-54b31402-1693-4271-a949-191fc85d1535,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-2c3e8a9f-64ee-4d7e-8841-98ad3ccb9240,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-0a8b010f-584f-49f4-a683-e357e673b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-748cda43-bb1f-492e-8099-44a5c00785dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-98372f66-e69a-45e5-990b-f403a39ea330,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-28ff80f5-51cf-4637-a838-11deff504fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-8f66cace-78dc-48dd-b176-5c093182bb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804544763-172.17.0.20-1595590708638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42452,DS-d7497a1d-7bd9-4158-8fb0-00f573ec1685,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-54b31402-1693-4271-a949-191fc85d1535,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-2c3e8a9f-64ee-4d7e-8841-98ad3ccb9240,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-0a8b010f-584f-49f4-a683-e357e673b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-748cda43-bb1f-492e-8099-44a5c00785dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-98372f66-e69a-45e5-990b-f403a39ea330,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-28ff80f5-51cf-4637-a838-11deff504fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-8f66cace-78dc-48dd-b176-5c093182bb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792393074-172.17.0.20-1595591033238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42313,DS-6525694e-5410-4080-964b-e7d7520491ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-030444b3-6701-495e-9db4-f9ec5c8c5711,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-8beac993-d7c6-420b-ac1c-0eec889ff098,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-ff4c1b3f-90b3-4224-8d6a-e5e1dc6bcbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ea4ade09-1779-49f7-a0b2-52b330ec5be6,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-a70f2015-c4d5-4431-9582-0b26d47c8371,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-8320f3ea-fe84-449e-b3a7-942f3d73cdea,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-38cc23f6-bb20-4b72-8ea4-aab161e314c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792393074-172.17.0.20-1595591033238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42313,DS-6525694e-5410-4080-964b-e7d7520491ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-030444b3-6701-495e-9db4-f9ec5c8c5711,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-8beac993-d7c6-420b-ac1c-0eec889ff098,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-ff4c1b3f-90b3-4224-8d6a-e5e1dc6bcbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ea4ade09-1779-49f7-a0b2-52b330ec5be6,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-a70f2015-c4d5-4431-9582-0b26d47c8371,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-8320f3ea-fe84-449e-b3a7-942f3d73cdea,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-38cc23f6-bb20-4b72-8ea4-aab161e314c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275858546-172.17.0.20-1595591320162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-78735bd3-6c49-4173-a55a-2b4ae75d76ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-68981a88-48b4-4dfd-a787-fd0e360bace4,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-9819f50b-8083-42d4-8910-06bcf1480191,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-ff1a9037-66bf-4cec-8fdc-c65021e82014,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-6bfc5761-d755-466c-9b69-a9f417f529f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-3645c075-2fdd-4e09-a2d3-e99aeb5352a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-d40bbef7-91ca-438b-91c9-f2e27b62d183,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-0eae45b2-8f6e-48ef-b06e-f169e6f4461e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275858546-172.17.0.20-1595591320162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-78735bd3-6c49-4173-a55a-2b4ae75d76ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-68981a88-48b4-4dfd-a787-fd0e360bace4,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-9819f50b-8083-42d4-8910-06bcf1480191,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-ff1a9037-66bf-4cec-8fdc-c65021e82014,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-6bfc5761-d755-466c-9b69-a9f417f529f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-3645c075-2fdd-4e09-a2d3-e99aeb5352a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-d40bbef7-91ca-438b-91c9-f2e27b62d183,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-0eae45b2-8f6e-48ef-b06e-f169e6f4461e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180022659-172.17.0.20-1595591570650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-096a549f-163c-4c02-bcd7-98c817af4084,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-ca2ebab5-2bf2-4dc3-92ce-27a64fe49380,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-29bc4a43-b999-48ac-9bc9-941da999dca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-b5ed9411-dc2f-4941-8345-45d27ff1c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-bb64b58d-6eff-4cc5-9eba-089a9e8a8058,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-68361792-2d8c-487e-a7eb-9b043fd8939a,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-c9ee4fda-ade7-4d90-82a0-1afa06c272bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-02947c50-a6f5-43fb-97ea-06293f3225ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180022659-172.17.0.20-1595591570650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-096a549f-163c-4c02-bcd7-98c817af4084,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-ca2ebab5-2bf2-4dc3-92ce-27a64fe49380,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-29bc4a43-b999-48ac-9bc9-941da999dca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-b5ed9411-dc2f-4941-8345-45d27ff1c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-bb64b58d-6eff-4cc5-9eba-089a9e8a8058,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-68361792-2d8c-487e-a7eb-9b043fd8939a,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-c9ee4fda-ade7-4d90-82a0-1afa06c272bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-02947c50-a6f5-43fb-97ea-06293f3225ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471736091-172.17.0.20-1595591676709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36178,DS-b124d4e5-2b44-4b2e-ae1b-7385b8c03ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-ce8db652-5524-4675-b0ff-f05f9b001ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-eb1df278-e36d-4f25-a1c6-204b6dee7d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-e1cceec0-6c6d-4953-9954-745b1c8d6870,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-f0dce3de-997f-492b-8105-7e372459e6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-75b2a226-bec7-47fb-b7fe-6911b031b205,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-942e5fcb-a451-4d46-a6b7-247d0022fe31,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-9c5ca017-8fee-40cf-88ab-d3d23911fb48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471736091-172.17.0.20-1595591676709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36178,DS-b124d4e5-2b44-4b2e-ae1b-7385b8c03ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-ce8db652-5524-4675-b0ff-f05f9b001ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-eb1df278-e36d-4f25-a1c6-204b6dee7d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-e1cceec0-6c6d-4953-9954-745b1c8d6870,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-f0dce3de-997f-492b-8105-7e372459e6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-75b2a226-bec7-47fb-b7fe-6911b031b205,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-942e5fcb-a451-4d46-a6b7-247d0022fe31,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-9c5ca017-8fee-40cf-88ab-d3d23911fb48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707255166-172.17.0.20-1595591846650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-d85b63e0-da61-4c58-8785-54574593c85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-757372d0-6075-4204-918a-f767ac5938c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-94d01e57-1b25-4db0-9e2e-322c4719503f,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-755232e8-e52d-478c-864f-0241b86257ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-43d36260-3911-470f-9ae7-5317111332dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-eb78ff85-0044-4615-9590-ab33b6a646b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-f3472241-fce2-43fd-b9f1-7b55d78a3f11,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-7722a532-78e2-4181-a004-37a96a2b5530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707255166-172.17.0.20-1595591846650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-d85b63e0-da61-4c58-8785-54574593c85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-757372d0-6075-4204-918a-f767ac5938c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-94d01e57-1b25-4db0-9e2e-322c4719503f,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-755232e8-e52d-478c-864f-0241b86257ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-43d36260-3911-470f-9ae7-5317111332dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-eb78ff85-0044-4615-9590-ab33b6a646b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-f3472241-fce2-43fd-b9f1-7b55d78a3f11,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-7722a532-78e2-4181-a004-37a96a2b5530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955737136-172.17.0.20-1595592635339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-ce2887f8-6879-4f90-9b2a-6d2b3c9701b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-cfb9157f-eb71-4262-8e0c-b4860b65dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-800f0e64-b4b8-42b4-bb5b-b14b123da521,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-1ceb19ca-efbc-4c53-bca0-6d754b651fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-da231ad1-ced1-4ada-93c8-24efcac7d52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-e29613d7-d578-4150-b782-64d692350504,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-1b0c6bbe-9bac-48a4-9dcf-78bd2637910d,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-8fce22a4-b8f2-4217-b799-8a409735f7f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955737136-172.17.0.20-1595592635339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-ce2887f8-6879-4f90-9b2a-6d2b3c9701b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-cfb9157f-eb71-4262-8e0c-b4860b65dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-800f0e64-b4b8-42b4-bb5b-b14b123da521,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-1ceb19ca-efbc-4c53-bca0-6d754b651fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-da231ad1-ced1-4ada-93c8-24efcac7d52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-e29613d7-d578-4150-b782-64d692350504,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-1b0c6bbe-9bac-48a4-9dcf-78bd2637910d,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-8fce22a4-b8f2-4217-b799-8a409735f7f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452989158-172.17.0.20-1595593841109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43977,DS-6a6df2dd-26da-4720-8def-13d15cb28ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-febcd12f-d0bc-46f3-9cd0-92412fbc9518,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-9d1326bc-4a92-4625-9c0e-9c293aed2802,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-a44e39cb-1dae-4a5f-8bc9-118fd3b5e0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-5a63c09d-9fa8-485f-a7ac-a5a0181ac6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-fc4a5329-12a0-4110-b636-bf936741b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-0a7fa3ac-8042-46a6-9d83-6a7a93909c59,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-0d5d653d-57aa-4449-8a5f-18b0a7dcdad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452989158-172.17.0.20-1595593841109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43977,DS-6a6df2dd-26da-4720-8def-13d15cb28ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-febcd12f-d0bc-46f3-9cd0-92412fbc9518,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-9d1326bc-4a92-4625-9c0e-9c293aed2802,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-a44e39cb-1dae-4a5f-8bc9-118fd3b5e0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-5a63c09d-9fa8-485f-a7ac-a5a0181ac6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-fc4a5329-12a0-4110-b636-bf936741b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-0a7fa3ac-8042-46a6-9d83-6a7a93909c59,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-0d5d653d-57aa-4449-8a5f-18b0a7dcdad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5393
