reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405998948-172.17.0.14-1595659991724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-6ba69400-dc98-4fc5-8ee6-e61555312953,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-4d060f93-7a8d-4e40-a0e0-e8aee76559e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-d1c8eb73-30f3-4b1c-a03f-3c6d1fa0f279,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-66724b37-4850-4de8-ae48-1e3a41ef15d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-888b3af9-598a-4e2f-8296-aaaef7b6a171,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-39ba8f77-beae-41e9-8de1-086bf0524f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-e9ec398c-6a47-4af7-8512-622d844ea30a,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-1d535fad-a962-43dc-a152-0627af89fac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405998948-172.17.0.14-1595659991724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-6ba69400-dc98-4fc5-8ee6-e61555312953,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-4d060f93-7a8d-4e40-a0e0-e8aee76559e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-d1c8eb73-30f3-4b1c-a03f-3c6d1fa0f279,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-66724b37-4850-4de8-ae48-1e3a41ef15d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-888b3af9-598a-4e2f-8296-aaaef7b6a171,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-39ba8f77-beae-41e9-8de1-086bf0524f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-e9ec398c-6a47-4af7-8512-622d844ea30a,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-1d535fad-a962-43dc-a152-0627af89fac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753786680-172.17.0.14-1595661398746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43614,DS-9747bd46-fe65-44d6-8b84-8e6cd17d23ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-6f8f275a-3fba-4cc6-b20e-a255deeec1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-340be9e8-cf6b-4123-aa60-fc501d2891b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-8990f39f-564a-4995-b44e-2d5facc05ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-6cc0d47d-8bc0-4630-845e-8ebb937924b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-643a6856-fb39-498d-8fbf-bcb495c6160b,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-f0fb9e03-fceb-4e8a-a599-f799e942a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-8d293fed-879b-4841-bd45-9256bc3628aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753786680-172.17.0.14-1595661398746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43614,DS-9747bd46-fe65-44d6-8b84-8e6cd17d23ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-6f8f275a-3fba-4cc6-b20e-a255deeec1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-340be9e8-cf6b-4123-aa60-fc501d2891b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-8990f39f-564a-4995-b44e-2d5facc05ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-6cc0d47d-8bc0-4630-845e-8ebb937924b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-643a6856-fb39-498d-8fbf-bcb495c6160b,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-f0fb9e03-fceb-4e8a-a599-f799e942a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-8d293fed-879b-4841-bd45-9256bc3628aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167340615-172.17.0.14-1595661786165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40535,DS-368adaaf-cdf7-49c2-91a8-7d74d5178f08,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-c333991e-e870-4cb7-9026-0e315e9e5b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-9f3af16b-7bea-43a0-be9c-0aec512286bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-acfc9d3b-5e14-473e-9253-6a52bc13369c,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-447e0914-9276-4c4a-842a-24f0b5c99278,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-6b01141b-b206-467b-9597-0ed26115491d,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-c680cc91-0551-4a3a-abfd-948bd9a1d4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-d653cfaf-6237-4503-a898-b87e103b970f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167340615-172.17.0.14-1595661786165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40535,DS-368adaaf-cdf7-49c2-91a8-7d74d5178f08,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-c333991e-e870-4cb7-9026-0e315e9e5b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-9f3af16b-7bea-43a0-be9c-0aec512286bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-acfc9d3b-5e14-473e-9253-6a52bc13369c,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-447e0914-9276-4c4a-842a-24f0b5c99278,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-6b01141b-b206-467b-9597-0ed26115491d,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-c680cc91-0551-4a3a-abfd-948bd9a1d4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-d653cfaf-6237-4503-a898-b87e103b970f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062996743-172.17.0.14-1595662148794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34183,DS-425c0309-02ff-449b-9d7d-e2a994e07e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-1b7e2a9d-7c3d-4adf-a40b-9942a77f3bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-c3d48e5c-565a-4c07-a7e2-192ac37b9459,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-af75577e-0298-4b23-8488-d31136935ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-1a2f3f1d-1edd-48ea-93db-16f082020f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-7102e943-d1cd-4c24-a9af-24e63825b049,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-d4452bc8-44bf-4d59-9892-0ceab984c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-5cbf3835-dc04-42e8-8e74-744d09a89328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062996743-172.17.0.14-1595662148794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34183,DS-425c0309-02ff-449b-9d7d-e2a994e07e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-1b7e2a9d-7c3d-4adf-a40b-9942a77f3bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-c3d48e5c-565a-4c07-a7e2-192ac37b9459,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-af75577e-0298-4b23-8488-d31136935ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-1a2f3f1d-1edd-48ea-93db-16f082020f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-7102e943-d1cd-4c24-a9af-24e63825b049,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-d4452bc8-44bf-4d59-9892-0ceab984c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-5cbf3835-dc04-42e8-8e74-744d09a89328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774447052-172.17.0.14-1595662358386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-0fdba11e-e050-4b0d-84e3-2e96481f3727,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-1e6edefe-6c27-43ce-94f0-17956c3b6ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-9f6c449b-079b-43c4-ba12-b59c3e6a1641,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-a38a8a83-f4dc-46f5-8cf7-ae70214886b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-ea8753ac-01fc-4986-bdb7-b5e845d1e21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-e482fabc-54e3-4f1d-a665-9ec2ea68e953,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-70c60c15-0f22-4bff-ad1f-ae65a4bf8e87,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-8527d761-fbe9-4666-ae9a-b591b4634650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774447052-172.17.0.14-1595662358386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-0fdba11e-e050-4b0d-84e3-2e96481f3727,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-1e6edefe-6c27-43ce-94f0-17956c3b6ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-9f6c449b-079b-43c4-ba12-b59c3e6a1641,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-a38a8a83-f4dc-46f5-8cf7-ae70214886b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-ea8753ac-01fc-4986-bdb7-b5e845d1e21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-e482fabc-54e3-4f1d-a665-9ec2ea68e953,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-70c60c15-0f22-4bff-ad1f-ae65a4bf8e87,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-8527d761-fbe9-4666-ae9a-b591b4634650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548151769-172.17.0.14-1595662969019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41790,DS-7dd4472d-cdb1-45ac-b028-3c4aeac3ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-692c509c-14b1-46e6-b91b-5590ca1eb4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-727f8de1-da8c-47df-b459-fcbcd62a5ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-4f929331-07e6-4019-8caa-df6858511dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-caff7b76-c71a-48a2-bae6-fa2a83eeae41,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-1fe9e345-8ace-4231-8c5d-95fb879668bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-1c9e9fb5-0c1c-4825-bc9a-32349c23844f,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-0def6d78-0b83-4c2d-ba10-f34f6eea778d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548151769-172.17.0.14-1595662969019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41790,DS-7dd4472d-cdb1-45ac-b028-3c4aeac3ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-692c509c-14b1-46e6-b91b-5590ca1eb4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-727f8de1-da8c-47df-b459-fcbcd62a5ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-4f929331-07e6-4019-8caa-df6858511dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-caff7b76-c71a-48a2-bae6-fa2a83eeae41,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-1fe9e345-8ace-4231-8c5d-95fb879668bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-1c9e9fb5-0c1c-4825-bc9a-32349c23844f,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-0def6d78-0b83-4c2d-ba10-f34f6eea778d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372125499-172.17.0.14-1595663159626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39502,DS-b47ee785-d877-469d-a72c-bedba6f23abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-12296754-0eb6-4f1e-9efb-c5bbacc31658,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-ae783bd6-f39d-4365-ad20-265f5820fd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-11629cc1-e77e-4f6d-8124-45d0d28dac52,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-50030680-5d6c-49c5-9906-9bab2079b502,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-7b3a3e85-4089-46fb-a51e-09635e0e7d70,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-56330758-135d-4404-be34-32a5e8b3fc58,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-f810de9a-d6a0-4444-856f-dcd49ac562d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372125499-172.17.0.14-1595663159626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39502,DS-b47ee785-d877-469d-a72c-bedba6f23abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-12296754-0eb6-4f1e-9efb-c5bbacc31658,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-ae783bd6-f39d-4365-ad20-265f5820fd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-11629cc1-e77e-4f6d-8124-45d0d28dac52,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-50030680-5d6c-49c5-9906-9bab2079b502,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-7b3a3e85-4089-46fb-a51e-09635e0e7d70,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-56330758-135d-4404-be34-32a5e8b3fc58,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-f810de9a-d6a0-4444-856f-dcd49ac562d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749470527-172.17.0.14-1595663236028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40267,DS-bc0d7d0d-abd7-401d-aa0a-438b621117d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-ea51e8a5-060b-483d-bde5-e7ce03a63ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-6e86b3b0-2ef5-495a-8f24-f34b774aa215,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-d43bf834-59a0-4a3b-bcf5-550c521c1808,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-f0c2fd5f-94c2-4c7e-ac20-cb7e552344aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-195944af-d853-4e06-806a-8f7463842a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-23e71c7d-a2fd-403f-90ff-38adf8f6d434,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-69a374fb-f42a-4dba-b142-36a16d247aef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749470527-172.17.0.14-1595663236028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40267,DS-bc0d7d0d-abd7-401d-aa0a-438b621117d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-ea51e8a5-060b-483d-bde5-e7ce03a63ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-6e86b3b0-2ef5-495a-8f24-f34b774aa215,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-d43bf834-59a0-4a3b-bcf5-550c521c1808,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-f0c2fd5f-94c2-4c7e-ac20-cb7e552344aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-195944af-d853-4e06-806a-8f7463842a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-23e71c7d-a2fd-403f-90ff-38adf8f6d434,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-69a374fb-f42a-4dba-b142-36a16d247aef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827331362-172.17.0.14-1595663266534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-b73ac29f-aa3a-4c78-8cab-5e3fa7ec949f,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-a14089c8-dbff-4708-b35f-5d60b2e2c6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-393c6b8a-ba1c-4ff1-964b-9b0a91764e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-a656cd41-bec9-474c-834c-972793071c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-3587a9c1-b999-4f35-872f-026f33cf68f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-9a09eef5-3ae5-4c56-844f-36a02b9844c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-2eadcadc-7e97-4add-93a6-008423ae0f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-5f33cfef-9681-4efd-a07a-50d6f9c72a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827331362-172.17.0.14-1595663266534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-b73ac29f-aa3a-4c78-8cab-5e3fa7ec949f,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-a14089c8-dbff-4708-b35f-5d60b2e2c6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-393c6b8a-ba1c-4ff1-964b-9b0a91764e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-a656cd41-bec9-474c-834c-972793071c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-3587a9c1-b999-4f35-872f-026f33cf68f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-9a09eef5-3ae5-4c56-844f-36a02b9844c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-2eadcadc-7e97-4add-93a6-008423ae0f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-5f33cfef-9681-4efd-a07a-50d6f9c72a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955843181-172.17.0.14-1595663376184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-d0c6752c-6d83-4947-b8d0-af55141c9323,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-29732d7c-67cf-4c3e-8c04-d7a8c24d70b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-6fea22c4-d733-44c6-829d-70304910c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-d1c2b9e4-8e03-406d-b77b-882c85f87c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-9abf56e9-d90d-4493-956c-80c229590cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-060e3c02-ffd9-4e4e-9a21-43ae293ee1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-55d73099-c184-445f-89ae-a8781114ec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-5e012645-84b0-4b21-8097-fd80c3782e70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955843181-172.17.0.14-1595663376184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-d0c6752c-6d83-4947-b8d0-af55141c9323,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-29732d7c-67cf-4c3e-8c04-d7a8c24d70b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-6fea22c4-d733-44c6-829d-70304910c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-d1c2b9e4-8e03-406d-b77b-882c85f87c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-9abf56e9-d90d-4493-956c-80c229590cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-060e3c02-ffd9-4e4e-9a21-43ae293ee1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-55d73099-c184-445f-89ae-a8781114ec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-5e012645-84b0-4b21-8097-fd80c3782e70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771285477-172.17.0.14-1595663992362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44908,DS-ff170664-5943-494d-ba15-9d269bcc0fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-a9e9660d-4529-47d1-aae6-603fb856cc62,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-2ff5afff-e5a2-4315-ab02-1310ba4fd935,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-b4feb9af-181f-4348-a78e-e8554e90688b,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-f3a9b202-e2fc-406e-ab10-b71de85ad0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-980590d7-fbf4-436a-98d0-1ebe905859cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-8a9713ac-622b-4de9-bdbe-d43c509ddb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-564abbdb-8d61-4f71-8f7a-47069507131b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771285477-172.17.0.14-1595663992362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44908,DS-ff170664-5943-494d-ba15-9d269bcc0fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-a9e9660d-4529-47d1-aae6-603fb856cc62,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-2ff5afff-e5a2-4315-ab02-1310ba4fd935,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-b4feb9af-181f-4348-a78e-e8554e90688b,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-f3a9b202-e2fc-406e-ab10-b71de85ad0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-980590d7-fbf4-436a-98d0-1ebe905859cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-8a9713ac-622b-4de9-bdbe-d43c509ddb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-564abbdb-8d61-4f71-8f7a-47069507131b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795233153-172.17.0.14-1595664061712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46871,DS-a0e4ee4b-e7cf-4938-87b5-2fe9db6e8fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-410ca4de-cae6-4295-ad27-7b4ace165179,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-0f6005cb-0004-43b0-bf6b-98de6e76a708,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-11443ea8-7138-43ac-96a2-95fda5c52529,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-bc40720e-80a4-4c14-aede-519777e6ebb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-89e1dac1-226b-4be9-8e18-470ef05858d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-e1987960-3f78-4785-8999-f2dec1f680e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-5b364121-b185-42b7-9dd2-cb64896ff3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795233153-172.17.0.14-1595664061712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46871,DS-a0e4ee4b-e7cf-4938-87b5-2fe9db6e8fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-410ca4de-cae6-4295-ad27-7b4ace165179,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-0f6005cb-0004-43b0-bf6b-98de6e76a708,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-11443ea8-7138-43ac-96a2-95fda5c52529,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-bc40720e-80a4-4c14-aede-519777e6ebb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-89e1dac1-226b-4be9-8e18-470ef05858d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-e1987960-3f78-4785-8999-f2dec1f680e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-5b364121-b185-42b7-9dd2-cb64896ff3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967281053-172.17.0.14-1595664461615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-6b48953d-f866-4dec-aa0a-fc05d0c08a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-e9f73ce4-4f4f-40e9-9da0-7ef0e28a9101,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-2724f0ea-bd8a-4966-b9b3-b49baf159b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-e6f9824f-bd9a-4675-9140-8fd9fa021786,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-a0735556-6d7f-4988-aed7-f883e7b24837,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-e5c11608-71e8-4aea-9ff1-3e4b7c8ab47d,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-66dfc263-53d9-44d9-ab06-d2c6425ffbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-438b94f1-4eb2-45c0-89ba-963a5c8e64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967281053-172.17.0.14-1595664461615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-6b48953d-f866-4dec-aa0a-fc05d0c08a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-e9f73ce4-4f4f-40e9-9da0-7ef0e28a9101,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-2724f0ea-bd8a-4966-b9b3-b49baf159b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-e6f9824f-bd9a-4675-9140-8fd9fa021786,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-a0735556-6d7f-4988-aed7-f883e7b24837,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-e5c11608-71e8-4aea-9ff1-3e4b7c8ab47d,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-66dfc263-53d9-44d9-ab06-d2c6425ffbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-438b94f1-4eb2-45c0-89ba-963a5c8e64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99793872-172.17.0.14-1595664642572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-eb76f581-fd8b-4883-ba7f-bc8728ac9008,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-79954c4a-38ca-4444-a73b-89ffe7a0d625,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-6a2fe7d4-ff15-4c74-912a-c32c2f89e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-4f93520d-bc08-4ef2-a17a-654fcc926f74,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-8152063c-95e6-4bc3-bfaf-15070bc9bc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-92c1c814-2c94-4fbd-bfa2-24eecdd69825,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-92b63e10-8291-41e2-95ee-ff2a12798d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-ce62a11f-12a1-4a46-b892-bb356d4c6df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99793872-172.17.0.14-1595664642572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-eb76f581-fd8b-4883-ba7f-bc8728ac9008,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-79954c4a-38ca-4444-a73b-89ffe7a0d625,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-6a2fe7d4-ff15-4c74-912a-c32c2f89e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-4f93520d-bc08-4ef2-a17a-654fcc926f74,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-8152063c-95e6-4bc3-bfaf-15070bc9bc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-92c1c814-2c94-4fbd-bfa2-24eecdd69825,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-92b63e10-8291-41e2-95ee-ff2a12798d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-ce62a11f-12a1-4a46-b892-bb356d4c6df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 4792
