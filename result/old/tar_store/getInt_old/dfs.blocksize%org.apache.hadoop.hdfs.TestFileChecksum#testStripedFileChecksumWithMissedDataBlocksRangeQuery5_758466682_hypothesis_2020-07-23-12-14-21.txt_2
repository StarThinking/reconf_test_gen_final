reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907751025-172.17.0.8-1595506472937:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41882,DS-28d28be7-d450-4811-a659-abcc960f34d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-38dce20f-1497-40dc-9403-62d98f2a1ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-29490dca-1512-4cd6-b3ab-ed244ab29672,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-ceb226c7-2485-416c-91c1-b67dafb2a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-9450989f-d27f-431b-8477-51559f5926d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-6b773575-a1df-4d2d-812b-008937959b07,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-2a9389a5-fc0a-4792-af2f-f38d912b5d37,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-7c0043af-16fd-4ea0-af7d-526870a42fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907751025-172.17.0.8-1595506472937:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41882,DS-28d28be7-d450-4811-a659-abcc960f34d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-38dce20f-1497-40dc-9403-62d98f2a1ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-29490dca-1512-4cd6-b3ab-ed244ab29672,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-ceb226c7-2485-416c-91c1-b67dafb2a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-9450989f-d27f-431b-8477-51559f5926d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-6b773575-a1df-4d2d-812b-008937959b07,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-2a9389a5-fc0a-4792-af2f-f38d912b5d37,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-7c0043af-16fd-4ea0-af7d-526870a42fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339597289-172.17.0.8-1595506543576:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-77175277-869b-4720-b9e6-9f72e9d8e3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-0073d0d4-835b-4fa4-a554-f27b2a565e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-35c07e2b-f654-400f-8cfe-0b746a456892,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-45599aa3-13df-4259-aaa6-c02873515507,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-ff9f5fd2-dc7d-4818-858d-7e60f5c40265,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-e5f95df2-0982-4cb1-bfab-c222e68cc812,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-8c0baf4d-cd6b-41d0-93a0-15b3ecd797de,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-93bf4cbc-eb63-4be5-84b2-61069a744d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339597289-172.17.0.8-1595506543576:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-77175277-869b-4720-b9e6-9f72e9d8e3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-0073d0d4-835b-4fa4-a554-f27b2a565e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-35c07e2b-f654-400f-8cfe-0b746a456892,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-45599aa3-13df-4259-aaa6-c02873515507,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-ff9f5fd2-dc7d-4818-858d-7e60f5c40265,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-e5f95df2-0982-4cb1-bfab-c222e68cc812,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-8c0baf4d-cd6b-41d0-93a0-15b3ecd797de,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-93bf4cbc-eb63-4be5-84b2-61069a744d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140267542-172.17.0.8-1595506668022:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-7f03c210-668a-4b38-adb8-9baac2433ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-757b5d2e-5ce8-4e59-9dbf-466a4c5c2a28,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-cf02a8d5-a724-4a4e-a8ad-6e7fa9e2439c,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-d0f1e469-f52c-4566-b377-1b54b6e4564f,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-eb8aaeb9-8f13-473a-a804-e0f3b17ff897,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-a128fa27-a3b2-44f1-8f52-259d3b03e495,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-4a2e1680-2735-4210-ba9d-0aaf8eef9a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-7d9496ce-13a0-420e-8c2c-f7658b970355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140267542-172.17.0.8-1595506668022:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-7f03c210-668a-4b38-adb8-9baac2433ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-757b5d2e-5ce8-4e59-9dbf-466a4c5c2a28,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-cf02a8d5-a724-4a4e-a8ad-6e7fa9e2439c,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-d0f1e469-f52c-4566-b377-1b54b6e4564f,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-eb8aaeb9-8f13-473a-a804-e0f3b17ff897,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-a128fa27-a3b2-44f1-8f52-259d3b03e495,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-4a2e1680-2735-4210-ba9d-0aaf8eef9a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-7d9496ce-13a0-420e-8c2c-f7658b970355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495168303-172.17.0.8-1595507565329:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-87b7f5ea-44ce-4369-97a1-98b2271ff8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-f7e57c6c-689f-43a3-ae1b-944bd83be686,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-daedf457-5c0a-4300-a0db-50cb8fae9530,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-10eee4d2-5a79-42b0-b0dd-b14e74206fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-a099c5ff-87ec-4413-997b-e6e75fcaa5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-460fe223-0256-439e-9360-36463ff7f4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-b9c85a7b-481a-40ab-938a-a22c2dff7c30,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-3cea5a75-565c-47ae-bd65-0b11358ac1d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495168303-172.17.0.8-1595507565329:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-87b7f5ea-44ce-4369-97a1-98b2271ff8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-f7e57c6c-689f-43a3-ae1b-944bd83be686,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-daedf457-5c0a-4300-a0db-50cb8fae9530,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-10eee4d2-5a79-42b0-b0dd-b14e74206fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-a099c5ff-87ec-4413-997b-e6e75fcaa5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-460fe223-0256-439e-9360-36463ff7f4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-b9c85a7b-481a-40ab-938a-a22c2dff7c30,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-3cea5a75-565c-47ae-bd65-0b11358ac1d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745939177-172.17.0.8-1595507597662:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-7c0394a9-fea9-4918-a68e-a94b9b56e83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-ab44e9a8-08f5-4ed2-a590-d56182e47205,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-054ed618-b5c4-49e1-94ef-9e25bbb16b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-89234a68-a81e-44af-90c5-100a03646843,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-e8c27e6a-3f3b-4831-a74f-b6ee157fd6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-e6f55098-70fa-4a88-9f4d-806257ac167a,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-b869fe77-56b1-4f40-962f-117fdfc3c32d,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-bb4d83d5-e7f7-46fa-b0cd-48602a0c4ee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745939177-172.17.0.8-1595507597662:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-7c0394a9-fea9-4918-a68e-a94b9b56e83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-ab44e9a8-08f5-4ed2-a590-d56182e47205,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-054ed618-b5c4-49e1-94ef-9e25bbb16b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-89234a68-a81e-44af-90c5-100a03646843,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-e8c27e6a-3f3b-4831-a74f-b6ee157fd6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-e6f55098-70fa-4a88-9f4d-806257ac167a,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-b869fe77-56b1-4f40-962f-117fdfc3c32d,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-bb4d83d5-e7f7-46fa-b0cd-48602a0c4ee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40581667-172.17.0.8-1595507697381:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-a2bcc3d3-d291-47e4-9806-bf7ce4e78267,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-28a8ddcd-14bd-4a23-9704-57a17424e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-2ab40ce7-48b6-4c6d-8104-0183e865a45e,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-0545e2ff-0d5a-486d-857c-17bac3c0bbee,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-53dba033-80c8-4a0c-9794-277ffdac5bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-9cef07b4-a426-4eb1-b7af-a6ff45fcc8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-65e53013-74a3-40c3-9634-5ee4342887c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-753473c5-310c-4d79-9a53-6a04477be8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40581667-172.17.0.8-1595507697381:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-a2bcc3d3-d291-47e4-9806-bf7ce4e78267,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-28a8ddcd-14bd-4a23-9704-57a17424e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-2ab40ce7-48b6-4c6d-8104-0183e865a45e,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-0545e2ff-0d5a-486d-857c-17bac3c0bbee,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-53dba033-80c8-4a0c-9794-277ffdac5bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-9cef07b4-a426-4eb1-b7af-a6ff45fcc8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-65e53013-74a3-40c3-9634-5ee4342887c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-753473c5-310c-4d79-9a53-6a04477be8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62308173-172.17.0.8-1595507728949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44498,DS-73c8bd5b-aa7d-454c-9b0a-1dd28e0c78d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-a8233b6e-b1d5-44d1-adee-846514e060d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-3362f8be-d43e-46da-898b-6c55ab58cc93,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-b2e700b1-0d28-411d-a9c6-323ef4f8ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-b88f3e20-408b-4eb1-9765-6f6411959a64,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-66bc460c-c2a7-4fd6-9ee1-07c28f03aba3,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-bc954ce4-a106-4b2f-aabb-b109a68cc83e,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-a0dbbe65-9fb7-4d94-a632-6f79ecdf8d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62308173-172.17.0.8-1595507728949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44498,DS-73c8bd5b-aa7d-454c-9b0a-1dd28e0c78d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-a8233b6e-b1d5-44d1-adee-846514e060d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-3362f8be-d43e-46da-898b-6c55ab58cc93,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-b2e700b1-0d28-411d-a9c6-323ef4f8ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-b88f3e20-408b-4eb1-9765-6f6411959a64,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-66bc460c-c2a7-4fd6-9ee1-07c28f03aba3,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-bc954ce4-a106-4b2f-aabb-b109a68cc83e,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-a0dbbe65-9fb7-4d94-a632-6f79ecdf8d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422000794-172.17.0.8-1595507977449:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-b838a6ec-b9d1-46be-952a-31ddffb12587,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-39564c49-55e9-45bf-b44e-5f01db27eb87,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-9add137a-5dfa-4374-ab95-6ffbb2ba94ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-15568374-de93-4ba7-aa5f-f89eba598fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-26f89d15-f562-497e-8516-b52bc4f05fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-ae840d8d-2be9-4f83-b5f3-a65e1445816b,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-d234f056-5c7c-498c-af83-02b441498445,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-f9035187-5e84-47bb-b6e0-2af3d88143b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422000794-172.17.0.8-1595507977449:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-b838a6ec-b9d1-46be-952a-31ddffb12587,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-39564c49-55e9-45bf-b44e-5f01db27eb87,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-9add137a-5dfa-4374-ab95-6ffbb2ba94ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-15568374-de93-4ba7-aa5f-f89eba598fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-26f89d15-f562-497e-8516-b52bc4f05fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-ae840d8d-2be9-4f83-b5f3-a65e1445816b,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-d234f056-5c7c-498c-af83-02b441498445,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-f9035187-5e84-47bb-b6e0-2af3d88143b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832248491-172.17.0.8-1595508132192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35735,DS-1d3b7c84-b470-4e48-978b-519b01789a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-856fa4f3-1c45-4cd8-bdbf-1b37bf918b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-b4946da4-5e00-4ac9-9c02-84e3a8ae81bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-51e9bc2a-e37e-490e-a729-91d470a4785a,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-e19cef8a-837b-4922-a1bf-98af6112b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-668332d8-369e-4564-8648-d6d41ab0a22c,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-63d58d49-3f9d-40cc-9cd4-e8f228ec7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-601ed2e0-9d6a-44c3-b232-f072ee792d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832248491-172.17.0.8-1595508132192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35735,DS-1d3b7c84-b470-4e48-978b-519b01789a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-856fa4f3-1c45-4cd8-bdbf-1b37bf918b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-b4946da4-5e00-4ac9-9c02-84e3a8ae81bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-51e9bc2a-e37e-490e-a729-91d470a4785a,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-e19cef8a-837b-4922-a1bf-98af6112b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-668332d8-369e-4564-8648-d6d41ab0a22c,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-63d58d49-3f9d-40cc-9cd4-e8f228ec7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-601ed2e0-9d6a-44c3-b232-f072ee792d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996429428-172.17.0.8-1595508166956:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-d511ca5f-8d8d-49b3-a7ef-fd2847b11600,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-c1e58501-49cd-42f9-ab92-6c2a4ccc2ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-48a41d4a-2a94-4b94-824b-f6bb94279ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-9a4de6c9-de55-46f1-a1eb-94955ebcc8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-a473b022-a2fb-4481-94af-2238864346dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-e397ca79-8de1-42e8-9bed-bc74a046a07d,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-da7f1342-53aa-4610-9097-d930983bfd71,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-30ba23d6-1c57-4674-ab02-2bf26063f094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996429428-172.17.0.8-1595508166956:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-d511ca5f-8d8d-49b3-a7ef-fd2847b11600,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-c1e58501-49cd-42f9-ab92-6c2a4ccc2ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-48a41d4a-2a94-4b94-824b-f6bb94279ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-9a4de6c9-de55-46f1-a1eb-94955ebcc8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-a473b022-a2fb-4481-94af-2238864346dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-e397ca79-8de1-42e8-9bed-bc74a046a07d,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-da7f1342-53aa-4610-9097-d930983bfd71,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-30ba23d6-1c57-4674-ab02-2bf26063f094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995626724-172.17.0.8-1595508351032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35557,DS-1394e1e0-4fd6-4a2f-9743-12f938118c56,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-9eae8133-efd1-4de5-83c2-4c4eb9a2a7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-502391e2-a0c8-46eb-a0ab-60ac13ab5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-a4cdd1f4-2197-414b-b838-4cf1605a10b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-da75c782-ad7f-4a8a-b4a4-27cbb721e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-4c76e5a3-5c1b-4cfe-b0a1-43535872f256,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-6438452f-d3e0-4a63-a7b5-c0641881eca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-9791c903-806d-4754-85c9-696294f9634b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995626724-172.17.0.8-1595508351032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35557,DS-1394e1e0-4fd6-4a2f-9743-12f938118c56,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-9eae8133-efd1-4de5-83c2-4c4eb9a2a7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-502391e2-a0c8-46eb-a0ab-60ac13ab5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-a4cdd1f4-2197-414b-b838-4cf1605a10b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-da75c782-ad7f-4a8a-b4a4-27cbb721e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-4c76e5a3-5c1b-4cfe-b0a1-43535872f256,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-6438452f-d3e0-4a63-a7b5-c0641881eca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-9791c903-806d-4754-85c9-696294f9634b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086863699-172.17.0.8-1595508643795:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44699,DS-947ba139-bcfe-4a59-b8d1-17d88c08e4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-35955dbf-d604-4a2b-95c5-322a61b7dc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-b522a42e-6bec-4a89-a6ac-cba33d849eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-4201b6ea-9793-407a-920e-2beca3effc59,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-e81aa103-5011-4e78-8ac4-1ba8ba605318,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-9cf56680-eb17-40a5-a36d-c5df24a2bef6,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-399d2aa6-fea0-40f4-af5b-faddda827446,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-3d36e21e-9177-427f-bbd6-e4773c726a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086863699-172.17.0.8-1595508643795:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44699,DS-947ba139-bcfe-4a59-b8d1-17d88c08e4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-35955dbf-d604-4a2b-95c5-322a61b7dc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-b522a42e-6bec-4a89-a6ac-cba33d849eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-4201b6ea-9793-407a-920e-2beca3effc59,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-e81aa103-5011-4e78-8ac4-1ba8ba605318,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-9cf56680-eb17-40a5-a36d-c5df24a2bef6,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-399d2aa6-fea0-40f4-af5b-faddda827446,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-3d36e21e-9177-427f-bbd6-e4773c726a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214904790-172.17.0.8-1595509241378:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-4abe20a4-5bb8-4246-85bc-8d1a0c8c37eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-3543085a-694e-49e4-af5e-a73af51c4401,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-ac1feec0-e120-4806-9cc6-f6e89694de1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-6c18423e-45aa-4a5c-adc6-63bfa4ae9417,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-f13b9d23-c04c-415c-87ca-fbb625a035dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-111d2c6c-54f7-4780-a893-0998dd63e2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-8abfa82e-10b7-44cf-bde9-830d35204398,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-73054688-9ea2-4f81-b4fb-e70b7cb935b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214904790-172.17.0.8-1595509241378:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-4abe20a4-5bb8-4246-85bc-8d1a0c8c37eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-3543085a-694e-49e4-af5e-a73af51c4401,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-ac1feec0-e120-4806-9cc6-f6e89694de1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-6c18423e-45aa-4a5c-adc6-63bfa4ae9417,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-f13b9d23-c04c-415c-87ca-fbb625a035dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-111d2c6c-54f7-4780-a893-0998dd63e2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-8abfa82e-10b7-44cf-bde9-830d35204398,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-73054688-9ea2-4f81-b4fb-e70b7cb935b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61359529-172.17.0.8-1595509551482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40104,DS-fe841141-9455-49aa-bf2c-c21d76b7aae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-444d9c34-d3df-4257-a953-7a11b191fcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-eb1e10ef-128d-4155-ab91-33d57581f599,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-689acbde-887a-4d84-b1e8-5f0a0b690f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-e6eb1a42-47f7-4406-ad75-7e955ddf429a,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-fe7ed1cf-b60c-41d8-aa73-7ff0eaaf5c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-5d8f212d-5e5b-42f0-8e32-99e73d78f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-9a29dcfa-6d83-42c7-b950-d37fd5ac9c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61359529-172.17.0.8-1595509551482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40104,DS-fe841141-9455-49aa-bf2c-c21d76b7aae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-444d9c34-d3df-4257-a953-7a11b191fcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-eb1e10ef-128d-4155-ab91-33d57581f599,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-689acbde-887a-4d84-b1e8-5f0a0b690f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-e6eb1a42-47f7-4406-ad75-7e955ddf429a,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-fe7ed1cf-b60c-41d8-aa73-7ff0eaaf5c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-5d8f212d-5e5b-42f0-8e32-99e73d78f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-9a29dcfa-6d83-42c7-b950-d37fd5ac9c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568689505-172.17.0.8-1595509696374:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46332,DS-a30432bd-4fb7-49f3-a8fa-f4f238a9dd72,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-a1791bad-4133-4f19-b003-49f42312f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-8e062d50-0abd-4507-892d-a092d51f3c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-51a8aa6d-2319-4314-9c3c-03937a67cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-66e92a1c-f6c3-4ed8-b192-26f87a211247,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-d9db7af5-8513-4090-9021-955484aabae7,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-f854e419-e754-4497-a681-58c9c249629a,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-47de90e0-b308-40d4-b23c-fbf5549a0b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568689505-172.17.0.8-1595509696374:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46332,DS-a30432bd-4fb7-49f3-a8fa-f4f238a9dd72,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-a1791bad-4133-4f19-b003-49f42312f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-8e062d50-0abd-4507-892d-a092d51f3c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-51a8aa6d-2319-4314-9c3c-03937a67cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-66e92a1c-f6c3-4ed8-b192-26f87a211247,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-d9db7af5-8513-4090-9021-955484aabae7,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-f854e419-e754-4497-a681-58c9c249629a,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-47de90e0-b308-40d4-b23c-fbf5549a0b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327012801-172.17.0.8-1595510318735:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34495,DS-54fbcd8b-f385-41d6-b03f-70fdc6272836,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-b5638677-5515-446c-8b1c-9060e39b4e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-83435eae-b452-4616-a92f-53358e5bdc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-25eeabf5-7a79-4416-b86c-80a019025e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-c038d2ee-0b96-4ab9-843c-6be0bc16388a,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-d900087e-40f6-42a4-85d8-69464ff77592,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-9c4cb696-6453-4871-be76-abd0a37a6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-c923570f-5122-4ad8-9acf-08992811c248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327012801-172.17.0.8-1595510318735:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34495,DS-54fbcd8b-f385-41d6-b03f-70fdc6272836,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-b5638677-5515-446c-8b1c-9060e39b4e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-83435eae-b452-4616-a92f-53358e5bdc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-25eeabf5-7a79-4416-b86c-80a019025e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-c038d2ee-0b96-4ab9-843c-6be0bc16388a,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-d900087e-40f6-42a4-85d8-69464ff77592,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-9c4cb696-6453-4871-be76-abd0a37a6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-c923570f-5122-4ad8-9acf-08992811c248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388783591-172.17.0.8-1595510486195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43900,DS-4f491d5d-b663-46bc-9ad8-8bd11d7539b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-3876f265-07e2-4f08-bcb6-ac0084ffaf20,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-c26949fb-dc40-4bee-9c75-14633ac01ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-d08ed5d2-5d93-4523-9788-b08ef0f6dd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-3b5a92a9-d228-4a4a-a8d1-28ca3c6d81ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3b9ef462-5d5f-4d23-b2f4-880330ffc788,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-44332b13-9817-4b17-b921-c8338efc52a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-7f432b95-4934-4d3c-bd2d-28bbbc43d269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388783591-172.17.0.8-1595510486195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43900,DS-4f491d5d-b663-46bc-9ad8-8bd11d7539b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-3876f265-07e2-4f08-bcb6-ac0084ffaf20,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-c26949fb-dc40-4bee-9c75-14633ac01ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-d08ed5d2-5d93-4523-9788-b08ef0f6dd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-3b5a92a9-d228-4a4a-a8d1-28ca3c6d81ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3b9ef462-5d5f-4d23-b2f4-880330ffc788,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-44332b13-9817-4b17-b921-c8338efc52a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-7f432b95-4934-4d3c-bd2d-28bbbc43d269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349145809-172.17.0.8-1595510890177:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46779,DS-af72b65f-f4df-4054-9481-ca61a2f25790,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-171e7586-c8e1-4d25-ad1b-33a05b1f3d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-630be6b5-c2ef-4628-9d85-316848217363,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-e3186385-a5bb-424f-aa66-50857676b0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-a1cd8471-ac47-433e-97fe-c6567cabbe15,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-0690f440-bde3-46de-afa3-b2b7b0ed6083,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-711de4ab-770e-45e0-a65b-54f0d430e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-e4da9268-3bb4-4060-8692-b5703619889f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349145809-172.17.0.8-1595510890177:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46779,DS-af72b65f-f4df-4054-9481-ca61a2f25790,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-171e7586-c8e1-4d25-ad1b-33a05b1f3d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-630be6b5-c2ef-4628-9d85-316848217363,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-e3186385-a5bb-424f-aa66-50857676b0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-a1cd8471-ac47-433e-97fe-c6567cabbe15,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-0690f440-bde3-46de-afa3-b2b7b0ed6083,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-711de4ab-770e-45e0-a65b-54f0d430e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-e4da9268-3bb4-4060-8692-b5703619889f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718766154-172.17.0.8-1595511111651:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-864ac383-50ff-453d-b8d5-988356f09029,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-9baeb098-a750-4b7b-9e5c-ad94239b74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-376cdef1-f9c9-47bc-ab6b-68697d8a91ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-21c46eba-121b-43b0-a1e7-1bbcc16094a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-a41dfe17-f167-4723-bea3-f6e6391d4fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-734f5145-b3d8-4239-a800-f68d5e98d92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-669b36a9-83e8-4e2b-9eca-01cef7fc8534,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-0b515b17-fc0a-4778-b2a9-57166b20d666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718766154-172.17.0.8-1595511111651:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-864ac383-50ff-453d-b8d5-988356f09029,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-9baeb098-a750-4b7b-9e5c-ad94239b74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-376cdef1-f9c9-47bc-ab6b-68697d8a91ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-21c46eba-121b-43b0-a1e7-1bbcc16094a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-a41dfe17-f167-4723-bea3-f6e6391d4fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-734f5145-b3d8-4239-a800-f68d5e98d92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-669b36a9-83e8-4e2b-9eca-01cef7fc8534,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-0b515b17-fc0a-4778-b2a9-57166b20d666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111795665-172.17.0.8-1595511288541:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-1815f3bd-1b26-4eea-aa3f-a69d7b02bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-5ac20d7e-83a5-4e37-af63-3f2da6262d49,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-864e8aeb-205e-4142-b6c8-c41ef173623f,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-e0142635-fb44-4384-aabc-4684f4d91bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-66d14a08-e19d-4433-86fe-8fbd5dbf1112,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-61efe15f-0f58-44de-8bbb-c5f107e24d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-1ac2bf47-8770-456d-b413-61e04a6beb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-ac385393-9d72-4e3e-81da-af6165b15f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111795665-172.17.0.8-1595511288541:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-1815f3bd-1b26-4eea-aa3f-a69d7b02bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-5ac20d7e-83a5-4e37-af63-3f2da6262d49,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-864e8aeb-205e-4142-b6c8-c41ef173623f,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-e0142635-fb44-4384-aabc-4684f4d91bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-66d14a08-e19d-4433-86fe-8fbd5dbf1112,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-61efe15f-0f58-44de-8bbb-c5f107e24d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-1ac2bf47-8770-456d-b413-61e04a6beb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-ac385393-9d72-4e3e-81da-af6165b15f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297762004-172.17.0.8-1595511358019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35421,DS-1a8b55f8-e6e0-499d-8c79-9a7e108491fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-45877400-cc4d-46f7-a66d-df680bf0af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-fb26dea0-a2a0-4671-aa69-bd01b154c632,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-9b8582eb-4070-4d9e-8826-0684fdfacefa,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-55721145-4ede-43d7-953c-391937a0f660,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-30ff1d7b-0044-4564-a4a3-68506e18509c,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-d4ed25f8-3a7d-4dc1-9b16-f046ddfca0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-84641bb8-9f7f-44e2-8796-816597a2f79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297762004-172.17.0.8-1595511358019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35421,DS-1a8b55f8-e6e0-499d-8c79-9a7e108491fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-45877400-cc4d-46f7-a66d-df680bf0af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-fb26dea0-a2a0-4671-aa69-bd01b154c632,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-9b8582eb-4070-4d9e-8826-0684fdfacefa,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-55721145-4ede-43d7-953c-391937a0f660,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-30ff1d7b-0044-4564-a4a3-68506e18509c,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-d4ed25f8-3a7d-4dc1-9b16-f046ddfca0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-84641bb8-9f7f-44e2-8796-816597a2f79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38413872-172.17.0.8-1595511609384:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36391,DS-bad3de24-58ed-4460-bb91-53065ec5836f,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-434e01a1-cff7-44e9-a0ef-921820b98c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-0a9d957f-0645-451e-9e20-50a147cb03b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-ba43386b-8203-4cbd-a009-a5514fed778c,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-5c59711a-40cd-455a-81e8-e3c4a670a4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-6335288b-8f07-41f1-871f-4250f72f0b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-a5cba237-62e4-4db9-a285-e73138d9998a,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-50dd745e-e36e-4c65-97e1-f0fabb90c9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38413872-172.17.0.8-1595511609384:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36391,DS-bad3de24-58ed-4460-bb91-53065ec5836f,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-434e01a1-cff7-44e9-a0ef-921820b98c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-0a9d957f-0645-451e-9e20-50a147cb03b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-ba43386b-8203-4cbd-a009-a5514fed778c,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-5c59711a-40cd-455a-81e8-e3c4a670a4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-6335288b-8f07-41f1-871f-4250f72f0b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-a5cba237-62e4-4db9-a285-e73138d9998a,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-50dd745e-e36e-4c65-97e1-f0fabb90c9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706073666-172.17.0.8-1595511633188:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35797,DS-42bbe178-16e4-48e2-80c7-58bc1c460614,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-18f7f949-a8eb-4aec-b0c3-bf1242e6b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-ecbadeca-55bc-46a7-8851-596d23e1d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-3f80cfbb-07da-4646-bac0-cca02b1126e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-25a3d9b4-ebbe-4d19-845b-a0277dc6a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-dbfb5635-b120-4fe6-8474-efaaf3216e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-07bbb2eb-9d66-459b-a0e4-b71cbc0c8a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-22fdea76-4aff-4f3c-88cc-595edb60e9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706073666-172.17.0.8-1595511633188:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35797,DS-42bbe178-16e4-48e2-80c7-58bc1c460614,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-18f7f949-a8eb-4aec-b0c3-bf1242e6b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-ecbadeca-55bc-46a7-8851-596d23e1d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-3f80cfbb-07da-4646-bac0-cca02b1126e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-25a3d9b4-ebbe-4d19-845b-a0277dc6a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-dbfb5635-b120-4fe6-8474-efaaf3216e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-07bbb2eb-9d66-459b-a0e4-b71cbc0c8a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-22fdea76-4aff-4f3c-88cc-595edb60e9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5259
