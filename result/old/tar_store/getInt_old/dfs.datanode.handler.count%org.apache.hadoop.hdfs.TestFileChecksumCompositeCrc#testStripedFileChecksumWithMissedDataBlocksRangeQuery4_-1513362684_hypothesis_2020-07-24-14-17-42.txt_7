reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658940280-172.17.0.10-1595601119511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-5db1aeaa-9ee1-41e1-8478-b0c166822072,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-7519faac-d6c6-464a-8a2f-4ee9a4e44e50,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-191d1877-457e-404f-957a-3b1e26eaddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-42198d65-d25d-45d4-92fc-446aed694859,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-7b1d73ca-46c6-4fc6-acda-8a2c642b9d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-4c38bc04-2da6-4b43-bd38-6a723cf3a592,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-df4f9618-32ae-406c-9f55-843d30c7afb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-01f1b0bb-11a0-4e7f-afa8-eae64035b34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658940280-172.17.0.10-1595601119511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-5db1aeaa-9ee1-41e1-8478-b0c166822072,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-7519faac-d6c6-464a-8a2f-4ee9a4e44e50,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-191d1877-457e-404f-957a-3b1e26eaddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-42198d65-d25d-45d4-92fc-446aed694859,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-7b1d73ca-46c6-4fc6-acda-8a2c642b9d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-4c38bc04-2da6-4b43-bd38-6a723cf3a592,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-df4f9618-32ae-406c-9f55-843d30c7afb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-01f1b0bb-11a0-4e7f-afa8-eae64035b34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269230603-172.17.0.10-1595601263124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43136,DS-fa5e120f-adc4-42c4-8f7f-41afc48695f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-86b2ac41-cb11-46a3-8719-63dba4de240c,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-5bbe9990-960d-450c-a220-7f4a4ff8c486,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-fe1f2dcc-7948-479c-ac72-6208b92091fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-79c59f47-e93d-43f6-ae07-ec406db78363,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-a649fe01-ce95-400e-b9b6-b82a1a2de93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-dc9e6ca1-78b0-4c89-959d-12f67d50dd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-b9be673a-9c1c-4bdf-b069-87d7655669e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269230603-172.17.0.10-1595601263124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43136,DS-fa5e120f-adc4-42c4-8f7f-41afc48695f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-86b2ac41-cb11-46a3-8719-63dba4de240c,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-5bbe9990-960d-450c-a220-7f4a4ff8c486,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-fe1f2dcc-7948-479c-ac72-6208b92091fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-79c59f47-e93d-43f6-ae07-ec406db78363,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-a649fe01-ce95-400e-b9b6-b82a1a2de93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-dc9e6ca1-78b0-4c89-959d-12f67d50dd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-b9be673a-9c1c-4bdf-b069-87d7655669e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940232017-172.17.0.10-1595601445461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35589,DS-37bfd39b-0627-47fd-8ffc-79e9d15baeac,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-27819ee0-7874-4dc3-a0ac-9afad3867b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-50d81188-663a-40c3-a955-7d00de3efb29,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-3aabb9ba-5f93-4570-a40a-d9e49cb747e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-3aff6d88-9777-4ce2-b163-b79c06cc0b36,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-c1a5382c-2b7d-4e6f-b314-ea7f688ceea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-2913c104-211d-4d31-92b5-0703233fc7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-d19f0367-9a37-4c6e-a0b0-242c785ed239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940232017-172.17.0.10-1595601445461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35589,DS-37bfd39b-0627-47fd-8ffc-79e9d15baeac,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-27819ee0-7874-4dc3-a0ac-9afad3867b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-50d81188-663a-40c3-a955-7d00de3efb29,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-3aabb9ba-5f93-4570-a40a-d9e49cb747e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-3aff6d88-9777-4ce2-b163-b79c06cc0b36,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-c1a5382c-2b7d-4e6f-b314-ea7f688ceea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-2913c104-211d-4d31-92b5-0703233fc7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-d19f0367-9a37-4c6e-a0b0-242c785ed239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963781983-172.17.0.10-1595602007757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-85b3e4fe-9ccd-4333-a222-05edb417eed4,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-488848ff-2c3b-41f9-89a4-1363a2b7932c,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-347eb73f-a40f-4215-8285-3aa8b430bb84,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-386ef1b4-d0fc-4ab7-8250-6042cae6590e,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-42f60e09-c309-4cf3-b9fa-2b5c50de04a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-cbc5c215-b7fd-48fb-bf5b-e072f17657b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-2a1979b7-ad00-4119-9fea-f4698c3e2483,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-352f5b68-abcd-4c88-8489-5752cbe79de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963781983-172.17.0.10-1595602007757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-85b3e4fe-9ccd-4333-a222-05edb417eed4,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-488848ff-2c3b-41f9-89a4-1363a2b7932c,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-347eb73f-a40f-4215-8285-3aa8b430bb84,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-386ef1b4-d0fc-4ab7-8250-6042cae6590e,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-42f60e09-c309-4cf3-b9fa-2b5c50de04a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-cbc5c215-b7fd-48fb-bf5b-e072f17657b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-2a1979b7-ad00-4119-9fea-f4698c3e2483,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-352f5b68-abcd-4c88-8489-5752cbe79de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989884697-172.17.0.10-1595602520786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-b0ae4476-01d6-40e5-931c-8c744282f751,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-0f6ea139-bac7-40bc-ab02-d6cbecec1ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-db6b9894-7423-4d9d-8296-afe8538bbf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-fb700c32-b35f-433e-9436-c182f05d670d,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8eb105ab-b29c-4274-ac74-66d492bdd699,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-ab62936d-e014-4f20-8ca9-9613b3ef01a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-faf491b1-7e33-4001-9459-0cca3da1a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-ca01e12b-10b2-4051-b759-d33c4150d130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989884697-172.17.0.10-1595602520786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-b0ae4476-01d6-40e5-931c-8c744282f751,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-0f6ea139-bac7-40bc-ab02-d6cbecec1ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-db6b9894-7423-4d9d-8296-afe8538bbf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-fb700c32-b35f-433e-9436-c182f05d670d,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8eb105ab-b29c-4274-ac74-66d492bdd699,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-ab62936d-e014-4f20-8ca9-9613b3ef01a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-faf491b1-7e33-4001-9459-0cca3da1a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-ca01e12b-10b2-4051-b759-d33c4150d130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642549041-172.17.0.10-1595603380851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40619,DS-27427a5b-daae-41c3-a1ec-d434287c35e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-ffa88232-59d6-4440-a83d-756e109ce9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-d4492467-1718-4251-b7cd-4ad3ca8fd577,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-545d2c46-7ba8-47c5-a419-0f1baf0fe37b,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-faeba80f-7b03-4af3-9713-52035e83bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-b3b4a268-c773-4e52-b180-2802297d0afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-9f75a229-8d54-4573-825a-fb3f5320e77f,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-28fbc341-f479-4b7d-b737-a10b59424d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642549041-172.17.0.10-1595603380851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40619,DS-27427a5b-daae-41c3-a1ec-d434287c35e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-ffa88232-59d6-4440-a83d-756e109ce9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-d4492467-1718-4251-b7cd-4ad3ca8fd577,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-545d2c46-7ba8-47c5-a419-0f1baf0fe37b,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-faeba80f-7b03-4af3-9713-52035e83bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-b3b4a268-c773-4e52-b180-2802297d0afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-9f75a229-8d54-4573-825a-fb3f5320e77f,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-28fbc341-f479-4b7d-b737-a10b59424d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875798028-172.17.0.10-1595603971195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-fe8d947e-8549-411c-aac7-957505c12aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-2dc7ac38-e213-454f-bba1-22b5e2235efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-f6745548-0a82-4c95-a549-68cf273116cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-5eed841e-f70b-4afe-a2d8-79576478e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-9bc46a01-a26c-4559-8fae-f8f46384b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-fa5524a0-34cb-4602-b31c-e49e79ec40ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-05c44db1-f6a0-47ed-957d-a0db4da0e649,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-6dc974d9-056c-4691-9abe-98caaa93c83e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875798028-172.17.0.10-1595603971195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-fe8d947e-8549-411c-aac7-957505c12aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-2dc7ac38-e213-454f-bba1-22b5e2235efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-f6745548-0a82-4c95-a549-68cf273116cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-5eed841e-f70b-4afe-a2d8-79576478e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-9bc46a01-a26c-4559-8fae-f8f46384b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-fa5524a0-34cb-4602-b31c-e49e79ec40ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-05c44db1-f6a0-47ed-957d-a0db4da0e649,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-6dc974d9-056c-4691-9abe-98caaa93c83e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061044446-172.17.0.10-1595604329172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40670,DS-764edaf4-70e2-47f2-8c13-943b29f40698,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-8170923c-62d8-41ef-b0c3-6dccb8de04e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-3756aa02-9896-4fdb-bb59-f28f56647937,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-7dd637b7-9a80-4527-bab3-5faee4f603ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-4b36af70-c4e9-409e-a996-2af6d1e485ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-40228992-c3da-4295-948e-882cc121052f,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-28af07c7-3733-459e-8bdb-72bc742cdb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-52efee29-afc1-45b1-9248-a7660ce321d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061044446-172.17.0.10-1595604329172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40670,DS-764edaf4-70e2-47f2-8c13-943b29f40698,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-8170923c-62d8-41ef-b0c3-6dccb8de04e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-3756aa02-9896-4fdb-bb59-f28f56647937,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-7dd637b7-9a80-4527-bab3-5faee4f603ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-4b36af70-c4e9-409e-a996-2af6d1e485ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-40228992-c3da-4295-948e-882cc121052f,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-28af07c7-3733-459e-8bdb-72bc742cdb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-52efee29-afc1-45b1-9248-a7660ce321d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946429134-172.17.0.10-1595604502722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-48bbf00e-a7a2-4b92-b7ca-53c1c111107e,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-bff9f6d9-a1dd-4412-8557-e71c3f1f5ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-41637e46-e722-448c-90c1-ed503a61626e,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-5678948b-da98-426c-9328-b94ebd2583d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-2115649c-a58d-4b99-8d6f-28eb9d9c9700,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-6d65f12b-ca43-4d00-9466-68057ae54d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-e9c2d1d9-3c89-4470-87dc-49609fc10731,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-7a9c7095-63ba-4a1f-9c9c-6f94105e7dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946429134-172.17.0.10-1595604502722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-48bbf00e-a7a2-4b92-b7ca-53c1c111107e,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-bff9f6d9-a1dd-4412-8557-e71c3f1f5ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-41637e46-e722-448c-90c1-ed503a61626e,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-5678948b-da98-426c-9328-b94ebd2583d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-2115649c-a58d-4b99-8d6f-28eb9d9c9700,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-6d65f12b-ca43-4d00-9466-68057ae54d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-e9c2d1d9-3c89-4470-87dc-49609fc10731,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-7a9c7095-63ba-4a1f-9c9c-6f94105e7dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114842990-172.17.0.10-1595604535243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-3966a304-4edf-45ad-a011-b956c356cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-a4c7f4cb-e4c4-4053-8c79-2ba5bf1c5cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-0c4f27f7-7506-4bf6-a244-5fd3551b5808,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-d4997684-5f37-4bbe-9d69-28c8450c8168,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-605b4015-0968-467d-9fef-04aa37e144b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-ed5db97d-6bcd-486b-bc24-d046e2346250,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-b6da5630-1016-40bc-b1aa-69c15cc267d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-0f4a5d15-525c-4647-a36d-e2bfe4d730c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114842990-172.17.0.10-1595604535243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-3966a304-4edf-45ad-a011-b956c356cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-a4c7f4cb-e4c4-4053-8c79-2ba5bf1c5cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-0c4f27f7-7506-4bf6-a244-5fd3551b5808,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-d4997684-5f37-4bbe-9d69-28c8450c8168,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-605b4015-0968-467d-9fef-04aa37e144b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-ed5db97d-6bcd-486b-bc24-d046e2346250,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-b6da5630-1016-40bc-b1aa-69c15cc267d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-0f4a5d15-525c-4647-a36d-e2bfe4d730c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227715185-172.17.0.10-1595604841608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34428,DS-32d3160a-1773-4e94-9630-c00c2ad13570,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-cbe3f6ba-af51-40d4-b953-d3da0483a20a,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-b2fb6cb6-f3a4-4300-82c9-0a83269eeb58,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-c6dc24d3-6f9b-4929-870f-be1635945491,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-aa8fdcf1-acac-4e05-8bcf-153f36693754,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-d9c40295-a44e-4d02-8937-83a684d15edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-65148b6d-735d-4ba0-a11d-c35196b4fdda,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-e2a0ba00-3182-4626-8620-f782215b8395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227715185-172.17.0.10-1595604841608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34428,DS-32d3160a-1773-4e94-9630-c00c2ad13570,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-cbe3f6ba-af51-40d4-b953-d3da0483a20a,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-b2fb6cb6-f3a4-4300-82c9-0a83269eeb58,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-c6dc24d3-6f9b-4929-870f-be1635945491,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-aa8fdcf1-acac-4e05-8bcf-153f36693754,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-d9c40295-a44e-4d02-8937-83a684d15edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-65148b6d-735d-4ba0-a11d-c35196b4fdda,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-e2a0ba00-3182-4626-8620-f782215b8395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621605847-172.17.0.10-1595604995999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38308,DS-5216e5f6-a6c2-42bd-85b7-516cf5add912,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-2f3fb359-9ebe-403c-aa85-2902497c4b72,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-bc045a52-2a5b-45f1-a01b-ad04367dad78,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-e9c915d1-dc96-4568-90d0-a4b658899bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-67d8bef4-382e-42b9-ae36-ec734536f5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-76a7ba04-e21b-4b3b-ac00-dede6ed55243,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-d28ff27a-d82c-4231-ac3e-35c9b529e6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-5cc17a59-ec6f-4b20-b349-54e20d6fa987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621605847-172.17.0.10-1595604995999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38308,DS-5216e5f6-a6c2-42bd-85b7-516cf5add912,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-2f3fb359-9ebe-403c-aa85-2902497c4b72,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-bc045a52-2a5b-45f1-a01b-ad04367dad78,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-e9c915d1-dc96-4568-90d0-a4b658899bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-67d8bef4-382e-42b9-ae36-ec734536f5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-76a7ba04-e21b-4b3b-ac00-dede6ed55243,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-d28ff27a-d82c-4231-ac3e-35c9b529e6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-5cc17a59-ec6f-4b20-b349-54e20d6fa987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134447888-172.17.0.10-1595605264921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-95dfd8f2-87c2-4d83-b879-4bb262c040cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-1674e979-10b4-4df0-b038-46297190d41d,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-01de82ac-90f4-4097-8012-0cad0138ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-e40d6622-2805-4b9d-8399-dc0dcbce2870,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-c5d2e8d9-42f8-4160-9303-0f03c86de04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-bf1ee867-310d-4819-bd0b-6de22476098e,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-a298f7cb-6042-413d-9b11-c095b20de19d,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-ad8c06de-d446-42a6-9fc4-9cd68956ff7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134447888-172.17.0.10-1595605264921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-95dfd8f2-87c2-4d83-b879-4bb262c040cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-1674e979-10b4-4df0-b038-46297190d41d,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-01de82ac-90f4-4097-8012-0cad0138ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-e40d6622-2805-4b9d-8399-dc0dcbce2870,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-c5d2e8d9-42f8-4160-9303-0f03c86de04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-bf1ee867-310d-4819-bd0b-6de22476098e,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-a298f7cb-6042-413d-9b11-c095b20de19d,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-ad8c06de-d446-42a6-9fc4-9cd68956ff7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049435281-172.17.0.10-1595605440671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-55837657-d802-4ea8-ad0c-4fed6e384e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-ab836051-9158-40eb-a0fd-cebd51e33895,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-00072413-e907-4ffc-b4a4-5ec07855d292,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-1371ec51-fb75-4f46-9270-48a149b30a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-fd196391-d6b4-40c7-9ce3-33d158438e17,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-6529e26c-50e0-4acf-b812-b75fbcbf4ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-fbb7337e-1f02-4a37-9024-280c76f8d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-d74f359f-3c61-45e8-97d2-48d16633164c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049435281-172.17.0.10-1595605440671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-55837657-d802-4ea8-ad0c-4fed6e384e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-ab836051-9158-40eb-a0fd-cebd51e33895,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-00072413-e907-4ffc-b4a4-5ec07855d292,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-1371ec51-fb75-4f46-9270-48a149b30a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-fd196391-d6b4-40c7-9ce3-33d158438e17,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-6529e26c-50e0-4acf-b812-b75fbcbf4ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-fbb7337e-1f02-4a37-9024-280c76f8d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-d74f359f-3c61-45e8-97d2-48d16633164c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5497
