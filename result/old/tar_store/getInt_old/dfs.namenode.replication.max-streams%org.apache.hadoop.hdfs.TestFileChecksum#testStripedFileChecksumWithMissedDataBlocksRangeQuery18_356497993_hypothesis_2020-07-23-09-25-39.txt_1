reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006042261-172.17.0.12-1595496773886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-97fa623e-9b96-40ee-a789-f7e1c38ee876,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-59f08cdb-89d3-452b-8455-48ce193f7e50,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-9819250e-704c-424e-aa5e-5349ed2277fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-d673f034-a6e9-41eb-a8c1-cbc7a0b1e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-b44c7751-26bb-4d11-9aca-b307acf13dea,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-32157f38-92b1-4eb4-8f19-1ea1d8c8b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-a442fb88-08f0-431b-b37e-9ac3354839b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-a0fde81f-2bbb-4902-8e0e-12cca62280f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006042261-172.17.0.12-1595496773886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-97fa623e-9b96-40ee-a789-f7e1c38ee876,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-59f08cdb-89d3-452b-8455-48ce193f7e50,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-9819250e-704c-424e-aa5e-5349ed2277fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-d673f034-a6e9-41eb-a8c1-cbc7a0b1e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-b44c7751-26bb-4d11-9aca-b307acf13dea,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-32157f38-92b1-4eb4-8f19-1ea1d8c8b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-a442fb88-08f0-431b-b37e-9ac3354839b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-a0fde81f-2bbb-4902-8e0e-12cca62280f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019738108-172.17.0.12-1595496880011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-5e1b1aeb-c78a-42cc-8f4a-fee12b2c6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-70c4af62-4484-41ed-a1a9-c6be602c01e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-49f30084-ef25-42de-8a29-d6fd12461ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-9bc313c5-b28d-40e4-b67f-1357af46addd,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-ec1ec479-890c-456f-86fc-8ec7d7ad74b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-2daaa048-5d75-4be9-89cd-c2167bdc97f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-946283ea-1131-44bb-94fc-6adb1b0dafcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-70ca813f-d561-4679-ab5e-0e39a15ef115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019738108-172.17.0.12-1595496880011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-5e1b1aeb-c78a-42cc-8f4a-fee12b2c6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-70c4af62-4484-41ed-a1a9-c6be602c01e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-49f30084-ef25-42de-8a29-d6fd12461ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-9bc313c5-b28d-40e4-b67f-1357af46addd,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-ec1ec479-890c-456f-86fc-8ec7d7ad74b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-2daaa048-5d75-4be9-89cd-c2167bdc97f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-946283ea-1131-44bb-94fc-6adb1b0dafcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-70ca813f-d561-4679-ab5e-0e39a15ef115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221939357-172.17.0.12-1595497419329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-676ff1c4-4efa-43cd-810d-3d97e0fc42a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-952a978d-22d3-4f5c-a31d-f36d10bf2734,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-18336b57-22f3-4822-bc6a-01f89c3ef6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-52c62a5d-471d-4df2-accf-acf774f01624,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-95f9bb1a-e4fa-43b5-bd93-70bcd4a87d58,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-4c734230-9efa-4da7-a5a7-60cc0ed4fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-cbb2f58c-78fb-4b76-b01b-538226ff8f62,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-305dd7a3-5098-4128-a17b-8e646bf977dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221939357-172.17.0.12-1595497419329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-676ff1c4-4efa-43cd-810d-3d97e0fc42a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-952a978d-22d3-4f5c-a31d-f36d10bf2734,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-18336b57-22f3-4822-bc6a-01f89c3ef6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-52c62a5d-471d-4df2-accf-acf774f01624,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-95f9bb1a-e4fa-43b5-bd93-70bcd4a87d58,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-4c734230-9efa-4da7-a5a7-60cc0ed4fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-cbb2f58c-78fb-4b76-b01b-538226ff8f62,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-305dd7a3-5098-4128-a17b-8e646bf977dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31703747-172.17.0.12-1595497522641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-403cc3df-2999-4dea-bdf6-bf79797084bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-086a3bce-9816-40bd-8c78-eb60d0be998d,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-7700d5e1-553c-493e-8ce4-0fc7cedda783,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-cee8042b-6f1b-4c65-9922-e4fa47f548f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-4c4a4c9b-2b1a-4c59-900f-ca3772cc92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-638a85ed-3313-4c29-bff7-78fd29eb5648,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-a60e81e1-275a-49e8-8dfc-7e9262f89b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-0d4ccad8-5aba-4166-b955-bc8ef7a326e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31703747-172.17.0.12-1595497522641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-403cc3df-2999-4dea-bdf6-bf79797084bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-086a3bce-9816-40bd-8c78-eb60d0be998d,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-7700d5e1-553c-493e-8ce4-0fc7cedda783,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-cee8042b-6f1b-4c65-9922-e4fa47f548f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-4c4a4c9b-2b1a-4c59-900f-ca3772cc92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-638a85ed-3313-4c29-bff7-78fd29eb5648,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-a60e81e1-275a-49e8-8dfc-7e9262f89b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-0d4ccad8-5aba-4166-b955-bc8ef7a326e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538649813-172.17.0.12-1595497565655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41449,DS-abf30d08-86dc-4a9f-b607-7ed43d3e926f,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-5c0cacfd-5774-4448-bfff-6b1a4f957980,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-28825cad-2477-41ef-8497-bf94d40bba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-b0baa3c9-810b-440c-89e0-19c1f6906302,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-5e009487-b290-47a8-a468-7322350ca65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-983515e0-baa6-4b1b-8bda-3a4670ce0509,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-5156423c-96f6-4842-9faf-fa49456cf5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-ebef7c3c-a6f5-4819-900b-a3ce973006db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538649813-172.17.0.12-1595497565655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41449,DS-abf30d08-86dc-4a9f-b607-7ed43d3e926f,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-5c0cacfd-5774-4448-bfff-6b1a4f957980,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-28825cad-2477-41ef-8497-bf94d40bba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-b0baa3c9-810b-440c-89e0-19c1f6906302,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-5e009487-b290-47a8-a468-7322350ca65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-983515e0-baa6-4b1b-8bda-3a4670ce0509,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-5156423c-96f6-4842-9faf-fa49456cf5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-ebef7c3c-a6f5-4819-900b-a3ce973006db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402524527-172.17.0.12-1595497712913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37726,DS-29ff34dd-a109-4d8c-9012-46692e38863f,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-cf11f011-18bf-4412-b363-5a1fe4f1d403,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-54b129bd-1d44-46b7-a5d7-5beddc27e959,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-38d2dae1-3314-4118-822e-c92b8d437890,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-597b9180-5ccc-4e87-8fab-ef658ed515d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-b71aea73-0421-4561-b46d-1103a4fbc8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-c45c0477-2660-403b-8972-59fd01c0528c,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-a4058f3a-9e8a-4e5f-944b-3ccf8ecfee4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402524527-172.17.0.12-1595497712913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37726,DS-29ff34dd-a109-4d8c-9012-46692e38863f,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-cf11f011-18bf-4412-b363-5a1fe4f1d403,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-54b129bd-1d44-46b7-a5d7-5beddc27e959,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-38d2dae1-3314-4118-822e-c92b8d437890,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-597b9180-5ccc-4e87-8fab-ef658ed515d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-b71aea73-0421-4561-b46d-1103a4fbc8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-c45c0477-2660-403b-8972-59fd01c0528c,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-a4058f3a-9e8a-4e5f-944b-3ccf8ecfee4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295642160-172.17.0.12-1595498022679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43560,DS-b4ba0466-3554-4bb0-9f0c-acc08fd899fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-74d1847d-4d74-406a-8515-1ed16a34df58,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-f4c9bb61-752b-4a98-a351-a6f810f09428,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-39176780-10dc-4dc7-85c5-1d85b00ed07f,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-c397c0f4-9ddd-4ee5-8999-dab4428fd4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-a075a810-3cb7-4e41-b0ce-1f35ef215a73,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-c50d7413-78bb-4563-a3a2-8d99ac663023,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-4492dc2a-f294-44cf-b018-c61a1301d019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295642160-172.17.0.12-1595498022679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43560,DS-b4ba0466-3554-4bb0-9f0c-acc08fd899fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-74d1847d-4d74-406a-8515-1ed16a34df58,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-f4c9bb61-752b-4a98-a351-a6f810f09428,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-39176780-10dc-4dc7-85c5-1d85b00ed07f,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-c397c0f4-9ddd-4ee5-8999-dab4428fd4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-a075a810-3cb7-4e41-b0ce-1f35ef215a73,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-c50d7413-78bb-4563-a3a2-8d99ac663023,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-4492dc2a-f294-44cf-b018-c61a1301d019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759687154-172.17.0.12-1595498281916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-7bb004c8-8f48-4d96-be75-d0542ca4cb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-ff08d5b6-5da8-410c-8933-12df90ec12bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-2ecf0ce3-cce7-49dc-ab07-6064db350281,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-0580957a-cb0d-4aae-a477-1b34de254154,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-8507ccf2-3486-45cc-8a7c-2e75d91156d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-aeb6283f-183f-4b04-8d37-04efd49831b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-f6d462f6-3769-4d12-8a3e-5b4c42907044,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-a57af25b-bcec-41b3-82f8-9bc73b4fc866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759687154-172.17.0.12-1595498281916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-7bb004c8-8f48-4d96-be75-d0542ca4cb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-ff08d5b6-5da8-410c-8933-12df90ec12bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-2ecf0ce3-cce7-49dc-ab07-6064db350281,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-0580957a-cb0d-4aae-a477-1b34de254154,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-8507ccf2-3486-45cc-8a7c-2e75d91156d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-aeb6283f-183f-4b04-8d37-04efd49831b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-f6d462f6-3769-4d12-8a3e-5b4c42907044,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-a57af25b-bcec-41b3-82f8-9bc73b4fc866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209677301-172.17.0.12-1595499293616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35099,DS-15308b3a-0fd9-4261-b5c0-b4cf9c2cdfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-0a6185ac-976b-499c-ab92-4290256c9a59,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-329885cc-374a-4249-9722-f5bb726ebb46,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-ea3afc8b-2fe0-439c-b9f2-568f711ba467,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-38c41d1f-7501-483c-b0d6-97dcd0406212,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-756a498d-99c9-4cb9-86b9-c48272ed2c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-d69c4ef2-beca-459c-8d6f-0cfe274168a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-5868a07e-b34b-4558-8d10-ba7ead982a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209677301-172.17.0.12-1595499293616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35099,DS-15308b3a-0fd9-4261-b5c0-b4cf9c2cdfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-0a6185ac-976b-499c-ab92-4290256c9a59,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-329885cc-374a-4249-9722-f5bb726ebb46,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-ea3afc8b-2fe0-439c-b9f2-568f711ba467,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-38c41d1f-7501-483c-b0d6-97dcd0406212,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-756a498d-99c9-4cb9-86b9-c48272ed2c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-d69c4ef2-beca-459c-8d6f-0cfe274168a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-5868a07e-b34b-4558-8d10-ba7ead982a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840294746-172.17.0.12-1595499441496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-0a0874d2-51dd-4005-97a1-3b49090aa718,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-4abc9c03-cd6e-4527-80b8-e5e6fad692a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-fa8d163d-bec0-421d-b0a5-0af8ef1035de,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-f064fb34-083b-40a9-bf50-f6a623286f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-d71167b7-f075-40b6-b6ea-25e442b637af,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-d30d6252-235f-4889-99d1-a92391d32e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-b0716787-b6cf-4ea6-b3fe-b765b1a16694,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-eff99622-1b2b-49dd-9166-34bc332c5f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840294746-172.17.0.12-1595499441496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-0a0874d2-51dd-4005-97a1-3b49090aa718,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-4abc9c03-cd6e-4527-80b8-e5e6fad692a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-fa8d163d-bec0-421d-b0a5-0af8ef1035de,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-f064fb34-083b-40a9-bf50-f6a623286f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-d71167b7-f075-40b6-b6ea-25e442b637af,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-d30d6252-235f-4889-99d1-a92391d32e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-b0716787-b6cf-4ea6-b3fe-b765b1a16694,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-eff99622-1b2b-49dd-9166-34bc332c5f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138246812-172.17.0.12-1595499940305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45910,DS-fe458703-34ba-4f85-92e9-7dd502d0521b,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-e5cad02c-fd25-439f-a08d-1e3d7f4b8b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-7133a78b-f7a0-4c15-8592-e410fbc48027,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-03248684-5c57-41dd-985c-1ee069542cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-4309e7ea-926f-4c6f-ac50-a8feedcd5feb,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-38f54f22-d535-4bb6-aeba-b4b831f922e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-8a391dc5-2c88-47be-a8d2-3f71a43f1291,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-986e542a-4924-4f64-ba04-a233682bf96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138246812-172.17.0.12-1595499940305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45910,DS-fe458703-34ba-4f85-92e9-7dd502d0521b,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-e5cad02c-fd25-439f-a08d-1e3d7f4b8b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-7133a78b-f7a0-4c15-8592-e410fbc48027,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-03248684-5c57-41dd-985c-1ee069542cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-4309e7ea-926f-4c6f-ac50-a8feedcd5feb,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-38f54f22-d535-4bb6-aeba-b4b831f922e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-8a391dc5-2c88-47be-a8d2-3f71a43f1291,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-986e542a-4924-4f64-ba04-a233682bf96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918632635-172.17.0.12-1595500575228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-034231ad-d499-4dbd-8e5b-917ed30c3258,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-74671173-5c2a-40e7-9117-7e565e19040a,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-429c8650-a224-4c75-b4ef-f766b43b8510,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-92e247ec-c8c2-4339-80f6-2da76ec536fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-8dce5cb4-a606-4823-a121-6ce52ed9b2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-9e095d1b-168e-418d-9ba9-3bf2bd7908ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-58dfdf6e-b6d5-4149-8eb5-acdcf5627421,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-1408f915-0b58-475e-9b45-3f8fa5adbff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918632635-172.17.0.12-1595500575228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-034231ad-d499-4dbd-8e5b-917ed30c3258,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-74671173-5c2a-40e7-9117-7e565e19040a,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-429c8650-a224-4c75-b4ef-f766b43b8510,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-92e247ec-c8c2-4339-80f6-2da76ec536fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-8dce5cb4-a606-4823-a121-6ce52ed9b2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-9e095d1b-168e-418d-9ba9-3bf2bd7908ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-58dfdf6e-b6d5-4149-8eb5-acdcf5627421,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-1408f915-0b58-475e-9b45-3f8fa5adbff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236375267-172.17.0.12-1595500953685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33583,DS-5787d30d-c57f-499b-a830-848355544d80,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-ff5cba0a-065f-442d-be6e-93cc1ff88923,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-068b1c8a-c28e-4715-a26e-e5c161f6bdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-3f9d6163-b5f6-4916-a07f-832d6757d126,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-7bf86034-dd45-4e61-9ccb-316681ab65c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-1457bbc5-14ad-4621-8286-71e16b03ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-e1d9eb67-2cae-43b4-8f10-6498af6bd00c,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-f9f51c61-0071-4ac4-ae85-3b4dbbd6be50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236375267-172.17.0.12-1595500953685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33583,DS-5787d30d-c57f-499b-a830-848355544d80,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-ff5cba0a-065f-442d-be6e-93cc1ff88923,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-068b1c8a-c28e-4715-a26e-e5c161f6bdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-3f9d6163-b5f6-4916-a07f-832d6757d126,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-7bf86034-dd45-4e61-9ccb-316681ab65c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-1457bbc5-14ad-4621-8286-71e16b03ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-e1d9eb67-2cae-43b4-8f10-6498af6bd00c,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-f9f51c61-0071-4ac4-ae85-3b4dbbd6be50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457568124-172.17.0.12-1595500982359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40881,DS-d93ad768-561b-4073-b97e-3b316d4cee22,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-11312034-7a5d-43a7-80ad-e6edf7f08aae,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-0094646f-0967-4c31-9d20-e22323cb7533,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-bdfaedec-cf63-4f89-af28-a9cca350bc64,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-c24b595b-7cdc-40cd-9e7f-3ee250502eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-7ecc3134-273d-4c42-8bf3-56867a05bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-a2889dea-4dea-4c26-b209-cba99984d402,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-66b12eaa-eb63-4858-86b8-9f23da602ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457568124-172.17.0.12-1595500982359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40881,DS-d93ad768-561b-4073-b97e-3b316d4cee22,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-11312034-7a5d-43a7-80ad-e6edf7f08aae,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-0094646f-0967-4c31-9d20-e22323cb7533,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-bdfaedec-cf63-4f89-af28-a9cca350bc64,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-c24b595b-7cdc-40cd-9e7f-3ee250502eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-7ecc3134-273d-4c42-8bf3-56867a05bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-a2889dea-4dea-4c26-b209-cba99984d402,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-66b12eaa-eb63-4858-86b8-9f23da602ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001922032-172.17.0.12-1595501133783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-77f4d9b7-964d-4241-8ded-e136a5b61007,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-39860ceb-991c-444f-9c5b-8ce4ac4d9873,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-7cf51d3c-d693-4c99-894d-a9052511d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-d9759961-a044-474c-b5e2-b20707d77b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-b0f1669e-d33f-4fc7-8564-25b9a47450b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-8b88bd7a-a5a5-4487-aa02-ba78eadbe8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-0fb51639-6a2e-42a7-96a0-fb3e5d57aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-668b0944-ed96-4ffb-ad8d-529140810eb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001922032-172.17.0.12-1595501133783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-77f4d9b7-964d-4241-8ded-e136a5b61007,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-39860ceb-991c-444f-9c5b-8ce4ac4d9873,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-7cf51d3c-d693-4c99-894d-a9052511d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-d9759961-a044-474c-b5e2-b20707d77b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-b0f1669e-d33f-4fc7-8564-25b9a47450b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-8b88bd7a-a5a5-4487-aa02-ba78eadbe8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-0fb51639-6a2e-42a7-96a0-fb3e5d57aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-668b0944-ed96-4ffb-ad8d-529140810eb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274849996-172.17.0.12-1595501285170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-994e0d7f-fa02-4c12-b933-519c13f67927,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-db6c7268-fa0d-4518-8e84-20bf1d722cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-c18916af-8721-4b11-903c-08d7509188bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-b499c6db-7cc2-4b35-b8aa-d89debfe2222,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-d7f41600-2923-45bf-87f1-4013e410f2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-2225ee78-6cf8-468d-8ad9-28e27ecd5163,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-3c0cac5a-754a-4aad-bdf6-79e9e8201286,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-f0d9f8d4-aaf8-4357-9d6c-97beb825ef24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274849996-172.17.0.12-1595501285170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-994e0d7f-fa02-4c12-b933-519c13f67927,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-db6c7268-fa0d-4518-8e84-20bf1d722cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-c18916af-8721-4b11-903c-08d7509188bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-b499c6db-7cc2-4b35-b8aa-d89debfe2222,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-d7f41600-2923-45bf-87f1-4013e410f2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-2225ee78-6cf8-468d-8ad9-28e27ecd5163,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-3c0cac5a-754a-4aad-bdf6-79e9e8201286,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-f0d9f8d4-aaf8-4357-9d6c-97beb825ef24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373572845-172.17.0.12-1595501375693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43085,DS-a2f70753-213b-4108-b4d4-ac8857019622,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-a93c111c-d8e9-4dbb-82ef-59c278cca17a,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-2e860bad-c827-46c8-b983-569065e4c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-38c289a3-d753-4aed-89d7-d39260b0f948,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-472ae51c-c79d-40ce-ac06-a0b9a5f8e751,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-b5f50163-25ed-43ad-ad4e-af076dd74985,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-e7205200-4e88-44b2-a8c9-418db5a6b227,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-a53a70f3-8d1d-4a3a-a882-5240001e9ae4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373572845-172.17.0.12-1595501375693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43085,DS-a2f70753-213b-4108-b4d4-ac8857019622,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-a93c111c-d8e9-4dbb-82ef-59c278cca17a,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-2e860bad-c827-46c8-b983-569065e4c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-38c289a3-d753-4aed-89d7-d39260b0f948,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-472ae51c-c79d-40ce-ac06-a0b9a5f8e751,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-b5f50163-25ed-43ad-ad4e-af076dd74985,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-e7205200-4e88-44b2-a8c9-418db5a6b227,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-a53a70f3-8d1d-4a3a-a882-5240001e9ae4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701342535-172.17.0.12-1595501476044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-c51872cc-4776-4172-b1af-1871c3e0df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-ec49d356-47dc-4a4d-8aaf-a98ef135f66b,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-7f1ecd38-72b2-464c-84ac-973be47afedd,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-c20c1349-c9ca-429f-a8c4-840b7fac98df,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-c992318d-ee58-46a8-86d4-d847f14606f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-62bb31d6-8a2a-4151-9eca-22d0d5ba0c91,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-861237b4-10bd-4f0a-9459-fc669fefe791,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-392ec1d1-e4e9-451c-9c1e-caa67e9ccd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701342535-172.17.0.12-1595501476044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-c51872cc-4776-4172-b1af-1871c3e0df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-ec49d356-47dc-4a4d-8aaf-a98ef135f66b,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-7f1ecd38-72b2-464c-84ac-973be47afedd,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-c20c1349-c9ca-429f-a8c4-840b7fac98df,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-c992318d-ee58-46a8-86d4-d847f14606f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-62bb31d6-8a2a-4151-9eca-22d0d5ba0c91,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-861237b4-10bd-4f0a-9459-fc669fefe791,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-392ec1d1-e4e9-451c-9c1e-caa67e9ccd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5215
