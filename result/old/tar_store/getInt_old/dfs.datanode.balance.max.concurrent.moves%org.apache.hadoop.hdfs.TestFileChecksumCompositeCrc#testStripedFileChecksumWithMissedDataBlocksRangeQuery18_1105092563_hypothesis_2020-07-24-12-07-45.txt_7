reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202671152-172.17.0.15-1595593792173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39481,DS-3cbd2948-ece7-4be6-8f3a-b0759674b5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-7b526282-eef2-4833-bc7a-3c590fe31781,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-84ea1bc1-b17e-4816-a0dc-77ad1674436d,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-7978f96f-9984-4e4a-b15a-4f6ce7651085,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-26e4a714-0791-415c-bc01-4d6f2b997865,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-9ac84543-cd48-416b-a5d5-eb399afb221b,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-66f98f00-a368-4d5f-b77d-fdf70a76a401,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-6679391e-4065-4d56-9f77-d3ed43eddbdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202671152-172.17.0.15-1595593792173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39481,DS-3cbd2948-ece7-4be6-8f3a-b0759674b5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-7b526282-eef2-4833-bc7a-3c590fe31781,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-84ea1bc1-b17e-4816-a0dc-77ad1674436d,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-7978f96f-9984-4e4a-b15a-4f6ce7651085,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-26e4a714-0791-415c-bc01-4d6f2b997865,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-9ac84543-cd48-416b-a5d5-eb399afb221b,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-66f98f00-a368-4d5f-b77d-fdf70a76a401,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-6679391e-4065-4d56-9f77-d3ed43eddbdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321559918-172.17.0.15-1595594755988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39878,DS-515bfeda-81c1-48f1-bf94-4d757ef6c23e,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-f5f0cee2-60bd-45b0-b3ec-52b38527cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-35e90e95-f7b6-4ff4-9721-23ba059fd4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-cb61aad7-4ce1-4f50-b6e3-3929374ea917,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-9bb685cf-a75c-4b99-9631-e67b65545d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-35806750-90e0-46cc-8e57-639d34f9a286,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-f1107b86-33ca-4c9f-99e0-c96d634ac1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-82c80641-30df-457a-a01a-25aee72bb9bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321559918-172.17.0.15-1595594755988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39878,DS-515bfeda-81c1-48f1-bf94-4d757ef6c23e,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-f5f0cee2-60bd-45b0-b3ec-52b38527cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-35e90e95-f7b6-4ff4-9721-23ba059fd4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-cb61aad7-4ce1-4f50-b6e3-3929374ea917,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-9bb685cf-a75c-4b99-9631-e67b65545d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-35806750-90e0-46cc-8e57-639d34f9a286,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-f1107b86-33ca-4c9f-99e0-c96d634ac1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-82c80641-30df-457a-a01a-25aee72bb9bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571526763-172.17.0.15-1595594986065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43570,DS-4c58e1e9-2a7e-4687-8350-b18c37371823,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-a25c1b6d-6ede-4f6b-bd6b-088df4537167,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-262a531f-3f51-4737-93cb-79af767b7939,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-65ba676d-0137-43fa-ae5c-14cf407f407b,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-f30eb1b6-63c9-43e9-88aa-0f128cfc0c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-f3c2eb3c-a458-4c89-a79f-e5d6d70335ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-1f8a6fb6-aba5-4a1b-932f-f05a19e18e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-4828beb2-1807-4e38-b282-437b69623f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571526763-172.17.0.15-1595594986065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43570,DS-4c58e1e9-2a7e-4687-8350-b18c37371823,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-a25c1b6d-6ede-4f6b-bd6b-088df4537167,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-262a531f-3f51-4737-93cb-79af767b7939,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-65ba676d-0137-43fa-ae5c-14cf407f407b,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-f30eb1b6-63c9-43e9-88aa-0f128cfc0c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-f3c2eb3c-a458-4c89-a79f-e5d6d70335ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-1f8a6fb6-aba5-4a1b-932f-f05a19e18e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-4828beb2-1807-4e38-b282-437b69623f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197185712-172.17.0.15-1595595168633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-e24d35c6-e544-44ce-b223-054ce84dd772,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-6ddf1ac8-218f-4db7-af5c-836ada858e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-ad107f9e-44d1-41f4-9522-973980ba331a,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-127e3506-afcd-4351-b540-6546c0c45f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-14931317-9b21-46a9-8d85-08888ba07f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-9b241229-6b95-49ee-9a58-50063402bc85,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-bcaf6f97-2f3c-4c16-973d-3af8dc1b41cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-aa495212-6b7b-4a7e-8d84-1849c18982fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197185712-172.17.0.15-1595595168633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-e24d35c6-e544-44ce-b223-054ce84dd772,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-6ddf1ac8-218f-4db7-af5c-836ada858e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-ad107f9e-44d1-41f4-9522-973980ba331a,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-127e3506-afcd-4351-b540-6546c0c45f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-14931317-9b21-46a9-8d85-08888ba07f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-9b241229-6b95-49ee-9a58-50063402bc85,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-bcaf6f97-2f3c-4c16-973d-3af8dc1b41cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-aa495212-6b7b-4a7e-8d84-1849c18982fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789933190-172.17.0.15-1595595453649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33412,DS-2f05f245-c015-4484-8c41-fdb75a6d38c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-b6ca6b91-e696-4750-bbff-6d3e61741557,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-e9953f37-a668-4e84-8cc7-5985e93376cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-e38f4127-d2fc-4405-b1b6-a33acae77d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-e7a2a83b-151a-45fc-93f5-19bf258de040,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-4f865b6f-a4e6-4ba2-b9dc-5499d9848538,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-489c70fa-415b-4e83-9a46-6d96a6dd15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-9d1f1145-9ce1-496b-bb1e-7812e81d9d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789933190-172.17.0.15-1595595453649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33412,DS-2f05f245-c015-4484-8c41-fdb75a6d38c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-b6ca6b91-e696-4750-bbff-6d3e61741557,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-e9953f37-a668-4e84-8cc7-5985e93376cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-e38f4127-d2fc-4405-b1b6-a33acae77d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-e7a2a83b-151a-45fc-93f5-19bf258de040,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-4f865b6f-a4e6-4ba2-b9dc-5499d9848538,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-489c70fa-415b-4e83-9a46-6d96a6dd15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-9d1f1145-9ce1-496b-bb1e-7812e81d9d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677520404-172.17.0.15-1595595595709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-d5189cff-7d93-4289-94f3-b61d9b2ab1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-8f945ce0-4bd5-4312-a792-68c4bc540404,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-8a15b916-417b-4a4f-93c3-958e397282c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-f11d1742-a062-41db-a75c-6d7d61de002b,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-e6eae8f8-4d66-400c-9db3-844285e1078f,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-66290030-46ed-4e19-80f9-2b3d93ab4cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-50ed70e3-24e0-49ea-8991-2a0c18c285d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-2098b224-986d-4fbd-a62d-ffae69567dfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677520404-172.17.0.15-1595595595709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-d5189cff-7d93-4289-94f3-b61d9b2ab1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-8f945ce0-4bd5-4312-a792-68c4bc540404,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-8a15b916-417b-4a4f-93c3-958e397282c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-f11d1742-a062-41db-a75c-6d7d61de002b,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-e6eae8f8-4d66-400c-9db3-844285e1078f,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-66290030-46ed-4e19-80f9-2b3d93ab4cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-50ed70e3-24e0-49ea-8991-2a0c18c285d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-2098b224-986d-4fbd-a62d-ffae69567dfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756273199-172.17.0.15-1595595833085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35824,DS-91db2645-cef3-4ca6-b9f9-2f2fae4350dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-206c332c-87d8-4c55-874b-0f4c380f070f,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-1391e653-6f53-4921-8c55-11210f29c1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-1978604a-8948-4a15-8e4f-b043e6795147,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-66fc7caf-2aa5-48b1-9018-98589b197724,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-43422020-f975-474d-8f95-1d9175b58157,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-dcf01c25-6952-4084-80c6-ba11f104cb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-0e05c9fa-94a2-4953-8031-76efe2e2c94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756273199-172.17.0.15-1595595833085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35824,DS-91db2645-cef3-4ca6-b9f9-2f2fae4350dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-206c332c-87d8-4c55-874b-0f4c380f070f,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-1391e653-6f53-4921-8c55-11210f29c1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-1978604a-8948-4a15-8e4f-b043e6795147,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-66fc7caf-2aa5-48b1-9018-98589b197724,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-43422020-f975-474d-8f95-1d9175b58157,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-dcf01c25-6952-4084-80c6-ba11f104cb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-0e05c9fa-94a2-4953-8031-76efe2e2c94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778731101-172.17.0.15-1595595936830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45415,DS-999f2ea0-b0c5-4b88-859c-88e4fd533a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-134d2317-777e-42aa-8085-db7279ee13f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-931928f7-e321-4207-ad13-f208945bfdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-96aaf467-393c-4124-ad2c-b38287962ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-eb594a80-9efc-4d4a-bf16-5b0a28c91902,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-c8f45529-3282-4522-8e9f-89d2b3ab4ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-9dd1bf57-8498-47b7-93bb-eb257c6f4eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-e21d882b-c7b0-4265-ae34-158ef45792ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778731101-172.17.0.15-1595595936830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45415,DS-999f2ea0-b0c5-4b88-859c-88e4fd533a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-134d2317-777e-42aa-8085-db7279ee13f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-931928f7-e321-4207-ad13-f208945bfdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-96aaf467-393c-4124-ad2c-b38287962ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-eb594a80-9efc-4d4a-bf16-5b0a28c91902,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-c8f45529-3282-4522-8e9f-89d2b3ab4ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-9dd1bf57-8498-47b7-93bb-eb257c6f4eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-e21d882b-c7b0-4265-ae34-158ef45792ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812295446-172.17.0.15-1595596089008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43666,DS-73a2c7e0-e314-4fe1-9db7-a09ae0dbc859,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-bd5b0982-16b5-4768-ac90-57a32f912697,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-63986179-49e0-4a80-92df-499f28235049,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6976ffcd-5104-4d86-b36a-01868b8efe71,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-c49bdb55-337c-4097-92c3-f7e57ae7af59,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-f49e9065-3183-4d88-b9a3-a1794787f46c,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-34318e0a-6138-4ea8-af5a-ad932a03b0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-6173260e-fc27-4843-8a93-fdb37561ddff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812295446-172.17.0.15-1595596089008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43666,DS-73a2c7e0-e314-4fe1-9db7-a09ae0dbc859,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-bd5b0982-16b5-4768-ac90-57a32f912697,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-63986179-49e0-4a80-92df-499f28235049,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6976ffcd-5104-4d86-b36a-01868b8efe71,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-c49bdb55-337c-4097-92c3-f7e57ae7af59,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-f49e9065-3183-4d88-b9a3-a1794787f46c,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-34318e0a-6138-4ea8-af5a-ad932a03b0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-6173260e-fc27-4843-8a93-fdb37561ddff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525995999-172.17.0.15-1595596247598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39465,DS-df9a97cb-8aed-4ee6-b288-1ef38f21cff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-3314c9e1-2b52-4a92-850c-e92093b2821f,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-9903ecb6-8c61-4489-8f66-609b0ffc169a,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-51105436-6d14-4074-b8ae-a55490d5d633,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-867d2cd1-6e3e-4fe3-b8ca-b8b87ceb7e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-0c47f0ca-2673-403d-8885-88eb5a1cfc14,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-2f1b93f6-da72-452f-a758-038347213f48,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-f1a66dd5-ef93-4e71-b5fd-d533d8d0846b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525995999-172.17.0.15-1595596247598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39465,DS-df9a97cb-8aed-4ee6-b288-1ef38f21cff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-3314c9e1-2b52-4a92-850c-e92093b2821f,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-9903ecb6-8c61-4489-8f66-609b0ffc169a,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-51105436-6d14-4074-b8ae-a55490d5d633,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-867d2cd1-6e3e-4fe3-b8ca-b8b87ceb7e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-0c47f0ca-2673-403d-8885-88eb5a1cfc14,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-2f1b93f6-da72-452f-a758-038347213f48,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-f1a66dd5-ef93-4e71-b5fd-d533d8d0846b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420641036-172.17.0.15-1595596383577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-12e723f2-9f74-4c2e-8d3d-1819290a869a,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-75e55c1b-59cb-4278-926b-f5cbdc36665c,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-695730c4-8e42-4a5f-97b1-89b499d76600,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-cd707807-a2f9-4f9c-b01b-02a9b3ba1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-45ec33fe-f8e7-457b-b58b-727068c9b1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-cd039a28-61d4-4230-b48b-f21a585584df,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-2fc5bb2e-c5ac-4002-950f-76aafedff4db,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-f90a7ff4-8a2e-47ff-b34e-b1f74873c724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420641036-172.17.0.15-1595596383577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-12e723f2-9f74-4c2e-8d3d-1819290a869a,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-75e55c1b-59cb-4278-926b-f5cbdc36665c,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-695730c4-8e42-4a5f-97b1-89b499d76600,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-cd707807-a2f9-4f9c-b01b-02a9b3ba1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-45ec33fe-f8e7-457b-b58b-727068c9b1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-cd039a28-61d4-4230-b48b-f21a585584df,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-2fc5bb2e-c5ac-4002-950f-76aafedff4db,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-f90a7ff4-8a2e-47ff-b34e-b1f74873c724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86045383-172.17.0.15-1595596524928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34041,DS-f83fcabe-67ef-4249-9f25-fb2f1f44a65d,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-4d5884ab-15cd-4ec1-bba3-2b27caff175a,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-2e0ac2e7-2bdd-46bb-ab67-bb6baf21b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-9bf01eb9-53d3-4259-a16c-8dee62a20402,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-979563a3-d359-4d7f-b5cf-b0c5d335641a,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c174398d-6242-41d2-aebc-0c7f76827d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-85de2a19-82dd-4b9c-a825-c872cd8a9a08,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-a663664b-aee2-4297-aa2d-7167fd776e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86045383-172.17.0.15-1595596524928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34041,DS-f83fcabe-67ef-4249-9f25-fb2f1f44a65d,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-4d5884ab-15cd-4ec1-bba3-2b27caff175a,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-2e0ac2e7-2bdd-46bb-ab67-bb6baf21b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-9bf01eb9-53d3-4259-a16c-8dee62a20402,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-979563a3-d359-4d7f-b5cf-b0c5d335641a,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c174398d-6242-41d2-aebc-0c7f76827d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-85de2a19-82dd-4b9c-a825-c872cd8a9a08,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-a663664b-aee2-4297-aa2d-7167fd776e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624638776-172.17.0.15-1595597557830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39887,DS-2b16b4a5-df7f-46e6-a2e1-98425242ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-ac5e47bd-29db-4147-9a11-719f927d23e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-35daa497-4dab-44e0-9cd4-cf702903cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-243357fa-5311-4fea-ba4a-b13b3bc3b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-142140d7-8eeb-438d-9e92-d20e44b9c326,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-87867716-9de9-40f8-9920-9f0b27d405a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-6d4cda67-1530-41c4-9a1d-7a7a970c353b,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-32d7dc19-f3bd-4742-b776-0e39bd134dea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624638776-172.17.0.15-1595597557830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39887,DS-2b16b4a5-df7f-46e6-a2e1-98425242ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-ac5e47bd-29db-4147-9a11-719f927d23e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-35daa497-4dab-44e0-9cd4-cf702903cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-243357fa-5311-4fea-ba4a-b13b3bc3b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-142140d7-8eeb-438d-9e92-d20e44b9c326,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-87867716-9de9-40f8-9920-9f0b27d405a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-6d4cda67-1530-41c4-9a1d-7a7a970c353b,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-32d7dc19-f3bd-4742-b776-0e39bd134dea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331653783-172.17.0.15-1595598021928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-a3d6c13b-e390-49ec-a00c-5f2e1270c09a,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-f37d38bd-a6ee-479a-8649-1f9bc82766c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-41d40565-37df-4c9f-8d2e-c9071be04534,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-2f5c7200-7006-43bf-b0aa-942342d1b8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-9ff37a1c-ac0a-404c-9bac-bc3c0767c9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-05e4b00c-b2dc-4849-894d-a3e74bb569f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-2ad63858-4dfd-42f5-b3d1-e2d541d1d43e,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-5c1e08f4-944f-4cc4-8acb-3070fb2395c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331653783-172.17.0.15-1595598021928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-a3d6c13b-e390-49ec-a00c-5f2e1270c09a,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-f37d38bd-a6ee-479a-8649-1f9bc82766c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-41d40565-37df-4c9f-8d2e-c9071be04534,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-2f5c7200-7006-43bf-b0aa-942342d1b8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-9ff37a1c-ac0a-404c-9bac-bc3c0767c9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-05e4b00c-b2dc-4849-894d-a3e74bb569f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-2ad63858-4dfd-42f5-b3d1-e2d541d1d43e,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-5c1e08f4-944f-4cc4-8acb-3070fb2395c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550660004-172.17.0.15-1595598809900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44478,DS-cff76246-bd2b-43e0-84cc-fea553739a37,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-1af28032-fb37-4dea-9ee9-2c5ca2ef3d34,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-5fa34989-6c3e-416e-a9f2-2142688eba68,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-594646bf-9d2c-44ea-acfb-827db0a873d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-c51b236f-b762-40c0-b6cf-f49092f0f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-2278b056-2eb3-4ce5-a1fb-d28c5d15f802,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-f2dd7ec9-9ebd-443c-879e-e30216729303,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-963f87df-7a04-4be2-ab5d-9e6fde913610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550660004-172.17.0.15-1595598809900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44478,DS-cff76246-bd2b-43e0-84cc-fea553739a37,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-1af28032-fb37-4dea-9ee9-2c5ca2ef3d34,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-5fa34989-6c3e-416e-a9f2-2142688eba68,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-594646bf-9d2c-44ea-acfb-827db0a873d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-c51b236f-b762-40c0-b6cf-f49092f0f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-2278b056-2eb3-4ce5-a1fb-d28c5d15f802,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-f2dd7ec9-9ebd-443c-879e-e30216729303,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-963f87df-7a04-4be2-ab5d-9e6fde913610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244222646-172.17.0.15-1595598849465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36108,DS-8610709a-10cc-4e90-8c27-8cb17e4ca39d,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-f54135c4-7f3b-4d6f-a17a-07d3bf486b22,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-71bfd3e5-8c2c-408f-ba4d-9439907302a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-7c6071fc-958c-43ba-9fda-6d406b86022a,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-5c23fbf9-f830-4516-ac8f-700c51ed5e13,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-70301b1c-e2a5-4d85-9aea-251a23fb5a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-345b5e7b-7622-4a43-89e0-b5efa063c343,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-b0cae32e-e396-4d55-82be-6a694ad4decc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244222646-172.17.0.15-1595598849465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36108,DS-8610709a-10cc-4e90-8c27-8cb17e4ca39d,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-f54135c4-7f3b-4d6f-a17a-07d3bf486b22,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-71bfd3e5-8c2c-408f-ba4d-9439907302a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-7c6071fc-958c-43ba-9fda-6d406b86022a,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-5c23fbf9-f830-4516-ac8f-700c51ed5e13,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-70301b1c-e2a5-4d85-9aea-251a23fb5a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-345b5e7b-7622-4a43-89e0-b5efa063c343,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-b0cae32e-e396-4d55-82be-6a694ad4decc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441296312-172.17.0.15-1595599003025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40565,DS-4db307f3-a255-48f2-b177-39d5028d1ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-482e5deb-3a35-4079-9ef1-909f714cda97,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-0b527875-589b-4b83-8ada-3cd99bdefe63,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-8ae0d17b-eef6-46b2-a40d-650d6a330570,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-c8e122fc-b678-4332-84e9-eb09c4e13606,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-fcf5fe12-a1b4-4ec1-98cf-bf091394a7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-828cdc2a-b3ae-444b-90b1-9299db788d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-b377fd85-2f2b-4eb3-90b2-95d718c7a184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441296312-172.17.0.15-1595599003025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40565,DS-4db307f3-a255-48f2-b177-39d5028d1ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-482e5deb-3a35-4079-9ef1-909f714cda97,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-0b527875-589b-4b83-8ada-3cd99bdefe63,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-8ae0d17b-eef6-46b2-a40d-650d6a330570,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-c8e122fc-b678-4332-84e9-eb09c4e13606,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-fcf5fe12-a1b4-4ec1-98cf-bf091394a7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-828cdc2a-b3ae-444b-90b1-9299db788d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-b377fd85-2f2b-4eb3-90b2-95d718c7a184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6923
