reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358288461-172.17.0.7-1595620022756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43800,DS-e950fcb1-c5df-40cd-ba5a-7a857bc6ee59,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-a85e990f-a8a3-47eb-b9be-af20f56d139a,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-97b8c51c-1285-46da-9984-3d2c888a649c,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-535bf7da-3a59-420c-881f-75f3e980f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-082d1b6b-23fc-41b2-a69b-a471cee49d71,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-07c1be7e-d73f-4aa0-997c-5a860cf428e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-15305358-9dbb-43c8-86d5-0ade91c00fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-b363e7d9-c512-4de3-8aa4-17e99884e1fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358288461-172.17.0.7-1595620022756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43800,DS-e950fcb1-c5df-40cd-ba5a-7a857bc6ee59,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-a85e990f-a8a3-47eb-b9be-af20f56d139a,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-97b8c51c-1285-46da-9984-3d2c888a649c,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-535bf7da-3a59-420c-881f-75f3e980f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-082d1b6b-23fc-41b2-a69b-a471cee49d71,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-07c1be7e-d73f-4aa0-997c-5a860cf428e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-15305358-9dbb-43c8-86d5-0ade91c00fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-b363e7d9-c512-4de3-8aa4-17e99884e1fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537873349-172.17.0.7-1595620210664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43190,DS-89abbe54-b4d0-4a1a-92f1-767521e59db9,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-38dd2ad7-c588-4fab-bcd0-2ce88f31ec2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-327be115-bc83-449e-bc57-e77a0f526821,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-39e5be46-4237-431b-a4b7-4989ec66f0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-c8fd3ddd-15c0-4981-841f-2f4c36efd665,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-e167faa8-296a-46dc-a457-a683b135ec90,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-7d7c8350-9452-4299-af92-8c5d0f4bcc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-4e31cbb2-14c3-4282-ab96-ae468cd8aa27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537873349-172.17.0.7-1595620210664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43190,DS-89abbe54-b4d0-4a1a-92f1-767521e59db9,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-38dd2ad7-c588-4fab-bcd0-2ce88f31ec2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-327be115-bc83-449e-bc57-e77a0f526821,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-39e5be46-4237-431b-a4b7-4989ec66f0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-c8fd3ddd-15c0-4981-841f-2f4c36efd665,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-e167faa8-296a-46dc-a457-a683b135ec90,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-7d7c8350-9452-4299-af92-8c5d0f4bcc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-4e31cbb2-14c3-4282-ab96-ae468cd8aa27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419185740-172.17.0.7-1595620348195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-b73d6ae3-0760-4a6e-bb2e-c29fa312d379,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-06e4694e-38b2-4ba5-a9df-5c82aa082b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-9f2f3faf-357a-4385-820d-b7f1c424b8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-b6ba7e95-e2ea-497a-9eed-9c60e9780fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-a008bbd7-25a1-4565-9026-22f215a9cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-f36bb53f-3c6b-496c-ba30-c65520c41389,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-518fe41d-2579-4355-b305-cc1b63ffe1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-7beb52ea-da86-48e4-8894-3acfda7da252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419185740-172.17.0.7-1595620348195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-b73d6ae3-0760-4a6e-bb2e-c29fa312d379,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-06e4694e-38b2-4ba5-a9df-5c82aa082b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-9f2f3faf-357a-4385-820d-b7f1c424b8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-b6ba7e95-e2ea-497a-9eed-9c60e9780fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-a008bbd7-25a1-4565-9026-22f215a9cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-f36bb53f-3c6b-496c-ba30-c65520c41389,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-518fe41d-2579-4355-b305-cc1b63ffe1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-7beb52ea-da86-48e4-8894-3acfda7da252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784612198-172.17.0.7-1595620768404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46621,DS-1b79a77e-810f-4779-bb1d-d795a9dafdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-0aea1bf4-dccb-4bea-a56b-2189bca5c30a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-6209699b-6789-4fe2-bf23-00c1e5000302,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-a42c2ead-d820-4c65-ab07-1c826d37d1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-189aaf93-8f02-47a7-82b7-ba0d3143b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-13d72f84-7d57-4e16-a72d-a86291dcfbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-78f76d73-08c4-4ce5-a6ad-874f09a963b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-f52a883a-fb56-4c9b-975e-831f62ddba93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784612198-172.17.0.7-1595620768404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46621,DS-1b79a77e-810f-4779-bb1d-d795a9dafdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-0aea1bf4-dccb-4bea-a56b-2189bca5c30a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-6209699b-6789-4fe2-bf23-00c1e5000302,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-a42c2ead-d820-4c65-ab07-1c826d37d1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-189aaf93-8f02-47a7-82b7-ba0d3143b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-13d72f84-7d57-4e16-a72d-a86291dcfbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-78f76d73-08c4-4ce5-a6ad-874f09a963b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-f52a883a-fb56-4c9b-975e-831f62ddba93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198780750-172.17.0.7-1595621383316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37202,DS-ca65ab86-b57d-4f96-8992-eda2765e9c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-e3514921-f43e-4a52-b178-aeeab3245a78,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-e7392425-75eb-4913-98a4-4534d91a429d,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-6f2b42c8-cc86-4eac-92f4-e5ae455120bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-59cd45ee-1167-47ae-b46f-014921427dde,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-8e9e4752-b9dd-4061-9626-b14a9574ec40,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-a530e6a3-b6bb-4250-bc56-da3ec0630c13,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-e99adaf2-e809-445a-917a-cfbf7947156e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198780750-172.17.0.7-1595621383316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37202,DS-ca65ab86-b57d-4f96-8992-eda2765e9c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-e3514921-f43e-4a52-b178-aeeab3245a78,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-e7392425-75eb-4913-98a4-4534d91a429d,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-6f2b42c8-cc86-4eac-92f4-e5ae455120bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-59cd45ee-1167-47ae-b46f-014921427dde,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-8e9e4752-b9dd-4061-9626-b14a9574ec40,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-a530e6a3-b6bb-4250-bc56-da3ec0630c13,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-e99adaf2-e809-445a-917a-cfbf7947156e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132000622-172.17.0.7-1595621485452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34361,DS-d289f08a-2229-4517-9894-ddaed18fc014,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-211d6a98-d307-447e-9831-e8e3d0fe2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-d6cd3587-1756-43d4-baef-9ecff6de5ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-e10a2777-3d66-4697-970d-f5bfa2a3f0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-d7df09e1-d3fc-4ded-b3e9-9a0f9a0a45df,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-ec9622a6-a815-4dd4-bcf1-444a559aa9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-8c6dbd18-706f-4a55-b421-853a6bc9a941,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-caa68339-e569-4584-8704-1bb2fd7b96cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132000622-172.17.0.7-1595621485452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34361,DS-d289f08a-2229-4517-9894-ddaed18fc014,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-211d6a98-d307-447e-9831-e8e3d0fe2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-d6cd3587-1756-43d4-baef-9ecff6de5ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-e10a2777-3d66-4697-970d-f5bfa2a3f0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-d7df09e1-d3fc-4ded-b3e9-9a0f9a0a45df,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-ec9622a6-a815-4dd4-bcf1-444a559aa9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-8c6dbd18-706f-4a55-b421-853a6bc9a941,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-caa68339-e569-4584-8704-1bb2fd7b96cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371636265-172.17.0.7-1595621553071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-2efac6d0-28a7-4119-9ad2-e82875207c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-e7e7a39b-b8b8-48c0-913c-d918cea23a81,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-bb043769-22d0-4ff5-b17e-91c8df03adb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-6437f6de-15d3-44d4-b304-9a05f6e4b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-43cbdc88-87fa-46f4-b568-b7762cf4655a,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-455f78a5-950e-454a-b801-198997bb9fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-5541c67d-b887-4cf9-b773-7ed6fe20500f,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-a39a5763-8480-4222-a78e-6fcdd0f7a42d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371636265-172.17.0.7-1595621553071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-2efac6d0-28a7-4119-9ad2-e82875207c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-e7e7a39b-b8b8-48c0-913c-d918cea23a81,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-bb043769-22d0-4ff5-b17e-91c8df03adb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-6437f6de-15d3-44d4-b304-9a05f6e4b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-43cbdc88-87fa-46f4-b568-b7762cf4655a,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-455f78a5-950e-454a-b801-198997bb9fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-5541c67d-b887-4cf9-b773-7ed6fe20500f,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-a39a5763-8480-4222-a78e-6fcdd0f7a42d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095291314-172.17.0.7-1595621586773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33490,DS-90b91238-d4a6-4406-9323-b8303181d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-96b365e5-ee74-4d91-9c67-4ca423aa91d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-b6dfde0f-47c3-4f9d-9ce2-c490d6976b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-ea6d7b09-e448-4522-9262-596d080734c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-c32c3d83-1eae-4445-98c5-31065b21c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-02bf14ff-e277-4e32-b98d-aff35acc76de,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-5fac97b6-1224-4c50-b50e-911b3c9301e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-1b7e49b8-4028-42f9-8c89-2fa79531263d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095291314-172.17.0.7-1595621586773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33490,DS-90b91238-d4a6-4406-9323-b8303181d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-96b365e5-ee74-4d91-9c67-4ca423aa91d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-b6dfde0f-47c3-4f9d-9ce2-c490d6976b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-ea6d7b09-e448-4522-9262-596d080734c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-c32c3d83-1eae-4445-98c5-31065b21c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-02bf14ff-e277-4e32-b98d-aff35acc76de,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-5fac97b6-1224-4c50-b50e-911b3c9301e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-1b7e49b8-4028-42f9-8c89-2fa79531263d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153671082-172.17.0.7-1595622025237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-bcb57ca6-bbc6-485f-a993-252b86e60585,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-1d548250-14be-43c2-a64b-01903991f9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-3e109c16-42bc-4ae9-966a-9b3525c49a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-8968edae-f7da-4386-b85e-42de6f1c067c,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-8e328fa6-886a-4752-89a9-3c73ddefdaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-4823b077-6d8e-4712-876d-d2d6c202fd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-994fe544-7de2-45da-90ea-7c4f6d57a55a,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4dc80d71-f8fe-4844-aea2-bd3a04943239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153671082-172.17.0.7-1595622025237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-bcb57ca6-bbc6-485f-a993-252b86e60585,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-1d548250-14be-43c2-a64b-01903991f9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-3e109c16-42bc-4ae9-966a-9b3525c49a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-8968edae-f7da-4386-b85e-42de6f1c067c,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-8e328fa6-886a-4752-89a9-3c73ddefdaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-4823b077-6d8e-4712-876d-d2d6c202fd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-994fe544-7de2-45da-90ea-7c4f6d57a55a,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4dc80d71-f8fe-4844-aea2-bd3a04943239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095893993-172.17.0.7-1595622174448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-47c570de-9be7-49ff-960e-5742bdb9a292,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-4c370cd0-c90f-40fc-af9c-dd350b8d17a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-1ee9b6e3-0e31-413f-9033-899d0667afb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-40b0cf1e-8394-4e11-a755-da2c32d33ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-050e4b65-494a-4f41-8f29-cf0cb159a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-4f1f3153-8b0c-4b7a-a07d-8c057e1193d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-3507c2ae-5493-47dc-8507-f2d4ee0ca5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-041edd5f-5f6d-4095-9c10-0750c92474e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095893993-172.17.0.7-1595622174448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-47c570de-9be7-49ff-960e-5742bdb9a292,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-4c370cd0-c90f-40fc-af9c-dd350b8d17a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-1ee9b6e3-0e31-413f-9033-899d0667afb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-40b0cf1e-8394-4e11-a755-da2c32d33ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-050e4b65-494a-4f41-8f29-cf0cb159a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-4f1f3153-8b0c-4b7a-a07d-8c057e1193d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-3507c2ae-5493-47dc-8507-f2d4ee0ca5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-041edd5f-5f6d-4095-9c10-0750c92474e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645253936-172.17.0.7-1595622239992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-9aa5e2cf-96b0-460c-9224-b26147ba12eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-8a117d34-3a31-4308-8825-c82fc4c6451e,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-7d090dbc-f3b3-4f01-a249-52063952242d,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-00ea96e8-b790-4bc6-8ca9-299033528506,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-0996e394-0ade-47d5-a097-57ce6d6a7bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-d65b556c-20e3-42ca-91be-9961667f290f,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-0c4fd362-ff5c-41fa-bce8-3fe1009198a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-c6ec0afe-b582-4429-934c-d0990494e146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645253936-172.17.0.7-1595622239992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-9aa5e2cf-96b0-460c-9224-b26147ba12eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-8a117d34-3a31-4308-8825-c82fc4c6451e,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-7d090dbc-f3b3-4f01-a249-52063952242d,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-00ea96e8-b790-4bc6-8ca9-299033528506,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-0996e394-0ade-47d5-a097-57ce6d6a7bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-d65b556c-20e3-42ca-91be-9961667f290f,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-0c4fd362-ff5c-41fa-bce8-3fe1009198a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-c6ec0afe-b582-4429-934c-d0990494e146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614325884-172.17.0.7-1595622382780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-e7f94f88-fdf6-40e6-bf99-90d400191d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-22962529-2dcf-4e7a-bd94-6c6c4550f14c,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-6780e528-f4e6-4aa4-8f81-7c598f78ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-122f2309-49f6-452b-8f72-827dbde5b40c,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-b1361dfb-3bc7-4bdc-932f-80807799c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-e7ad4be5-c5e0-4a67-9a4b-8cd74617e8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-b85f8396-8c0d-45a2-a668-37c5659f6105,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-2bfbc220-5a06-416c-9721-4ca2c87a57f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614325884-172.17.0.7-1595622382780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-e7f94f88-fdf6-40e6-bf99-90d400191d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-22962529-2dcf-4e7a-bd94-6c6c4550f14c,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-6780e528-f4e6-4aa4-8f81-7c598f78ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-122f2309-49f6-452b-8f72-827dbde5b40c,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-b1361dfb-3bc7-4bdc-932f-80807799c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-e7ad4be5-c5e0-4a67-9a4b-8cd74617e8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-b85f8396-8c0d-45a2-a668-37c5659f6105,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-2bfbc220-5a06-416c-9721-4ca2c87a57f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97053979-172.17.0.7-1595622869199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40048,DS-ef954f72-b128-4da0-a33a-ee3ace4b1036,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-46317c0a-0d63-4126-9697-dcdc1db394eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-6cdc7ffc-1aba-4541-b6d1-08e127ef3731,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-44346278-9247-494f-92ed-7ffdfb1337c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-0119393e-de81-4b77-bc6a-acd9c214af20,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-278a3da9-7e89-492f-82ee-32c8b8e0710c,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-6137677b-3fc4-46d9-943b-5d5743e6afc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-7707e74a-3f4b-4b57-9229-89a10f8bd85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97053979-172.17.0.7-1595622869199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40048,DS-ef954f72-b128-4da0-a33a-ee3ace4b1036,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-46317c0a-0d63-4126-9697-dcdc1db394eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-6cdc7ffc-1aba-4541-b6d1-08e127ef3731,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-44346278-9247-494f-92ed-7ffdfb1337c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-0119393e-de81-4b77-bc6a-acd9c214af20,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-278a3da9-7e89-492f-82ee-32c8b8e0710c,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-6137677b-3fc4-46d9-943b-5d5743e6afc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-7707e74a-3f4b-4b57-9229-89a10f8bd85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751418606-172.17.0.7-1595623011891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41661,DS-0410796f-3ba7-462d-8704-7052aa72c10e,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-b59fd244-1c8e-4bad-aace-fb0237c05cde,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-d40c2c85-0843-4068-a9b3-2572c53e9e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-ffdb8cd5-988a-470e-87d5-e8edc523be24,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-3d0df589-449b-4882-8285-73d79a77f385,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-e7264919-999c-4a3c-8594-df33a7bf055e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-024b0f9c-0cf4-440e-9817-c98d6f869684,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-11a02e2f-60da-4a88-b910-0225d6ede94d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751418606-172.17.0.7-1595623011891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41661,DS-0410796f-3ba7-462d-8704-7052aa72c10e,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-b59fd244-1c8e-4bad-aace-fb0237c05cde,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-d40c2c85-0843-4068-a9b3-2572c53e9e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-ffdb8cd5-988a-470e-87d5-e8edc523be24,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-3d0df589-449b-4882-8285-73d79a77f385,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-e7264919-999c-4a3c-8594-df33a7bf055e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-024b0f9c-0cf4-440e-9817-c98d6f869684,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-11a02e2f-60da-4a88-b910-0225d6ede94d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529776842-172.17.0.7-1595623300107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38749,DS-d6c2daeb-6360-4a10-ac0c-53683d81ec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-5da7c3b7-1768-4947-91c8-76e197e94c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-2f616046-e08b-4cff-b84f-c27773dd0341,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-276d36a4-03c5-48af-adf0-ef603d64d97e,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-49ed2927-9186-46cd-b18c-2a634c61592f,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-10e70a7c-15c9-4f8f-9bad-3ca41bae8278,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-c1fd924e-e9dd-4554-a391-173219d2bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-0d1bde51-21c8-4681-baf5-4dbebb1c49cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529776842-172.17.0.7-1595623300107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38749,DS-d6c2daeb-6360-4a10-ac0c-53683d81ec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-5da7c3b7-1768-4947-91c8-76e197e94c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-2f616046-e08b-4cff-b84f-c27773dd0341,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-276d36a4-03c5-48af-adf0-ef603d64d97e,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-49ed2927-9186-46cd-b18c-2a634c61592f,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-10e70a7c-15c9-4f8f-9bad-3ca41bae8278,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-c1fd924e-e9dd-4554-a391-173219d2bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-0d1bde51-21c8-4681-baf5-4dbebb1c49cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006100792-172.17.0.7-1595623337629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45128,DS-e9b3bded-d540-4285-893b-4c22e500d535,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-89fef708-bc82-4d3d-a990-1c8b358f36c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-8c308337-67f9-4a31-8091-de9d76f6ef27,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-50719ca8-0c11-465e-b96d-eeb5dd1cbbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-e3c76626-1635-4007-bbec-dca69440ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-53b75366-32c6-450d-a163-fb6d46098658,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-e9f03d59-e84a-4986-baf8-8237f84cca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-3fc8d3d4-9394-4598-b737-e79f08b8fedf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006100792-172.17.0.7-1595623337629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45128,DS-e9b3bded-d540-4285-893b-4c22e500d535,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-89fef708-bc82-4d3d-a990-1c8b358f36c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-8c308337-67f9-4a31-8091-de9d76f6ef27,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-50719ca8-0c11-465e-b96d-eeb5dd1cbbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-e3c76626-1635-4007-bbec-dca69440ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-53b75366-32c6-450d-a163-fb6d46098658,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-e9f03d59-e84a-4986-baf8-8237f84cca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-3fc8d3d4-9394-4598-b737-e79f08b8fedf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026127377-172.17.0.7-1595623367104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38022,DS-2779c9bc-eee2-4563-9172-8737ef3c964f,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-b0d47b7f-4013-474f-9ddd-3568710114bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-043e7d83-99ae-41a4-9a86-ff021519c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-6458d9a9-2f50-41d6-ad13-8d4bfa800ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-d88558f7-0af7-4537-b597-a51ee970e4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-00b1e9e6-839a-42ca-beb1-cf4e918bbf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-7de89813-7773-484a-b250-ef2b2ee922ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-2a9387b4-a19d-49a5-88da-2d932f6905ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026127377-172.17.0.7-1595623367104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38022,DS-2779c9bc-eee2-4563-9172-8737ef3c964f,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-b0d47b7f-4013-474f-9ddd-3568710114bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-043e7d83-99ae-41a4-9a86-ff021519c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-6458d9a9-2f50-41d6-ad13-8d4bfa800ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-d88558f7-0af7-4537-b597-a51ee970e4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-00b1e9e6-839a-42ca-beb1-cf4e918bbf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-7de89813-7773-484a-b250-ef2b2ee922ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-2a9387b4-a19d-49a5-88da-2d932f6905ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-85116300-172.17.0.7-1595623878153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41961,DS-7aedb2ff-53ff-491f-adb3-ed76e1f8fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-8e017739-c680-44a1-96b5-db0152bbbe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-c157e4a9-53cf-4225-82d1-dff6b6f0aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-bb3c1192-f1dc-493f-8bb0-45e7ab9d6452,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-5102736b-5547-44b4-8c93-397b94daaa73,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-03756c6b-d353-4447-a36f-8cdcd7ce754d,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-ad236cd2-ca14-4ea1-841a-2fe251c73463,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-e32cd827-9dc4-43e7-a986-af67f67154bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-85116300-172.17.0.7-1595623878153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41961,DS-7aedb2ff-53ff-491f-adb3-ed76e1f8fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-8e017739-c680-44a1-96b5-db0152bbbe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-c157e4a9-53cf-4225-82d1-dff6b6f0aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-bb3c1192-f1dc-493f-8bb0-45e7ab9d6452,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-5102736b-5547-44b4-8c93-397b94daaa73,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-03756c6b-d353-4447-a36f-8cdcd7ce754d,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-ad236cd2-ca14-4ea1-841a-2fe251c73463,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-e32cd827-9dc4-43e7-a986-af67f67154bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837865829-172.17.0.7-1595624073922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37585,DS-dcb81d89-b0d9-40bd-8ea6-fba055141f55,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-ecd91ef8-595c-4053-a313-40d50b8504f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-8f759c98-4ef6-4648-8d50-dfacd4ae3d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-41d3cad1-939f-4ce9-bf0f-992a2a9c855c,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-9205d04a-8c35-4805-a80e-ff76f1fc9267,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-fddd973e-f1e0-4d78-b5a2-7555eb500302,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-aa31b564-2f55-49ca-9662-c83d713fa2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-508c2c2d-2f65-4b0b-956f-3122624c7097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837865829-172.17.0.7-1595624073922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37585,DS-dcb81d89-b0d9-40bd-8ea6-fba055141f55,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-ecd91ef8-595c-4053-a313-40d50b8504f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-8f759c98-4ef6-4648-8d50-dfacd4ae3d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-41d3cad1-939f-4ce9-bf0f-992a2a9c855c,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-9205d04a-8c35-4805-a80e-ff76f1fc9267,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-fddd973e-f1e0-4d78-b5a2-7555eb500302,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-aa31b564-2f55-49ca-9662-c83d713fa2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-508c2c2d-2f65-4b0b-956f-3122624c7097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645127544-172.17.0.7-1595624107047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37008,DS-2be2a929-3069-41a4-bcb2-6de26579dded,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-448d2e30-5697-485e-803e-83437bfa2d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-1a2b0680-20c3-4f6f-b232-d3d18d9804b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-2d2ba38c-c901-4475-a50a-79b9c3b9d320,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-ebf00285-4294-41b1-9111-c05e19e68972,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-c1616ebd-c731-408d-99e8-610a40f6bb06,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-30e4fe13-6f12-4f17-b666-7cf10b9fb884,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-dfd1d58c-a1ec-4523-a0d9-2476fd04a8b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645127544-172.17.0.7-1595624107047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37008,DS-2be2a929-3069-41a4-bcb2-6de26579dded,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-448d2e30-5697-485e-803e-83437bfa2d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-1a2b0680-20c3-4f6f-b232-d3d18d9804b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-2d2ba38c-c901-4475-a50a-79b9c3b9d320,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-ebf00285-4294-41b1-9111-c05e19e68972,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-c1616ebd-c731-408d-99e8-610a40f6bb06,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-30e4fe13-6f12-4f17-b666-7cf10b9fb884,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-dfd1d58c-a1ec-4523-a0d9-2476fd04a8b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5126
