reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686754863-172.17.0.12-1595667185497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42290,DS-bc8c9ee0-e49c-4457-83f6-81e2f89788f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-11d4d81c-2b52-491f-bd44-5568f8aa68e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-4e77e3ae-b4ed-45fa-a9bb-b57dd0a5b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-2d1d449b-d827-46c6-878f-154c8a80a7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-af3c7712-334a-46dd-946d-440976fb6f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-a9b5df86-8b91-47a8-b8cf-051b846364cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-58bee459-8063-4ec7-8dc7-732957eb7fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-0effbc76-ad48-4ade-b53e-001fe8136c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686754863-172.17.0.12-1595667185497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42290,DS-bc8c9ee0-e49c-4457-83f6-81e2f89788f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-11d4d81c-2b52-491f-bd44-5568f8aa68e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-4e77e3ae-b4ed-45fa-a9bb-b57dd0a5b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-2d1d449b-d827-46c6-878f-154c8a80a7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-af3c7712-334a-46dd-946d-440976fb6f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-a9b5df86-8b91-47a8-b8cf-051b846364cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-58bee459-8063-4ec7-8dc7-732957eb7fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-0effbc76-ad48-4ade-b53e-001fe8136c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015252046-172.17.0.12-1595667286222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-c12b8fd5-3458-4780-990a-fedc1e06fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-85e5b0d1-0ffb-4959-a0a3-15c5bdb3af55,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-00dbccde-fa4e-4876-a2b5-39b5bed63110,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-15d26538-fddd-4f7c-883b-8605dda438d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-59478794-a470-4215-a99b-33ed6b942439,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-7e231cdf-9e76-4620-ad26-16c5cc20b865,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-046ca0c6-a2d5-4e36-abea-213f7d0c44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-8dbb3b03-c202-4654-ab68-c9ec40557280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015252046-172.17.0.12-1595667286222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-c12b8fd5-3458-4780-990a-fedc1e06fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-85e5b0d1-0ffb-4959-a0a3-15c5bdb3af55,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-00dbccde-fa4e-4876-a2b5-39b5bed63110,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-15d26538-fddd-4f7c-883b-8605dda438d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-59478794-a470-4215-a99b-33ed6b942439,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-7e231cdf-9e76-4620-ad26-16c5cc20b865,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-046ca0c6-a2d5-4e36-abea-213f7d0c44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-8dbb3b03-c202-4654-ab68-c9ec40557280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1885661318-172.17.0.12-1595667617844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41827,DS-81a91362-0cfb-457b-900e-52248bfc7f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-91d91680-e1b2-4b71-857b-17c9e66a4fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-318c5a8d-f7a4-4dbf-aeca-14007a2124a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-3e3f8254-2415-4e60-94af-dbd8320851a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-0ce50f74-e36b-4e00-847b-d5e8fe8ea75b,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-59e0e57e-f5f9-4ae2-890a-1f610ba82e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-9b2245f2-4fda-4149-a0d4-4816a81e67ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-f2dd3cac-ee51-4902-95d3-07f7adfa7b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1885661318-172.17.0.12-1595667617844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41827,DS-81a91362-0cfb-457b-900e-52248bfc7f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-91d91680-e1b2-4b71-857b-17c9e66a4fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-318c5a8d-f7a4-4dbf-aeca-14007a2124a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-3e3f8254-2415-4e60-94af-dbd8320851a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-0ce50f74-e36b-4e00-847b-d5e8fe8ea75b,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-59e0e57e-f5f9-4ae2-890a-1f610ba82e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-9b2245f2-4fda-4149-a0d4-4816a81e67ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-f2dd3cac-ee51-4902-95d3-07f7adfa7b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601914826-172.17.0.12-1595667679253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-acf6fd3f-d434-4bc1-bc1e-c00bf6740fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-cb2c22b6-a8b9-4252-a2d7-18a0f19409c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-31e2dcbd-805e-4641-904d-4abd8c195dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-37e5290c-777b-4ec6-9367-33340e20aeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-37939617-f56b-4166-9928-68d1a7b8c6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-0aacfbb8-8f56-4942-85e6-458b02b2ffdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-acff9f6e-7095-458f-bd7c-eba208b9af5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-c0ded62d-850a-4193-9c8d-cb8a968ff881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601914826-172.17.0.12-1595667679253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-acf6fd3f-d434-4bc1-bc1e-c00bf6740fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-cb2c22b6-a8b9-4252-a2d7-18a0f19409c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-31e2dcbd-805e-4641-904d-4abd8c195dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-37e5290c-777b-4ec6-9367-33340e20aeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-37939617-f56b-4166-9928-68d1a7b8c6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-0aacfbb8-8f56-4942-85e6-458b02b2ffdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-acff9f6e-7095-458f-bd7c-eba208b9af5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-c0ded62d-850a-4193-9c8d-cb8a968ff881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285593716-172.17.0.12-1595667711696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34878,DS-bdc82ab1-ed84-48d2-8520-df795d849731,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-cdf9d806-32d3-4c75-a286-548320c3bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-66661226-17f4-4748-913a-d98e1cba4174,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-d22a081b-955d-4e41-91c1-f6eb03cfb5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-4cac7d01-5d52-4dc1-bc67-783f9bc480a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-68c8fe91-dfd0-4639-af87-fd7b8bae8471,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-ba051331-8a0a-4420-b5a5-95ae6a6d2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-a0d356c4-ee8c-4150-bd82-c62cd4e615ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285593716-172.17.0.12-1595667711696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34878,DS-bdc82ab1-ed84-48d2-8520-df795d849731,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-cdf9d806-32d3-4c75-a286-548320c3bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-66661226-17f4-4748-913a-d98e1cba4174,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-d22a081b-955d-4e41-91c1-f6eb03cfb5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-4cac7d01-5d52-4dc1-bc67-783f9bc480a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-68c8fe91-dfd0-4639-af87-fd7b8bae8471,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-ba051331-8a0a-4420-b5a5-95ae6a6d2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-a0d356c4-ee8c-4150-bd82-c62cd4e615ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341382528-172.17.0.12-1595668424118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34514,DS-254baba3-f433-43ff-a2da-e53f150a0e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-8ac9668e-62a4-4422-b374-f4a687ac41a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-8b7861e2-c5ed-4627-b74a-6b991b800c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-7f35de61-5063-4248-85b9-99f497747e91,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-4faac8e0-28a5-4583-a25c-c63ca13b8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-86d6d42f-a892-4ea8-840b-c6b2305355d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-6b777624-c299-4edd-9e51-45eb41f96ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-be32c533-a9c7-4f57-a8e7-032002a77e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341382528-172.17.0.12-1595668424118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34514,DS-254baba3-f433-43ff-a2da-e53f150a0e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-8ac9668e-62a4-4422-b374-f4a687ac41a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-8b7861e2-c5ed-4627-b74a-6b991b800c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-7f35de61-5063-4248-85b9-99f497747e91,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-4faac8e0-28a5-4583-a25c-c63ca13b8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-86d6d42f-a892-4ea8-840b-c6b2305355d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-6b777624-c299-4edd-9e51-45eb41f96ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-be32c533-a9c7-4f57-a8e7-032002a77e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40626983-172.17.0.12-1595668907453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-83fe91fb-ef9a-4e36-a440-813e2850f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-71992625-c477-4d57-b295-02c76c92ba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-59d2fe6e-b4dc-4150-8418-06591949dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-46094814-00f7-4555-a7fe-da9b535b05fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-bd1658cc-30f7-414a-9908-f7a690d8a685,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-04676076-8cdf-4443-949d-619ee5f806de,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-9e95202f-7839-4640-b700-ff6ca78c0330,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-af9915eb-3893-480e-9b31-2860cc95b954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40626983-172.17.0.12-1595668907453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-83fe91fb-ef9a-4e36-a440-813e2850f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-71992625-c477-4d57-b295-02c76c92ba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-59d2fe6e-b4dc-4150-8418-06591949dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-46094814-00f7-4555-a7fe-da9b535b05fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-bd1658cc-30f7-414a-9908-f7a690d8a685,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-04676076-8cdf-4443-949d-619ee5f806de,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-9e95202f-7839-4640-b700-ff6ca78c0330,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-af9915eb-3893-480e-9b31-2860cc95b954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025916573-172.17.0.12-1595669437379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40697,DS-154fb50a-73be-44e5-88b5-86095734069d,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-5ab3e1a5-fb04-45aa-9705-9a263ba346da,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-52802e24-a477-4faa-9785-17516b0ba584,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-cd1747c4-4a9b-4721-a229-445936366fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-bc8e2553-4b97-4d4a-aa0b-c0b039b3bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-1e4ba3df-d6d7-4fa2-9234-cb754aae1cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-24ed5cc7-038c-4417-8d03-d949e84aba13,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-492f2614-54f9-4788-bce1-00878320bb10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025916573-172.17.0.12-1595669437379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40697,DS-154fb50a-73be-44e5-88b5-86095734069d,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-5ab3e1a5-fb04-45aa-9705-9a263ba346da,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-52802e24-a477-4faa-9785-17516b0ba584,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-cd1747c4-4a9b-4721-a229-445936366fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-bc8e2553-4b97-4d4a-aa0b-c0b039b3bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-1e4ba3df-d6d7-4fa2-9234-cb754aae1cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-24ed5cc7-038c-4417-8d03-d949e84aba13,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-492f2614-54f9-4788-bce1-00878320bb10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315369582-172.17.0.12-1595669894563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36880,DS-595696f0-aaba-45fe-aa86-68b2c8e2dc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-722822f3-398e-46b8-8de0-12296705e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-9b615393-30ba-4e10-9c45-1a9e1af8bc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-d020ccb0-114f-4d2b-9aaa-e49bd84f582c,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-adfb30ef-ab29-4d86-b0b8-0f2a74bb60c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-7697a580-9bed-4650-a652-e9e2d993c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-e532a784-5430-4310-a7d5-26b6cf1f074c,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-4e5491ac-e747-43b7-9d9f-668c03fd9bcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315369582-172.17.0.12-1595669894563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36880,DS-595696f0-aaba-45fe-aa86-68b2c8e2dc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-722822f3-398e-46b8-8de0-12296705e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-9b615393-30ba-4e10-9c45-1a9e1af8bc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-d020ccb0-114f-4d2b-9aaa-e49bd84f582c,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-adfb30ef-ab29-4d86-b0b8-0f2a74bb60c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-7697a580-9bed-4650-a652-e9e2d993c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-e532a784-5430-4310-a7d5-26b6cf1f074c,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-4e5491ac-e747-43b7-9d9f-668c03fd9bcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360624215-172.17.0.12-1595670344368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46644,DS-6f0d134a-3966-4804-a47e-97f14c1afbac,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-2895c18c-ac73-4138-928f-c0631e30e995,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-02e5177b-a770-4a03-bec7-24d2fb265a01,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-ab5b79fe-6d61-4621-a8c4-a28b19a24b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-161fc649-a19e-40a3-b318-06ac84a8b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-9fd82a91-ec66-4ef2-90a3-640d7f585319,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-9bcb646e-1e2d-448d-8310-38e030e4f587,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-3a9207f7-12a3-4965-ad29-9dd0e98f1282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360624215-172.17.0.12-1595670344368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46644,DS-6f0d134a-3966-4804-a47e-97f14c1afbac,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-2895c18c-ac73-4138-928f-c0631e30e995,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-02e5177b-a770-4a03-bec7-24d2fb265a01,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-ab5b79fe-6d61-4621-a8c4-a28b19a24b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-161fc649-a19e-40a3-b318-06ac84a8b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-9fd82a91-ec66-4ef2-90a3-640d7f585319,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-9bcb646e-1e2d-448d-8310-38e030e4f587,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-3a9207f7-12a3-4965-ad29-9dd0e98f1282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363752020-172.17.0.12-1595670497515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-e6ec66c8-2500-47f0-8e83-404c95369833,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-5bde57e4-9dd3-4282-8174-c997b6caca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-8a066893-0791-4cba-b5a7-91ce7ad62829,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-a297327c-1045-40e8-bd5f-524e711b88ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-67035e0f-0e44-48c6-b3c4-d19f79c4fe83,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-b1ebc1de-db64-48b5-8f28-74dc7369ff0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-d844693d-5034-4aff-a3fe-8806aacc8040,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-9e8263ea-6bde-43a5-8a5f-35b874eca4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363752020-172.17.0.12-1595670497515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-e6ec66c8-2500-47f0-8e83-404c95369833,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-5bde57e4-9dd3-4282-8174-c997b6caca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-8a066893-0791-4cba-b5a7-91ce7ad62829,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-a297327c-1045-40e8-bd5f-524e711b88ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-67035e0f-0e44-48c6-b3c4-d19f79c4fe83,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-b1ebc1de-db64-48b5-8f28-74dc7369ff0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-d844693d-5034-4aff-a3fe-8806aacc8040,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-9e8263ea-6bde-43a5-8a5f-35b874eca4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434242916-172.17.0.12-1595670758191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42519,DS-80085c52-2bfd-4029-9c38-dbd1aae32660,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-4ebe584f-fc44-4f61-871b-f70e061a3983,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-770d4ca9-e7f4-49cc-87de-08272792ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-eddc8d48-e36d-4da8-9e50-40f72a53e442,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-f0ab2b79-f0b3-441c-b886-1e5fb8a4ff25,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-3a1663e8-f93a-41e9-b4cc-4a55e82639c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-ca2c32a3-11ec-4f66-8277-700e31e91557,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-379da29f-fc34-4d48-a84d-078f166d426e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434242916-172.17.0.12-1595670758191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42519,DS-80085c52-2bfd-4029-9c38-dbd1aae32660,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-4ebe584f-fc44-4f61-871b-f70e061a3983,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-770d4ca9-e7f4-49cc-87de-08272792ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-eddc8d48-e36d-4da8-9e50-40f72a53e442,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-f0ab2b79-f0b3-441c-b886-1e5fb8a4ff25,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-3a1663e8-f93a-41e9-b4cc-4a55e82639c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-ca2c32a3-11ec-4f66-8277-700e31e91557,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-379da29f-fc34-4d48-a84d-078f166d426e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106514334-172.17.0.12-1595671075453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38529,DS-a3c5b6e7-7702-45d7-a852-ed203cefc237,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-d95af24c-d1e1-45e4-a7ba-a63e942faea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-aed87896-3a9c-442c-895f-defc3091e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-c88c9c11-306e-4afb-8b2f-a66219165c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-c298bb03-1b92-446e-a6df-58d44b56216b,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-ac8d7c9f-9fda-47e5-b0d6-a76900d06664,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-b7f4f633-b178-47ed-a4f7-c303ada82685,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-bec169a1-ef5a-45c1-be01-d1d6ee14ce63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106514334-172.17.0.12-1595671075453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38529,DS-a3c5b6e7-7702-45d7-a852-ed203cefc237,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-d95af24c-d1e1-45e4-a7ba-a63e942faea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-aed87896-3a9c-442c-895f-defc3091e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-c88c9c11-306e-4afb-8b2f-a66219165c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-c298bb03-1b92-446e-a6df-58d44b56216b,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-ac8d7c9f-9fda-47e5-b0d6-a76900d06664,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-b7f4f633-b178-47ed-a4f7-c303ada82685,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-bec169a1-ef5a-45c1-be01-d1d6ee14ce63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60151220-172.17.0.12-1595671304142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43937,DS-3537c2d9-93da-419e-b745-2b29b54a3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-e5ff201b-e89a-420e-8e60-033f44d07fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-fb0d3674-64dd-4a74-9d3c-25024828b26e,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-bdb68a28-9916-4fd3-b15d-b28ebaba0c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-75df8f6b-e706-463c-b640-95421ac96d76,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-39b1189d-749b-4507-8808-b5587de03939,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-28136203-60ff-4794-82ce-b355ea1e61b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-b87090c0-7511-4261-8e51-300199103ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60151220-172.17.0.12-1595671304142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43937,DS-3537c2d9-93da-419e-b745-2b29b54a3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-e5ff201b-e89a-420e-8e60-033f44d07fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-fb0d3674-64dd-4a74-9d3c-25024828b26e,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-bdb68a28-9916-4fd3-b15d-b28ebaba0c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-75df8f6b-e706-463c-b640-95421ac96d76,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-39b1189d-749b-4507-8808-b5587de03939,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-28136203-60ff-4794-82ce-b355ea1e61b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-b87090c0-7511-4261-8e51-300199103ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055851656-172.17.0.12-1595671559405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-e27d82c6-9d7c-4bf6-9922-b13f1c963300,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-c7d828c1-3edb-4070-a869-2d0d6d57442d,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-7d0e3974-c0a5-4d2c-ab6b-c1836a6b3d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-673b2950-e078-44f3-b2c6-7935c71b889e,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-fe878a6b-b050-4a0f-9109-842d000dfee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-b86c3d10-f602-40c8-9f19-496ab6a1f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-72424b3b-466a-4016-b1f7-acd12e1d6236,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-641f3906-aadc-445a-b7d0-f367b234dcb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055851656-172.17.0.12-1595671559405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-e27d82c6-9d7c-4bf6-9922-b13f1c963300,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-c7d828c1-3edb-4070-a869-2d0d6d57442d,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-7d0e3974-c0a5-4d2c-ab6b-c1836a6b3d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-673b2950-e078-44f3-b2c6-7935c71b889e,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-fe878a6b-b050-4a0f-9109-842d000dfee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-b86c3d10-f602-40c8-9f19-496ab6a1f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-72424b3b-466a-4016-b1f7-acd12e1d6236,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-641f3906-aadc-445a-b7d0-f367b234dcb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900126326-172.17.0.12-1595671784494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-f8370c34-6c36-4331-a402-942a4877a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-eca7d4ee-cdb1-4bb8-8514-5205a3b3b764,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-b5cbd337-7454-418f-ae43-6fc1836475a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-c39a98f1-c36a-4af0-b1b0-ff8f10815ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-2be7f8c6-ecff-460e-bf33-a625d8c3f111,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-1e7ddade-4eeb-43b1-a80b-e32ae531ec51,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-93b0f68b-c5d3-4fc5-aa5b-1ccfd78ce5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-fff99da2-bff0-4ad5-a515-6bfd7dad2cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900126326-172.17.0.12-1595671784494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-f8370c34-6c36-4331-a402-942a4877a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-eca7d4ee-cdb1-4bb8-8514-5205a3b3b764,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-b5cbd337-7454-418f-ae43-6fc1836475a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-c39a98f1-c36a-4af0-b1b0-ff8f10815ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-2be7f8c6-ecff-460e-bf33-a625d8c3f111,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-1e7ddade-4eeb-43b1-a80b-e32ae531ec51,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-93b0f68b-c5d3-4fc5-aa5b-1ccfd78ce5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-fff99da2-bff0-4ad5-a515-6bfd7dad2cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5315
