reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611508676-172.17.0.20-1595606340368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36822,DS-fe090c6e-3c11-490e-a4c2-a26c970c6244,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-49fc1292-1737-4274-ba52-bff69a681d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-77cb7b2e-4320-4bb6-a16b-78dd88e9cb40,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-ebc5fd6e-84ff-4f8d-bec9-a5fea91fa91e,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-549ec547-a1ec-42e2-813b-0de886470b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-31e0a4f0-f951-439a-aa10-002b81c22661,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-a980c9a6-2db5-415d-9b76-eba4a09a5876,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-685dae70-cb27-463c-9854-76c591e242bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611508676-172.17.0.20-1595606340368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36822,DS-fe090c6e-3c11-490e-a4c2-a26c970c6244,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-49fc1292-1737-4274-ba52-bff69a681d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-77cb7b2e-4320-4bb6-a16b-78dd88e9cb40,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-ebc5fd6e-84ff-4f8d-bec9-a5fea91fa91e,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-549ec547-a1ec-42e2-813b-0de886470b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-31e0a4f0-f951-439a-aa10-002b81c22661,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-a980c9a6-2db5-415d-9b76-eba4a09a5876,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-685dae70-cb27-463c-9854-76c591e242bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291755032-172.17.0.20-1595606548079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-316c5160-1e93-4d6b-a901-1424b5d0c07d,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-1ced7084-f880-4395-a32d-87cf56d116e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-bb4cf378-c044-4ab8-97d7-b45e41dc8be8,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-71a0b0db-bc90-42dd-85ec-341705750752,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-20e990c9-eae6-40ca-817d-5060a9c756d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-d9463536-62fc-41ef-8c95-b32c217d334a,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-5a93fc86-eebb-4964-a68f-c649f83bc642,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-04164386-8dde-4fc0-9d03-f7240093a02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291755032-172.17.0.20-1595606548079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-316c5160-1e93-4d6b-a901-1424b5d0c07d,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-1ced7084-f880-4395-a32d-87cf56d116e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-bb4cf378-c044-4ab8-97d7-b45e41dc8be8,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-71a0b0db-bc90-42dd-85ec-341705750752,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-20e990c9-eae6-40ca-817d-5060a9c756d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-d9463536-62fc-41ef-8c95-b32c217d334a,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-5a93fc86-eebb-4964-a68f-c649f83bc642,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-04164386-8dde-4fc0-9d03-f7240093a02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927931426-172.17.0.20-1595606589125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39568,DS-f52ce90d-ce87-4617-842d-c8ddc04da41d,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-7257c9b4-0416-41e7-943b-84f45bd08a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-14755e33-d602-4695-84aa-497ba45e98da,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-39c11c80-0f58-4726-8c67-c0e21f164440,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-59380324-67aa-409e-a977-f06637f401fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-0b487402-f6f6-4948-9115-5bd502bcb122,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-7dd9d880-b68b-483a-a09e-21e68adcb6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-02756470-1dc8-4b04-8664-37a30a4caf6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927931426-172.17.0.20-1595606589125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39568,DS-f52ce90d-ce87-4617-842d-c8ddc04da41d,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-7257c9b4-0416-41e7-943b-84f45bd08a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-14755e33-d602-4695-84aa-497ba45e98da,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-39c11c80-0f58-4726-8c67-c0e21f164440,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-59380324-67aa-409e-a977-f06637f401fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-0b487402-f6f6-4948-9115-5bd502bcb122,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-7dd9d880-b68b-483a-a09e-21e68adcb6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-02756470-1dc8-4b04-8664-37a30a4caf6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614239206-172.17.0.20-1595606834400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42750,DS-d84b8d22-df3d-42a9-91bf-307f07987fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-b263d9e8-4690-4074-82fc-8313b35dfa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-c3c693ec-b4eb-4506-95e0-c71d6688f1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-4caf9566-9b77-440f-bd57-df10fda7d47a,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-f1167494-d71e-4e5e-bb5a-fb1fe0eb619e,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-4f2c9f08-3881-42fc-b9b4-c57b2cbe3572,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-9511b97c-8650-4a79-94e8-c9be1e29cb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-5ac86725-d772-48ca-a83d-6c7b5ed582a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614239206-172.17.0.20-1595606834400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42750,DS-d84b8d22-df3d-42a9-91bf-307f07987fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-b263d9e8-4690-4074-82fc-8313b35dfa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-c3c693ec-b4eb-4506-95e0-c71d6688f1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-4caf9566-9b77-440f-bd57-df10fda7d47a,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-f1167494-d71e-4e5e-bb5a-fb1fe0eb619e,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-4f2c9f08-3881-42fc-b9b4-c57b2cbe3572,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-9511b97c-8650-4a79-94e8-c9be1e29cb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-5ac86725-d772-48ca-a83d-6c7b5ed582a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998560299-172.17.0.20-1595607144591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43648,DS-3bdd0968-fa8d-43b8-bd8d-bdf2d9b7594b,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-0c92c886-5df5-4b62-8d97-67d92899ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-397f2a6a-67a7-4068-823a-9e0e1640d394,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-f302cd9e-6496-4b7e-93c3-38422fd12083,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-012dc5d4-5af7-4be1-956e-4e49b0b8e064,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-7d3d975f-5f80-4a0a-b292-37943d5ec87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-0024313a-adc4-44dd-9f7e-8a1aff10db96,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-9632e09e-7fc4-49a2-be93-d82bfdcfad21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998560299-172.17.0.20-1595607144591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43648,DS-3bdd0968-fa8d-43b8-bd8d-bdf2d9b7594b,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-0c92c886-5df5-4b62-8d97-67d92899ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-397f2a6a-67a7-4068-823a-9e0e1640d394,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-f302cd9e-6496-4b7e-93c3-38422fd12083,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-012dc5d4-5af7-4be1-956e-4e49b0b8e064,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-7d3d975f-5f80-4a0a-b292-37943d5ec87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-0024313a-adc4-44dd-9f7e-8a1aff10db96,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-9632e09e-7fc4-49a2-be93-d82bfdcfad21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590680331-172.17.0.20-1595607542039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-63f08ecc-1881-498a-8908-2970efb483dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-407c6951-2e6a-42e1-86a6-2d4a4218900f,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-1a1ff50b-55a7-425c-9c74-f96490e1c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-8bb3f45b-80eb-4638-809f-ec0aa0cf4412,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-1342fc6d-826d-423f-9e9c-44f472a04210,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-9cb6d61c-3040-46a2-a1e4-9416b8368051,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-8700df5e-0c28-4e3b-a9a7-4d7a7811cfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-0ce27bdf-a67b-4d6b-a29d-ae7b13679dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590680331-172.17.0.20-1595607542039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-63f08ecc-1881-498a-8908-2970efb483dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-407c6951-2e6a-42e1-86a6-2d4a4218900f,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-1a1ff50b-55a7-425c-9c74-f96490e1c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-8bb3f45b-80eb-4638-809f-ec0aa0cf4412,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-1342fc6d-826d-423f-9e9c-44f472a04210,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-9cb6d61c-3040-46a2-a1e4-9416b8368051,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-8700df5e-0c28-4e3b-a9a7-4d7a7811cfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-0ce27bdf-a67b-4d6b-a29d-ae7b13679dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352167477-172.17.0.20-1595608056400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-028bf0c4-3985-44ae-9b5f-a6e0ba245def,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-e492ce80-f927-4a44-8dab-2dd0863a7d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-690e61b3-ccce-47a1-9b97-efb1ce2194f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-517a2a87-001a-4757-9668-75c37b71362a,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-bd95df9b-699f-42b4-b959-12467da95f49,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-5f43549f-f3ae-4f82-b278-d8bfd2d0682e,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-5280f7ee-27f3-4347-af41-0ad401b0d307,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-2ddb8d5c-bb1a-442d-be79-18034e71d825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352167477-172.17.0.20-1595608056400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-028bf0c4-3985-44ae-9b5f-a6e0ba245def,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-e492ce80-f927-4a44-8dab-2dd0863a7d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-690e61b3-ccce-47a1-9b97-efb1ce2194f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-517a2a87-001a-4757-9668-75c37b71362a,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-bd95df9b-699f-42b4-b959-12467da95f49,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-5f43549f-f3ae-4f82-b278-d8bfd2d0682e,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-5280f7ee-27f3-4347-af41-0ad401b0d307,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-2ddb8d5c-bb1a-442d-be79-18034e71d825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30877879-172.17.0.20-1595608196388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-b5262079-ec3c-48ef-b12b-cffb050274c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-4d22aa29-4529-4387-b1f6-022d431168a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-2502e5c1-2dff-489e-914f-f11aaec64d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-b58cfb9e-5be3-47d4-b251-0ca62434fb06,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-d1c0a0a9-4238-4cb9-9638-9009d15ff3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-5b18924e-6e28-4775-9834-cc7ab29aad36,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-e2a69938-a991-4859-84ff-6b11ebf6fbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-c89b20c3-de57-4e03-8dcb-53700a5993c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30877879-172.17.0.20-1595608196388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-b5262079-ec3c-48ef-b12b-cffb050274c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-4d22aa29-4529-4387-b1f6-022d431168a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-2502e5c1-2dff-489e-914f-f11aaec64d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-b58cfb9e-5be3-47d4-b251-0ca62434fb06,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-d1c0a0a9-4238-4cb9-9638-9009d15ff3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-5b18924e-6e28-4775-9834-cc7ab29aad36,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-e2a69938-a991-4859-84ff-6b11ebf6fbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-c89b20c3-de57-4e03-8dcb-53700a5993c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887330430-172.17.0.20-1595608367452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-3fb8c761-500a-4613-a3c8-925277b04655,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-4c0df89d-93c8-4861-9532-1921551bc639,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-a1bf7b45-b37c-4434-bebf-1340a209667d,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-3c15d8f8-53b1-4803-9245-d85ce14e7a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-e482ccd0-28f5-45b8-9b00-8d4183f51121,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-1a8182ad-0566-483c-b0a3-75c1a4dea143,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-b718e923-ce06-4f0d-83c6-de033074c474,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-1f30dc2e-4180-4ef1-b13b-ac604060f690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887330430-172.17.0.20-1595608367452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-3fb8c761-500a-4613-a3c8-925277b04655,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-4c0df89d-93c8-4861-9532-1921551bc639,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-a1bf7b45-b37c-4434-bebf-1340a209667d,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-3c15d8f8-53b1-4803-9245-d85ce14e7a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-e482ccd0-28f5-45b8-9b00-8d4183f51121,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-1a8182ad-0566-483c-b0a3-75c1a4dea143,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-b718e923-ce06-4f0d-83c6-de033074c474,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-1f30dc2e-4180-4ef1-b13b-ac604060f690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410454250-172.17.0.20-1595609008533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-4de6cf3c-7671-4ef4-ba06-cd4e3ead31ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-8310d42c-636e-48a4-a9ff-0dbe918f4564,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-fc34c59e-1a02-471a-aab9-260252a61ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-cb2aa64e-d9fc-4476-8025-f199185d3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-af27cdf3-a8b4-4bae-9315-e8d06cc6ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-d0caa8ef-e261-4852-8ee9-825900f489ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-0108f2c1-06f7-4c02-9f5a-213113e574be,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-d9fa929e-1e94-4dd8-b2f1-7328a8bafc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410454250-172.17.0.20-1595609008533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-4de6cf3c-7671-4ef4-ba06-cd4e3ead31ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-8310d42c-636e-48a4-a9ff-0dbe918f4564,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-fc34c59e-1a02-471a-aab9-260252a61ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-cb2aa64e-d9fc-4476-8025-f199185d3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-af27cdf3-a8b4-4bae-9315-e8d06cc6ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-d0caa8ef-e261-4852-8ee9-825900f489ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-0108f2c1-06f7-4c02-9f5a-213113e574be,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-d9fa929e-1e94-4dd8-b2f1-7328a8bafc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377989238-172.17.0.20-1595609813671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36276,DS-a2eb64e3-b4c5-482c-96bb-6bf1fa62d2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-17ae4a0d-d810-462d-8c53-7979b10ba4da,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-77f86ef5-4b41-401b-8273-e3b01403f80f,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-30416443-93a6-42fe-8164-943adce8ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-988ecc7b-e225-4f03-a073-90df55aa3c75,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-c9da2ff5-eee0-4d1b-8bfb-bb565e8e0014,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-d74f5b35-98ce-4a62-a725-8498aecb4752,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-13453426-d0ad-4a9c-8202-3b6c720945a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377989238-172.17.0.20-1595609813671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36276,DS-a2eb64e3-b4c5-482c-96bb-6bf1fa62d2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-17ae4a0d-d810-462d-8c53-7979b10ba4da,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-77f86ef5-4b41-401b-8273-e3b01403f80f,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-30416443-93a6-42fe-8164-943adce8ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-988ecc7b-e225-4f03-a073-90df55aa3c75,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-c9da2ff5-eee0-4d1b-8bfb-bb565e8e0014,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-d74f5b35-98ce-4a62-a725-8498aecb4752,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-13453426-d0ad-4a9c-8202-3b6c720945a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137132664-172.17.0.20-1595610541545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34605,DS-c91ac36a-3163-4048-a929-82270256c286,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-40d9dcea-13aa-4eb6-90ff-f6864336820d,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-acbe8c21-1ee4-4b38-8678-a65f18e1842e,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-ae1e4c91-a280-4d89-b831-1566ba6fc950,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-90b58e09-d391-451f-bca8-e21bdb875e94,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-dcce6a53-feb3-450b-b8f5-f4186c3af1df,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-2b783a10-7c50-402c-a0ba-15ab6a6173ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-c43560fc-5ae8-478b-a457-725162cb671d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137132664-172.17.0.20-1595610541545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34605,DS-c91ac36a-3163-4048-a929-82270256c286,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-40d9dcea-13aa-4eb6-90ff-f6864336820d,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-acbe8c21-1ee4-4b38-8678-a65f18e1842e,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-ae1e4c91-a280-4d89-b831-1566ba6fc950,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-90b58e09-d391-451f-bca8-e21bdb875e94,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-dcce6a53-feb3-450b-b8f5-f4186c3af1df,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-2b783a10-7c50-402c-a0ba-15ab6a6173ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-c43560fc-5ae8-478b-a457-725162cb671d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096289502-172.17.0.20-1595610577739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-090c542f-af91-4ccc-8375-730031517920,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-525cf0a9-02ae-4198-9d40-3d14545ebf20,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-e880270d-455a-43bc-bdd9-e537536d2bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-e845140a-564c-4df7-b815-4dd5d386984d,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-4bc81af0-575c-4c14-b1e4-0cd1e7a6863e,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-6c663748-33cc-4808-9740-08e9707c59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-d481d762-eec9-4351-b88e-4612c9a8814d,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-ff661e07-1251-4bca-9592-18264677186c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096289502-172.17.0.20-1595610577739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-090c542f-af91-4ccc-8375-730031517920,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-525cf0a9-02ae-4198-9d40-3d14545ebf20,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-e880270d-455a-43bc-bdd9-e537536d2bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-e845140a-564c-4df7-b815-4dd5d386984d,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-4bc81af0-575c-4c14-b1e4-0cd1e7a6863e,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-6c663748-33cc-4808-9740-08e9707c59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-d481d762-eec9-4351-b88e-4612c9a8814d,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-ff661e07-1251-4bca-9592-18264677186c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914483418-172.17.0.20-1595611439095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-430b6c8d-3e84-4508-94c2-7c61e1cee5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-a91dce71-a44e-4337-a16e-8c5c6e36dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-1711b7dc-918e-4674-aa31-7f1b407e3161,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-5b18aa7f-200f-454e-a1bc-ecf8378b4a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-ee8bad5a-4a4d-4bbf-a25a-6d2b0bf8f983,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-44a656ff-bd57-445f-acb7-a73c7b027c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-c9775364-06be-4352-8b0b-63a4a8ad99ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-576c6f4d-298d-447b-9701-0dbf082a8fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914483418-172.17.0.20-1595611439095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-430b6c8d-3e84-4508-94c2-7c61e1cee5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-a91dce71-a44e-4337-a16e-8c5c6e36dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-1711b7dc-918e-4674-aa31-7f1b407e3161,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-5b18aa7f-200f-454e-a1bc-ecf8378b4a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-ee8bad5a-4a4d-4bbf-a25a-6d2b0bf8f983,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-44a656ff-bd57-445f-acb7-a73c7b027c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-c9775364-06be-4352-8b0b-63a4a8ad99ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-576c6f4d-298d-447b-9701-0dbf082a8fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578823887-172.17.0.20-1595611517433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44930,DS-d9085d00-028e-40ee-a5b8-357983fbebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-1e437677-7322-485a-8f90-5e4ba984ad0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-4fb8d5e7-633b-4f89-a87c-614830402681,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-9fceb378-ba31-4e4c-ace5-ef7ee96e729b,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-e13893de-943d-475b-82f9-04c3d404aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-8881965f-f74f-419b-bdd4-d490e362bcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-420c4b9d-7ba9-4a5a-9270-089686e0371d,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-283e1e44-e96a-453a-ab01-26220ccab018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578823887-172.17.0.20-1595611517433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44930,DS-d9085d00-028e-40ee-a5b8-357983fbebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-1e437677-7322-485a-8f90-5e4ba984ad0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-4fb8d5e7-633b-4f89-a87c-614830402681,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-9fceb378-ba31-4e4c-ace5-ef7ee96e729b,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-e13893de-943d-475b-82f9-04c3d404aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-8881965f-f74f-419b-bdd4-d490e362bcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-420c4b9d-7ba9-4a5a-9270-089686e0371d,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-283e1e44-e96a-453a-ab01-26220ccab018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629215541-172.17.0.20-1595611679145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37476,DS-ca1faeb4-8099-4c55-8d1b-662d2bec8caf,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-6e3e0b9e-9c9e-4223-849d-9c5f5169f4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-533d50d4-3093-49f5-8b5a-83aeb3aade95,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-0d44372e-1e7a-4071-9ca1-46a3e65e18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-40e3209e-9b7a-44cc-87ea-29b17e7da499,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-1bdcda3c-50cb-4553-8a23-e7a9ffed3091,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-8ea0445b-6655-4c75-bc5f-2aa121c2d179,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-48acef9f-299c-4a89-a84f-82483ec3eae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629215541-172.17.0.20-1595611679145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37476,DS-ca1faeb4-8099-4c55-8d1b-662d2bec8caf,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-6e3e0b9e-9c9e-4223-849d-9c5f5169f4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-533d50d4-3093-49f5-8b5a-83aeb3aade95,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-0d44372e-1e7a-4071-9ca1-46a3e65e18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-40e3209e-9b7a-44cc-87ea-29b17e7da499,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-1bdcda3c-50cb-4553-8a23-e7a9ffed3091,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-8ea0445b-6655-4c75-bc5f-2aa121c2d179,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-48acef9f-299c-4a89-a84f-82483ec3eae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084463832-172.17.0.20-1595612098979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37269,DS-c5f064b9-fc3b-44dc-a129-fc65767f6522,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-5ef28b29-f092-4fb6-b5af-0428abdd9db2,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-c2315a50-f3c9-46e7-96a1-8a264e0e3ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-0f1c03e7-0dde-4e4d-8991-fa1b116d5b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-62542626-a8ee-4e1f-8bcb-7b04badc4c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-9d672e59-115a-4ecb-b8d1-32bf3e868aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-166eaacc-ab06-4e87-a6ee-b4c3ca6b052d,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-776e7eac-43ae-4d02-9007-38464bf83dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084463832-172.17.0.20-1595612098979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37269,DS-c5f064b9-fc3b-44dc-a129-fc65767f6522,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-5ef28b29-f092-4fb6-b5af-0428abdd9db2,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-c2315a50-f3c9-46e7-96a1-8a264e0e3ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-0f1c03e7-0dde-4e4d-8991-fa1b116d5b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-62542626-a8ee-4e1f-8bcb-7b04badc4c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-9d672e59-115a-4ecb-b8d1-32bf3e868aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-166eaacc-ab06-4e87-a6ee-b4c3ca6b052d,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-776e7eac-43ae-4d02-9007-38464bf83dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6295
