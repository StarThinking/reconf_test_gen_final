reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83395836-172.17.0.18-1595502886760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35606,DS-9ef7ef6b-b512-408e-b8a1-a7ebe934606c,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-34d07e2a-fa94-46e1-957d-8b3e88eddcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-9e413508-1fba-4105-99fa-09ed8625d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-8eac6404-b624-4853-9655-dce31a351325,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-02e1471d-a47e-4483-8ee6-232b14a8e2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-4405c05f-0e5e-4957-8074-d222c324c150,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-36da7b11-d15f-42b9-a098-3c03716ffacf,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-50e2ccdb-f3cf-4ec0-8cc2-2206dffabe33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83395836-172.17.0.18-1595502886760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35606,DS-9ef7ef6b-b512-408e-b8a1-a7ebe934606c,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-34d07e2a-fa94-46e1-957d-8b3e88eddcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-9e413508-1fba-4105-99fa-09ed8625d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-8eac6404-b624-4853-9655-dce31a351325,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-02e1471d-a47e-4483-8ee6-232b14a8e2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-4405c05f-0e5e-4957-8074-d222c324c150,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-36da7b11-d15f-42b9-a098-3c03716ffacf,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-50e2ccdb-f3cf-4ec0-8cc2-2206dffabe33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663939286-172.17.0.18-1595503589993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45271,DS-959bcf1b-bc27-473f-a42f-bbc8a004e197,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-0791ce72-93ae-4791-be39-b8ed5ed85a53,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-e6b2f215-b5a9-4489-a506-25c207bec08c,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-4eace7ac-38f3-48f9-b766-e757dfe496d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-0e6a31f3-0f3b-480f-b48f-acc7153f57a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-60599a0a-41b4-4157-88d3-75586133c2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-9533351f-8335-43e4-b019-bfeb150276d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-d5ad2c18-124a-4f45-bc20-093dee367faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663939286-172.17.0.18-1595503589993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45271,DS-959bcf1b-bc27-473f-a42f-bbc8a004e197,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-0791ce72-93ae-4791-be39-b8ed5ed85a53,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-e6b2f215-b5a9-4489-a506-25c207bec08c,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-4eace7ac-38f3-48f9-b766-e757dfe496d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-0e6a31f3-0f3b-480f-b48f-acc7153f57a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-60599a0a-41b4-4157-88d3-75586133c2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-9533351f-8335-43e4-b019-bfeb150276d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-d5ad2c18-124a-4f45-bc20-093dee367faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324994844-172.17.0.18-1595504121358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44437,DS-244ffff1-ec24-48ff-a31c-f176e5a37619,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-97300be8-c3a2-4c91-973a-4201d02118d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-87e8e822-c841-4eb6-bd12-f35309ff187e,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-f1bec56a-c215-4961-aa41-cffee8724d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-eef5ce58-f4df-447f-85fd-c0bc8ba4419b,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-e21314df-01a0-45fc-987d-e36da79e2a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-817f6549-5740-4fd5-b66d-98e9fc7f32d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-c837d209-8627-433a-a653-4c497fdf91d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324994844-172.17.0.18-1595504121358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44437,DS-244ffff1-ec24-48ff-a31c-f176e5a37619,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-97300be8-c3a2-4c91-973a-4201d02118d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-87e8e822-c841-4eb6-bd12-f35309ff187e,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-f1bec56a-c215-4961-aa41-cffee8724d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-eef5ce58-f4df-447f-85fd-c0bc8ba4419b,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-e21314df-01a0-45fc-987d-e36da79e2a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-817f6549-5740-4fd5-b66d-98e9fc7f32d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-c837d209-8627-433a-a653-4c497fdf91d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609761027-172.17.0.18-1595504477974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-119b671a-15d1-479b-84ec-4cfc7d46e1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-b5740ea5-a121-47bd-af12-3ea85d632c16,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-09ffb0a6-5c53-4a6a-881c-38367e1b730f,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-5beb5141-f437-4350-80b0-4d07c68198ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-065eb779-25aa-4a82-bebc-73088f8e27d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-7935a331-ea71-4478-861a-c27ef237a190,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-786ffbaf-1de7-4b43-89ca-d1f250991ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-75373789-a913-4e0a-9833-ad314555077d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609761027-172.17.0.18-1595504477974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-119b671a-15d1-479b-84ec-4cfc7d46e1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-b5740ea5-a121-47bd-af12-3ea85d632c16,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-09ffb0a6-5c53-4a6a-881c-38367e1b730f,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-5beb5141-f437-4350-80b0-4d07c68198ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-065eb779-25aa-4a82-bebc-73088f8e27d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-7935a331-ea71-4478-861a-c27ef237a190,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-786ffbaf-1de7-4b43-89ca-d1f250991ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-75373789-a913-4e0a-9833-ad314555077d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055969417-172.17.0.18-1595504578562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46816,DS-84b6875c-dbf0-4198-9813-113d9ea7796d,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-845563e7-7f2c-48b4-86e7-5686bfdb85e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-6a9dc9c8-69d1-4dc2-b4eb-3dac604a1ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-d0d0b42c-0ded-47a7-961f-563652b4bb36,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-c5b7dd7a-878c-49e0-bf86-e285ecde93b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-8329dfc3-02aa-4278-b789-6db0890135d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-10ea5573-50d6-4631-bc33-1175c7f3774d,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-b17736aa-55bb-4f97-97d7-49406e010917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055969417-172.17.0.18-1595504578562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46816,DS-84b6875c-dbf0-4198-9813-113d9ea7796d,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-845563e7-7f2c-48b4-86e7-5686bfdb85e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-6a9dc9c8-69d1-4dc2-b4eb-3dac604a1ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-d0d0b42c-0ded-47a7-961f-563652b4bb36,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-c5b7dd7a-878c-49e0-bf86-e285ecde93b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-8329dfc3-02aa-4278-b789-6db0890135d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-10ea5573-50d6-4631-bc33-1175c7f3774d,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-b17736aa-55bb-4f97-97d7-49406e010917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597795568-172.17.0.18-1595504872397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43042,DS-3fbb6c74-e407-456d-b893-8692b945c73b,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-4f2f568d-e226-4129-ab6e-2bde434e43d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-1e295a1a-1826-483c-bf0b-56602ca80f83,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-d8af70b1-dae8-40f4-a742-56ff0288c4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-908834db-b4be-43f2-a89e-baf63fcaea10,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-58000de9-977e-4078-aea3-9bbe178f1da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-8519fc29-b907-4b7b-a485-490cc71a8164,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-b91641cd-5cfa-48c3-bb62-b77392480de3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597795568-172.17.0.18-1595504872397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43042,DS-3fbb6c74-e407-456d-b893-8692b945c73b,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-4f2f568d-e226-4129-ab6e-2bde434e43d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-1e295a1a-1826-483c-bf0b-56602ca80f83,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-d8af70b1-dae8-40f4-a742-56ff0288c4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-908834db-b4be-43f2-a89e-baf63fcaea10,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-58000de9-977e-4078-aea3-9bbe178f1da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-8519fc29-b907-4b7b-a485-490cc71a8164,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-b91641cd-5cfa-48c3-bb62-b77392480de3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695741581-172.17.0.18-1595504983489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40916,DS-2c0832af-951e-4a66-b4ec-b37faf652f38,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-411cf832-1a00-45b3-ba6f-005af3bcc9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-c77f2a73-a739-4307-bf27-12416f22e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-5f2d4f2f-5b86-4499-83c4-339dff0ce9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-11ca42c0-133e-428e-a6d0-059f612bb055,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-69611cf0-a6aa-4c05-bd23-6bb761df09b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-7105a103-a758-4f82-afbe-c9337a6f57f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-d26f5362-a8ad-4eae-9bf0-8163dc525f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695741581-172.17.0.18-1595504983489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40916,DS-2c0832af-951e-4a66-b4ec-b37faf652f38,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-411cf832-1a00-45b3-ba6f-005af3bcc9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-c77f2a73-a739-4307-bf27-12416f22e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-5f2d4f2f-5b86-4499-83c4-339dff0ce9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-11ca42c0-133e-428e-a6d0-059f612bb055,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-69611cf0-a6aa-4c05-bd23-6bb761df09b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-7105a103-a758-4f82-afbe-c9337a6f57f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-d26f5362-a8ad-4eae-9bf0-8163dc525f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846912352-172.17.0.18-1595505191226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-ff19c9fb-06a8-4e37-82d2-c63c4b1f97ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-654f1110-fdd6-4716-8232-f6cd5b692a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-ca2370a3-844f-4f12-9bd8-bcf9efa92e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-211d4990-5e57-407c-9033-2b61a30ba174,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-4d082ab5-7d14-47e8-84e5-1e225e02fd96,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-a5636a64-bbfe-45a3-ab60-41ce89fd7690,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-7be8d2ed-6584-4d18-92e0-0fea6f0a02de,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-50ba73df-5cbc-4258-b5d2-a4ab32040f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846912352-172.17.0.18-1595505191226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-ff19c9fb-06a8-4e37-82d2-c63c4b1f97ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-654f1110-fdd6-4716-8232-f6cd5b692a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-ca2370a3-844f-4f12-9bd8-bcf9efa92e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-211d4990-5e57-407c-9033-2b61a30ba174,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-4d082ab5-7d14-47e8-84e5-1e225e02fd96,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-a5636a64-bbfe-45a3-ab60-41ce89fd7690,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-7be8d2ed-6584-4d18-92e0-0fea6f0a02de,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-50ba73df-5cbc-4258-b5d2-a4ab32040f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923866998-172.17.0.18-1595505523027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37588,DS-dadcfb0e-63cf-485b-9b86-009595e8ff22,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-f5815779-f6e4-4c6b-877b-c1151e0ad1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-0e72cc48-d092-4b7a-8816-feeeccefd9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-ee1fce98-4c4b-46a8-b7f7-a0e0e4ec922f,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-3834bc38-de99-4fe2-9022-46f8c2e3777d,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-2b6cde7e-37c9-4854-aa33-d0b3e7ad243b,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-553515bb-1e72-4fed-9cd8-669be0276c02,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-95b26000-126d-46a2-a584-db57b1c27ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923866998-172.17.0.18-1595505523027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37588,DS-dadcfb0e-63cf-485b-9b86-009595e8ff22,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-f5815779-f6e4-4c6b-877b-c1151e0ad1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-0e72cc48-d092-4b7a-8816-feeeccefd9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-ee1fce98-4c4b-46a8-b7f7-a0e0e4ec922f,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-3834bc38-de99-4fe2-9022-46f8c2e3777d,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-2b6cde7e-37c9-4854-aa33-d0b3e7ad243b,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-553515bb-1e72-4fed-9cd8-669be0276c02,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-95b26000-126d-46a2-a584-db57b1c27ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065688630-172.17.0.18-1595505628548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39566,DS-e956d5af-9756-4784-a931-9a3dcd7b1308,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-738a84b1-a6ac-403f-8904-c98e18d703d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-8d3dc877-b039-475a-b7d9-00315967237c,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-c64e9bb2-f07f-4114-b9bc-a7eb3fc39f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-c4ebcaf4-cbb4-406a-88dc-5aaafee6430b,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-cbd9839a-a133-4342-94b7-8fbf985f481e,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-6ccf3d05-0ddf-4047-b53c-97a73a9793be,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-96304b3b-2709-49b1-8621-cc591fe04a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065688630-172.17.0.18-1595505628548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39566,DS-e956d5af-9756-4784-a931-9a3dcd7b1308,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-738a84b1-a6ac-403f-8904-c98e18d703d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-8d3dc877-b039-475a-b7d9-00315967237c,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-c64e9bb2-f07f-4114-b9bc-a7eb3fc39f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-c4ebcaf4-cbb4-406a-88dc-5aaafee6430b,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-cbd9839a-a133-4342-94b7-8fbf985f481e,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-6ccf3d05-0ddf-4047-b53c-97a73a9793be,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-96304b3b-2709-49b1-8621-cc591fe04a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662577795-172.17.0.18-1595505994083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43441,DS-121e0ac7-d69a-40df-b15c-a362b3fd73c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-24c454ba-eb81-4994-aa48-9945f4d089ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-0798fb77-c74c-4b53-a6d3-4c6fad176203,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-d38e0c3e-36e1-40b0-8e2d-aea31f27406b,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-1c72b018-0816-4649-abdd-154fbf66fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-cfa0ac28-45ca-4326-93f0-169cc8b77b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-62282173-d646-4387-9c94-839b1d16d6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-3cedd5b2-1284-4171-934a-f270dad5c868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662577795-172.17.0.18-1595505994083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43441,DS-121e0ac7-d69a-40df-b15c-a362b3fd73c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-24c454ba-eb81-4994-aa48-9945f4d089ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-0798fb77-c74c-4b53-a6d3-4c6fad176203,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-d38e0c3e-36e1-40b0-8e2d-aea31f27406b,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-1c72b018-0816-4649-abdd-154fbf66fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-cfa0ac28-45ca-4326-93f0-169cc8b77b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-62282173-d646-4387-9c94-839b1d16d6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-3cedd5b2-1284-4171-934a-f270dad5c868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891908458-172.17.0.18-1595506811024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37277,DS-88e42f09-20f2-4b9f-b6b5-6778a39e9bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-2edfaad0-d1db-484e-a59d-36205865fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-cb8f9602-95dc-4199-880e-bfdcafbcab21,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-31ce6965-120b-48d3-9e8a-3cb6c4faeeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-8f3c1e6b-f161-4f31-ab05-f238765eda61,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-f4a4b29e-f79d-4bc4-a7ae-51e1c034fe86,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-e5e58d71-b4cb-467e-893c-13e1f4a9d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-eba5cae1-d7a0-4f71-b08e-be59b058073f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891908458-172.17.0.18-1595506811024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37277,DS-88e42f09-20f2-4b9f-b6b5-6778a39e9bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-2edfaad0-d1db-484e-a59d-36205865fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-cb8f9602-95dc-4199-880e-bfdcafbcab21,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-31ce6965-120b-48d3-9e8a-3cb6c4faeeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-8f3c1e6b-f161-4f31-ab05-f238765eda61,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-f4a4b29e-f79d-4bc4-a7ae-51e1c034fe86,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-e5e58d71-b4cb-467e-893c-13e1f4a9d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-eba5cae1-d7a0-4f71-b08e-be59b058073f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756571393-172.17.0.18-1595507137357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46709,DS-73d19e05-4854-4d7c-809c-9bca1897fc03,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-793c0ef2-a506-49a2-ad4e-30076b954b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-d89e14f7-9d51-4007-aa57-f8b87a9264fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-dbbe71bc-92b7-4019-ad93-eb69a17626c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-a315823d-0d37-46d7-bc9d-edcd99a4592d,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-0626f4b3-7993-4c37-a9b0-4edee4e272c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-73c4fb15-cb42-4ace-bb82-188be5da7f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-66edc209-8665-4a24-bb4c-06bf84d0f8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756571393-172.17.0.18-1595507137357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46709,DS-73d19e05-4854-4d7c-809c-9bca1897fc03,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-793c0ef2-a506-49a2-ad4e-30076b954b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-d89e14f7-9d51-4007-aa57-f8b87a9264fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-dbbe71bc-92b7-4019-ad93-eb69a17626c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-a315823d-0d37-46d7-bc9d-edcd99a4592d,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-0626f4b3-7993-4c37-a9b0-4edee4e272c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-73c4fb15-cb42-4ace-bb82-188be5da7f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-66edc209-8665-4a24-bb4c-06bf84d0f8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140564736-172.17.0.18-1595507232150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-bb78e386-2f76-4657-95d4-2d81c29b7817,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-96ecd6d8-27f0-40b3-ab08-1087d773456a,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-f41e6c6a-8d2a-4da0-a5c5-83d027f8eb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-a5712bca-f23f-4a48-9f69-ddab34b0d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-729621c1-3b6f-4732-ac9c-358abb6de0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-d36859af-6b5f-473a-ace3-fe85b1e4fd60,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-f029ad29-3e50-4187-b8a0-6e0fc9993d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-294d68da-cd9a-4217-8259-288a6f2b2883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140564736-172.17.0.18-1595507232150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-bb78e386-2f76-4657-95d4-2d81c29b7817,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-96ecd6d8-27f0-40b3-ab08-1087d773456a,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-f41e6c6a-8d2a-4da0-a5c5-83d027f8eb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-a5712bca-f23f-4a48-9f69-ddab34b0d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-729621c1-3b6f-4732-ac9c-358abb6de0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-d36859af-6b5f-473a-ace3-fe85b1e4fd60,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-f029ad29-3e50-4187-b8a0-6e0fc9993d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-294d68da-cd9a-4217-8259-288a6f2b2883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24613010-172.17.0.18-1595507427587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-9bf24ef5-fb9d-4b4f-ae2a-9214632ce4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-17d54ebd-f770-43a2-b47c-600f32d8bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-eeb02566-c3fb-4f19-b3b2-8178355133db,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-a35cc646-40fb-4dbd-a983-f480ce42d22a,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-81c0ed2a-6f07-4aef-86f5-b1651e578fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-508f683e-c62b-408d-b04e-4933e7ea9aae,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-bea49060-66fa-4536-a464-a2dc3139a998,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-ba6e75fe-9d72-4ca7-b170-010b7ed819a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24613010-172.17.0.18-1595507427587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-9bf24ef5-fb9d-4b4f-ae2a-9214632ce4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-17d54ebd-f770-43a2-b47c-600f32d8bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-eeb02566-c3fb-4f19-b3b2-8178355133db,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-a35cc646-40fb-4dbd-a983-f480ce42d22a,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-81c0ed2a-6f07-4aef-86f5-b1651e578fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-508f683e-c62b-408d-b04e-4933e7ea9aae,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-bea49060-66fa-4536-a464-a2dc3139a998,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-ba6e75fe-9d72-4ca7-b170-010b7ed819a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4960
