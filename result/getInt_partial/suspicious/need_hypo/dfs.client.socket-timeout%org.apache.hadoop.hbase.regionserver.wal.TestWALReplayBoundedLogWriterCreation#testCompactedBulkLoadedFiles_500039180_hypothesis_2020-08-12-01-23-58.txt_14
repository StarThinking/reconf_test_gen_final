reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-0367a059-bdd1-4b7e-be3d-528754615f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-2d9c3fd1-ecf7-4bc1-bd97-3048a73ac682,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38217,DS-2d9c3fd1-ecf7-4bc1-bd97-3048a73ac682,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-0367a059-bdd1-4b7e-be3d-528754615f17,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-0367a059-bdd1-4b7e-be3d-528754615f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-2d9c3fd1-ecf7-4bc1-bd97-3048a73ac682,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38217,DS-2d9c3fd1-ecf7-4bc1-bd97-3048a73ac682,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-0367a059-bdd1-4b7e-be3d-528754615f17,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37463,DS-3594b96e-d7f2-486f-88dc-38198a1fcf43,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-350d969a-48b8-4faa-a4c3-ac57488f4d2b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-350d969a-48b8-4faa-a4c3-ac57488f4d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-3594b96e-d7f2-486f-88dc-38198a1fcf43,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34314,DS-2c391a60-ba6f-4787-aed6-821198679f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-3e40f2c4-f23c-48e4-85db-2a7c88754e52,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34314,DS-2c391a60-ba6f-4787-aed6-821198679f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-3e40f2c4-f23c-48e4-85db-2a7c88754e52,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43165,DS-5ad16bd7-d668-4811-9c28-9b8b1b1295af,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-a551f429-38b9-40ae-92a8-4d128d45d7cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43165,DS-5ad16bd7-d668-4811-9c28-9b8b1b1295af,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-a551f429-38b9-40ae-92a8-4d128d45d7cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37384,DS-3fd38f89-5ec2-43f7-be82-8193b9c0476b,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-5559849f-285c-45c5-b5c9-790ea6f7800b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37384,DS-3fd38f89-5ec2-43f7-be82-8193b9c0476b,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-5559849f-285c-45c5-b5c9-790ea6f7800b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-71d8eab0-96d1-4350-a5f8-8c9f0ad49962,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-8bc5cf71-09de-473a-a85c-1e468fcc3327,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-71d8eab0-96d1-4350-a5f8-8c9f0ad49962,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-8bc5cf71-09de-473a-a85c-1e468fcc3327,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-71d8eab0-96d1-4350-a5f8-8c9f0ad49962,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-8bc5cf71-09de-473a-a85c-1e468fcc3327,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-71d8eab0-96d1-4350-a5f8-8c9f0ad49962,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-8bc5cf71-09de-473a-a85c-1e468fcc3327,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-5985b1ee-5c0d-4f01-be03-01cd54f918fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-8ed5ce5c-9075-4c4b-8f44-815379ffddbe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-8ed5ce5c-9075-4c4b-8f44-815379ffddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-5985b1ee-5c0d-4f01-be03-01cd54f918fa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-5985b1ee-5c0d-4f01-be03-01cd54f918fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-8ed5ce5c-9075-4c4b-8f44-815379ffddbe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-8ed5ce5c-9075-4c4b-8f44-815379ffddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-5985b1ee-5c0d-4f01-be03-01cd54f918fa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36479,DS-1293e9d9-4f09-48d8-ab57-7a6a77ff8f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-8f776f3f-4aef-4854-a7ba-d24cd402e8de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36831,DS-8f776f3f-4aef-4854-a7ba-d24cd402e8de,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-1293e9d9-4f09-48d8-ab57-7a6a77ff8f95,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-152ee195-f119-4064-bd62-a6d0f9b16099,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-7a3e0fa3-7fd9-4764-8ea0-4b6777f9c576,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-152ee195-f119-4064-bd62-a6d0f9b16099,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-7a3e0fa3-7fd9-4764-8ea0-4b6777f9c576,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-152ee195-f119-4064-bd62-a6d0f9b16099,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-7a3e0fa3-7fd9-4764-8ea0-4b6777f9c576,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-152ee195-f119-4064-bd62-a6d0f9b16099,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-7a3e0fa3-7fd9-4764-8ea0-4b6777f9c576,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35453,DS-f09d63d2-70e2-4c42-bcc1-6128dca87908,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-4e6d4a21-a236-48a0-88be-00f9e6f150d2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35453,DS-f09d63d2-70e2-4c42-bcc1-6128dca87908,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-4e6d4a21-a236-48a0-88be-00f9e6f150d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 15
v1v1v2v2 failed with probability 0 out of 15
result: might be true error
Total execution time in seconds : 2881
