reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-3236233e-2d51-4577-9761-33a7c5e28627,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-2598b524-9c99-4ec1-84d5-57303444d81c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-3236233e-2d51-4577-9761-33a7c5e28627,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-2598b524-9c99-4ec1-84d5-57303444d81c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-3236233e-2d51-4577-9761-33a7c5e28627,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-2598b524-9c99-4ec1-84d5-57303444d81c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-3236233e-2d51-4577-9761-33a7c5e28627,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-2598b524-9c99-4ec1-84d5-57303444d81c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-df0849a9-509e-4c78-a5a5-8b558a1a3888,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-1f55981f-f36f-424e-8fca-5bd6d0f792b2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-df0849a9-509e-4c78-a5a5-8b558a1a3888,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-1f55981f-f36f-424e-8fca-5bd6d0f792b2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-df0849a9-509e-4c78-a5a5-8b558a1a3888,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-1f55981f-f36f-424e-8fca-5bd6d0f792b2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-df0849a9-509e-4c78-a5a5-8b558a1a3888,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-1f55981f-f36f-424e-8fca-5bd6d0f792b2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Append sequenceId=37, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=37, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-1ddf8d0f-27c8-4661-be6d-088442d1c801,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-7010d18b-e363-4d8d-a618-99b88761ff33,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-1ddf8d0f-27c8-4661-be6d-088442d1c801,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-7010d18b-e363-4d8d-a618-99b88761ff33,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-9864d141-81e8-46c5-8960-ec0ebff01cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-0e901311-008c-4582-94f5-63dacf1230cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-9864d141-81e8-46c5-8960-ec0ebff01cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-0e901311-008c-4582-94f5-63dacf1230cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-9864d141-81e8-46c5-8960-ec0ebff01cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-0e901311-008c-4582-94f5-63dacf1230cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-9864d141-81e8-46c5-8960-ec0ebff01cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-0e901311-008c-4582-94f5-63dacf1230cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45039,DS-44bfabea-2740-4665-b444-613419fe7c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-bfaac68b-d3e5-40c4-afc5-a22f67c92dfc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42915,DS-bfaac68b-d3e5-40c4-afc5-a22f67c92dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-44bfabea-2740-4665-b444-613419fe7c4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45039,DS-44bfabea-2740-4665-b444-613419fe7c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-bfaac68b-d3e5-40c4-afc5-a22f67c92dfc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42915,DS-bfaac68b-d3e5-40c4-afc5-a22f67c92dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-44bfabea-2740-4665-b444-613419fe7c4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34825,DS-a47c26ec-808f-432e-b0db-d536d1dd7356,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-24da1bd2-48be-45ac-801d-5f24775da21e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34825,DS-a47c26ec-808f-432e-b0db-d536d1dd7356,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-24da1bd2-48be-45ac-801d-5f24775da21e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34825,DS-a47c26ec-808f-432e-b0db-d536d1dd7356,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-24da1bd2-48be-45ac-801d-5f24775da21e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34825,DS-a47c26ec-808f-432e-b0db-d536d1dd7356,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-24da1bd2-48be-45ac-801d-5f24775da21e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-0340da8c-c5aa-4209-822e-d15815b331e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-5fa4191f-4a8f-4c51-93bc-712e011424c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40750,DS-5fa4191f-4a8f-4c51-93bc-712e011424c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-0340da8c-c5aa-4209-822e-d15815b331e6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-0340da8c-c5aa-4209-822e-d15815b331e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-5fa4191f-4a8f-4c51-93bc-712e011424c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40750,DS-5fa4191f-4a8f-4c51-93bc-712e011424c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-0340da8c-c5aa-4209-822e-d15815b331e6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-5494026f-6a01-45c0-ba9f-2d7158c5fdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-55b8ea3a-628c-46a8-ad07-ffd7cbeda7cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-5494026f-6a01-45c0-ba9f-2d7158c5fdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-55b8ea3a-628c-46a8-ad07-ffd7cbeda7cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-5494026f-6a01-45c0-ba9f-2d7158c5fdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-55b8ea3a-628c-46a8-ad07-ffd7cbeda7cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-5494026f-6a01-45c0-ba9f-2d7158c5fdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-55b8ea3a-628c-46a8-ad07-ffd7cbeda7cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 18
v1v1v2v2 failed with probability 0 out of 18
result: might be true error
Total execution time in seconds : 5416
