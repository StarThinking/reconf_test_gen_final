reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38701,DS-8624d3dd-5bfd-47d6-b852-c57d1d787b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-4f239b1e-5116-4fef-b556-aa54511faffd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-4f239b1e-5116-4fef-b556-aa54511faffd,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-8624d3dd-5bfd-47d6-b852-c57d1d787b4b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38701,DS-8624d3dd-5bfd-47d6-b852-c57d1d787b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-4f239b1e-5116-4fef-b556-aa54511faffd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-4f239b1e-5116-4fef-b556-aa54511faffd,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-8624d3dd-5bfd-47d6-b852-c57d1d787b4b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-4fe4e7b3-7fb6-4368-b225-51754b11c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-49f82e2f-f77e-4293-bff3-67f41bd75611,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-4fe4e7b3-7fb6-4368-b225-51754b11c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-49f82e2f-f77e-4293-bff3-67f41bd75611,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-4fe4e7b3-7fb6-4368-b225-51754b11c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-49f82e2f-f77e-4293-bff3-67f41bd75611,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-4fe4e7b3-7fb6-4368-b225-51754b11c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-49f82e2f-f77e-4293-bff3-67f41bd75611,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45981,DS-55a60ab7-d969-498e-9022-51517513c682,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-1a3ca3b4-e786-4c9f-a0c9-5b759e331bfe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45981,DS-55a60ab7-d969-498e-9022-51517513c682,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-1a3ca3b4-e786-4c9f-a0c9-5b759e331bfe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45981,DS-55a60ab7-d969-498e-9022-51517513c682,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-1a3ca3b4-e786-4c9f-a0c9-5b759e331bfe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45981,DS-55a60ab7-d969-498e-9022-51517513c682,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-1a3ca3b4-e786-4c9f-a0c9-5b759e331bfe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-9ce3e4e5-758e-4d8a-9f99-55a4abc617c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-ac80a933-2064-4bf6-ba6d-e2e944fde6f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-9ce3e4e5-758e-4d8a-9f99-55a4abc617c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-ac80a933-2064-4bf6-ba6d-e2e944fde6f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-9ce3e4e5-758e-4d8a-9f99-55a4abc617c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-ac80a933-2064-4bf6-ba6d-e2e944fde6f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-9ce3e4e5-758e-4d8a-9f99-55a4abc617c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-ac80a933-2064-4bf6-ba6d-e2e944fde6f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-612097e9-432e-4020-b67c-4b616040814c,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-8f91a608-6f28-449f-bcdf-e364efbb8183,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-612097e9-432e-4020-b67c-4b616040814c,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-8f91a608-6f28-449f-bcdf-e364efbb8183,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-612097e9-432e-4020-b67c-4b616040814c,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-8f91a608-6f28-449f-bcdf-e364efbb8183,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-612097e9-432e-4020-b67c-4b616040814c,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-8f91a608-6f28-449f-bcdf-e364efbb8183,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-e06d1e3e-3cb2-46ea-9032-fc9143741fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-f67a3706-303c-4ec4-855f-5a26a04a6770,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-e06d1e3e-3cb2-46ea-9032-fc9143741fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-f67a3706-303c-4ec4-855f-5a26a04a6770,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-e06d1e3e-3cb2-46ea-9032-fc9143741fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-f67a3706-303c-4ec4-855f-5a26a04a6770,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-e06d1e3e-3cb2-46ea-9032-fc9143741fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-f67a3706-303c-4ec4-855f-5a26a04a6770,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-ddeec906-d736-4408-916a-338b4d04f248,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-ddeec906-d736-4408-916a-338b4d04f248,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-ddeec906-d736-4408-916a-338b4d04f248,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-ddeec906-d736-4408-916a-338b4d04f248,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44588,DS-77d6880b-d8a8-4be5-bf10-16864147291f,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-121b8fa2-a334-4fc8-9338-6168bb164eab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34080,DS-121b8fa2-a334-4fc8-9338-6168bb164eab,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-77d6880b-d8a8-4be5-bf10-16864147291f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44588,DS-77d6880b-d8a8-4be5-bf10-16864147291f,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-121b8fa2-a334-4fc8-9338-6168bb164eab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34080,DS-121b8fa2-a334-4fc8-9338-6168bb164eab,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-77d6880b-d8a8-4be5-bf10-16864147291f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-53fd5227-ed59-421d-94ce-146c48d84ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-5e866820-b273-4665-b493-75647aec383a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-53fd5227-ed59-421d-94ce-146c48d84ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-5e866820-b273-4665-b493-75647aec383a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-53fd5227-ed59-421d-94ce-146c48d84ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-5e866820-b273-4665-b493-75647aec383a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-53fd5227-ed59-421d-94ce-146c48d84ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-5e866820-b273-4665-b493-75647aec383a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-d4955b31-101b-446d-bcae-fcb1e36af27b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-6163d0d6-66cb-4aa8-be4c-519a4e5cbeef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-d4955b31-101b-446d-bcae-fcb1e36af27b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-6163d0d6-66cb-4aa8-be4c-519a4e5cbeef,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-d4955b31-101b-446d-bcae-fcb1e36af27b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-6163d0d6-66cb-4aa8-be4c-519a4e5cbeef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-d4955b31-101b-446d-bcae-fcb1e36af27b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-6163d0d6-66cb-4aa8-be4c-519a4e5cbeef,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43346,DS-4cad827e-9a59-4453-9dad-6da2b2ea6e78,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-7d171072-cdb0-49d0-b320-b13584ef3036,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-7d171072-cdb0-49d0-b320-b13584ef3036,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-4cad827e-9a59-4453-9dad-6da2b2ea6e78,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43346,DS-4cad827e-9a59-4453-9dad-6da2b2ea6e78,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-7d171072-cdb0-49d0-b320-b13584ef3036,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-7d171072-cdb0-49d0-b320-b13584ef3036,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-4cad827e-9a59-4453-9dad-6da2b2ea6e78,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45355,DS-a0e9e040-c2e0-4994-8ba8-0d9c51a7d0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-45117075-c4b1-42aa-a7ab-0fcefe4cf766,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45355,DS-a0e9e040-c2e0-4994-8ba8-0d9c51a7d0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-45117075-c4b1-42aa-a7ab-0fcefe4cf766,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45355,DS-a0e9e040-c2e0-4994-8ba8-0d9c51a7d0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-45117075-c4b1-42aa-a7ab-0fcefe4cf766,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45355,DS-a0e9e040-c2e0-4994-8ba8-0d9c51a7d0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-45117075-c4b1-42aa-a7ab-0fcefe4cf766,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-55b6324e-8858-4111-8716-03570ad73288,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-1f8b33fa-dec2-434b-8102-efba75b5251a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-55b6324e-8858-4111-8716-03570ad73288,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-1f8b33fa-dec2-434b-8102-efba75b5251a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-55b6324e-8858-4111-8716-03570ad73288,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-1f8b33fa-dec2-434b-8102-efba75b5251a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-55b6324e-8858-4111-8716-03570ad73288,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-1f8b33fa-dec2-434b-8102-efba75b5251a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-9872ff9a-8f57-4ceb-baa4-5fbb8b8cac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-7802cca5-2eb9-407a-b6ab-6d192d964e5a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-9872ff9a-8f57-4ceb-baa4-5fbb8b8cac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-7802cca5-2eb9-407a-b6ab-6d192d964e5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-9872ff9a-8f57-4ceb-baa4-5fbb8b8cac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-7802cca5-2eb9-407a-b6ab-6d192d964e5a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-9872ff9a-8f57-4ceb-baa4-5fbb8b8cac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-7802cca5-2eb9-407a-b6ab-6d192d964e5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40397,DS-d29000b3-56f1-4e0e-be8b-45837e360610,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40397,DS-d29000b3-56f1-4e0e-be8b-45837e360610,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40397,DS-d29000b3-56f1-4e0e-be8b-45837e360610,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40397,DS-d29000b3-56f1-4e0e-be8b-45837e360610,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36921,DS-7a879f23-9873-495b-b597-20575da2f73d,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-7eb89aa3-4a04-41f2-a3fd-8554498d1688,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36921,DS-7a879f23-9873-495b-b597-20575da2f73d,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-7eb89aa3-4a04-41f2-a3fd-8554498d1688,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36921,DS-7a879f23-9873-495b-b597-20575da2f73d,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-7eb89aa3-4a04-41f2-a3fd-8554498d1688,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36921,DS-7a879f23-9873-495b-b597-20575da2f73d,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-7eb89aa3-4a04-41f2-a3fd-8554498d1688,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testNameConflictWhenSplit0
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-501e9e67-42cf-4641-be4a-a752d95c6b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-c7ec794b-125a-4af0-9978-15dca8da5ad6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-c7ec794b-125a-4af0-9978-15dca8da5ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-501e9e67-42cf-4641-be4a-a752d95c6b5c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-501e9e67-42cf-4641-be4a-a752d95c6b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-c7ec794b-125a-4af0-9978-15dca8da5ad6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-c7ec794b-125a-4af0-9978-15dca8da5ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-501e9e67-42cf-4641-be4a-a752d95c6b5c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)


v1v2 failed with probability 23 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: might be true error
Total execution time in seconds : 12129
