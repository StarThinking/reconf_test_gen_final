reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-c44e3c38-5c53-4baa-8ae3-10cf48e1c169,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-98741ec1-06f4-45cd-96dc-0793e04d007b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42318,DS-98741ec1-06f4-45cd-96dc-0793e04d007b,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-c44e3c38-5c53-4baa-8ae3-10cf48e1c169,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-c44e3c38-5c53-4baa-8ae3-10cf48e1c169,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-98741ec1-06f4-45cd-96dc-0793e04d007b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42318,DS-98741ec1-06f4-45cd-96dc-0793e04d007b,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-c44e3c38-5c53-4baa-8ae3-10cf48e1c169,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-59202884-e84f-4866-8a31-7a8e5a068244,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-72dffd75-d66c-47b7-a500-2cd10ed583c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-59202884-e84f-4866-8a31-7a8e5a068244,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-72dffd75-d66c-47b7-a500-2cd10ed583c1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-59202884-e84f-4866-8a31-7a8e5a068244,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-72dffd75-d66c-47b7-a500-2cd10ed583c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-59202884-e84f-4866-8a31-7a8e5a068244,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-72dffd75-d66c-47b7-a500-2cd10ed583c1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-81bc904c-4c5a-460e-8d85-9b5b05391624,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-6eb9fbaf-9904-4578-94c1-428a25ea3b7b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-81bc904c-4c5a-460e-8d85-9b5b05391624,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-6eb9fbaf-9904-4578-94c1-428a25ea3b7b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-81bc904c-4c5a-460e-8d85-9b5b05391624,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-6eb9fbaf-9904-4578-94c1-428a25ea3b7b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-81bc904c-4c5a-460e-8d85-9b5b05391624,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-6eb9fbaf-9904-4578-94c1-428a25ea3b7b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-a6ce705b-f6c0-45ca-9251-db49392146dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-4125e9f8-d2e8-42ee-963f-c2f215c5bdcd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-a6ce705b-f6c0-45ca-9251-db49392146dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-4125e9f8-d2e8-42ee-963f-c2f215c5bdcd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-a6ce705b-f6c0-45ca-9251-db49392146dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-4125e9f8-d2e8-42ee-963f-c2f215c5bdcd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-a6ce705b-f6c0-45ca-9251-db49392146dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-4125e9f8-d2e8-42ee-963f-c2f215c5bdcd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-06875974-5a56-40ac-bc1f-8ed18cba8839,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-95a27c73-e82e-4cf7-b6b4-5bd44b80daee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44753,DS-95a27c73-e82e-4cf7-b6b4-5bd44b80daee,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-06875974-5a56-40ac-bc1f-8ed18cba8839,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-06875974-5a56-40ac-bc1f-8ed18cba8839,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-95a27c73-e82e-4cf7-b6b4-5bd44b80daee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44753,DS-95a27c73-e82e-4cf7-b6b4-5bd44b80daee,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-06875974-5a56-40ac-bc1f-8ed18cba8839,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37327,DS-7f6b0307-c31f-4952-9cd7-4caa90130776,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-b033410d-95aa-439b-b8ce-4e471b3fc14b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37327,DS-7f6b0307-c31f-4952-9cd7-4caa90130776,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-b033410d-95aa-439b-b8ce-4e471b3fc14b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37327,DS-7f6b0307-c31f-4952-9cd7-4caa90130776,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-b033410d-95aa-439b-b8ce-4e471b3fc14b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37327,DS-7f6b0307-c31f-4952-9cd7-4caa90130776,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-b033410d-95aa-439b-b8ce-4e471b3fc14b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40299,DS-69a4fdd8-984b-4b42-a203-8cbe8d91b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-30491e28-3822-48cd-af4f-cbf012bfec9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40299,DS-69a4fdd8-984b-4b42-a203-8cbe8d91b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-30491e28-3822-48cd-af4f-cbf012bfec9f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40299,DS-69a4fdd8-984b-4b42-a203-8cbe8d91b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-30491e28-3822-48cd-af4f-cbf012bfec9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40299,DS-69a4fdd8-984b-4b42-a203-8cbe8d91b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-30491e28-3822-48cd-af4f-cbf012bfec9f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-e3536cd1-a576-42c4-935d-1455c1f659ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-9f983b7b-7ee5-4cc6-9463-605cf5c8dcc9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-e3536cd1-a576-42c4-935d-1455c1f659ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-9f983b7b-7ee5-4cc6-9463-605cf5c8dcc9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-e3536cd1-a576-42c4-935d-1455c1f659ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-9f983b7b-7ee5-4cc6-9463-605cf5c8dcc9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-e3536cd1-a576-42c4-935d-1455c1f659ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-9f983b7b-7ee5-4cc6-9463-605cf5c8dcc9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40260,DS-29e36e37-e333-4b01-91b6-72862f673b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-0807fd41-11d2-4008-bf77-1c2a6bceba36,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46196,DS-0807fd41-11d2-4008-bf77-1c2a6bceba36,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-29e36e37-e333-4b01-91b6-72862f673b0f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40260,DS-29e36e37-e333-4b01-91b6-72862f673b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-0807fd41-11d2-4008-bf77-1c2a6bceba36,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46196,DS-0807fd41-11d2-4008-bf77-1c2a6bceba36,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-29e36e37-e333-4b01-91b6-72862f673b0f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33318,DS-37cc7833-4316-429a-ada4-49695c0454be,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-746d87c3-db53-4866-8d70-5b649ad2f71d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45196,DS-746d87c3-db53-4866-8d70-5b649ad2f71d,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-37cc7833-4316-429a-ada4-49695c0454be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33318,DS-37cc7833-4316-429a-ada4-49695c0454be,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-746d87c3-db53-4866-8d70-5b649ad2f71d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45196,DS-746d87c3-db53-4866-8d70-5b649ad2f71d,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-37cc7833-4316-429a-ada4-49695c0454be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 24
v1v1v2v2 failed with probability 0 out of 24
result: might be true error
Total execution time in seconds : 6433
