reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37510,DS-0063590d-638a-4454-904e-0cc0543d713e,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-35235e4b-708d-4b88-9f19-702ab47c4972,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-35235e4b-708d-4b88-9f19-702ab47c4972,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-0063590d-638a-4454-904e-0cc0543d713e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37510,DS-0063590d-638a-4454-904e-0cc0543d713e,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-35235e4b-708d-4b88-9f19-702ab47c4972,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-35235e4b-708d-4b88-9f19-702ab47c4972,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-0063590d-638a-4454-904e-0cc0543d713e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-2892b2d7-2178-4917-9cac-1342f3e69bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-b6b0bd95-8717-40cb-bdc5-03e38db7fc3d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-2892b2d7-2178-4917-9cac-1342f3e69bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-b6b0bd95-8717-40cb-bdc5-03e38db7fc3d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-2892b2d7-2178-4917-9cac-1342f3e69bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-b6b0bd95-8717-40cb-bdc5-03e38db7fc3d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-2892b2d7-2178-4917-9cac-1342f3e69bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-b6b0bd95-8717-40cb-bdc5-03e38db7fc3d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-591a4f83-c4ed-4bca-8385-d9fe1ec7e524,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-ce44127c-b99a-444b-b9fd-95bd4530ae26,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-591a4f83-c4ed-4bca-8385-d9fe1ec7e524,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-ce44127c-b99a-444b-b9fd-95bd4530ae26,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-591a4f83-c4ed-4bca-8385-d9fe1ec7e524,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-ce44127c-b99a-444b-b9fd-95bd4530ae26,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-591a4f83-c4ed-4bca-8385-d9fe1ec7e524,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-ce44127c-b99a-444b-b9fd-95bd4530ae26,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-08ae7bfa-38eb-4489-a25c-52df7ef6f9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-0f7226bb-354b-4c55-8726-c119d1017474,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43322,DS-0f7226bb-354b-4c55-8726-c119d1017474,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-08ae7bfa-38eb-4489-a25c-52df7ef6f9d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-08ae7bfa-38eb-4489-a25c-52df7ef6f9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-0f7226bb-354b-4c55-8726-c119d1017474,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43322,DS-0f7226bb-354b-4c55-8726-c119d1017474,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-08ae7bfa-38eb-4489-a25c-52df7ef6f9d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-58e09ee7-8452-4e30-8153-3f59f78702f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-5e844e96-db09-48b4-8b2f-25010d2cedb0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-58e09ee7-8452-4e30-8153-3f59f78702f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-5e844e96-db09-48b4-8b2f-25010d2cedb0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-58e09ee7-8452-4e30-8153-3f59f78702f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-5e844e96-db09-48b4-8b2f-25010d2cedb0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-58e09ee7-8452-4e30-8153-3f59f78702f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-5e844e96-db09-48b4-8b2f-25010d2cedb0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-c73f8918-d2d9-41f2-9ef1-bdefd2961a49,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-ef421c86-d6af-46fe-872b-3b10279b0598,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-ef421c86-d6af-46fe-872b-3b10279b0598,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-c73f8918-d2d9-41f2-9ef1-bdefd2961a49,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-c73f8918-d2d9-41f2-9ef1-bdefd2961a49,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-ef421c86-d6af-46fe-872b-3b10279b0598,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-ef421c86-d6af-46fe-872b-3b10279b0598,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-c73f8918-d2d9-41f2-9ef1-bdefd2961a49,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44457,DS-f70ca431-2862-4ee2-a3fc-f3d5af611e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-0ea2ca86-9e5c-4bd1-8856-57cca432b2e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44457,DS-f70ca431-2862-4ee2-a3fc-f3d5af611e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-0ea2ca86-9e5c-4bd1-8856-57cca432b2e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44457,DS-f70ca431-2862-4ee2-a3fc-f3d5af611e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-0ea2ca86-9e5c-4bd1-8856-57cca432b2e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44457,DS-f70ca431-2862-4ee2-a3fc-f3d5af611e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-0ea2ca86-9e5c-4bd1-8856-57cca432b2e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44392,DS-7d7d9591-26bc-493a-9908-e14f00607189,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-c8aeabf7-ffe5-428d-a134-9ec142677bd4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44392,DS-7d7d9591-26bc-493a-9908-e14f00607189,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-c8aeabf7-ffe5-428d-a134-9ec142677bd4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44392,DS-7d7d9591-26bc-493a-9908-e14f00607189,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-c8aeabf7-ffe5-428d-a134-9ec142677bd4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44392,DS-7d7d9591-26bc-493a-9908-e14f00607189,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-c8aeabf7-ffe5-428d-a134-9ec142677bd4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43582,DS-de9bb7a1-8f65-4832-b219-25bc2d153953,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-d990b037-24a2-4ea5-b77c-19931f539aef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43582,DS-de9bb7a1-8f65-4832-b219-25bc2d153953,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-d990b037-24a2-4ea5-b77c-19931f539aef,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43582,DS-de9bb7a1-8f65-4832-b219-25bc2d153953,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-d990b037-24a2-4ea5-b77c-19931f539aef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43582,DS-de9bb7a1-8f65-4832-b219-25bc2d153953,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-d990b037-24a2-4ea5-b77c-19931f539aef,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33646,DS-ba5d85c8-8ba1-4255-bfc8-6fb2376643a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-5ed1e352-3503-4aaf-b213-d69eb98267f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33646,DS-ba5d85c8-8ba1-4255-bfc8-6fb2376643a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-5ed1e352-3503-4aaf-b213-d69eb98267f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33646,DS-ba5d85c8-8ba1-4255-bfc8-6fb2376643a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-5ed1e352-3503-4aaf-b213-d69eb98267f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33646,DS-ba5d85c8-8ba1-4255-bfc8-6fb2376643a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-5ed1e352-3503-4aaf-b213-d69eb98267f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2154
