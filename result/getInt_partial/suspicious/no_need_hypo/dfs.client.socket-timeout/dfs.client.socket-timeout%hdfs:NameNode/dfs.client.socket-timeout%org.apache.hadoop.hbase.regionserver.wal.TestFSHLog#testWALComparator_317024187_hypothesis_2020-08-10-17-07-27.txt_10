reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39141,DS-1a053400-8174-4129-ae82-f102ff924b07,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-89bc9d5b-2706-444c-8959-328ef18a243b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-89bc9d5b-2706-444c-8959-328ef18a243b,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-1a053400-8174-4129-ae82-f102ff924b07,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39141,DS-1a053400-8174-4129-ae82-f102ff924b07,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-89bc9d5b-2706-444c-8959-328ef18a243b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-89bc9d5b-2706-444c-8959-328ef18a243b,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-1a053400-8174-4129-ae82-f102ff924b07,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35161,DS-1de92259-bbf3-44f9-b827-a37886c6c97e,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-9b690ba7-b91c-488b-b8a9-8776fb0b0333,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35161,DS-1de92259-bbf3-44f9-b827-a37886c6c97e,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-9b690ba7-b91c-488b-b8a9-8776fb0b0333,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35161,DS-1de92259-bbf3-44f9-b827-a37886c6c97e,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-9b690ba7-b91c-488b-b8a9-8776fb0b0333,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35161,DS-1de92259-bbf3-44f9-b827-a37886c6c97e,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-9b690ba7-b91c-488b-b8a9-8776fb0b0333,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34468,DS-2143507a-1346-43e4-9fc7-ff7d216286a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-beeee092-56bd-4919-a8f8-fd96cfa56ee7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34468,DS-2143507a-1346-43e4-9fc7-ff7d216286a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-beeee092-56bd-4919-a8f8-fd96cfa56ee7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34468,DS-2143507a-1346-43e4-9fc7-ff7d216286a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-beeee092-56bd-4919-a8f8-fd96cfa56ee7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34468,DS-2143507a-1346-43e4-9fc7-ff7d216286a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-beeee092-56bd-4919-a8f8-fd96cfa56ee7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41898,DS-7d4fc74f-ba10-4cdf-b8a1-ae9cdb61c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-105067ec-4fe8-42e8-abc5-67bba13f7921,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41898,DS-7d4fc74f-ba10-4cdf-b8a1-ae9cdb61c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-105067ec-4fe8-42e8-abc5-67bba13f7921,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41898,DS-7d4fc74f-ba10-4cdf-b8a1-ae9cdb61c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-105067ec-4fe8-42e8-abc5-67bba13f7921,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41898,DS-7d4fc74f-ba10-4cdf-b8a1-ae9cdb61c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-105067ec-4fe8-42e8-abc5-67bba13f7921,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-c5305145-dd94-4711-84f1-45f3215bf4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-0b13b167-4558-4021-8b25-59b4f52305db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-c5305145-dd94-4711-84f1-45f3215bf4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-0b13b167-4558-4021-8b25-59b4f52305db,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-c5305145-dd94-4711-84f1-45f3215bf4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-0b13b167-4558-4021-8b25-59b4f52305db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-c5305145-dd94-4711-84f1-45f3215bf4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-0b13b167-4558-4021-8b25-59b4f52305db,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34617,DS-deef36e3-ad40-4175-9bac-282fd9492038,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-95a946a1-73b9-4671-b32e-57b38b8c0951,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-95a946a1-73b9-4671-b32e-57b38b8c0951,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-deef36e3-ad40-4175-9bac-282fd9492038,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34617,DS-deef36e3-ad40-4175-9bac-282fd9492038,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-95a946a1-73b9-4671-b32e-57b38b8c0951,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-95a946a1-73b9-4671-b32e-57b38b8c0951,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-deef36e3-ad40-4175-9bac-282fd9492038,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33631,DS-a98c7afb-25c5-4d20-95f2-a6568adf8ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-2223ffc4-d220-4b83-abbe-ba01d2eed5e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33631,DS-a98c7afb-25c5-4d20-95f2-a6568adf8ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-2223ffc4-d220-4b83-abbe-ba01d2eed5e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33631,DS-a98c7afb-25c5-4d20-95f2-a6568adf8ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-2223ffc4-d220-4b83-abbe-ba01d2eed5e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33631,DS-a98c7afb-25c5-4d20-95f2-a6568adf8ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-2223ffc4-d220-4b83-abbe-ba01d2eed5e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32770,DS-d41c55c4-6a84-48ad-afba-0411919f0c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-8fdf9dac-8378-4eb1-a12a-16da454ba459,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32770,DS-d41c55c4-6a84-48ad-afba-0411919f0c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-8fdf9dac-8378-4eb1-a12a-16da454ba459,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32770,DS-d41c55c4-6a84-48ad-afba-0411919f0c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-8fdf9dac-8378-4eb1-a12a-16da454ba459,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32770,DS-d41c55c4-6a84-48ad-afba-0411919f0c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-8fdf9dac-8378-4eb1-a12a-16da454ba459,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41436,DS-95c1b29e-fca3-4dcd-9430-4783eb01d604,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b8bdddf1-1251-43e9-a0d3-f3733bda553b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44160,DS-b8bdddf1-1251-43e9-a0d3-f3733bda553b,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-95c1b29e-fca3-4dcd-9430-4783eb01d604,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41436,DS-95c1b29e-fca3-4dcd-9430-4783eb01d604,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b8bdddf1-1251-43e9-a0d3-f3733bda553b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44160,DS-b8bdddf1-1251-43e9-a0d3-f3733bda553b,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-95c1b29e-fca3-4dcd-9430-4783eb01d604,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-c774e7e8-7693-4aa5-8cbf-55ae6670cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-96dcc9ac-000b-409b-8967-92a5390fb915,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-c774e7e8-7693-4aa5-8cbf-55ae6670cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-96dcc9ac-000b-409b-8967-92a5390fb915,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-c774e7e8-7693-4aa5-8cbf-55ae6670cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-96dcc9ac-000b-409b-8967-92a5390fb915,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-c774e7e8-7693-4aa5-8cbf-55ae6670cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-96dcc9ac-000b-409b-8967-92a5390fb915,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-68347a16-a664-4163-81d2-818336dc3c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-17defd3a-241b-4ebf-adc3-6c5944af20f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-68347a16-a664-4163-81d2-818336dc3c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-17defd3a-241b-4ebf-adc3-6c5944af20f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-68347a16-a664-4163-81d2-818336dc3c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-17defd3a-241b-4ebf-adc3-6c5944af20f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-68347a16-a664-4163-81d2-818336dc3c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-17defd3a-241b-4ebf-adc3-6c5944af20f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42895,DS-00d18bf9-14b1-46f1-9c82-fdd97fa072ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-fa995ab6-98d9-4f2e-8b28-83d1f3226fa5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42895,DS-00d18bf9-14b1-46f1-9c82-fdd97fa072ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-fa995ab6-98d9-4f2e-8b28-83d1f3226fa5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42895,DS-00d18bf9-14b1-46f1-9c82-fdd97fa072ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-fa995ab6-98d9-4f2e-8b28-83d1f3226fa5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42895,DS-00d18bf9-14b1-46f1-9c82-fdd97fa072ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-fa995ab6-98d9-4f2e-8b28-83d1f3226fa5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-83f3b2bd-4e7e-4968-8e04-6b4b94d59173,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-61717b8d-c19e-430c-97c6-4bc9ba40b8b6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-61717b8d-c19e-430c-97c6-4bc9ba40b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-83f3b2bd-4e7e-4968-8e04-6b4b94d59173,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-83f3b2bd-4e7e-4968-8e04-6b4b94d59173,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-61717b8d-c19e-430c-97c6-4bc9ba40b8b6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-61717b8d-c19e-430c-97c6-4bc9ba40b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-83f3b2bd-4e7e-4968-8e04-6b4b94d59173,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-b667fb9e-24aa-48b3-8207-c37c8d5dc360,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-bc079c1a-59f8-4cea-8aaf-002efd443707,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-b667fb9e-24aa-48b3-8207-c37c8d5dc360,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-bc079c1a-59f8-4cea-8aaf-002efd443707,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-b667fb9e-24aa-48b3-8207-c37c8d5dc360,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-bc079c1a-59f8-4cea-8aaf-002efd443707,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-b667fb9e-24aa-48b3-8207-c37c8d5dc360,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-bc079c1a-59f8-4cea-8aaf-002efd443707,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33924,DS-4353102a-5483-4659-9b6a-cdf4073357f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-09e34413-b2e7-4038-b15b-a4e6b71d2cf7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33924,DS-4353102a-5483-4659-9b6a-cdf4073357f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-09e34413-b2e7-4038-b15b-a4e6b71d2cf7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33924,DS-4353102a-5483-4659-9b6a-cdf4073357f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-09e34413-b2e7-4038-b15b-a4e6b71d2cf7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33924,DS-4353102a-5483-4659-9b6a-cdf4073357f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-09e34413-b2e7-4038-b15b-a4e6b71d2cf7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38031,DS-a5f6c386-4cca-4129-97f5-8bd0f513a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-24423d46-d28a-4735-9539-66d48483a89c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38031,DS-a5f6c386-4cca-4129-97f5-8bd0f513a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-24423d46-d28a-4735-9539-66d48483a89c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38031,DS-a5f6c386-4cca-4129-97f5-8bd0f513a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-24423d46-d28a-4735-9539-66d48483a89c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38031,DS-a5f6c386-4cca-4129-97f5-8bd0f513a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-24423d46-d28a-4735-9539-66d48483a89c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-9383aee8-9bbe-4057-90a3-091bd271eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-2d36f8dd-536f-4e2b-bcc8-e3eb3ef7ce63,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-9383aee8-9bbe-4057-90a3-091bd271eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-2d36f8dd-536f-4e2b-bcc8-e3eb3ef7ce63,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-9383aee8-9bbe-4057-90a3-091bd271eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-2d36f8dd-536f-4e2b-bcc8-e3eb3ef7ce63,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-9383aee8-9bbe-4057-90a3-091bd271eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-2d36f8dd-536f-4e2b-bcc8-e3eb3ef7ce63,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44200,DS-2c88632a-ebe0-4566-b3eb-b547763d0ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-52e5f77e-8eb6-4551-8052-954a84ee7f27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45497,DS-52e5f77e-8eb6-4551-8052-954a84ee7f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-2c88632a-ebe0-4566-b3eb-b547763d0ef7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44200,DS-2c88632a-ebe0-4566-b3eb-b547763d0ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-52e5f77e-8eb6-4551-8052-954a84ee7f27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45497,DS-52e5f77e-8eb6-4551-8052-954a84ee7f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-2c88632a-ebe0-4566-b3eb-b547763d0ef7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39845,DS-b26a5d54-73f3-49b7-b317-e3481b5ed0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-c0de4cea-c4ba-4b40-880f-a643866a06b8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-c0de4cea-c4ba-4b40-880f-a643866a06b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-b26a5d54-73f3-49b7-b317-e3481b5ed0cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39845,DS-b26a5d54-73f3-49b7-b317-e3481b5ed0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-c0de4cea-c4ba-4b40-880f-a643866a06b8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-c0de4cea-c4ba-4b40-880f-a643866a06b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-b26a5d54-73f3-49b7-b317-e3481b5ed0cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-8ee3770e-97fb-4b8d-911b-da35faf39985,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-e48487f8-cd9b-429a-95e4-06c79e773d8e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37751,DS-e48487f8-cd9b-429a-95e4-06c79e773d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-8ee3770e-97fb-4b8d-911b-da35faf39985,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-8ee3770e-97fb-4b8d-911b-da35faf39985,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-e48487f8-cd9b-429a-95e4-06c79e773d8e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37751,DS-e48487f8-cd9b-429a-95e4-06c79e773d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-8ee3770e-97fb-4b8d-911b-da35faf39985,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37149,DS-bc4f8c66-fd59-4366-9207-7bc305657967,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-6e3f9c53-f5a6-4d60-adee-2202747d71da,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37149,DS-bc4f8c66-fd59-4366-9207-7bc305657967,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-6e3f9c53-f5a6-4d60-adee-2202747d71da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37149,DS-bc4f8c66-fd59-4366-9207-7bc305657967,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-6e3f9c53-f5a6-4d60-adee-2202747d71da,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37149,DS-bc4f8c66-fd59-4366-9207-7bc305657967,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-6e3f9c53-f5a6-4d60-adee-2202747d71da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35176,DS-e21370d3-8fac-4a56-9382-f3fd93e8abae,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-cd1b32c9-e865-4410-b01e-7160cce05eae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35176,DS-e21370d3-8fac-4a56-9382-f3fd93e8abae,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-cd1b32c9-e865-4410-b01e-7160cce05eae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35176,DS-e21370d3-8fac-4a56-9382-f3fd93e8abae,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-cd1b32c9-e865-4410-b01e-7160cce05eae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35176,DS-e21370d3-8fac-4a56-9382-f3fd93e8abae,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-cd1b32c9-e865-4410-b01e-7160cce05eae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-144d2fe2-bc85-457a-aade-4b6f7484bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-f09a88a6-8202-4d33-81af-3d213177ca44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-144d2fe2-bc85-457a-aade-4b6f7484bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-f09a88a6-8202-4d33-81af-3d213177ca44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-144d2fe2-bc85-457a-aade-4b6f7484bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-f09a88a6-8202-4d33-81af-3d213177ca44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-144d2fe2-bc85-457a-aade-4b6f7484bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-f09a88a6-8202-4d33-81af-3d213177ca44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38717,DS-ca58d0bd-27e1-463a-89da-87e36f2719a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-311cadcc-68de-4029-a4dc-2ff2274886ef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-311cadcc-68de-4029-a4dc-2ff2274886ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-ca58d0bd-27e1-463a-89da-87e36f2719a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38717,DS-ca58d0bd-27e1-463a-89da-87e36f2719a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-311cadcc-68de-4029-a4dc-2ff2274886ef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-311cadcc-68de-4029-a4dc-2ff2274886ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-ca58d0bd-27e1-463a-89da-87e36f2719a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-af4acb4e-4f0d-42b3-b80a-003f9bf39454,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-98e41b5c-dff4-402a-aad8-3c5529cbf5ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-af4acb4e-4f0d-42b3-b80a-003f9bf39454,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-98e41b5c-dff4-402a-aad8-3c5529cbf5ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-af4acb4e-4f0d-42b3-b80a-003f9bf39454,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-98e41b5c-dff4-402a-aad8-3c5529cbf5ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-af4acb4e-4f0d-42b3-b80a-003f9bf39454,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-98e41b5c-dff4-402a-aad8-3c5529cbf5ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40316,DS-3bb7e386-8c8a-441b-9919-7129d504eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-f08498da-6f8a-46e4-abe6-21e388792105,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-f08498da-6f8a-46e4-abe6-21e388792105,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-3bb7e386-8c8a-441b-9919-7129d504eb2c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40316,DS-3bb7e386-8c8a-441b-9919-7129d504eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-f08498da-6f8a-46e4-abe6-21e388792105,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-f08498da-6f8a-46e4-abe6-21e388792105,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-3bb7e386-8c8a-441b-9919-7129d504eb2c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-5de279ae-33c4-4a94-8aa6-3e6f03368cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-58900b2e-1558-4ce4-823f-9d30bae01de2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-5de279ae-33c4-4a94-8aa6-3e6f03368cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-58900b2e-1558-4ce4-823f-9d30bae01de2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-5de279ae-33c4-4a94-8aa6-3e6f03368cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-58900b2e-1558-4ce4-823f-9d30bae01de2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-5de279ae-33c4-4a94-8aa6-3e6f03368cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-58900b2e-1558-4ce4-823f-9d30bae01de2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38259,DS-956bf37a-ca5c-40a8-942e-ed0a3525b335,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-ea1fa7f0-6377-4734-a108-b0742ddc06be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38259,DS-956bf37a-ca5c-40a8-942e-ed0a3525b335,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-ea1fa7f0-6377-4734-a108-b0742ddc06be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38259,DS-956bf37a-ca5c-40a8-942e-ed0a3525b335,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-ea1fa7f0-6377-4734-a108-b0742ddc06be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38259,DS-956bf37a-ca5c-40a8-942e-ed0a3525b335,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-ea1fa7f0-6377-4734-a108-b0742ddc06be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-0e1d05a4-9888-4d1a-8136-d92df1dd76bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-504b8d23-325c-4895-86f3-dab7bf2d45bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-0e1d05a4-9888-4d1a-8136-d92df1dd76bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-504b8d23-325c-4895-86f3-dab7bf2d45bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-0e1d05a4-9888-4d1a-8136-d92df1dd76bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-504b8d23-325c-4895-86f3-dab7bf2d45bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-0e1d05a4-9888-4d1a-8136-d92df1dd76bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-504b8d23-325c-4895-86f3-dab7bf2d45bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-55e9e70f-cc40-4aa7-87f5-7ffd24856d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-3c3a6b5d-7cf3-4af1-a3df-db9f140d40d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-55e9e70f-cc40-4aa7-87f5-7ffd24856d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-3c3a6b5d-7cf3-4af1-a3df-db9f140d40d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-55e9e70f-cc40-4aa7-87f5-7ffd24856d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-3c3a6b5d-7cf3-4af1-a3df-db9f140d40d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-55e9e70f-cc40-4aa7-87f5-7ffd24856d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-3c3a6b5d-7cf3-4af1-a3df-db9f140d40d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46536,DS-967fca62-ffb5-411c-8c74-8191b6b568d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-76c513ce-81c1-458d-b06b-00e306e1824e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46536,DS-967fca62-ffb5-411c-8c74-8191b6b568d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-76c513ce-81c1-458d-b06b-00e306e1824e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46536,DS-967fca62-ffb5-411c-8c74-8191b6b568d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-76c513ce-81c1-458d-b06b-00e306e1824e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46536,DS-967fca62-ffb5-411c-8c74-8191b6b568d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-76c513ce-81c1-458d-b06b-00e306e1824e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42402,DS-196fc622-8519-421d-bfc6-2895278a5114,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-efbf471c-a6ba-4f85-bbce-2ca6e7a88154,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-efbf471c-a6ba-4f85-bbce-2ca6e7a88154,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-196fc622-8519-421d-bfc6-2895278a5114,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42402,DS-196fc622-8519-421d-bfc6-2895278a5114,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-efbf471c-a6ba-4f85-bbce-2ca6e7a88154,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-efbf471c-a6ba-4f85-bbce-2ca6e7a88154,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-196fc622-8519-421d-bfc6-2895278a5114,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41669,DS-7728e499-81d6-4e1f-8b5a-365cb3e7ea9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-c76f5644-5608-40f8-8396-2812ef2d8bcc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-c76f5644-5608-40f8-8396-2812ef2d8bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-7728e499-81d6-4e1f-8b5a-365cb3e7ea9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41669,DS-7728e499-81d6-4e1f-8b5a-365cb3e7ea9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-c76f5644-5608-40f8-8396-2812ef2d8bcc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-c76f5644-5608-40f8-8396-2812ef2d8bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-7728e499-81d6-4e1f-8b5a-365cb3e7ea9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37355,DS-cf31a5fd-492f-461c-a788-52d1ca0c02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-0a8acb7e-d804-4838-ae45-d24401b46c2f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37355,DS-cf31a5fd-492f-461c-a788-52d1ca0c02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-0a8acb7e-d804-4838-ae45-d24401b46c2f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37355,DS-cf31a5fd-492f-461c-a788-52d1ca0c02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-0a8acb7e-d804-4838-ae45-d24401b46c2f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37355,DS-cf31a5fd-492f-461c-a788-52d1ca0c02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-0a8acb7e-d804-4838-ae45-d24401b46c2f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-11de552c-a279-47dc-850d-0dca031a6ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-bf9038dc-9436-4252-8250-7e04656cf98c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-11de552c-a279-47dc-850d-0dca031a6ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-bf9038dc-9436-4252-8250-7e04656cf98c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-11de552c-a279-47dc-850d-0dca031a6ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-bf9038dc-9436-4252-8250-7e04656cf98c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-11de552c-a279-47dc-850d-0dca031a6ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-bf9038dc-9436-4252-8250-7e04656cf98c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-26fe79dc-bfdd-48de-aa1d-324f1027adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-ef0619ec-a2cf-4039-9dcd-5810cf1fb363,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-26fe79dc-bfdd-48de-aa1d-324f1027adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-ef0619ec-a2cf-4039-9dcd-5810cf1fb363,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-26fe79dc-bfdd-48de-aa1d-324f1027adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-ef0619ec-a2cf-4039-9dcd-5810cf1fb363,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-26fe79dc-bfdd-48de-aa1d-324f1027adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-ef0619ec-a2cf-4039-9dcd-5810cf1fb363,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-d15ccd43-b176-4975-a623-953d0a613182,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-592a4889-8332-445f-8701-7036b93f17d0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-d15ccd43-b176-4975-a623-953d0a613182,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-592a4889-8332-445f-8701-7036b93f17d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-d15ccd43-b176-4975-a623-953d0a613182,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-592a4889-8332-445f-8701-7036b93f17d0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-d15ccd43-b176-4975-a623-953d0a613182,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-592a4889-8332-445f-8701-7036b93f17d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-d5d1040c-3dbd-4162-82ba-21fd01d8df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-9c7d0cbb-da63-4567-bf8b-68717e912bd2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-d5d1040c-3dbd-4162-82ba-21fd01d8df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-9c7d0cbb-da63-4567-bf8b-68717e912bd2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-d5d1040c-3dbd-4162-82ba-21fd01d8df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-9c7d0cbb-da63-4567-bf8b-68717e912bd2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-d5d1040c-3dbd-4162-82ba-21fd01d8df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-9c7d0cbb-da63-4567-bf8b-68717e912bd2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44895,DS-8c52e848-1d16-4636-a9b7-feaadd612985,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-384935ee-b459-4c97-863b-00f963f71d27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44895,DS-8c52e848-1d16-4636-a9b7-feaadd612985,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-384935ee-b459-4c97-863b-00f963f71d27,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44895,DS-8c52e848-1d16-4636-a9b7-feaadd612985,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-384935ee-b459-4c97-863b-00f963f71d27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44895,DS-8c52e848-1d16-4636-a9b7-feaadd612985,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-384935ee-b459-4c97-863b-00f963f71d27,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45643,DS-adbc65b5-9af0-4534-8c5e-e8f52ff82bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-96d03034-34db-4e40-ae44-0b6366ab96e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45643,DS-adbc65b5-9af0-4534-8c5e-e8f52ff82bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-96d03034-34db-4e40-ae44-0b6366ab96e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45643,DS-adbc65b5-9af0-4534-8c5e-e8f52ff82bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-96d03034-34db-4e40-ae44-0b6366ab96e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45643,DS-adbc65b5-9af0-4534-8c5e-e8f52ff82bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-96d03034-34db-4e40-ae44-0b6366ab96e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-8c85b8d1-c8f6-463c-a3d5-4e55aa2a54be,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-72e53269-fa18-4c3f-859f-e5e39e7ec62f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-8c85b8d1-c8f6-463c-a3d5-4e55aa2a54be,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-72e53269-fa18-4c3f-859f-e5e39e7ec62f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-8c85b8d1-c8f6-463c-a3d5-4e55aa2a54be,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-72e53269-fa18-4c3f-859f-e5e39e7ec62f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-8c85b8d1-c8f6-463c-a3d5-4e55aa2a54be,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-72e53269-fa18-4c3f-859f-e5e39e7ec62f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-e50d8fb8-96d1-4704-a24f-fd22ac53110b,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-d5184823-148c-4f2e-a2cd-a3d529c0ae05,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-e50d8fb8-96d1-4704-a24f-fd22ac53110b,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-d5184823-148c-4f2e-a2cd-a3d529c0ae05,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-e50d8fb8-96d1-4704-a24f-fd22ac53110b,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-d5184823-148c-4f2e-a2cd-a3d529c0ae05,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-e50d8fb8-96d1-4704-a24f-fd22ac53110b,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-d5184823-148c-4f2e-a2cd-a3d529c0ae05,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40360,DS-efc554a4-eb65-44e9-962c-d0ecd330d110,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-3f5717ab-4bf9-47c8-9822-a4dfc76b4265,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40360,DS-efc554a4-eb65-44e9-962c-d0ecd330d110,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-3f5717ab-4bf9-47c8-9822-a4dfc76b4265,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40360,DS-efc554a4-eb65-44e9-962c-d0ecd330d110,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-3f5717ab-4bf9-47c8-9822-a4dfc76b4265,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40360,DS-efc554a4-eb65-44e9-962c-d0ecd330d110,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-3f5717ab-4bf9-47c8-9822-a4dfc76b4265,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-52872733-5301-41b8-a2af-d729cd6975c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-c41be205-b9e0-4b35-b277-d3b48b8d842e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-c41be205-b9e0-4b35-b277-d3b48b8d842e,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-52872733-5301-41b8-a2af-d729cd6975c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-52872733-5301-41b8-a2af-d729cd6975c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-c41be205-b9e0-4b35-b277-d3b48b8d842e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-c41be205-b9e0-4b35-b277-d3b48b8d842e,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-52872733-5301-41b8-a2af-d729cd6975c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39743,DS-e746a0a6-d1dd-4a55-9cc5-7010c12d6c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-98ebed43-e5a3-4444-9b49-cf793dba1208,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-98ebed43-e5a3-4444-9b49-cf793dba1208,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-e746a0a6-d1dd-4a55-9cc5-7010c12d6c79,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39743,DS-e746a0a6-d1dd-4a55-9cc5-7010c12d6c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-98ebed43-e5a3-4444-9b49-cf793dba1208,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-98ebed43-e5a3-4444-9b49-cf793dba1208,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-e746a0a6-d1dd-4a55-9cc5-7010c12d6c79,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-e4cdace9-25a4-4121-8815-c9413133d703,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-1c96e392-bafd-4054-95e5-0fb15c79678e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-1c96e392-bafd-4054-95e5-0fb15c79678e,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-e4cdace9-25a4-4121-8815-c9413133d703,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-e4cdace9-25a4-4121-8815-c9413133d703,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-1c96e392-bafd-4054-95e5-0fb15c79678e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-1c96e392-bafd-4054-95e5-0fb15c79678e,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-e4cdace9-25a4-4121-8815-c9413133d703,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-2bd7fe54-0044-44f3-b809-7087fc5c4a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-91b8febe-c663-43fa-a4f6-7e8fe4a2c98b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-2bd7fe54-0044-44f3-b809-7087fc5c4a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-91b8febe-c663-43fa-a4f6-7e8fe4a2c98b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-2bd7fe54-0044-44f3-b809-7087fc5c4a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-91b8febe-c663-43fa-a4f6-7e8fe4a2c98b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-2bd7fe54-0044-44f3-b809-7087fc5c4a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-91b8febe-c663-43fa-a4f6-7e8fe4a2c98b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44661,DS-fca4ffd9-1e23-4ecc-b1a0-9f369c94b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-2ef36e18-beae-430a-9534-84669228d2f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44661,DS-fca4ffd9-1e23-4ecc-b1a0-9f369c94b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-2ef36e18-beae-430a-9534-84669228d2f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44661,DS-fca4ffd9-1e23-4ecc-b1a0-9f369c94b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-2ef36e18-beae-430a-9534-84669228d2f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44661,DS-fca4ffd9-1e23-4ecc-b1a0-9f369c94b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-2ef36e18-beae-430a-9534-84669228d2f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-cd11ed4b-3cb9-4a5f-a4e5-54b984c2f3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-b0bb5c93-0d3c-47ac-ba5c-70de925e02fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-b0bb5c93-0d3c-47ac-ba5c-70de925e02fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-cd11ed4b-3cb9-4a5f-a4e5-54b984c2f3c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-cd11ed4b-3cb9-4a5f-a4e5-54b984c2f3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-b0bb5c93-0d3c-47ac-ba5c-70de925e02fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-b0bb5c93-0d3c-47ac-ba5c-70de925e02fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-cd11ed4b-3cb9-4a5f-a4e5-54b984c2f3c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-6106c83d-a359-4713-ae59-db51fd2d02b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-f6185a8f-0f44-4349-9c21-048f3ad43997,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-6106c83d-a359-4713-ae59-db51fd2d02b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-f6185a8f-0f44-4349-9c21-048f3ad43997,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-6106c83d-a359-4713-ae59-db51fd2d02b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-f6185a8f-0f44-4349-9c21-048f3ad43997,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-6106c83d-a359-4713-ae59-db51fd2d02b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-f6185a8f-0f44-4349-9c21-048f3ad43997,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-87aed84f-5001-44c0-9255-c5abc701518f,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-a5bba9b8-a165-4012-a939-8405ca8b3e7d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-87aed84f-5001-44c0-9255-c5abc701518f,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-a5bba9b8-a165-4012-a939-8405ca8b3e7d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-87aed84f-5001-44c0-9255-c5abc701518f,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-a5bba9b8-a165-4012-a939-8405ca8b3e7d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-87aed84f-5001-44c0-9255-c5abc701518f,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-a5bba9b8-a165-4012-a939-8405ca8b3e7d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40636,DS-0a9be629-54d7-4c56-bd53-cd282beb1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-1985695c-361d-4a25-a077-f69664fc0e4a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40636,DS-0a9be629-54d7-4c56-bd53-cd282beb1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-1985695c-361d-4a25-a077-f69664fc0e4a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40636,DS-0a9be629-54d7-4c56-bd53-cd282beb1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-1985695c-361d-4a25-a077-f69664fc0e4a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40636,DS-0a9be629-54d7-4c56-bd53-cd282beb1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-1985695c-361d-4a25-a077-f69664fc0e4a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45900,DS-dacf0683-4637-4c0f-805f-c3d68bda3dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-d6c4255f-ce1a-4b0a-a6d6-ac1c0c5f2ffb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45900,DS-dacf0683-4637-4c0f-805f-c3d68bda3dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-d6c4255f-ce1a-4b0a-a6d6-ac1c0c5f2ffb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45900,DS-dacf0683-4637-4c0f-805f-c3d68bda3dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-d6c4255f-ce1a-4b0a-a6d6-ac1c0c5f2ffb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45900,DS-dacf0683-4637-4c0f-805f-c3d68bda3dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-d6c4255f-ce1a-4b0a-a6d6-ac1c0c5f2ffb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-162bc0e1-2b26-4f87-8cf3-5610361d5394,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8391ec23-ae77-401f-96a4-49049d418a1c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-162bc0e1-2b26-4f87-8cf3-5610361d5394,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8391ec23-ae77-401f-96a4-49049d418a1c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-162bc0e1-2b26-4f87-8cf3-5610361d5394,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8391ec23-ae77-401f-96a4-49049d418a1c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-162bc0e1-2b26-4f87-8cf3-5610361d5394,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8391ec23-ae77-401f-96a4-49049d418a1c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37195,DS-e8e30c86-ab6d-4f9e-97c8-50fcdfc236db,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-ddf87bf1-a673-4613-9990-32162cf5a26e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-ddf87bf1-a673-4613-9990-32162cf5a26e,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-e8e30c86-ab6d-4f9e-97c8-50fcdfc236db,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37195,DS-e8e30c86-ab6d-4f9e-97c8-50fcdfc236db,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-ddf87bf1-a673-4613-9990-32162cf5a26e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-ddf87bf1-a673-4613-9990-32162cf5a26e,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-e8e30c86-ab6d-4f9e-97c8-50fcdfc236db,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-b86f3227-7991-40f0-9f46-a4f6fdb6ed15,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-c9da7433-b97a-43c2-ab4e-c9ccec093f1e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-b86f3227-7991-40f0-9f46-a4f6fdb6ed15,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-c9da7433-b97a-43c2-ab4e-c9ccec093f1e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-b86f3227-7991-40f0-9f46-a4f6fdb6ed15,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-c9da7433-b97a-43c2-ab4e-c9ccec093f1e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-b86f3227-7991-40f0-9f46-a4f6fdb6ed15,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-c9da7433-b97a-43c2-ab4e-c9ccec093f1e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36965,DS-8f8c7d4f-ce72-4a10-9e48-24b4f07d94d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-5fc137ea-c13f-45c0-8cb6-5bc71be1be3e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36965,DS-8f8c7d4f-ce72-4a10-9e48-24b4f07d94d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-5fc137ea-c13f-45c0-8cb6-5bc71be1be3e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36965,DS-8f8c7d4f-ce72-4a10-9e48-24b4f07d94d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-5fc137ea-c13f-45c0-8cb6-5bc71be1be3e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36965,DS-8f8c7d4f-ce72-4a10-9e48-24b4f07d94d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-5fc137ea-c13f-45c0-8cb6-5bc71be1be3e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33861,DS-a58518da-a3e8-455d-9e46-139da56c59ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-f32851ac-6f2b-4629-b3d7-5a9be230bbdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36810,DS-f32851ac-6f2b-4629-b3d7-5a9be230bbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-a58518da-a3e8-455d-9e46-139da56c59ac,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33861,DS-a58518da-a3e8-455d-9e46-139da56c59ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-f32851ac-6f2b-4629-b3d7-5a9be230bbdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36810,DS-f32851ac-6f2b-4629-b3d7-5a9be230bbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-a58518da-a3e8-455d-9e46-139da56c59ac,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 6646
