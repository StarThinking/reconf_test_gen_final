reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-baf01da5-c185-47a9-957b-f2833f98f1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-2283c584-a2b3-4dfd-8d81-ff048d5866c9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-baf01da5-c185-47a9-957b-f2833f98f1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-2283c584-a2b3-4dfd-8d81-ff048d5866c9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-baf01da5-c185-47a9-957b-f2833f98f1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-2283c584-a2b3-4dfd-8d81-ff048d5866c9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-baf01da5-c185-47a9-957b-f2833f98f1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-2283c584-a2b3-4dfd-8d81-ff048d5866c9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46600,DS-37094b97-950e-4266-910b-10cc8aa44359,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-0df7fb65-b690-4046-b940-ae1cbecde61c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46600,DS-37094b97-950e-4266-910b-10cc8aa44359,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-0df7fb65-b690-4046-b940-ae1cbecde61c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46600,DS-37094b97-950e-4266-910b-10cc8aa44359,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-0df7fb65-b690-4046-b940-ae1cbecde61c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46600,DS-37094b97-950e-4266-910b-10cc8aa44359,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-0df7fb65-b690-4046-b940-ae1cbecde61c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38569,DS-2ec5116f-8b4a-4af8-b269-901ad46a594f,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-f53fccd6-85df-4d2d-95cf-1ef92b1e3b5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-f53fccd6-85df-4d2d-95cf-1ef92b1e3b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-2ec5116f-8b4a-4af8-b269-901ad46a594f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38569,DS-2ec5116f-8b4a-4af8-b269-901ad46a594f,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-f53fccd6-85df-4d2d-95cf-1ef92b1e3b5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-f53fccd6-85df-4d2d-95cf-1ef92b1e3b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-2ec5116f-8b4a-4af8-b269-901ad46a594f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-a752f050-6459-48d3-9f5b-27edc25e4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0e3f8796-960b-468e-8733-6b0b11f1b58a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-a752f050-6459-48d3-9f5b-27edc25e4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0e3f8796-960b-468e-8733-6b0b11f1b58a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-a752f050-6459-48d3-9f5b-27edc25e4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0e3f8796-960b-468e-8733-6b0b11f1b58a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-a752f050-6459-48d3-9f5b-27edc25e4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0e3f8796-960b-468e-8733-6b0b11f1b58a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36151,DS-ccc4010a-f401-45ea-bfbf-2efa06056f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-e142831c-25b9-4edd-ba02-38807de04e40,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36151,DS-ccc4010a-f401-45ea-bfbf-2efa06056f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-e142831c-25b9-4edd-ba02-38807de04e40,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36151,DS-ccc4010a-f401-45ea-bfbf-2efa06056f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-e142831c-25b9-4edd-ba02-38807de04e40,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36151,DS-ccc4010a-f401-45ea-bfbf-2efa06056f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-e142831c-25b9-4edd-ba02-38807de04e40,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38209,DS-27125bcb-5e1c-4f90-be6f-ed0c669c4ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-b3902b67-9fdf-406c-b5e0-f014b204771a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38209,DS-27125bcb-5e1c-4f90-be6f-ed0c669c4ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-b3902b67-9fdf-406c-b5e0-f014b204771a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38209,DS-27125bcb-5e1c-4f90-be6f-ed0c669c4ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-b3902b67-9fdf-406c-b5e0-f014b204771a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38209,DS-27125bcb-5e1c-4f90-be6f-ed0c669c4ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-b3902b67-9fdf-406c-b5e0-f014b204771a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44242,DS-78685393-0c61-4fd4-9dd7-1062e4149a72,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-2c3cb0c5-f284-4790-9783-21a2cd380591,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33997,DS-2c3cb0c5-f284-4790-9783-21a2cd380591,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-78685393-0c61-4fd4-9dd7-1062e4149a72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44242,DS-78685393-0c61-4fd4-9dd7-1062e4149a72,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-2c3cb0c5-f284-4790-9783-21a2cd380591,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33997,DS-2c3cb0c5-f284-4790-9783-21a2cd380591,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-78685393-0c61-4fd4-9dd7-1062e4149a72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-b49eeb7e-6730-4043-b498-1cf88d4c6b46,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-bee5d7bc-019d-4f46-ae17-aa9f2ed25d46,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-bee5d7bc-019d-4f46-ae17-aa9f2ed25d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-b49eeb7e-6730-4043-b498-1cf88d4c6b46,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-b49eeb7e-6730-4043-b498-1cf88d4c6b46,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-bee5d7bc-019d-4f46-ae17-aa9f2ed25d46,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-bee5d7bc-019d-4f46-ae17-aa9f2ed25d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-b49eeb7e-6730-4043-b498-1cf88d4c6b46,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-a9298423-2098-4ca0-91f3-190bb4688cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-eb57f21f-315c-4311-ab47-f7779f146bf7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-a9298423-2098-4ca0-91f3-190bb4688cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-eb57f21f-315c-4311-ab47-f7779f146bf7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-a9298423-2098-4ca0-91f3-190bb4688cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-eb57f21f-315c-4311-ab47-f7779f146bf7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-a9298423-2098-4ca0-91f3-190bb4688cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-eb57f21f-315c-4311-ab47-f7779f146bf7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-1f12490f-2deb-43f5-9776-2d6c7a46cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-8ca71b9e-dafc-4ce5-993f-3a88d7e20f88,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-1f12490f-2deb-43f5-9776-2d6c7a46cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-8ca71b9e-dafc-4ce5-993f-3a88d7e20f88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-1f12490f-2deb-43f5-9776-2d6c7a46cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-8ca71b9e-dafc-4ce5-993f-3a88d7e20f88,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-1f12490f-2deb-43f5-9776-2d6c7a46cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-8ca71b9e-dafc-4ce5-993f-3a88d7e20f88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-5a4683d4-58e1-4e17-b098-d0e42e22a96f,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-ecb9772e-2c3b-4b2c-bcb8-38d0382b6263,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-5a4683d4-58e1-4e17-b098-d0e42e22a96f,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-ecb9772e-2c3b-4b2c-bcb8-38d0382b6263,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-5a4683d4-58e1-4e17-b098-d0e42e22a96f,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-ecb9772e-2c3b-4b2c-bcb8-38d0382b6263,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-5a4683d4-58e1-4e17-b098-d0e42e22a96f,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-ecb9772e-2c3b-4b2c-bcb8-38d0382b6263,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-3ff29d72-a9e4-447f-87e9-37ad452255f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-03532f4d-4f3d-420f-8ade-ea79fe9e724f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-3ff29d72-a9e4-447f-87e9-37ad452255f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-03532f4d-4f3d-420f-8ade-ea79fe9e724f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-3ff29d72-a9e4-447f-87e9-37ad452255f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-03532f4d-4f3d-420f-8ade-ea79fe9e724f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-3ff29d72-a9e4-447f-87e9-37ad452255f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-03532f4d-4f3d-420f-8ade-ea79fe9e724f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-0a54b633-f897-4970-abf7-401b52300a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-cfcd4dd0-1743-44fe-b88d-26176c2051b0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-0a54b633-f897-4970-abf7-401b52300a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-cfcd4dd0-1743-44fe-b88d-26176c2051b0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-0a54b633-f897-4970-abf7-401b52300a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-cfcd4dd0-1743-44fe-b88d-26176c2051b0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-0a54b633-f897-4970-abf7-401b52300a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-cfcd4dd0-1743-44fe-b88d-26176c2051b0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39121,DS-92ca8876-19ec-4ae2-9804-88295111f447,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-32a478d1-9511-45e8-adf0-4b136145d94b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39121,DS-92ca8876-19ec-4ae2-9804-88295111f447,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-32a478d1-9511-45e8-adf0-4b136145d94b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39121,DS-92ca8876-19ec-4ae2-9804-88295111f447,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-32a478d1-9511-45e8-adf0-4b136145d94b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39121,DS-92ca8876-19ec-4ae2-9804-88295111f447,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-32a478d1-9511-45e8-adf0-4b136145d94b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-8d971582-4df3-46cf-9a78-07a0a98708d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-6ebfe913-6398-4ad1-935c-feae6294fcd7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-8d971582-4df3-46cf-9a78-07a0a98708d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-6ebfe913-6398-4ad1-935c-feae6294fcd7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-8d971582-4df3-46cf-9a78-07a0a98708d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-6ebfe913-6398-4ad1-935c-feae6294fcd7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-8d971582-4df3-46cf-9a78-07a0a98708d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-6ebfe913-6398-4ad1-935c-feae6294fcd7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-f7cae226-2f15-4b95-874d-c8041e99a8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-a26ae13a-d443-4a7d-8869-cc26b865e442,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-a26ae13a-d443-4a7d-8869-cc26b865e442,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-f7cae226-2f15-4b95-874d-c8041e99a8a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-f7cae226-2f15-4b95-874d-c8041e99a8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-a26ae13a-d443-4a7d-8869-cc26b865e442,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-a26ae13a-d443-4a7d-8869-cc26b865e442,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-f7cae226-2f15-4b95-874d-c8041e99a8a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-0eced540-3dc4-413d-b4df-94a020b9b809,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-fb4a3867-9112-498f-b827-2a7a0a28130f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-0eced540-3dc4-413d-b4df-94a020b9b809,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-fb4a3867-9112-498f-b827-2a7a0a28130f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-0eced540-3dc4-413d-b4df-94a020b9b809,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-fb4a3867-9112-498f-b827-2a7a0a28130f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-0eced540-3dc4-413d-b4df-94a020b9b809,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-fb4a3867-9112-498f-b827-2a7a0a28130f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43317,DS-a23865ec-f5e2-4812-955a-f4e284414288,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-dee51496-ac44-47e9-9fad-30a6058fb6ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32887,DS-dee51496-ac44-47e9-9fad-30a6058fb6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-a23865ec-f5e2-4812-955a-f4e284414288,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43317,DS-a23865ec-f5e2-4812-955a-f4e284414288,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-dee51496-ac44-47e9-9fad-30a6058fb6ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32887,DS-dee51496-ac44-47e9-9fad-30a6058fb6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-a23865ec-f5e2-4812-955a-f4e284414288,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41838,DS-882c6d41-d059-4b5a-80e8-37278095e059,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-05526ed1-94e1-4b5a-adea-86668d5ef710,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37561,DS-05526ed1-94e1-4b5a-adea-86668d5ef710,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-882c6d41-d059-4b5a-80e8-37278095e059,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41838,DS-882c6d41-d059-4b5a-80e8-37278095e059,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-05526ed1-94e1-4b5a-adea-86668d5ef710,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37561,DS-05526ed1-94e1-4b5a-adea-86668d5ef710,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-882c6d41-d059-4b5a-80e8-37278095e059,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40372,DS-e23fd4dd-6130-45b3-9195-8ced54c8de7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-7c837e24-14fa-407b-a0e7-20c82f5e8589,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40372,DS-e23fd4dd-6130-45b3-9195-8ced54c8de7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-7c837e24-14fa-407b-a0e7-20c82f5e8589,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40372,DS-e23fd4dd-6130-45b3-9195-8ced54c8de7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-7c837e24-14fa-407b-a0e7-20c82f5e8589,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40372,DS-e23fd4dd-6130-45b3-9195-8ced54c8de7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-7c837e24-14fa-407b-a0e7-20c82f5e8589,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36901,DS-1ef38a6a-969c-47c3-a908-550e2efe94f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-3e48d1a3-3a63-4994-8512-139c1da58577,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36901,DS-1ef38a6a-969c-47c3-a908-550e2efe94f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-3e48d1a3-3a63-4994-8512-139c1da58577,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36901,DS-1ef38a6a-969c-47c3-a908-550e2efe94f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-3e48d1a3-3a63-4994-8512-139c1da58577,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36901,DS-1ef38a6a-969c-47c3-a908-550e2efe94f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-3e48d1a3-3a63-4994-8512-139c1da58577,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-95f9f4ce-e870-4aeb-a01b-87be35efffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-7119013a-c80c-4b9f-a963-ea83f9188475,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44107,DS-7119013a-c80c-4b9f-a963-ea83f9188475,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-95f9f4ce-e870-4aeb-a01b-87be35efffbe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-95f9f4ce-e870-4aeb-a01b-87be35efffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-7119013a-c80c-4b9f-a963-ea83f9188475,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44107,DS-7119013a-c80c-4b9f-a963-ea83f9188475,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-95f9f4ce-e870-4aeb-a01b-87be35efffbe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-6b9f5f0b-4d05-41c9-960a-27d2c3098c66,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-507c41ed-2f75-46d0-ac89-00eeb1b7ea39,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-6b9f5f0b-4d05-41c9-960a-27d2c3098c66,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-507c41ed-2f75-46d0-ac89-00eeb1b7ea39,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-6b9f5f0b-4d05-41c9-960a-27d2c3098c66,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-507c41ed-2f75-46d0-ac89-00eeb1b7ea39,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-6b9f5f0b-4d05-41c9-960a-27d2c3098c66,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-507c41ed-2f75-46d0-ac89-00eeb1b7ea39,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-716e02a3-78d0-41c4-a9f3-8e599f7e90de,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-9cdc8a93-b784-469e-98ee-9efe058ab46f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-716e02a3-78d0-41c4-a9f3-8e599f7e90de,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-9cdc8a93-b784-469e-98ee-9efe058ab46f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-716e02a3-78d0-41c4-a9f3-8e599f7e90de,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-9cdc8a93-b784-469e-98ee-9efe058ab46f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-716e02a3-78d0-41c4-a9f3-8e599f7e90de,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-9cdc8a93-b784-469e-98ee-9efe058ab46f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43365,DS-e7b7c46c-bb44-4dae-9f68-4d06b272c787,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-f50a6454-173a-4138-9e18-c3adc0d4b6a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41760,DS-f50a6454-173a-4138-9e18-c3adc0d4b6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-e7b7c46c-bb44-4dae-9f68-4d06b272c787,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43365,DS-e7b7c46c-bb44-4dae-9f68-4d06b272c787,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-f50a6454-173a-4138-9e18-c3adc0d4b6a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41760,DS-f50a6454-173a-4138-9e18-c3adc0d4b6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-e7b7c46c-bb44-4dae-9f68-4d06b272c787,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-5a9d3263-d08b-4d0b-8090-74b0abf8855b,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-90ebc877-aa1e-4e7a-a0e7-3c18ed2d3ff8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-5a9d3263-d08b-4d0b-8090-74b0abf8855b,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-90ebc877-aa1e-4e7a-a0e7-3c18ed2d3ff8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-5a9d3263-d08b-4d0b-8090-74b0abf8855b,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-90ebc877-aa1e-4e7a-a0e7-3c18ed2d3ff8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-5a9d3263-d08b-4d0b-8090-74b0abf8855b,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-90ebc877-aa1e-4e7a-a0e7-3c18ed2d3ff8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-2b4508c8-df16-4a50-8f56-ee55e16f97fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-d7c9cfbb-2d91-4918-babd-4704c3b992cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-2b4508c8-df16-4a50-8f56-ee55e16f97fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-d7c9cfbb-2d91-4918-babd-4704c3b992cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-2b4508c8-df16-4a50-8f56-ee55e16f97fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-d7c9cfbb-2d91-4918-babd-4704c3b992cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-2b4508c8-df16-4a50-8f56-ee55e16f97fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-d7c9cfbb-2d91-4918-babd-4704c3b992cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-846c8ee8-b063-4a30-b61d-2dd0d91f8c69,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-846c8ee8-b063-4a30-b61d-2dd0d91f8c69,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-846c8ee8-b063-4a30-b61d-2dd0d91f8c69,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-846c8ee8-b063-4a30-b61d-2dd0d91f8c69,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46333,DS-be7ea7b6-6b70-489c-9f2c-37ab32b20f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-ec52fb60-e87c-4af4-9bd1-190df3d6361c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37432,DS-ec52fb60-e87c-4af4-9bd1-190df3d6361c,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-be7ea7b6-6b70-489c-9f2c-37ab32b20f5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46333,DS-be7ea7b6-6b70-489c-9f2c-37ab32b20f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-ec52fb60-e87c-4af4-9bd1-190df3d6361c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37432,DS-ec52fb60-e87c-4af4-9bd1-190df3d6361c,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-be7ea7b6-6b70-489c-9f2c-37ab32b20f5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 26 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 4806
