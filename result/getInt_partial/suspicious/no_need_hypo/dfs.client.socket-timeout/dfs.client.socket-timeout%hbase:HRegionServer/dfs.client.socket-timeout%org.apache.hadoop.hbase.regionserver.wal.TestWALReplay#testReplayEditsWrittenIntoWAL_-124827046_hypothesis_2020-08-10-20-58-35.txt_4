reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38501,DS-6e3c2d19-6cb3-4074-a80b-7950902faad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-b5d2347b-981c-4d7d-98a6-02665c7eb747,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41936,DS-b5d2347b-981c-4d7d-98a6-02665c7eb747,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-6e3c2d19-6cb3-4074-a80b-7950902faad3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38501,DS-6e3c2d19-6cb3-4074-a80b-7950902faad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-b5d2347b-981c-4d7d-98a6-02665c7eb747,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41936,DS-b5d2347b-981c-4d7d-98a6-02665c7eb747,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-6e3c2d19-6cb3-4074-a80b-7950902faad3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-d5a8861b-f5f7-4222-a96e-390b7936be6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-bcca4857-2566-4086-8a92-711b2f84b372,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-d5a8861b-f5f7-4222-a96e-390b7936be6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-bcca4857-2566-4086-8a92-711b2f84b372,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-d5a8861b-f5f7-4222-a96e-390b7936be6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-bcca4857-2566-4086-8a92-711b2f84b372,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-d5a8861b-f5f7-4222-a96e-390b7936be6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-bcca4857-2566-4086-8a92-711b2f84b372,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44029,DS-a0645ab9-69bf-4051-b40e-dd6b97c1eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-e8fec379-c24a-4c55-bcd5-5985eb592471,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44029,DS-a0645ab9-69bf-4051-b40e-dd6b97c1eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-e8fec379-c24a-4c55-bcd5-5985eb592471,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44029,DS-a0645ab9-69bf-4051-b40e-dd6b97c1eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-e8fec379-c24a-4c55-bcd5-5985eb592471,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44029,DS-a0645ab9-69bf-4051-b40e-dd6b97c1eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-e8fec379-c24a-4c55-bcd5-5985eb592471,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-fa0ae78b-5f51-4a8a-9719-2619a53e940c,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-19750bb9-0cec-4157-825f-dbfd60e24dbe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40603,DS-19750bb9-0cec-4157-825f-dbfd60e24dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-fa0ae78b-5f51-4a8a-9719-2619a53e940c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-fa0ae78b-5f51-4a8a-9719-2619a53e940c,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-19750bb9-0cec-4157-825f-dbfd60e24dbe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40603,DS-19750bb9-0cec-4157-825f-dbfd60e24dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-fa0ae78b-5f51-4a8a-9719-2619a53e940c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-2edd2cb3-1bf9-452d-a80e-257162b40664,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-5895a073-b3c3-4301-9183-25fdaa8dfc0e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-2edd2cb3-1bf9-452d-a80e-257162b40664,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-5895a073-b3c3-4301-9183-25fdaa8dfc0e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-2edd2cb3-1bf9-452d-a80e-257162b40664,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-5895a073-b3c3-4301-9183-25fdaa8dfc0e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-2edd2cb3-1bf9-452d-a80e-257162b40664,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-5895a073-b3c3-4301-9183-25fdaa8dfc0e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-98d3ee26-232a-42f4-942e-bd2f2f4f9995,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-f4b9107a-b6d6-43e6-b960-3099c942271a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-98d3ee26-232a-42f4-942e-bd2f2f4f9995,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-f4b9107a-b6d6-43e6-b960-3099c942271a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-98d3ee26-232a-42f4-942e-bd2f2f4f9995,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-f4b9107a-b6d6-43e6-b960-3099c942271a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-98d3ee26-232a-42f4-942e-bd2f2f4f9995,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-f4b9107a-b6d6-43e6-b960-3099c942271a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-0749cbaa-fd55-478a-a947-e61ab64ea415,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-599c7797-4ce3-4bf3-b97e-a0120c0e1be3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-0749cbaa-fd55-478a-a947-e61ab64ea415,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-599c7797-4ce3-4bf3-b97e-a0120c0e1be3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-0749cbaa-fd55-478a-a947-e61ab64ea415,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-599c7797-4ce3-4bf3-b97e-a0120c0e1be3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-0749cbaa-fd55-478a-a947-e61ab64ea415,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-599c7797-4ce3-4bf3-b97e-a0120c0e1be3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-88d83dbc-c076-48fd-9e99-26f427943e89,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-1413995f-8bb6-4c6c-8081-46453fe1abf1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-88d83dbc-c076-48fd-9e99-26f427943e89,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-1413995f-8bb6-4c6c-8081-46453fe1abf1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-88d83dbc-c076-48fd-9e99-26f427943e89,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-1413995f-8bb6-4c6c-8081-46453fe1abf1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-88d83dbc-c076-48fd-9e99-26f427943e89,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-1413995f-8bb6-4c6c-8081-46453fe1abf1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38676,DS-a8dfd3d7-2aae-46e8-824f-4a17690d46fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cc470295-e869-4fd0-b9a2-fee847c33c0d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-cc470295-e869-4fd0-b9a2-fee847c33c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-a8dfd3d7-2aae-46e8-824f-4a17690d46fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38676,DS-a8dfd3d7-2aae-46e8-824f-4a17690d46fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cc470295-e869-4fd0-b9a2-fee847c33c0d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-cc470295-e869-4fd0-b9a2-fee847c33c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-a8dfd3d7-2aae-46e8-824f-4a17690d46fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-c5341cd1-ea07-4057-a3bc-4b41a483df68,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-a62a4055-4dcf-428d-93d3-9ffa957178f4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-c5341cd1-ea07-4057-a3bc-4b41a483df68,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-a62a4055-4dcf-428d-93d3-9ffa957178f4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-c5341cd1-ea07-4057-a3bc-4b41a483df68,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-a62a4055-4dcf-428d-93d3-9ffa957178f4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-c5341cd1-ea07-4057-a3bc-4b41a483df68,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-a62a4055-4dcf-428d-93d3-9ffa957178f4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-df436d3a-c221-4f83-8c3f-b6ce4c77fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-c188e709-9966-4b5a-a1a5-b547a1c738b5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-df436d3a-c221-4f83-8c3f-b6ce4c77fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-c188e709-9966-4b5a-a1a5-b547a1c738b5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-df436d3a-c221-4f83-8c3f-b6ce4c77fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-c188e709-9966-4b5a-a1a5-b547a1c738b5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-df436d3a-c221-4f83-8c3f-b6ce4c77fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-c188e709-9966-4b5a-a1a5-b547a1c738b5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-cae1bc57-0608-45fa-8204-b8e0703fe544,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-40ecf0e8-42f2-4830-b28a-e2f5bb5b8830,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-cae1bc57-0608-45fa-8204-b8e0703fe544,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-40ecf0e8-42f2-4830-b28a-e2f5bb5b8830,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-cae1bc57-0608-45fa-8204-b8e0703fe544,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-40ecf0e8-42f2-4830-b28a-e2f5bb5b8830,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-cae1bc57-0608-45fa-8204-b8e0703fe544,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-40ecf0e8-42f2-4830-b28a-e2f5bb5b8830,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-65619d2e-78c9-47d4-a7b0-3bbb531af2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-e1d28059-d5a4-4103-ae7d-837c7d552a13,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-65619d2e-78c9-47d4-a7b0-3bbb531af2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-e1d28059-d5a4-4103-ae7d-837c7d552a13,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-65619d2e-78c9-47d4-a7b0-3bbb531af2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-e1d28059-d5a4-4103-ae7d-837c7d552a13,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-65619d2e-78c9-47d4-a7b0-3bbb531af2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-e1d28059-d5a4-4103-ae7d-837c7d552a13,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-0d9903c0-4af2-4caa-85b9-4e429c688183,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-23ea47de-dced-4e69-b25c-ea6a9aa6da92,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-0d9903c0-4af2-4caa-85b9-4e429c688183,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-23ea47de-dced-4e69-b25c-ea6a9aa6da92,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-0d9903c0-4af2-4caa-85b9-4e429c688183,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-23ea47de-dced-4e69-b25c-ea6a9aa6da92,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-0d9903c0-4af2-4caa-85b9-4e429c688183,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-23ea47de-dced-4e69-b25c-ea6a9aa6da92,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-554bf6d6-5028-430c-8282-381ec9ffdb25,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-feee4d9d-16dc-4cc4-83bd-9621eca587a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-554bf6d6-5028-430c-8282-381ec9ffdb25,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-feee4d9d-16dc-4cc4-83bd-9621eca587a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-554bf6d6-5028-430c-8282-381ec9ffdb25,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-feee4d9d-16dc-4cc4-83bd-9621eca587a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-554bf6d6-5028-430c-8282-381ec9ffdb25,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-feee4d9d-16dc-4cc4-83bd-9621eca587a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36719,DS-54e49b81-e8ff-47e3-a025-78ae89195079,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-9bdf047a-8b9a-4866-8216-6a74c80f9d65,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36719,DS-54e49b81-e8ff-47e3-a025-78ae89195079,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-9bdf047a-8b9a-4866-8216-6a74c80f9d65,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36719,DS-54e49b81-e8ff-47e3-a025-78ae89195079,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-9bdf047a-8b9a-4866-8216-6a74c80f9d65,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36719,DS-54e49b81-e8ff-47e3-a025-78ae89195079,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-9bdf047a-8b9a-4866-8216-6a74c80f9d65,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-7c2b2cc8-5501-423e-9068-b0b75a6eb51f,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-b0d362ea-d20e-4375-b299-9f7566b6fad5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-7c2b2cc8-5501-423e-9068-b0b75a6eb51f,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-b0d362ea-d20e-4375-b299-9f7566b6fad5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-7c2b2cc8-5501-423e-9068-b0b75a6eb51f,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-b0d362ea-d20e-4375-b299-9f7566b6fad5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-7c2b2cc8-5501-423e-9068-b0b75a6eb51f,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-b0d362ea-d20e-4375-b299-9f7566b6fad5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-e132e08e-4125-495f-9825-43bcf668a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-2ce4ef26-4e69-47a1-b671-1545bf19ca3e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-e132e08e-4125-495f-9825-43bcf668a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-2ce4ef26-4e69-47a1-b671-1545bf19ca3e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-e132e08e-4125-495f-9825-43bcf668a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-2ce4ef26-4e69-47a1-b671-1545bf19ca3e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-e132e08e-4125-495f-9825-43bcf668a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-2ce4ef26-4e69-47a1-b671-1545bf19ca3e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-84f4baeb-7a63-4e72-bb0e-83577aaf02c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-a13d63bc-4509-4f9f-b720-7587416d4e2a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35573,DS-a13d63bc-4509-4f9f-b720-7587416d4e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-84f4baeb-7a63-4e72-bb0e-83577aaf02c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-84f4baeb-7a63-4e72-bb0e-83577aaf02c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-a13d63bc-4509-4f9f-b720-7587416d4e2a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35573,DS-a13d63bc-4509-4f9f-b720-7587416d4e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-84f4baeb-7a63-4e72-bb0e-83577aaf02c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-4d15a9ed-57aa-49de-bd9d-d210c9bf60cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-96168c9b-824e-4a97-a883-e79bfbf0576b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-4d15a9ed-57aa-49de-bd9d-d210c9bf60cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-96168c9b-824e-4a97-a883-e79bfbf0576b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-4d15a9ed-57aa-49de-bd9d-d210c9bf60cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-96168c9b-824e-4a97-a883-e79bfbf0576b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-4d15a9ed-57aa-49de-bd9d-d210c9bf60cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-96168c9b-824e-4a97-a883-e79bfbf0576b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-f255cd37-58ea-4867-bb90-d69ce729ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-92381eb2-aab7-44cf-bc08-f586fdc18496,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-f255cd37-58ea-4867-bb90-d69ce729ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-92381eb2-aab7-44cf-bc08-f586fdc18496,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-f255cd37-58ea-4867-bb90-d69ce729ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-92381eb2-aab7-44cf-bc08-f586fdc18496,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-f255cd37-58ea-4867-bb90-d69ce729ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-92381eb2-aab7-44cf-bc08-f586fdc18496,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-71165241-2927-4a9d-9dfb-3b7d4a3810c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-c0dbd8d0-9524-409f-b37d-b7891a6dd878,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-c0dbd8d0-9524-409f-b37d-b7891a6dd878,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-71165241-2927-4a9d-9dfb-3b7d4a3810c9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-71165241-2927-4a9d-9dfb-3b7d4a3810c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-c0dbd8d0-9524-409f-b37d-b7891a6dd878,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-c0dbd8d0-9524-409f-b37d-b7891a6dd878,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-71165241-2927-4a9d-9dfb-3b7d4a3810c9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-1bfec46b-8b89-424c-b497-7a87a28d5d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-47d61a3b-71e6-4bbb-966c-69b198b950fd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-1bfec46b-8b89-424c-b497-7a87a28d5d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-47d61a3b-71e6-4bbb-966c-69b198b950fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-1bfec46b-8b89-424c-b497-7a87a28d5d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-47d61a3b-71e6-4bbb-966c-69b198b950fd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-1bfec46b-8b89-424c-b497-7a87a28d5d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-47d61a3b-71e6-4bbb-966c-69b198b950fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-187d0258-8654-4579-bf3e-bd92dbfb3111,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-9ee0436f-3c95-4c9c-ae01-362250e62f11,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-187d0258-8654-4579-bf3e-bd92dbfb3111,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-9ee0436f-3c95-4c9c-ae01-362250e62f11,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-187d0258-8654-4579-bf3e-bd92dbfb3111,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-9ee0436f-3c95-4c9c-ae01-362250e62f11,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-187d0258-8654-4579-bf3e-bd92dbfb3111,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-9ee0436f-3c95-4c9c-ae01-362250e62f11,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41994,DS-8fe0aeb2-6480-4faf-8ec1-91ce87fd2c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-db8ee39b-24de-4179-98b5-ff55a88278fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40066,DS-db8ee39b-24de-4179-98b5-ff55a88278fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-8fe0aeb2-6480-4faf-8ec1-91ce87fd2c54,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41994,DS-8fe0aeb2-6480-4faf-8ec1-91ce87fd2c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-db8ee39b-24de-4179-98b5-ff55a88278fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40066,DS-db8ee39b-24de-4179-98b5-ff55a88278fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-8fe0aeb2-6480-4faf-8ec1-91ce87fd2c54,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-ae112d40-2ca1-45e1-8a28-a5d14db9bfab,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-e35bf420-70e3-436f-9983-ec8b20116313,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-ae112d40-2ca1-45e1-8a28-a5d14db9bfab,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-e35bf420-70e3-436f-9983-ec8b20116313,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-ae112d40-2ca1-45e1-8a28-a5d14db9bfab,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-e35bf420-70e3-436f-9983-ec8b20116313,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-ae112d40-2ca1-45e1-8a28-a5d14db9bfab,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-e35bf420-70e3-436f-9983-ec8b20116313,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35432,DS-3148c6cb-96ac-41d3-81e6-1524fe4dd641,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-b65ed10e-b0ec-4992-ba74-36e54e1ea3c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-b65ed10e-b0ec-4992-ba74-36e54e1ea3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-3148c6cb-96ac-41d3-81e6-1524fe4dd641,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35432,DS-3148c6cb-96ac-41d3-81e6-1524fe4dd641,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-b65ed10e-b0ec-4992-ba74-36e54e1ea3c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-b65ed10e-b0ec-4992-ba74-36e54e1ea3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-3148c6cb-96ac-41d3-81e6-1524fe4dd641,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38422,DS-30769330-eec9-46af-ab47-d3fb497142e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-1ead65e9-a972-4302-870d-008c435cbc69,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35732,DS-1ead65e9-a972-4302-870d-008c435cbc69,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-30769330-eec9-46af-ab47-d3fb497142e8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38422,DS-30769330-eec9-46af-ab47-d3fb497142e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-1ead65e9-a972-4302-870d-008c435cbc69,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35732,DS-1ead65e9-a972-4302-870d-008c435cbc69,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-30769330-eec9-46af-ab47-d3fb497142e8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42556,DS-e4403d83-1ed2-443e-93dd-a0d9637cdf89,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-54b056c0-d92b-4888-9c86-d8342580e2e9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42556,DS-e4403d83-1ed2-443e-93dd-a0d9637cdf89,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-54b056c0-d92b-4888-9c86-d8342580e2e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42556,DS-e4403d83-1ed2-443e-93dd-a0d9637cdf89,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-54b056c0-d92b-4888-9c86-d8342580e2e9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42556,DS-e4403d83-1ed2-443e-93dd-a0d9637cdf89,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-54b056c0-d92b-4888-9c86-d8342580e2e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-6867d1bc-b54e-4808-a570-b2e9cd85a832,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-c8edb7c1-35cd-40b0-a38b-0fd6d744925c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-6867d1bc-b54e-4808-a570-b2e9cd85a832,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-c8edb7c1-35cd-40b0-a38b-0fd6d744925c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-6867d1bc-b54e-4808-a570-b2e9cd85a832,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-c8edb7c1-35cd-40b0-a38b-0fd6d744925c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-6867d1bc-b54e-4808-a570-b2e9cd85a832,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-c8edb7c1-35cd-40b0-a38b-0fd6d744925c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-055efad1-285d-4048-bccb-7ec7fa2d587f,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-63a22139-5fda-46d9-b51a-9978e5df0d39,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-055efad1-285d-4048-bccb-7ec7fa2d587f,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-63a22139-5fda-46d9-b51a-9978e5df0d39,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-055efad1-285d-4048-bccb-7ec7fa2d587f,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-63a22139-5fda-46d9-b51a-9978e5df0d39,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-055efad1-285d-4048-bccb-7ec7fa2d587f,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-63a22139-5fda-46d9-b51a-9978e5df0d39,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41760,DS-0eb85de0-5de7-4708-bd7b-688f04d52faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-0ff15246-bc43-4e38-bdd1-a641ebfcfc95,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41760,DS-0eb85de0-5de7-4708-bd7b-688f04d52faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-0ff15246-bc43-4e38-bdd1-a641ebfcfc95,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41760,DS-0eb85de0-5de7-4708-bd7b-688f04d52faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-0ff15246-bc43-4e38-bdd1-a641ebfcfc95,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41760,DS-0eb85de0-5de7-4708-bd7b-688f04d52faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-0ff15246-bc43-4e38-bdd1-a641ebfcfc95,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36844,DS-ea6291b5-29f9-4198-9ef8-189ed3c7a257,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-e9646b33-faac-4201-a2a8-4d1dac82a8c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36844,DS-ea6291b5-29f9-4198-9ef8-189ed3c7a257,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-e9646b33-faac-4201-a2a8-4d1dac82a8c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36844,DS-ea6291b5-29f9-4198-9ef8-189ed3c7a257,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-e9646b33-faac-4201-a2a8-4d1dac82a8c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36844,DS-ea6291b5-29f9-4198-9ef8-189ed3c7a257,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-e9646b33-faac-4201-a2a8-4d1dac82a8c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38728,DS-6b049995-504a-4b34-8ce4-f50a0ed9f460,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-ace90494-7597-44f5-9343-125c2dddf3bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35104,DS-ace90494-7597-44f5-9343-125c2dddf3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-6b049995-504a-4b34-8ce4-f50a0ed9f460,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38728,DS-6b049995-504a-4b34-8ce4-f50a0ed9f460,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-ace90494-7597-44f5-9343-125c2dddf3bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35104,DS-ace90494-7597-44f5-9343-125c2dddf3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-6b049995-504a-4b34-8ce4-f50a0ed9f460,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-16219020-2c0b-4459-97dc-96e315c48868,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-6fb98085-255b-4288-a27f-fbf30140af76,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32793,DS-6fb98085-255b-4288-a27f-fbf30140af76,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-16219020-2c0b-4459-97dc-96e315c48868,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-16219020-2c0b-4459-97dc-96e315c48868,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-6fb98085-255b-4288-a27f-fbf30140af76,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32793,DS-6fb98085-255b-4288-a27f-fbf30140af76,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-16219020-2c0b-4459-97dc-96e315c48868,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-d8165b9c-dc0a-42d9-a5b8-c85dbb608aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-c1a80d58-aaab-4a29-bc51-cc6aa5e8c87c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-d8165b9c-dc0a-42d9-a5b8-c85dbb608aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-c1a80d58-aaab-4a29-bc51-cc6aa5e8c87c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-d8165b9c-dc0a-42d9-a5b8-c85dbb608aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-c1a80d58-aaab-4a29-bc51-cc6aa5e8c87c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-d8165b9c-dc0a-42d9-a5b8-c85dbb608aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-c1a80d58-aaab-4a29-bc51-cc6aa5e8c87c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-f89fdbcf-f06b-41c2-b70e-226ad38c1f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-7249bf6d-e661-46bf-ad18-409e4c40f122,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42794,DS-7249bf6d-e661-46bf-ad18-409e4c40f122,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-f89fdbcf-f06b-41c2-b70e-226ad38c1f7b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-f89fdbcf-f06b-41c2-b70e-226ad38c1f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-7249bf6d-e661-46bf-ad18-409e4c40f122,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42794,DS-7249bf6d-e661-46bf-ad18-409e4c40f122,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-f89fdbcf-f06b-41c2-b70e-226ad38c1f7b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-ea07d3da-9a47-40c9-9d78-8ec0eea4e450,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-84ccf617-ad47-4c09-8044-0bcbc4136adc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-ea07d3da-9a47-40c9-9d78-8ec0eea4e450,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-84ccf617-ad47-4c09-8044-0bcbc4136adc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-ea07d3da-9a47-40c9-9d78-8ec0eea4e450,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-84ccf617-ad47-4c09-8044-0bcbc4136adc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-ea07d3da-9a47-40c9-9d78-8ec0eea4e450,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-84ccf617-ad47-4c09-8044-0bcbc4136adc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-a76a2b42-cb59-472a-9edf-2a9398bc6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-e92b0f41-353f-47ca-8235-e4f0d2f561ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46291,DS-e92b0f41-353f-47ca-8235-e4f0d2f561ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-a76a2b42-cb59-472a-9edf-2a9398bc6ed7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-a76a2b42-cb59-472a-9edf-2a9398bc6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-e92b0f41-353f-47ca-8235-e4f0d2f561ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46291,DS-e92b0f41-353f-47ca-8235-e4f0d2f561ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-a76a2b42-cb59-472a-9edf-2a9398bc6ed7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35057,DS-1ee53c8e-4c59-4204-8cf3-4ba0d4206eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-eb62f062-ab6b-4f3d-9d14-3ad73a58cdbb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35057,DS-1ee53c8e-4c59-4204-8cf3-4ba0d4206eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-eb62f062-ab6b-4f3d-9d14-3ad73a58cdbb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35057,DS-1ee53c8e-4c59-4204-8cf3-4ba0d4206eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-eb62f062-ab6b-4f3d-9d14-3ad73a58cdbb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35057,DS-1ee53c8e-4c59-4204-8cf3-4ba0d4206eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-eb62f062-ab6b-4f3d-9d14-3ad73a58cdbb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-be8ab4eb-8dc9-4b0f-906c-e5a18e9484e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-a48ece64-d029-4c02-8c09-6dbd57b803db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-be8ab4eb-8dc9-4b0f-906c-e5a18e9484e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-a48ece64-d029-4c02-8c09-6dbd57b803db,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-be8ab4eb-8dc9-4b0f-906c-e5a18e9484e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-a48ece64-d029-4c02-8c09-6dbd57b803db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-be8ab4eb-8dc9-4b0f-906c-e5a18e9484e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-a48ece64-d029-4c02-8c09-6dbd57b803db,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33420,DS-aa87e577-dfde-4056-991f-be34f0d6b349,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-588850b4-bd41-41ed-84c9-7c11e99fe843,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-588850b4-bd41-41ed-84c9-7c11e99fe843,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-aa87e577-dfde-4056-991f-be34f0d6b349,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33420,DS-aa87e577-dfde-4056-991f-be34f0d6b349,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-588850b4-bd41-41ed-84c9-7c11e99fe843,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-588850b4-bd41-41ed-84c9-7c11e99fe843,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-aa87e577-dfde-4056-991f-be34f0d6b349,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-411dbd75-bae0-472d-98ee-142e97d99ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-69c1c9a1-fa69-4b34-9635-e5fdf091e1cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44498,DS-69c1c9a1-fa69-4b34-9635-e5fdf091e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-411dbd75-bae0-472d-98ee-142e97d99ecd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-411dbd75-bae0-472d-98ee-142e97d99ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-69c1c9a1-fa69-4b34-9635-e5fdf091e1cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44498,DS-69c1c9a1-fa69-4b34-9635-e5fdf091e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-411dbd75-bae0-472d-98ee-142e97d99ecd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-3a56972c-ba28-4446-950e-83257dc059d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-dfc3c263-d363-4d81-b5d7-a391f31161e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-3a56972c-ba28-4446-950e-83257dc059d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-dfc3c263-d363-4d81-b5d7-a391f31161e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-3a56972c-ba28-4446-950e-83257dc059d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-dfc3c263-d363-4d81-b5d7-a391f31161e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-3a56972c-ba28-4446-950e-83257dc059d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-dfc3c263-d363-4d81-b5d7-a391f31161e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-f76b973f-a19b-4e28-9877-6f825a712a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-12a0ad50-3519-48b3-b012-7fe9472515eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-f76b973f-a19b-4e28-9877-6f825a712a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-12a0ad50-3519-48b3-b012-7fe9472515eb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-f76b973f-a19b-4e28-9877-6f825a712a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-12a0ad50-3519-48b3-b012-7fe9472515eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-f76b973f-a19b-4e28-9877-6f825a712a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-12a0ad50-3519-48b3-b012-7fe9472515eb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-f52ced86-f4f1-4af3-8949-c22e046cda11,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-c1f46ec1-9d03-4a9e-a93f-327b3ff2769b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-f52ced86-f4f1-4af3-8949-c22e046cda11,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-c1f46ec1-9d03-4a9e-a93f-327b3ff2769b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-f52ced86-f4f1-4af3-8949-c22e046cda11,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-c1f46ec1-9d03-4a9e-a93f-327b3ff2769b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-f52ced86-f4f1-4af3-8949-c22e046cda11,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-c1f46ec1-9d03-4a9e-a93f-327b3ff2769b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 1 out of 50
result: might be true error
Total execution time in seconds : 15589
