reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-f6e950ba-e6f0-4a92-9a39-5500a9d9ee82,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-4c026b47-3502-4305-af74-b3f7189e6a53,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-f6e950ba-e6f0-4a92-9a39-5500a9d9ee82,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-4c026b47-3502-4305-af74-b3f7189e6a53,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-f6e950ba-e6f0-4a92-9a39-5500a9d9ee82,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-4c026b47-3502-4305-af74-b3f7189e6a53,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-f6e950ba-e6f0-4a92-9a39-5500a9d9ee82,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-4c026b47-3502-4305-af74-b3f7189e6a53,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40952,DS-82fd8a82-c74f-4a1c-acce-d0daac6c5af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-9becb0ac-f005-4682-8a65-9e5f795db6fd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40952,DS-82fd8a82-c74f-4a1c-acce-d0daac6c5af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-9becb0ac-f005-4682-8a65-9e5f795db6fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40952,DS-82fd8a82-c74f-4a1c-acce-d0daac6c5af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-9becb0ac-f005-4682-8a65-9e5f795db6fd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40952,DS-82fd8a82-c74f-4a1c-acce-d0daac6c5af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-9becb0ac-f005-4682-8a65-9e5f795db6fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34237,DS-b179c4b0-7dc2-4b96-a517-71f0547bdefb,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-b16f8425-992d-4312-af45-5b62e75fde68,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34237,DS-b179c4b0-7dc2-4b96-a517-71f0547bdefb,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-b16f8425-992d-4312-af45-5b62e75fde68,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34237,DS-b179c4b0-7dc2-4b96-a517-71f0547bdefb,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-b16f8425-992d-4312-af45-5b62e75fde68,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34237,DS-b179c4b0-7dc2-4b96-a517-71f0547bdefb,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-b16f8425-992d-4312-af45-5b62e75fde68,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-fa1af38b-ce96-45a6-ae42-9f074cd7fe53,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-873b157d-066b-4346-bb8c-29639c4e0811,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43507,DS-873b157d-066b-4346-bb8c-29639c4e0811,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-fa1af38b-ce96-45a6-ae42-9f074cd7fe53,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-fa1af38b-ce96-45a6-ae42-9f074cd7fe53,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-873b157d-066b-4346-bb8c-29639c4e0811,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43507,DS-873b157d-066b-4346-bb8c-29639c4e0811,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-fa1af38b-ce96-45a6-ae42-9f074cd7fe53,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44747,DS-e87c1e62-8758-41d7-b0bc-65c971004984,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-9321f934-34d8-492e-b8b7-7ec1fe81b4e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44747,DS-e87c1e62-8758-41d7-b0bc-65c971004984,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-9321f934-34d8-492e-b8b7-7ec1fe81b4e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44747,DS-e87c1e62-8758-41d7-b0bc-65c971004984,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-9321f934-34d8-492e-b8b7-7ec1fe81b4e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44747,DS-e87c1e62-8758-41d7-b0bc-65c971004984,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-9321f934-34d8-492e-b8b7-7ec1fe81b4e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-5d2a2772-88e3-4eab-890e-f40120ff9227,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-dc9091ca-ef7d-4114-b219-9959699f5d6e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-5d2a2772-88e3-4eab-890e-f40120ff9227,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-dc9091ca-ef7d-4114-b219-9959699f5d6e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-5d2a2772-88e3-4eab-890e-f40120ff9227,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-dc9091ca-ef7d-4114-b219-9959699f5d6e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-5d2a2772-88e3-4eab-890e-f40120ff9227,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-dc9091ca-ef7d-4114-b219-9959699f5d6e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45453,DS-5c260798-46c2-4b41-954d-d2922213125e,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-5d46fc93-cd9a-4d4a-92e3-a6d6bab64b9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45453,DS-5c260798-46c2-4b41-954d-d2922213125e,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-5d46fc93-cd9a-4d4a-92e3-a6d6bab64b9f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45453,DS-5c260798-46c2-4b41-954d-d2922213125e,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-5d46fc93-cd9a-4d4a-92e3-a6d6bab64b9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45453,DS-5c260798-46c2-4b41-954d-d2922213125e,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-5d46fc93-cd9a-4d4a-92e3-a6d6bab64b9f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39466,DS-af5cdfb9-b19e-4c62-8051-703d73a782e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-13ac0a91-d938-4358-8c44-d9e5c648472d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46443,DS-13ac0a91-d938-4358-8c44-d9e5c648472d,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-af5cdfb9-b19e-4c62-8051-703d73a782e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39466,DS-af5cdfb9-b19e-4c62-8051-703d73a782e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-13ac0a91-d938-4358-8c44-d9e5c648472d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46443,DS-13ac0a91-d938-4358-8c44-d9e5c648472d,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-af5cdfb9-b19e-4c62-8051-703d73a782e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-9d0ed1f9-c8bc-4c92-a13a-8e0973e2a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-5b438430-f922-4fd8-96d5-ed4555f1cdc9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-9d0ed1f9-c8bc-4c92-a13a-8e0973e2a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-5b438430-f922-4fd8-96d5-ed4555f1cdc9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-9d0ed1f9-c8bc-4c92-a13a-8e0973e2a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-5b438430-f922-4fd8-96d5-ed4555f1cdc9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-9d0ed1f9-c8bc-4c92-a13a-8e0973e2a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-5b438430-f922-4fd8-96d5-ed4555f1cdc9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveTable
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39063,DS-885a5505-5587-4451-8ec7-b7b07342fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-1ffa32f8-c7f3-42f9-b977-d5909471597e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39063,DS-885a5505-5587-4451-8ec7-b7b07342fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-1ffa32f8-c7f3-42f9-b977-d5909471597e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39063,DS-885a5505-5587-4451-8ec7-b7b07342fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-1ffa32f8-c7f3-42f9-b977-d5909471597e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39063,DS-885a5505-5587-4451-8ec7-b7b07342fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-1ffa32f8-c7f3-42f9-b977-d5909471597e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2234
