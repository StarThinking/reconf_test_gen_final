reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35783,DS-851c2a27-3568-496e-acde-99d82b76a06d,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-e8d69844-7c29-4d36-93d3-70c21404711b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35783,DS-851c2a27-3568-496e-acde-99d82b76a06d,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-e8d69844-7c29-4d36-93d3-70c21404711b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35783,DS-851c2a27-3568-496e-acde-99d82b76a06d,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-e8d69844-7c29-4d36-93d3-70c21404711b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35783,DS-851c2a27-3568-496e-acde-99d82b76a06d,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-e8d69844-7c29-4d36-93d3-70c21404711b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43481,DS-5a1cf6f4-1808-45b8-bbe7-42c22e3d65c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-03ecf20a-5b27-4132-84ad-59398efeac81,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43806,DS-03ecf20a-5b27-4132-84ad-59398efeac81,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-5a1cf6f4-1808-45b8-bbe7-42c22e3d65c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43481,DS-5a1cf6f4-1808-45b8-bbe7-42c22e3d65c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-03ecf20a-5b27-4132-84ad-59398efeac81,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43806,DS-03ecf20a-5b27-4132-84ad-59398efeac81,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-5a1cf6f4-1808-45b8-bbe7-42c22e3d65c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-14c10662-07ea-4b1e-9b03-9935a588833e,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-57d8b459-d0de-404d-9f8f-ced3bbd69b8e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-57d8b459-d0de-404d-9f8f-ced3bbd69b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-14c10662-07ea-4b1e-9b03-9935a588833e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-14c10662-07ea-4b1e-9b03-9935a588833e,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-57d8b459-d0de-404d-9f8f-ced3bbd69b8e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-57d8b459-d0de-404d-9f8f-ced3bbd69b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-14c10662-07ea-4b1e-9b03-9935a588833e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-147fd7d0-d1f5-48c3-8e2a-7422a0c84152,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-7669715b-e83d-43c5-804c-ec26643e120c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-147fd7d0-d1f5-48c3-8e2a-7422a0c84152,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-7669715b-e83d-43c5-804c-ec26643e120c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-147fd7d0-d1f5-48c3-8e2a-7422a0c84152,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-7669715b-e83d-43c5-804c-ec26643e120c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-147fd7d0-d1f5-48c3-8e2a-7422a0c84152,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-7669715b-e83d-43c5-804c-ec26643e120c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-f6feb644-7184-45cc-ac6f-50c931e33feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-8fa932bd-28b4-4223-9384-653f698cad7a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-f6feb644-7184-45cc-ac6f-50c931e33feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-8fa932bd-28b4-4223-9384-653f698cad7a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-f6feb644-7184-45cc-ac6f-50c931e33feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-8fa932bd-28b4-4223-9384-653f698cad7a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-f6feb644-7184-45cc-ac6f-50c931e33feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-8fa932bd-28b4-4223-9384-653f698cad7a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44800,DS-39a59250-6e42-45f0-9ce0-09019c76e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-2d02415e-135e-41e3-9f7e-094061386b4b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-2d02415e-135e-41e3-9f7e-094061386b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-39a59250-6e42-45f0-9ce0-09019c76e8aa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44800,DS-39a59250-6e42-45f0-9ce0-09019c76e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-2d02415e-135e-41e3-9f7e-094061386b4b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-2d02415e-135e-41e3-9f7e-094061386b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-39a59250-6e42-45f0-9ce0-09019c76e8aa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-25c5f2ed-2d3b-49ba-93c3-10fa973e4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-a573f533-7e45-4ff0-b377-6dc64bc2937a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-25c5f2ed-2d3b-49ba-93c3-10fa973e4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-a573f533-7e45-4ff0-b377-6dc64bc2937a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-25c5f2ed-2d3b-49ba-93c3-10fa973e4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-a573f533-7e45-4ff0-b377-6dc64bc2937a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-25c5f2ed-2d3b-49ba-93c3-10fa973e4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-a573f533-7e45-4ff0-b377-6dc64bc2937a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41778,DS-bda04758-216d-4aa0-ae38-7bbc353db22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-e0a6fc17-3ae9-40c8-b6fa-2cde06e128f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41778,DS-bda04758-216d-4aa0-ae38-7bbc353db22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-e0a6fc17-3ae9-40c8-b6fa-2cde06e128f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41778,DS-bda04758-216d-4aa0-ae38-7bbc353db22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-e0a6fc17-3ae9-40c8-b6fa-2cde06e128f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41778,DS-bda04758-216d-4aa0-ae38-7bbc353db22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-e0a6fc17-3ae9-40c8-b6fa-2cde06e128f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-ccff91d1-dcfa-46f8-b2cd-2e7fcd8818ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-65e087d6-dc39-468b-bc4b-f9362401dd87,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-ccff91d1-dcfa-46f8-b2cd-2e7fcd8818ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-65e087d6-dc39-468b-bc4b-f9362401dd87,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-ccff91d1-dcfa-46f8-b2cd-2e7fcd8818ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-65e087d6-dc39-468b-bc4b-f9362401dd87,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-ccff91d1-dcfa-46f8-b2cd-2e7fcd8818ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-65e087d6-dc39-468b-bc4b-f9362401dd87,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42230,DS-c64e6d5b-5b6a-42f1-8d52-c0f3ff72f2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-720e20b0-0846-489f-9077-3bb15c0db0b7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46484,DS-720e20b0-0846-489f-9077-3bb15c0db0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-c64e6d5b-5b6a-42f1-8d52-c0f3ff72f2e2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42230,DS-c64e6d5b-5b6a-42f1-8d52-c0f3ff72f2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-720e20b0-0846-489f-9077-3bb15c0db0b7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46484,DS-720e20b0-0846-489f-9077-3bb15c0db0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-c64e6d5b-5b6a-42f1-8d52-c0f3ff72f2e2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2777
