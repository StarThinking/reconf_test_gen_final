reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-003b4308-17ea-4339-82d3-d7591bc7d81a,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-0ab31b85-24a4-4ec9-8159-ef8869f6771c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-003b4308-17ea-4339-82d3-d7591bc7d81a,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-0ab31b85-24a4-4ec9-8159-ef8869f6771c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-003b4308-17ea-4339-82d3-d7591bc7d81a,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-0ab31b85-24a4-4ec9-8159-ef8869f6771c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-003b4308-17ea-4339-82d3-d7591bc7d81a,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-0ab31b85-24a4-4ec9-8159-ef8869f6771c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-e7cd1123-ce4a-416f-ae4f-7d19b089e428,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-a53de388-b237-487c-a18e-4c102605d96e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-e7cd1123-ce4a-416f-ae4f-7d19b089e428,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-a53de388-b237-487c-a18e-4c102605d96e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-e7cd1123-ce4a-416f-ae4f-7d19b089e428,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-a53de388-b237-487c-a18e-4c102605d96e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-e7cd1123-ce4a-416f-ae4f-7d19b089e428,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-a53de388-b237-487c-a18e-4c102605d96e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-29267c34-1647-482b-9bce-53eef1ac2620,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-209f2f3b-e14c-470e-b080-1d46f5fca5e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-29267c34-1647-482b-9bce-53eef1ac2620,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-209f2f3b-e14c-470e-b080-1d46f5fca5e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-29267c34-1647-482b-9bce-53eef1ac2620,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-209f2f3b-e14c-470e-b080-1d46f5fca5e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-29267c34-1647-482b-9bce-53eef1ac2620,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-209f2f3b-e14c-470e-b080-1d46f5fca5e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-df698a74-264c-4085-89ec-b208e37f32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-3741e2a9-f4dd-41f7-947a-0f505030fd3a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-df698a74-264c-4085-89ec-b208e37f32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-3741e2a9-f4dd-41f7-947a-0f505030fd3a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-df698a74-264c-4085-89ec-b208e37f32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-3741e2a9-f4dd-41f7-947a-0f505030fd3a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-df698a74-264c-4085-89ec-b208e37f32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-3741e2a9-f4dd-41f7-947a-0f505030fd3a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-062d77ce-f11b-4c96-9627-ffeb4951d3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-cd701c32-0fae-4023-91b8-e828bc92cdb8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-cd701c32-0fae-4023-91b8-e828bc92cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-062d77ce-f11b-4c96-9627-ffeb4951d3cf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-062d77ce-f11b-4c96-9627-ffeb4951d3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-cd701c32-0fae-4023-91b8-e828bc92cdb8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-cd701c32-0fae-4023-91b8-e828bc92cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-062d77ce-f11b-4c96-9627-ffeb4951d3cf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-b3add74d-7a6f-437d-b64d-9b82c4c3667a,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-23708904-5994-4a1b-a06b-44ad4aea98fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33239,DS-23708904-5994-4a1b-a06b-44ad4aea98fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-b3add74d-7a6f-437d-b64d-9b82c4c3667a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-b3add74d-7a6f-437d-b64d-9b82c4c3667a,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-23708904-5994-4a1b-a06b-44ad4aea98fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33239,DS-23708904-5994-4a1b-a06b-44ad4aea98fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-b3add74d-7a6f-437d-b64d-9b82c4c3667a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-98de9616-7c4e-4da3-a6e4-41c4fdd16984,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-e0ba4c36-7fe3-4bcc-94f8-71ed7493765a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-e0ba4c36-7fe3-4bcc-94f8-71ed7493765a,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-98de9616-7c4e-4da3-a6e4-41c4fdd16984,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-98de9616-7c4e-4da3-a6e4-41c4fdd16984,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-e0ba4c36-7fe3-4bcc-94f8-71ed7493765a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-e0ba4c36-7fe3-4bcc-94f8-71ed7493765a,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-98de9616-7c4e-4da3-a6e4-41c4fdd16984,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46017,DS-59e0aaf3-ff2c-42e5-a447-49cad1329d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-efab17b9-05c7-4841-99ff-3ca1a5615895,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35314,DS-efab17b9-05c7-4841-99ff-3ca1a5615895,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-59e0aaf3-ff2c-42e5-a447-49cad1329d0e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46017,DS-59e0aaf3-ff2c-42e5-a447-49cad1329d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-efab17b9-05c7-4841-99ff-3ca1a5615895,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35314,DS-efab17b9-05c7-4841-99ff-3ca1a5615895,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-59e0aaf3-ff2c-42e5-a447-49cad1329d0e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-3dac519d-1bad-4469-afa1-803a711525d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-0580d38a-0ed1-4e81-bce6-c058874e0af0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-3dac519d-1bad-4469-afa1-803a711525d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-0580d38a-0ed1-4e81-bce6-c058874e0af0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-3dac519d-1bad-4469-afa1-803a711525d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-0580d38a-0ed1-4e81-bce6-c058874e0af0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-3dac519d-1bad-4469-afa1-803a711525d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-0580d38a-0ed1-4e81-bce6-c058874e0af0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44000,DS-86af4db8-90b7-4832-b063-c3d8c2b77c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-c3b58338-92e5-453b-8e6d-532836cfd40c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36374,DS-c3b58338-92e5-453b-8e6d-532836cfd40c,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-86af4db8-90b7-4832-b063-c3d8c2b77c5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44000,DS-86af4db8-90b7-4832-b063-c3d8c2b77c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-c3b58338-92e5-453b-8e6d-532836cfd40c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36374,DS-c3b58338-92e5-453b-8e6d-532836cfd40c,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-86af4db8-90b7-4832-b063-c3d8c2b77c5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2163
