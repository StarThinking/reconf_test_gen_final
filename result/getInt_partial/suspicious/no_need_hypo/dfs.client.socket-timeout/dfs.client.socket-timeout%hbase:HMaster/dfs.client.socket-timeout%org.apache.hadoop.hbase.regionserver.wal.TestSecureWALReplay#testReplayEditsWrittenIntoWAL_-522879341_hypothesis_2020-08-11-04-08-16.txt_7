reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-ed08d5c6-8101-4144-bf42-b9735933828b,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-ea965129-632b-483b-bfcf-99ff536e1071,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-ed08d5c6-8101-4144-bf42-b9735933828b,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-ea965129-632b-483b-bfcf-99ff536e1071,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-ed08d5c6-8101-4144-bf42-b9735933828b,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-ea965129-632b-483b-bfcf-99ff536e1071,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-ed08d5c6-8101-4144-bf42-b9735933828b,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-ea965129-632b-483b-bfcf-99ff536e1071,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-606e5d14-f6fe-4c73-b542-b027d642ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-a9b6fd49-a7bc-402c-aee0-bc6820c08143,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-606e5d14-f6fe-4c73-b542-b027d642ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-a9b6fd49-a7bc-402c-aee0-bc6820c08143,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-606e5d14-f6fe-4c73-b542-b027d642ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-a9b6fd49-a7bc-402c-aee0-bc6820c08143,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-606e5d14-f6fe-4c73-b542-b027d642ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-a9b6fd49-a7bc-402c-aee0-bc6820c08143,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-0dedd96c-37e1-4c55-a215-832511437036,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-c0bad3bd-4022-4aaf-886f-b1763f902368,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-0dedd96c-37e1-4c55-a215-832511437036,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-c0bad3bd-4022-4aaf-886f-b1763f902368,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-0dedd96c-37e1-4c55-a215-832511437036,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-c0bad3bd-4022-4aaf-886f-b1763f902368,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-0dedd96c-37e1-4c55-a215-832511437036,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-c0bad3bd-4022-4aaf-886f-b1763f902368,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-f0e5712a-235f-421b-9073-6f73ee9b94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-6a875448-012e-4006-8523-fb0c75a3002d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-f0e5712a-235f-421b-9073-6f73ee9b94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-6a875448-012e-4006-8523-fb0c75a3002d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-f0e5712a-235f-421b-9073-6f73ee9b94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-6a875448-012e-4006-8523-fb0c75a3002d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-f0e5712a-235f-421b-9073-6f73ee9b94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-6a875448-012e-4006-8523-fb0c75a3002d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34608,DS-f8244893-6ae4-4c90-9bc4-5b652307607a,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-cf7e9ddb-f582-499c-b4cd-6b2a5de316d5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-cf7e9ddb-f582-499c-b4cd-6b2a5de316d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-f8244893-6ae4-4c90-9bc4-5b652307607a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34608,DS-f8244893-6ae4-4c90-9bc4-5b652307607a,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-cf7e9ddb-f582-499c-b4cd-6b2a5de316d5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-cf7e9ddb-f582-499c-b4cd-6b2a5de316d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-f8244893-6ae4-4c90-9bc4-5b652307607a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35300,DS-8ade4211-bcdf-4047-a009-04803fd27b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-4314d72a-fc16-4ab7-9766-56f34380ff1f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42540,DS-4314d72a-fc16-4ab7-9766-56f34380ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-8ade4211-bcdf-4047-a009-04803fd27b2c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35300,DS-8ade4211-bcdf-4047-a009-04803fd27b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-4314d72a-fc16-4ab7-9766-56f34380ff1f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42540,DS-4314d72a-fc16-4ab7-9766-56f34380ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-8ade4211-bcdf-4047-a009-04803fd27b2c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-cfdc8ae1-48f9-4573-8eb1-837bebadb7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-49632d80-52be-4d92-9313-333594f73e6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-cfdc8ae1-48f9-4573-8eb1-837bebadb7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-49632d80-52be-4d92-9313-333594f73e6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-cfdc8ae1-48f9-4573-8eb1-837bebadb7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-49632d80-52be-4d92-9313-333594f73e6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-cfdc8ae1-48f9-4573-8eb1-837bebadb7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-49632d80-52be-4d92-9313-333594f73e6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-0e5b7223-2c29-4f31-bee3-31f8272b10f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-0f37a66f-bd1b-4f72-b5f6-2c88d62e0334,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-0e5b7223-2c29-4f31-bee3-31f8272b10f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-0f37a66f-bd1b-4f72-b5f6-2c88d62e0334,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-0e5b7223-2c29-4f31-bee3-31f8272b10f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-0f37a66f-bd1b-4f72-b5f6-2c88d62e0334,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-0e5b7223-2c29-4f31-bee3-31f8272b10f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-0f37a66f-bd1b-4f72-b5f6-2c88d62e0334,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-2e791482-aca2-4ead-b81c-cae47bb9a223,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-db302c77-a548-45e3-a20b-e62a63141a84,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42869,DS-db302c77-a548-45e3-a20b-e62a63141a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-2e791482-aca2-4ead-b81c-cae47bb9a223,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-2e791482-aca2-4ead-b81c-cae47bb9a223,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-db302c77-a548-45e3-a20b-e62a63141a84,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42869,DS-db302c77-a548-45e3-a20b-e62a63141a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-2e791482-aca2-4ead-b81c-cae47bb9a223,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-044131e6-45c5-47f2-a22e-b666b7f94a81,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-9d62f61c-17b3-4eea-9839-e4dd80ac3bc7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36328,DS-9d62f61c-17b3-4eea-9839-e4dd80ac3bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-044131e6-45c5-47f2-a22e-b666b7f94a81,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-044131e6-45c5-47f2-a22e-b666b7f94a81,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-9d62f61c-17b3-4eea-9839-e4dd80ac3bc7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36328,DS-9d62f61c-17b3-4eea-9839-e4dd80ac3bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-044131e6-45c5-47f2-a22e-b666b7f94a81,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2041
