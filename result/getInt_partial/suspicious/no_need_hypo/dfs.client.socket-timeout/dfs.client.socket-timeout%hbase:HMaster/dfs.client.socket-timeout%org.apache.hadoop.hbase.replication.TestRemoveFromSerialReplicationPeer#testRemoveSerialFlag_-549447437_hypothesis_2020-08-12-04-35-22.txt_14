reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: test timed out after 780 seconds
stackTrace: org.junit.runners.model.TestTimedOutException: test timed out after 780 seconds
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.hadoop.hbase.ipc.BlockingRpcCallback.get(BlockingRpcCallback.java:62)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:333)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$200(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:585)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$BlockingStub.mutate(ClientProtos.java:42798)
	at org.apache.hadoop.hbase.client.ClientServiceCallable.doMutate(ClientServiceCallable.java:55)
	at org.apache.hadoop.hbase.client.HTable$3.rpcCall(HTable.java:536)
	at org.apache.hadoop.hbase.client.HTable$3.rpcCall(HTable.java:531)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:127)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Waiting timed out after [30,000] msec Log roll has not finished yet
stackTrace: java.lang.AssertionError: Waiting timed out after [30,000] msec Log roll has not finished yet
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:203)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:137)
	at org.apache.hadoop.hbase.HBaseCommonTestingUtility.waitFor(HBaseCommonTestingUtility.java:251)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.rollAllWALs(SerialReplicationTestBase.java:169)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.tearDown(SerialReplicationTestBase.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Waiting timed out after [30,000] msec Not enough entries replicated
stackTrace: java.lang.AssertionError: Waiting timed out after [30,000] msec Not enough entries replicated
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:203)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:137)
	at org.apache.hadoop.hbase.HBaseCommonTestingUtility.waitFor(HBaseCommonTestingUtility.java:251)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.waitUntilReplicationDone(SerialReplicationTestBase.java:190)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: java.util.concurrent.TimeoutException: The procedure 12 is still running
stackTrace: org.apache.hadoop.hbase.exceptions.TimeoutIOException: java.util.concurrent.TimeoutException: The procedure 12 is still running
	at org.apache.hadoop.hbase.client.HBaseAdmin.get(HBaseAdmin.java:2203)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:642)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:617)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.createTable(SerialReplicationTestBase.java:247)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:102)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: The procedure 12 is still running
	at org.apache.hadoop.hbase.client.HBaseAdmin$ProcedureFuture.waitProcedureResult(HBaseAdmin.java:3566)
	at org.apache.hadoop.hbase.client.HBaseAdmin$ProcedureFuture.get(HBaseAdmin.java:3487)
	at org.apache.hadoop.hbase.client.HBaseAdmin.get(HBaseAdmin.java:2197)
	... 30 more



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: java.util.concurrent.TimeoutException: The procedure 9 is still running
stackTrace: org.apache.hadoop.hbase.exceptions.TimeoutIOException: java.util.concurrent.TimeoutException: The procedure 9 is still running
	at org.apache.hadoop.hbase.client.HBaseAdmin.get(HBaseAdmin.java:2203)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:642)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:617)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.createTable(SerialReplicationTestBase.java:247)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:102)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: The procedure 9 is still running
	at org.apache.hadoop.hbase.client.HBaseAdmin$ProcedureFuture.waitProcedureResult(HBaseAdmin.java:3566)
	at org.apache.hadoop.hbase.client.HBaseAdmin$ProcedureFuture.get(HBaseAdmin.java:3487)
	at org.apache.hadoop.hbase.client.HBaseAdmin.get(HBaseAdmin.java:2197)
	... 30 more



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40160,DS-a375d04d-25ff-4102-8e3d-e0c14fce3b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a07a46f3-12ea-4eae-a4cc-33e934b89ed6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40160,DS-a375d04d-25ff-4102-8e3d-e0c14fce3b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a07a46f3-12ea-4eae-a4cc-33e934b89ed6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40160,DS-a375d04d-25ff-4102-8e3d-e0c14fce3b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a07a46f3-12ea-4eae-a4cc-33e934b89ed6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40160,DS-a375d04d-25ff-4102-8e3d-e0c14fce3b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a07a46f3-12ea-4eae-a4cc-33e934b89ed6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-ac527aac-9e55-4c42-a493-6349f8324457,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-16217922-aadf-4d2a-897b-9353f1c7e0a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-ac527aac-9e55-4c42-a493-6349f8324457,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-16217922-aadf-4d2a-897b-9353f1c7e0a5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-ac527aac-9e55-4c42-a493-6349f8324457,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-16217922-aadf-4d2a-897b-9353f1c7e0a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-ac527aac-9e55-4c42-a493-6349f8324457,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-16217922-aadf-4d2a-897b-9353f1c7e0a5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Waiting timed out after [30,000] msec Not enough entries replicated
stackTrace: java.lang.AssertionError: Waiting timed out after [30,000] msec Not enough entries replicated
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:203)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:137)
	at org.apache.hadoop.hbase.HBaseCommonTestingUtility.waitFor(HBaseCommonTestingUtility.java:251)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.waitUntilReplicationDone(SerialReplicationTestBase.java:190)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Waiting timed out after [30,000] msec Not enough entries replicated
stackTrace: java.lang.AssertionError: Waiting timed out after [30,000] msec Not enough entries replicated
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:203)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:137)
	at org.apache.hadoop.hbase.HBaseCommonTestingUtility.waitFor(HBaseCommonTestingUtility.java:251)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.waitUntilReplicationDone(SerialReplicationTestBase.java:190)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43217,DS-0d57be5b-4d2c-4163-9b4a-dbeb1dc66169,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-f0702905-8c11-4e19-8e81-ec5a4210e632,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43217,DS-0d57be5b-4d2c-4163-9b4a-dbeb1dc66169,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-f0702905-8c11-4e19-8e81-ec5a4210e632,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43217,DS-0d57be5b-4d2c-4163-9b4a-dbeb1dc66169,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-f0702905-8c11-4e19-8e81-ec5a4210e632,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43217,DS-0d57be5b-4d2c-4163-9b4a-dbeb1dc66169,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-f0702905-8c11-4e19-8e81-ec5a4210e632,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-82ddf9cb-b12c-452c-950d-17f0cb5ccdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-e28cef06-8806-4a49-919e-d7881c80a6f6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-82ddf9cb-b12c-452c-950d-17f0cb5ccdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-e28cef06-8806-4a49-919e-d7881c80a6f6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-82ddf9cb-b12c-452c-950d-17f0cb5ccdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-e28cef06-8806-4a49-919e-d7881c80a6f6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-82ddf9cb-b12c-452c-950d-17f0cb5ccdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-e28cef06-8806-4a49-919e-d7881c80a6f6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-fd9063c7-0c24-4e75-bcbe-9911546663ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-21de5709-bc84-461e-8c42-139499511f38,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41567,DS-21de5709-bc84-461e-8c42-139499511f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-fd9063c7-0c24-4e75-bcbe-9911546663ee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-fd9063c7-0c24-4e75-bcbe-9911546663ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-21de5709-bc84-461e-8c42-139499511f38,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41567,DS-21de5709-bc84-461e-8c42-139499511f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-fd9063c7-0c24-4e75-bcbe-9911546663ee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45388,DS-d8926193-d6e8-4b32-ac98-256ff16fb173,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-38228e01-75be-41a5-add9-9d86170dd3d5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45388,DS-d8926193-d6e8-4b32-ac98-256ff16fb173,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-38228e01-75be-41a5-add9-9d86170dd3d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45388,DS-d8926193-d6e8-4b32-ac98-256ff16fb173,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-38228e01-75be-41a5-add9-9d86170dd3d5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45388,DS-d8926193-d6e8-4b32-ac98-256ff16fb173,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-38228e01-75be-41a5-add9-9d86170dd3d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33682,DS-8757d468-5db0-4ce4-b933-996cb99e99c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-4f5d5cab-3429-471e-a427-ad0ea0c2dda6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45198,DS-4f5d5cab-3429-471e-a427-ad0ea0c2dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-8757d468-5db0-4ce4-b933-996cb99e99c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33682,DS-8757d468-5db0-4ce4-b933-996cb99e99c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-4f5d5cab-3429-471e-a427-ad0ea0c2dda6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45198,DS-4f5d5cab-3429-471e-a427-ad0ea0c2dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-8757d468-5db0-4ce4-b933-996cb99e99c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-69e45df5-7d2e-4922-9495-088892f149cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-4277b0ea-12cc-4cf8-9d2f-29d71356bf06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-69e45df5-7d2e-4922-9495-088892f149cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-4277b0ea-12cc-4cf8-9d2f-29d71356bf06,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-69e45df5-7d2e-4922-9495-088892f149cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-4277b0ea-12cc-4cf8-9d2f-29d71356bf06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-69e45df5-7d2e-4922-9495-088892f149cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-4277b0ea-12cc-4cf8-9d2f-29d71356bf06,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Waiting timed out after [30,000] msec Not enough entries replicated
stackTrace: java.lang.AssertionError: Waiting timed out after [30,000] msec Not enough entries replicated
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:203)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:137)
	at org.apache.hadoop.hbase.HBaseCommonTestingUtility.waitFor(HBaseCommonTestingUtility.java:251)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.waitUntilReplicationDone(SerialReplicationTestBase.java:190)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40020,DS-79faeb7b-403e-493b-acc6-cf5f2f6c5180,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-17c90f8d-28f7-40ab-a550-88e0adba9b77,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38805,DS-17c90f8d-28f7-40ab-a550-88e0adba9b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-79faeb7b-403e-493b-acc6-cf5f2f6c5180,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40020,DS-79faeb7b-403e-493b-acc6-cf5f2f6c5180,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-17c90f8d-28f7-40ab-a550-88e0adba9b77,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38805,DS-17c90f8d-28f7-40ab-a550-88e0adba9b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-79faeb7b-403e-493b-acc6-cf5f2f6c5180,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-21231111-3cb4-40f7-808f-a15c289b5ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-dd2809f3-87c1-4723-8328-89b3b3b33911,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-dd2809f3-87c1-4723-8328-89b3b3b33911,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-21231111-3cb4-40f7-808f-a15c289b5ee8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-21231111-3cb4-40f7-808f-a15c289b5ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-dd2809f3-87c1-4723-8328-89b3b3b33911,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-dd2809f3-87c1-4723-8328-89b3b3b33911,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-21231111-3cb4-40f7-808f-a15c289b5ee8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42388,DS-a67c1b9d-0b1c-46ba-a3ad-fde42257e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-d40e55a5-0e26-433f-adee-818c953eedff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42388,DS-a67c1b9d-0b1c-46ba-a3ad-fde42257e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-d40e55a5-0e26-433f-adee-818c953eedff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42388,DS-a67c1b9d-0b1c-46ba-a3ad-fde42257e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-d40e55a5-0e26-433f-adee-818c953eedff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42388,DS-a67c1b9d-0b1c-46ba-a3ad-fde42257e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-d40e55a5-0e26-433f-adee-818c953eedff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41792,DS-29f76caf-79ee-4f38-9847-1eb4164cb0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-6bbc3f02-60ac-4513-a64d-452c6efc9371,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41792,DS-29f76caf-79ee-4f38-9847-1eb4164cb0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-6bbc3f02-60ac-4513-a64d-452c6efc9371,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41792,DS-29f76caf-79ee-4f38-9847-1eb4164cb0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-6bbc3f02-60ac-4513-a64d-452c6efc9371,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41792,DS-29f76caf-79ee-4f38-9847-1eb4164cb0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-6bbc3f02-60ac-4513-a64d-452c6efc9371,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Waiting timed out after [30,000] msec Not enough entries replicated
stackTrace: java.lang.AssertionError: Waiting timed out after [30,000] msec Not enough entries replicated
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:203)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:137)
	at org.apache.hadoop.hbase.HBaseCommonTestingUtility.waitFor(HBaseCommonTestingUtility.java:251)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.waitUntilReplicationDone(SerialReplicationTestBase.java:190)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-c867b979-e540-4089-8879-5c61e55656ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-f5a961f4-b990-4201-a5fa-3f8604f50be4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-c867b979-e540-4089-8879-5c61e55656ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-f5a961f4-b990-4201-a5fa-3f8604f50be4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-c867b979-e540-4089-8879-5c61e55656ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-f5a961f4-b990-4201-a5fa-3f8604f50be4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-c867b979-e540-4089-8879-5c61e55656ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-f5a961f4-b990-4201-a5fa-3f8604f50be4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-8de2c55a-4e43-49b7-83be-1d60436071a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-1d23b842-73c7-4f14-a1c7-572022f0275a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-8de2c55a-4e43-49b7-83be-1d60436071a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-1d23b842-73c7-4f14-a1c7-572022f0275a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-8de2c55a-4e43-49b7-83be-1d60436071a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-1d23b842-73c7-4f14-a1c7-572022f0275a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-8de2c55a-4e43-49b7-83be-1d60436071a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-1d23b842-73c7-4f14-a1c7-572022f0275a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-3076267f-7e70-401a-9928-5cf27b96c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-4cbaa41b-e8cd-4622-9969-34a076d6531b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-3076267f-7e70-401a-9928-5cf27b96c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-4cbaa41b-e8cd-4622-9969-34a076d6531b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-3076267f-7e70-401a-9928-5cf27b96c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-4cbaa41b-e8cd-4622-9969-34a076d6531b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-3076267f-7e70-401a-9928-5cf27b96c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-4cbaa41b-e8cd-4622-9969-34a076d6531b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-28255657-2edf-481c-b627-220744777c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-2949f654-ce77-4798-93b2-6f73356f4bd3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-2949f654-ce77-4798-93b2-6f73356f4bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-28255657-2edf-481c-b627-220744777c10,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-28255657-2edf-481c-b627-220744777c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-2949f654-ce77-4798-93b2-6f73356f4bd3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-2949f654-ce77-4798-93b2-6f73356f4bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-28255657-2edf-481c-b627-220744777c10,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-0d4abef4-ed2b-4a17-bf13-f747d752a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-8420a65e-0b5a-4104-b5a7-df49974742dd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-0d4abef4-ed2b-4a17-bf13-f747d752a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-8420a65e-0b5a-4104-b5a7-df49974742dd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-0d4abef4-ed2b-4a17-bf13-f747d752a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-8420a65e-0b5a-4104-b5a7-df49974742dd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-0d4abef4-ed2b-4a17-bf13-f747d752a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-8420a65e-0b5a-4104-b5a7-df49974742dd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-aca968e7-797f-4476-a81a-e51403db80e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-4f7c2f9e-1099-40ab-9795-1a80f8fe134f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-aca968e7-797f-4476-a81a-e51403db80e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-4f7c2f9e-1099-40ab-9795-1a80f8fe134f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-aca968e7-797f-4476-a81a-e51403db80e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-4f7c2f9e-1099-40ab-9795-1a80f8fe134f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-aca968e7-797f-4476-a81a-e51403db80e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-4f7c2f9e-1099-40ab-9795-1a80f8fe134f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33800,DS-58239999-76cc-4aa6-b994-defa46a18f43,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-743f86dc-e46b-409a-bc9c-385cf14ca656,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-743f86dc-e46b-409a-bc9c-385cf14ca656,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-58239999-76cc-4aa6-b994-defa46a18f43,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33800,DS-58239999-76cc-4aa6-b994-defa46a18f43,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-743f86dc-e46b-409a-bc9c-385cf14ca656,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-743f86dc-e46b-409a-bc9c-385cf14ca656,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-58239999-76cc-4aa6-b994-defa46a18f43,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45827,DS-11c4bcf1-ef88-440a-8d9d-48224080511c,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-5f7bd27a-7bf1-4252-9ecf-b2f0926789e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44939,DS-5f7bd27a-7bf1-4252-9ecf-b2f0926789e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-11c4bcf1-ef88-440a-8d9d-48224080511c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45827,DS-11c4bcf1-ef88-440a-8d9d-48224080511c,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-5f7bd27a-7bf1-4252-9ecf-b2f0926789e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44939,DS-5f7bd27a-7bf1-4252-9ecf-b2f0926789e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-11c4bcf1-ef88-440a-8d9d-48224080511c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42864,DS-cff44cf1-1cd7-4b20-8517-e5c75892fba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-6b129ea5-091d-4eb2-b059-a610d8862ba0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42864,DS-cff44cf1-1cd7-4b20-8517-e5c75892fba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-6b129ea5-091d-4eb2-b059-a610d8862ba0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42864,DS-cff44cf1-1cd7-4b20-8517-e5c75892fba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-6b129ea5-091d-4eb2-b059-a610d8862ba0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42864,DS-cff44cf1-1cd7-4b20-8517-e5c75892fba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-6b129ea5-091d-4eb2-b059-a610d8862ba0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-0eed4b8c-7888-4d22-a4a5-565baf1af320,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-1fe6f226-0deb-49c2-8b7e-0c99d41bf585,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-1fe6f226-0deb-49c2-8b7e-0c99d41bf585,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-0eed4b8c-7888-4d22-a4a5-565baf1af320,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-0eed4b8c-7888-4d22-a4a5-565baf1af320,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-1fe6f226-0deb-49c2-8b7e-0c99d41bf585,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-1fe6f226-0deb-49c2-8b7e-0c99d41bf585,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-0eed4b8c-7888-4d22-a4a5-565baf1af320,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-89c4c4a5-c8a6-4d24-8480-8f29484a3c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-ef4d0ea1-5c23-430a-ab99-a8bba8d159ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43881,DS-ef4d0ea1-5c23-430a-ab99-a8bba8d159ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-89c4c4a5-c8a6-4d24-8480-8f29484a3c5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-89c4c4a5-c8a6-4d24-8480-8f29484a3c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-ef4d0ea1-5c23-430a-ab99-a8bba8d159ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43881,DS-ef4d0ea1-5c23-430a-ab99-a8bba8d159ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-89c4c4a5-c8a6-4d24-8480-8f29484a3c5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-10753a64-e5ee-42a7-860e-3481e5d46073,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-804c50f0-f64e-4fe2-86d9-ba5ffa27c6c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-10753a64-e5ee-42a7-860e-3481e5d46073,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-804c50f0-f64e-4fe2-86d9-ba5ffa27c6c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-10753a64-e5ee-42a7-860e-3481e5d46073,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-804c50f0-f64e-4fe2-86d9-ba5ffa27c6c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-10753a64-e5ee-42a7-860e-3481e5d46073,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-804c50f0-f64e-4fe2-86d9-ba5ffa27c6c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-323bf456-774f-45f5-86ce-30e77aca4739,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-113c1f31-f554-4ba2-bbdc-8c2de86448ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-323bf456-774f-45f5-86ce-30e77aca4739,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-113c1f31-f554-4ba2-bbdc-8c2de86448ca,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-323bf456-774f-45f5-86ce-30e77aca4739,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-113c1f31-f554-4ba2-bbdc-8c2de86448ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-323bf456-774f-45f5-86ce-30e77aca4739,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-113c1f31-f554-4ba2-bbdc-8c2de86448ca,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Waiting timed out after [30,000] msec Not enough entries replicated
stackTrace: java.lang.AssertionError: Waiting timed out after [30,000] msec Not enough entries replicated
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:203)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:137)
	at org.apache.hadoop.hbase.HBaseCommonTestingUtility.waitFor(HBaseCommonTestingUtility.java:251)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.waitUntilReplicationDone(SerialReplicationTestBase.java:190)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-587fee63-9272-43a2-bbfd-8c41043980e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-6b77a004-c5a1-47b6-8584-9a1bbddb5e8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-587fee63-9272-43a2-bbfd-8c41043980e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-6b77a004-c5a1-47b6-8584-9a1bbddb5e8a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-587fee63-9272-43a2-bbfd-8c41043980e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-6b77a004-c5a1-47b6-8584-9a1bbddb5e8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-587fee63-9272-43a2-bbfd-8c41043980e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-6b77a004-c5a1-47b6-8584-9a1bbddb5e8a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-ce9f845b-c6a9-4bb7-a3ee-b27e35ab2405,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-3907428f-d2fa-4916-98c5-2886518b0e7c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-ce9f845b-c6a9-4bb7-a3ee-b27e35ab2405,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-3907428f-d2fa-4916-98c5-2886518b0e7c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-ce9f845b-c6a9-4bb7-a3ee-b27e35ab2405,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-3907428f-d2fa-4916-98c5-2886518b0e7c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-ce9f845b-c6a9-4bb7-a3ee-b27e35ab2405,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-3907428f-d2fa-4916-98c5-2886518b0e7c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-1471340e-9cd0-4089-bd67-96a1dfd9b390,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-c3b974cc-48b0-49df-8fac-9524cc769e25,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-1471340e-9cd0-4089-bd67-96a1dfd9b390,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-c3b974cc-48b0-49df-8fac-9524cc769e25,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-1471340e-9cd0-4089-bd67-96a1dfd9b390,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-c3b974cc-48b0-49df-8fac-9524cc769e25,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-1471340e-9cd0-4089-bd67-96a1dfd9b390,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-c3b974cc-48b0-49df-8fac-9524cc769e25,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Waiting timed out after [30,000] msec Not enough entries replicated
stackTrace: java.lang.AssertionError: Waiting timed out after [30,000] msec Not enough entries replicated
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:203)
	at org.apache.hadoop.hbase.Waiter.waitFor(Waiter.java:137)
	at org.apache.hadoop.hbase.HBaseCommonTestingUtility.waitFor(HBaseCommonTestingUtility.java:251)
	at org.apache.hadoop.hbase.replication.SerialReplicationTestBase.waitUntilReplicationDone(SerialReplicationTestBase.java:190)
	at org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer.testRemoveSerialFlag(TestRemoveFromSerialReplicationPeer.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44526,DS-07dcaa34-2e5b-475a-820b-32ef9fd71c35,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-18a65df7-e11e-45a7-b434-2555fbda5dda,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41900,DS-18a65df7-e11e-45a7-b434-2555fbda5dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-07dcaa34-2e5b-475a-820b-32ef9fd71c35,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44526,DS-07dcaa34-2e5b-475a-820b-32ef9fd71c35,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-18a65df7-e11e-45a7-b434-2555fbda5dda,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41900,DS-18a65df7-e11e-45a7-b434-2555fbda5dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-07dcaa34-2e5b-475a-820b-32ef9fd71c35,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39531,DS-3edbd88a-5af0-45bb-bc8e-8b22e43654d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-5a614a45-1a51-418e-8e75-50956cbf3d49,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45987,DS-5a614a45-1a51-418e-8e75-50956cbf3d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-3edbd88a-5af0-45bb-bc8e-8b22e43654d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39531,DS-3edbd88a-5af0-45bb-bc8e-8b22e43654d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-5a614a45-1a51-418e-8e75-50956cbf3d49,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45987,DS-5a614a45-1a51-418e-8e75-50956cbf3d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-3edbd88a-5af0-45bb-bc8e-8b22e43654d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46433,DS-b98414cb-ef6c-460b-91ca-88d04304f61e,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-9a7cb87f-37e3-486e-9f7b-394b6b63477d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-9a7cb87f-37e3-486e-9f7b-394b6b63477d,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-b98414cb-ef6c-460b-91ca-88d04304f61e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46433,DS-b98414cb-ef6c-460b-91ca-88d04304f61e,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-9a7cb87f-37e3-486e-9f7b-394b6b63477d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-9a7cb87f-37e3-486e-9f7b-394b6b63477d,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-b98414cb-ef6c-460b-91ca-88d04304f61e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45693,DS-a0864820-7a31-42b9-b1e1-9921839f19fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-574e08ba-3298-4af6-b542-61b3e9ed6652,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45693,DS-a0864820-7a31-42b9-b1e1-9921839f19fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-574e08ba-3298-4af6-b542-61b3e9ed6652,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45693,DS-a0864820-7a31-42b9-b1e1-9921839f19fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-574e08ba-3298-4af6-b542-61b3e9ed6652,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45693,DS-a0864820-7a31-42b9-b1e1-9921839f19fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-574e08ba-3298-4af6-b542-61b3e9ed6652,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-63764803-2003-494a-a096-7e18def6628e,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-2b08f705-893b-48b3-909a-4700fb14a392,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-63764803-2003-494a-a096-7e18def6628e,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-2b08f705-893b-48b3-909a-4700fb14a392,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-63764803-2003-494a-a096-7e18def6628e,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-2b08f705-893b-48b3-909a-4700fb14a392,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-63764803-2003-494a-a096-7e18def6628e,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-2b08f705-893b-48b3-909a-4700fb14a392,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-3b15912b-8c7c-47aa-8df6-ad3407d0d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-317f478b-78cb-49be-969c-0c13f621b6f3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-3b15912b-8c7c-47aa-8df6-ad3407d0d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-317f478b-78cb-49be-969c-0c13f621b6f3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-3b15912b-8c7c-47aa-8df6-ad3407d0d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-317f478b-78cb-49be-969c-0c13f621b6f3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-3b15912b-8c7c-47aa-8df6-ad3407d0d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-317f478b-78cb-49be-969c-0c13f621b6f3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-b4bada79-eeb6-4354-ba5f-61d8f8d32170,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-579192fa-ef0b-418f-b175-fc3ee39ef149,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-b4bada79-eeb6-4354-ba5f-61d8f8d32170,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-579192fa-ef0b-418f-b175-fc3ee39ef149,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-b4bada79-eeb6-4354-ba5f-61d8f8d32170,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-579192fa-ef0b-418f-b175-fc3ee39ef149,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-b4bada79-eeb6-4354-ba5f-61d8f8d32170,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-579192fa-ef0b-418f-b175-fc3ee39ef149,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39460,DS-62ee74bd-bb46-494a-a9ea-9d70483de907,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-7d4d6266-f8ef-4b2e-bf86-debfbbf48096,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39460,DS-62ee74bd-bb46-494a-a9ea-9d70483de907,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-7d4d6266-f8ef-4b2e-bf86-debfbbf48096,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39460,DS-62ee74bd-bb46-494a-a9ea-9d70483de907,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-7d4d6266-f8ef-4b2e-bf86-debfbbf48096,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39460,DS-62ee74bd-bb46-494a-a9ea-9d70483de907,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-7d4d6266-f8ef-4b2e-bf86-debfbbf48096,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestRemoveFromSerialReplicationPeer#testRemoveSerialFlag
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41246,DS-9a00a0c9-bcf0-401f-a8cd-ee85607de842,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-d12b51e8-1683-40ef-b749-763bb417eea0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43149,DS-d12b51e8-1683-40ef-b749-763bb417eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-9a00a0c9-bcf0-401f-a8cd-ee85607de842,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41246,DS-9a00a0c9-bcf0-401f-a8cd-ee85607de842,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-d12b51e8-1683-40ef-b749-763bb417eea0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43149,DS-d12b51e8-1683-40ef-b749-763bb417eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-9a00a0c9-bcf0-401f-a8cd-ee85607de842,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 13852
