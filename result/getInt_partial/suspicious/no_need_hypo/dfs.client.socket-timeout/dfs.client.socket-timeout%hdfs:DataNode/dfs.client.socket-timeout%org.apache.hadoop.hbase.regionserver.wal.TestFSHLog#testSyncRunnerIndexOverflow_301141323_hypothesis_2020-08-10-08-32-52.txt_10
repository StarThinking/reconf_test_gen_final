reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-ec12dcf1-b9da-4277-a7ed-d5899c06082e,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-091d8cd4-825e-4c4e-88c8-1ae1d0eee2e8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-ec12dcf1-b9da-4277-a7ed-d5899c06082e,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-091d8cd4-825e-4c4e-88c8-1ae1d0eee2e8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-ec12dcf1-b9da-4277-a7ed-d5899c06082e,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-091d8cd4-825e-4c4e-88c8-1ae1d0eee2e8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-ec12dcf1-b9da-4277-a7ed-d5899c06082e,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-091d8cd4-825e-4c4e-88c8-1ae1d0eee2e8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-04185418-e8d0-425f-8460-ded7af15ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-2d02fc8e-b848-44ae-aba8-b94e8e3b1004,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-04185418-e8d0-425f-8460-ded7af15ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-2d02fc8e-b848-44ae-aba8-b94e8e3b1004,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-04185418-e8d0-425f-8460-ded7af15ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-2d02fc8e-b848-44ae-aba8-b94e8e3b1004,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-04185418-e8d0-425f-8460-ded7af15ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-2d02fc8e-b848-44ae-aba8-b94e8e3b1004,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-dc509fd3-c26a-41d4-abba-6405f4f74110,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-b36074f4-5443-48ce-b8b2-d45636cbb0a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-dc509fd3-c26a-41d4-abba-6405f4f74110,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-b36074f4-5443-48ce-b8b2-d45636cbb0a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-dc509fd3-c26a-41d4-abba-6405f4f74110,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-b36074f4-5443-48ce-b8b2-d45636cbb0a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-dc509fd3-c26a-41d4-abba-6405f4f74110,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-b36074f4-5443-48ce-b8b2-d45636cbb0a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-bb17b4c8-d705-4ee1-8f78-a66462eb1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-9e11137a-fb99-40e0-84a2-49e5cda20a49,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-bb17b4c8-d705-4ee1-8f78-a66462eb1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-9e11137a-fb99-40e0-84a2-49e5cda20a49,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-bb17b4c8-d705-4ee1-8f78-a66462eb1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-9e11137a-fb99-40e0-84a2-49e5cda20a49,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-bb17b4c8-d705-4ee1-8f78-a66462eb1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-9e11137a-fb99-40e0-84a2-49e5cda20a49,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-7d460b30-36ed-473c-b0a0-58d725f7f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-897c568c-9d0c-4c61-959c-300bdb508608,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-7d460b30-36ed-473c-b0a0-58d725f7f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-897c568c-9d0c-4c61-959c-300bdb508608,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-7d460b30-36ed-473c-b0a0-58d725f7f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-897c568c-9d0c-4c61-959c-300bdb508608,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-7d460b30-36ed-473c-b0a0-58d725f7f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-897c568c-9d0c-4c61-959c-300bdb508608,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38847,DS-d24fedd2-c774-4748-8e0c-40b03b06ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-deddf736-1393-47c4-8bcc-bba31083f348,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-deddf736-1393-47c4-8bcc-bba31083f348,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-d24fedd2-c774-4748-8e0c-40b03b06ee3d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38847,DS-d24fedd2-c774-4748-8e0c-40b03b06ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-deddf736-1393-47c4-8bcc-bba31083f348,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-deddf736-1393-47c4-8bcc-bba31083f348,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-d24fedd2-c774-4748-8e0c-40b03b06ee3d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-38aa9f31-8e71-48c8-a942-9b417a01da76,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-6c50b8b6-51a5-49f7-87a7-3aeb739161e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-38aa9f31-8e71-48c8-a942-9b417a01da76,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-6c50b8b6-51a5-49f7-87a7-3aeb739161e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-38aa9f31-8e71-48c8-a942-9b417a01da76,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-6c50b8b6-51a5-49f7-87a7-3aeb739161e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-38aa9f31-8e71-48c8-a942-9b417a01da76,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-6c50b8b6-51a5-49f7-87a7-3aeb739161e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45087,DS-ec58663e-2db2-4d74-9d8c-34e410cf9138,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-41a8303d-7ba1-4e98-b438-5770b2ea0be6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45087,DS-ec58663e-2db2-4d74-9d8c-34e410cf9138,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-41a8303d-7ba1-4e98-b438-5770b2ea0be6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45087,DS-ec58663e-2db2-4d74-9d8c-34e410cf9138,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-41a8303d-7ba1-4e98-b438-5770b2ea0be6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45087,DS-ec58663e-2db2-4d74-9d8c-34e410cf9138,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-41a8303d-7ba1-4e98-b438-5770b2ea0be6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-8597c6d9-1be5-40a4-9f42-8512a2d13a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-b1c68882-e70e-4c9e-bd58-112708e3076e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-8597c6d9-1be5-40a4-9f42-8512a2d13a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-b1c68882-e70e-4c9e-bd58-112708e3076e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-8597c6d9-1be5-40a4-9f42-8512a2d13a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-b1c68882-e70e-4c9e-bd58-112708e3076e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-8597c6d9-1be5-40a4-9f42-8512a2d13a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-b1c68882-e70e-4c9e-bd58-112708e3076e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-be252a7d-7137-4359-a531-8565d4d005f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-34035b7d-7a8a-4e47-970c-f4a7d41a76ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-be252a7d-7137-4359-a531-8565d4d005f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-34035b7d-7a8a-4e47-970c-f4a7d41a76ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-be252a7d-7137-4359-a531-8565d4d005f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-34035b7d-7a8a-4e47-970c-f4a7d41a76ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-be252a7d-7137-4359-a531-8565d4d005f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-34035b7d-7a8a-4e47-970c-f4a7d41a76ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1729
