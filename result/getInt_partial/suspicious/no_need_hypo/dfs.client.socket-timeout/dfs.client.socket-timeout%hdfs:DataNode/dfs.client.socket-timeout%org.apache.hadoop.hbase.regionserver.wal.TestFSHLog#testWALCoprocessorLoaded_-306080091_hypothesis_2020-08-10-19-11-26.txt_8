reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-01b10702-f510-41b7-bc1e-755eff953d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-f76da464-9d82-4719-95b5-30753cd843c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-01b10702-f510-41b7-bc1e-755eff953d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-f76da464-9d82-4719-95b5-30753cd843c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-01b10702-f510-41b7-bc1e-755eff953d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-f76da464-9d82-4719-95b5-30753cd843c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-01b10702-f510-41b7-bc1e-755eff953d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-f76da464-9d82-4719-95b5-30753cd843c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44096,DS-65f82f55-dadb-494f-947d-af39922ce82a,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-f910f016-740a-40ca-825b-98e530cef559,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-f910f016-740a-40ca-825b-98e530cef559,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-65f82f55-dadb-494f-947d-af39922ce82a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44096,DS-65f82f55-dadb-494f-947d-af39922ce82a,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-f910f016-740a-40ca-825b-98e530cef559,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-f910f016-740a-40ca-825b-98e530cef559,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-65f82f55-dadb-494f-947d-af39922ce82a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-2316b6cc-1530-4a07-b7dd-3664ce1118c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-5c4b6562-1a1c-408a-809f-3d64f66f6ed1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-5c4b6562-1a1c-408a-809f-3d64f66f6ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-2316b6cc-1530-4a07-b7dd-3664ce1118c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-2316b6cc-1530-4a07-b7dd-3664ce1118c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-5c4b6562-1a1c-408a-809f-3d64f66f6ed1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-5c4b6562-1a1c-408a-809f-3d64f66f6ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-2316b6cc-1530-4a07-b7dd-3664ce1118c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36278,DS-cd858710-34c5-4abe-8a5e-1829bd2464bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-e2322e07-0ac0-48de-99cf-b56f9f88bf03,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36278,DS-cd858710-34c5-4abe-8a5e-1829bd2464bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-e2322e07-0ac0-48de-99cf-b56f9f88bf03,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36278,DS-cd858710-34c5-4abe-8a5e-1829bd2464bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-e2322e07-0ac0-48de-99cf-b56f9f88bf03,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36278,DS-cd858710-34c5-4abe-8a5e-1829bd2464bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-e2322e07-0ac0-48de-99cf-b56f9f88bf03,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-12708118-9468-4b2d-940f-9dcdce19b40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-48b22f23-1aee-4b45-9d7c-df89a91b0202,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37269,DS-48b22f23-1aee-4b45-9d7c-df89a91b0202,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-12708118-9468-4b2d-940f-9dcdce19b40e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-12708118-9468-4b2d-940f-9dcdce19b40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-48b22f23-1aee-4b45-9d7c-df89a91b0202,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37269,DS-48b22f23-1aee-4b45-9d7c-df89a91b0202,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-12708118-9468-4b2d-940f-9dcdce19b40e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-6c4ed7cc-8d8f-44e4-9e92-9584d788364b,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-188fe867-adaf-49d1-8178-08271c170663,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-6c4ed7cc-8d8f-44e4-9e92-9584d788364b,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-188fe867-adaf-49d1-8178-08271c170663,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-6c4ed7cc-8d8f-44e4-9e92-9584d788364b,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-188fe867-adaf-49d1-8178-08271c170663,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-6c4ed7cc-8d8f-44e4-9e92-9584d788364b,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-188fe867-adaf-49d1-8178-08271c170663,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46552,DS-018e72e4-bb99-45e9-adad-b50cbe3a604f,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-9942bfc4-5b60-47b3-b69e-e3eeb6394e61,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-9942bfc4-5b60-47b3-b69e-e3eeb6394e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-018e72e4-bb99-45e9-adad-b50cbe3a604f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46552,DS-018e72e4-bb99-45e9-adad-b50cbe3a604f,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-9942bfc4-5b60-47b3-b69e-e3eeb6394e61,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-9942bfc4-5b60-47b3-b69e-e3eeb6394e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-018e72e4-bb99-45e9-adad-b50cbe3a604f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-4e322a13-1b31-4e6b-a2c7-dc7776342e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-8d6fe779-fe41-445c-9ecc-556370d30adc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43638,DS-8d6fe779-fe41-445c-9ecc-556370d30adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-4e322a13-1b31-4e6b-a2c7-dc7776342e4a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-4e322a13-1b31-4e6b-a2c7-dc7776342e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-8d6fe779-fe41-445c-9ecc-556370d30adc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43638,DS-8d6fe779-fe41-445c-9ecc-556370d30adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-4e322a13-1b31-4e6b-a2c7-dc7776342e4a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-59257575-cfbd-4f7f-b98c-49672ec6d377,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-fc6acabd-0d35-4a2a-8b54-3195c462d48e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39254,DS-fc6acabd-0d35-4a2a-8b54-3195c462d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-59257575-cfbd-4f7f-b98c-49672ec6d377,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-59257575-cfbd-4f7f-b98c-49672ec6d377,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-fc6acabd-0d35-4a2a-8b54-3195c462d48e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39254,DS-fc6acabd-0d35-4a2a-8b54-3195c462d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-59257575-cfbd-4f7f-b98c-49672ec6d377,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39356,DS-86b566b8-d3cb-4b2d-adac-a9b55d27eb35,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-ae86b116-500f-4840-bb17-6e79de320a0a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35858,DS-ae86b116-500f-4840-bb17-6e79de320a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-86b566b8-d3cb-4b2d-adac-a9b55d27eb35,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39356,DS-86b566b8-d3cb-4b2d-adac-a9b55d27eb35,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-ae86b116-500f-4840-bb17-6e79de320a0a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35858,DS-ae86b116-500f-4840-bb17-6e79de320a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-86b566b8-d3cb-4b2d-adac-a9b55d27eb35,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1361
