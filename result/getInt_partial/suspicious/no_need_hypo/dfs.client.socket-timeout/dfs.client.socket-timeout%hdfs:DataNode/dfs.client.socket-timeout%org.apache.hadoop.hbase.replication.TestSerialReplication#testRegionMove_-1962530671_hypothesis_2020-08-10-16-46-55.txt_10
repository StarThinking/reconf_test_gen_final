reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-766c80c8-3bdf-4ba3-b6fb-d101eec27fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-adba6886-8a00-4df6-b1f0-64079420dd58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-766c80c8-3bdf-4ba3-b6fb-d101eec27fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-adba6886-8a00-4df6-b1f0-64079420dd58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-766c80c8-3bdf-4ba3-b6fb-d101eec27fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-adba6886-8a00-4df6-b1f0-64079420dd58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-766c80c8-3bdf-4ba3-b6fb-d101eec27fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-adba6886-8a00-4df6-b1f0-64079420dd58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-dd83afbb-5acd-47f2-ac89-feb3110cbbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-2f54643e-9f29-467a-9c37-1ee6561e0453,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-dd83afbb-5acd-47f2-ac89-feb3110cbbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-2f54643e-9f29-467a-9c37-1ee6561e0453,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-dd83afbb-5acd-47f2-ac89-feb3110cbbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-2f54643e-9f29-467a-9c37-1ee6561e0453,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-dd83afbb-5acd-47f2-ac89-feb3110cbbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-2f54643e-9f29-467a-9c37-1ee6561e0453,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-aff81d7f-abac-42a1-b22b-b348cd55f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-435ccf6e-3bb5-4a8c-9a9a-44247c03bab0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-aff81d7f-abac-42a1-b22b-b348cd55f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-435ccf6e-3bb5-4a8c-9a9a-44247c03bab0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-aff81d7f-abac-42a1-b22b-b348cd55f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-435ccf6e-3bb5-4a8c-9a9a-44247c03bab0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-aff81d7f-abac-42a1-b22b-b348cd55f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-435ccf6e-3bb5-4a8c-9a9a-44247c03bab0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-c68e0072-905e-43f2-822a-55eebdcb7fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-573bd2f7-7737-4a5c-a2ee-b77a7cc6a57f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-c68e0072-905e-43f2-822a-55eebdcb7fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-573bd2f7-7737-4a5c-a2ee-b77a7cc6a57f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-c68e0072-905e-43f2-822a-55eebdcb7fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-573bd2f7-7737-4a5c-a2ee-b77a7cc6a57f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-c68e0072-905e-43f2-822a-55eebdcb7fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-573bd2f7-7737-4a5c-a2ee-b77a7cc6a57f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-8c84d50d-bce5-41f3-93d8-9b1f83711b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-60fbfba5-a0e0-456f-8687-e99b3dc6d8eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-8c84d50d-bce5-41f3-93d8-9b1f83711b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-60fbfba5-a0e0-456f-8687-e99b3dc6d8eb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-8c84d50d-bce5-41f3-93d8-9b1f83711b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-60fbfba5-a0e0-456f-8687-e99b3dc6d8eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-8c84d50d-bce5-41f3-93d8-9b1f83711b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-60fbfba5-a0e0-456f-8687-e99b3dc6d8eb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-de57e00a-4dc0-41f2-a8a6-18b02eb7296e,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-8794eb5f-cd8d-411f-a9f2-c169ea215c41,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-de57e00a-4dc0-41f2-a8a6-18b02eb7296e,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-8794eb5f-cd8d-411f-a9f2-c169ea215c41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-de57e00a-4dc0-41f2-a8a6-18b02eb7296e,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-8794eb5f-cd8d-411f-a9f2-c169ea215c41,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-de57e00a-4dc0-41f2-a8a6-18b02eb7296e,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-8794eb5f-cd8d-411f-a9f2-c169ea215c41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-1c5c8828-e52d-4eb3-a975-7f2ff109d762,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-05e8034f-916d-439a-9a34-3d56746cd824,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-1c5c8828-e52d-4eb3-a975-7f2ff109d762,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-05e8034f-916d-439a-9a34-3d56746cd824,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-1c5c8828-e52d-4eb3-a975-7f2ff109d762,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-05e8034f-916d-439a-9a34-3d56746cd824,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-1c5c8828-e52d-4eb3-a975-7f2ff109d762,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-05e8034f-916d-439a-9a34-3d56746cd824,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-a02d4ccc-978b-4f47-977a-ba2732505443,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-3ef8a8d1-dcb4-40d3-8e9c-ef99af523ef2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-3ef8a8d1-dcb4-40d3-8e9c-ef99af523ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-a02d4ccc-978b-4f47-977a-ba2732505443,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-a02d4ccc-978b-4f47-977a-ba2732505443,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-3ef8a8d1-dcb4-40d3-8e9c-ef99af523ef2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-3ef8a8d1-dcb4-40d3-8e9c-ef99af523ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-a02d4ccc-978b-4f47-977a-ba2732505443,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36531,DS-78513338-1282-4dc7-af82-a38219272e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-a21c9cfc-853a-4cee-9763-c823b15a6c06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36616,DS-a21c9cfc-853a-4cee-9763-c823b15a6c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-78513338-1282-4dc7-af82-a38219272e5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36531,DS-78513338-1282-4dc7-af82-a38219272e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-a21c9cfc-853a-4cee-9763-c823b15a6c06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36616,DS-a21c9cfc-853a-4cee-9763-c823b15a6c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-78513338-1282-4dc7-af82-a38219272e5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRegionMove
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-5a34c787-798d-436c-8175-729b91c45383,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-f730378a-ff8a-4c84-943f-fa5adddeb002,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-5a34c787-798d-436c-8175-729b91c45383,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-f730378a-ff8a-4c84-943f-fa5adddeb002,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-5a34c787-798d-436c-8175-729b91c45383,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-f730378a-ff8a-4c84-943f-fa5adddeb002,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-5a34c787-798d-436c-8175-729b91c45383,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-f730378a-ff8a-4c84-943f-fa5adddeb002,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2160
