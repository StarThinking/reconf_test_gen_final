reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-71e10fbd-1bde-4fd6-920a-d8a4f4c55809,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-026dc31b-a36d-446f-b066-caeee27d5723,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-71e10fbd-1bde-4fd6-920a-d8a4f4c55809,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-026dc31b-a36d-446f-b066-caeee27d5723,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-71e10fbd-1bde-4fd6-920a-d8a4f4c55809,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-026dc31b-a36d-446f-b066-caeee27d5723,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-71e10fbd-1bde-4fd6-920a-d8a4f4c55809,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-026dc31b-a36d-446f-b066-caeee27d5723,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-b8faede4-dbb9-47fc-b70b-f957b7470c16,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-b95e4559-420d-4d5e-b843-24ff56f06400,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-b8faede4-dbb9-47fc-b70b-f957b7470c16,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-b95e4559-420d-4d5e-b843-24ff56f06400,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-b8faede4-dbb9-47fc-b70b-f957b7470c16,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-b95e4559-420d-4d5e-b843-24ff56f06400,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-b8faede4-dbb9-47fc-b70b-f957b7470c16,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-b95e4559-420d-4d5e-b843-24ff56f06400,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-5de3a866-cc0d-4513-be7c-c6ae1883e90f,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-c2a7e528-c3db-499e-8311-4250e26ffc53,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-5de3a866-cc0d-4513-be7c-c6ae1883e90f,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-c2a7e528-c3db-499e-8311-4250e26ffc53,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-5de3a866-cc0d-4513-be7c-c6ae1883e90f,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-c2a7e528-c3db-499e-8311-4250e26ffc53,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-5de3a866-cc0d-4513-be7c-c6ae1883e90f,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-c2a7e528-c3db-499e-8311-4250e26ffc53,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38750,DS-604897d8-686e-4610-9f37-fa1c2ef8d01a,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-a6c0f7fe-94e4-4342-8ce1-314596f1b545,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-a6c0f7fe-94e4-4342-8ce1-314596f1b545,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-604897d8-686e-4610-9f37-fa1c2ef8d01a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38750,DS-604897d8-686e-4610-9f37-fa1c2ef8d01a,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-a6c0f7fe-94e4-4342-8ce1-314596f1b545,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-a6c0f7fe-94e4-4342-8ce1-314596f1b545,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-604897d8-686e-4610-9f37-fa1c2ef8d01a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44149,DS-13a6efb2-6107-4a99-aa1d-0cc76174673a,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-2ac3f67f-79c2-42f2-b514-9746e7bdcef0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44149,DS-13a6efb2-6107-4a99-aa1d-0cc76174673a,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-2ac3f67f-79c2-42f2-b514-9746e7bdcef0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44149,DS-13a6efb2-6107-4a99-aa1d-0cc76174673a,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-2ac3f67f-79c2-42f2-b514-9746e7bdcef0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44149,DS-13a6efb2-6107-4a99-aa1d-0cc76174673a,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-2ac3f67f-79c2-42f2-b514-9746e7bdcef0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42123,DS-c9adbee3-129d-4c53-8d4a-dd73ad24213f,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-3b8de1c2-7eb8-40a6-b80e-dfad91f10aa1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42123,DS-c9adbee3-129d-4c53-8d4a-dd73ad24213f,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-3b8de1c2-7eb8-40a6-b80e-dfad91f10aa1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42123,DS-c9adbee3-129d-4c53-8d4a-dd73ad24213f,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-3b8de1c2-7eb8-40a6-b80e-dfad91f10aa1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42123,DS-c9adbee3-129d-4c53-8d4a-dd73ad24213f,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-3b8de1c2-7eb8-40a6-b80e-dfad91f10aa1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-54598c4e-1068-4214-b02b-5a42edb69adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-edc0c276-5ad2-4e92-9ac6-8c16670ce2f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-54598c4e-1068-4214-b02b-5a42edb69adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-edc0c276-5ad2-4e92-9ac6-8c16670ce2f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-54598c4e-1068-4214-b02b-5a42edb69adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-edc0c276-5ad2-4e92-9ac6-8c16670ce2f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-54598c4e-1068-4214-b02b-5a42edb69adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-edc0c276-5ad2-4e92-9ac6-8c16670ce2f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-e266fdb3-8923-4c14-9de5-2ec0cef4fb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-ba614b25-0cdb-40a7-a6b0-552c9a19f27a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45687,DS-ba614b25-0cdb-40a7-a6b0-552c9a19f27a,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-e266fdb3-8923-4c14-9de5-2ec0cef4fb2a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-e266fdb3-8923-4c14-9de5-2ec0cef4fb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-ba614b25-0cdb-40a7-a6b0-552c9a19f27a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45687,DS-ba614b25-0cdb-40a7-a6b0-552c9a19f27a,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-e266fdb3-8923-4c14-9de5-2ec0cef4fb2a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-3be33f39-6526-4e95-b77b-78de516d78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-a7390314-a9e2-4b1d-8d4c-f0ac7fe6cea7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-3be33f39-6526-4e95-b77b-78de516d78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-a7390314-a9e2-4b1d-8d4c-f0ac7fe6cea7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-3be33f39-6526-4e95-b77b-78de516d78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-a7390314-a9e2-4b1d-8d4c-f0ac7fe6cea7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-3be33f39-6526-4e95-b77b-78de516d78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-a7390314-a9e2-4b1d-8d4c-f0ac7fe6cea7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42377,DS-595f11c2-4824-437d-ac1c-76237b65d140,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-606107f6-9d2a-4994-8118-a893e80a27cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42377,DS-595f11c2-4824-437d-ac1c-76237b65d140,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-606107f6-9d2a-4994-8118-a893e80a27cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42377,DS-595f11c2-4824-437d-ac1c-76237b65d140,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-606107f6-9d2a-4994-8118-a893e80a27cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42377,DS-595f11c2-4824-437d-ac1c-76237b65d140,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-606107f6-9d2a-4994-8118-a893e80a27cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1341
