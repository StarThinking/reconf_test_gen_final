reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34365,DS-c345f954-048e-4ec5-a9dd-c578b6c867f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-b6af21b2-c5b7-4d1f-ad5d-3f0864f5a05f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-b6af21b2-c5b7-4d1f-ad5d-3f0864f5a05f,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-c345f954-048e-4ec5-a9dd-c578b6c867f5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34365,DS-c345f954-048e-4ec5-a9dd-c578b6c867f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-b6af21b2-c5b7-4d1f-ad5d-3f0864f5a05f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-b6af21b2-c5b7-4d1f-ad5d-3f0864f5a05f,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-c345f954-048e-4ec5-a9dd-c578b6c867f5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-3221a3ba-1eee-4c13-a006-bd6dc62d9890,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-c4560a77-117b-4987-9956-7968ddd79dfc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-3221a3ba-1eee-4c13-a006-bd6dc62d9890,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-c4560a77-117b-4987-9956-7968ddd79dfc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-3221a3ba-1eee-4c13-a006-bd6dc62d9890,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-c4560a77-117b-4987-9956-7968ddd79dfc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-3221a3ba-1eee-4c13-a006-bd6dc62d9890,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-c4560a77-117b-4987-9956-7968ddd79dfc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-76a29e7e-5dd8-4400-9554-6bf867f4b752,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-97668745-9267-4d62-838f-a10f40e2f011,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-97668745-9267-4d62-838f-a10f40e2f011,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-76a29e7e-5dd8-4400-9554-6bf867f4b752,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-76a29e7e-5dd8-4400-9554-6bf867f4b752,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-97668745-9267-4d62-838f-a10f40e2f011,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-97668745-9267-4d62-838f-a10f40e2f011,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-76a29e7e-5dd8-4400-9554-6bf867f4b752,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40621,DS-6750dcae-f2d2-48b1-a83d-07b888f8af29,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-a313483a-4294-4239-818a-60a855275055,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40621,DS-6750dcae-f2d2-48b1-a83d-07b888f8af29,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-a313483a-4294-4239-818a-60a855275055,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40621,DS-6750dcae-f2d2-48b1-a83d-07b888f8af29,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-a313483a-4294-4239-818a-60a855275055,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40621,DS-6750dcae-f2d2-48b1-a83d-07b888f8af29,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-a313483a-4294-4239-818a-60a855275055,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43944,DS-c252a522-8719-4a30-ad2e-6bba25ebe65c,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-092fa6bb-c30f-4f6f-966b-8685880906bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35288,DS-092fa6bb-c30f-4f6f-966b-8685880906bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-c252a522-8719-4a30-ad2e-6bba25ebe65c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43944,DS-c252a522-8719-4a30-ad2e-6bba25ebe65c,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-092fa6bb-c30f-4f6f-966b-8685880906bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35288,DS-092fa6bb-c30f-4f6f-966b-8685880906bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-c252a522-8719-4a30-ad2e-6bba25ebe65c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-92ac821d-5681-4733-a13e-5acbf5a3083e,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-f594bfad-b2ff-4d63-b3ee-40c816272b01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-92ac821d-5681-4733-a13e-5acbf5a3083e,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-f594bfad-b2ff-4d63-b3ee-40c816272b01,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-92ac821d-5681-4733-a13e-5acbf5a3083e,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-f594bfad-b2ff-4d63-b3ee-40c816272b01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-92ac821d-5681-4733-a13e-5acbf5a3083e,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-f594bfad-b2ff-4d63-b3ee-40c816272b01,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-4fa5a500-a042-4b06-af45-3563fa8b34b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-ba389f32-3987-4d63-b571-bde7ef4d20ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-4fa5a500-a042-4b06-af45-3563fa8b34b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-ba389f32-3987-4d63-b571-bde7ef4d20ae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-4fa5a500-a042-4b06-af45-3563fa8b34b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-ba389f32-3987-4d63-b571-bde7ef4d20ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-4fa5a500-a042-4b06-af45-3563fa8b34b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-ba389f32-3987-4d63-b571-bde7ef4d20ae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-06b39164-2cdc-4e17-81f6-c5356d2ef887,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-b5f67f15-1c67-4a98-b8e6-efdc39358907,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-06b39164-2cdc-4e17-81f6-c5356d2ef887,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-b5f67f15-1c67-4a98-b8e6-efdc39358907,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-06b39164-2cdc-4e17-81f6-c5356d2ef887,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-b5f67f15-1c67-4a98-b8e6-efdc39358907,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-06b39164-2cdc-4e17-81f6-c5356d2ef887,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-b5f67f15-1c67-4a98-b8e6-efdc39358907,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-969aa7e8-1e7b-4e93-9e17-1f4c827ae192,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-9366d849-b116-4326-9326-9ce499705a6a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-969aa7e8-1e7b-4e93-9e17-1f4c827ae192,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-9366d849-b116-4326-9326-9ce499705a6a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-969aa7e8-1e7b-4e93-9e17-1f4c827ae192,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-9366d849-b116-4326-9326-9ce499705a6a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-969aa7e8-1e7b-4e93-9e17-1f4c827ae192,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-9366d849-b116-4326-9326-9ce499705a6a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36890,DS-d236dd8a-dc72-4a70-8523-48d7cd0c86b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-85728297-9a57-4fd8-bfc0-81af4de22d16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36890,DS-d236dd8a-dc72-4a70-8523-48d7cd0c86b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-85728297-9a57-4fd8-bfc0-81af4de22d16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36890,DS-d236dd8a-dc72-4a70-8523-48d7cd0c86b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-85728297-9a57-4fd8-bfc0-81af4de22d16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36890,DS-d236dd8a-dc72-4a70-8523-48d7cd0c86b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-85728297-9a57-4fd8-bfc0-81af4de22d16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1331
