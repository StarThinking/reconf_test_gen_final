reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37678,DS-f50b416d-9013-4662-9820-0372c663d270,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-98ee86a4-3d6f-425c-b92a-84a9a7e78d6a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44326,DS-98ee86a4-3d6f-425c-b92a-84a9a7e78d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-f50b416d-9013-4662-9820-0372c663d270,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37678,DS-f50b416d-9013-4662-9820-0372c663d270,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-98ee86a4-3d6f-425c-b92a-84a9a7e78d6a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44326,DS-98ee86a4-3d6f-425c-b92a-84a9a7e78d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-f50b416d-9013-4662-9820-0372c663d270,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41882,DS-a57c7a5b-02e8-4ea2-8225-fbce583171c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-30eae50b-76f6-404f-b206-080ead0166f3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34307,DS-30eae50b-76f6-404f-b206-080ead0166f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-a57c7a5b-02e8-4ea2-8225-fbce583171c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41882,DS-a57c7a5b-02e8-4ea2-8225-fbce583171c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-30eae50b-76f6-404f-b206-080ead0166f3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34307,DS-30eae50b-76f6-404f-b206-080ead0166f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-a57c7a5b-02e8-4ea2-8225-fbce583171c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-a5f227a4-c6b6-45be-9eff-0740f1dcadd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-732ce1a2-8412-44c3-aa38-a67cf3979504,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33148,DS-732ce1a2-8412-44c3-aa38-a67cf3979504,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-a5f227a4-c6b6-45be-9eff-0740f1dcadd4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-a5f227a4-c6b6-45be-9eff-0740f1dcadd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-732ce1a2-8412-44c3-aa38-a67cf3979504,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33148,DS-732ce1a2-8412-44c3-aa38-a67cf3979504,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-a5f227a4-c6b6-45be-9eff-0740f1dcadd4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44809,DS-eb5c18ca-5a4c-48f7-bbb9-c536b9471c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-40219dc2-70c8-4b47-a3bd-99ddff8b6b0d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44809,DS-eb5c18ca-5a4c-48f7-bbb9-c536b9471c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-40219dc2-70c8-4b47-a3bd-99ddff8b6b0d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44809,DS-eb5c18ca-5a4c-48f7-bbb9-c536b9471c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-40219dc2-70c8-4b47-a3bd-99ddff8b6b0d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44809,DS-eb5c18ca-5a4c-48f7-bbb9-c536b9471c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-40219dc2-70c8-4b47-a3bd-99ddff8b6b0d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-92e3ff67-7066-4373-8256-90cf2717dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-a4e63337-3843-41f1-bbab-8c69255b58c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-92e3ff67-7066-4373-8256-90cf2717dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-a4e63337-3843-41f1-bbab-8c69255b58c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-92e3ff67-7066-4373-8256-90cf2717dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-a4e63337-3843-41f1-bbab-8c69255b58c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-92e3ff67-7066-4373-8256-90cf2717dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-a4e63337-3843-41f1-bbab-8c69255b58c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-4688f4b7-18fa-41f0-ab9b-8f708bad35ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-0ba8a1bc-de47-408b-8cba-0f0675d79845,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-4688f4b7-18fa-41f0-ab9b-8f708bad35ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-0ba8a1bc-de47-408b-8cba-0f0675d79845,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-4688f4b7-18fa-41f0-ab9b-8f708bad35ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-0ba8a1bc-de47-408b-8cba-0f0675d79845,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-4688f4b7-18fa-41f0-ab9b-8f708bad35ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-0ba8a1bc-de47-408b-8cba-0f0675d79845,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-33c024d0-2d78-49f0-9f24-be6eecea6e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-258a3343-0122-4a6f-8872-9a80d79ac478,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33547,DS-258a3343-0122-4a6f-8872-9a80d79ac478,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-33c024d0-2d78-49f0-9f24-be6eecea6e3b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-33c024d0-2d78-49f0-9f24-be6eecea6e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-258a3343-0122-4a6f-8872-9a80d79ac478,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33547,DS-258a3343-0122-4a6f-8872-9a80d79ac478,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-33c024d0-2d78-49f0-9f24-be6eecea6e3b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-d9223dfc-1957-432e-a359-e4e8ddbf208a,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-0236bb0e-a754-464b-884b-3789492807c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-d9223dfc-1957-432e-a359-e4e8ddbf208a,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-0236bb0e-a754-464b-884b-3789492807c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-d9223dfc-1957-432e-a359-e4e8ddbf208a,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-0236bb0e-a754-464b-884b-3789492807c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-d9223dfc-1957-432e-a359-e4e8ddbf208a,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-0236bb0e-a754-464b-884b-3789492807c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-a6138952-d246-4623-b8bf-8125bef97d47,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-9e7420b0-78c7-42ce-9f40-3fabaaea29f4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-a6138952-d246-4623-b8bf-8125bef97d47,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-9e7420b0-78c7-42ce-9f40-3fabaaea29f4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-a6138952-d246-4623-b8bf-8125bef97d47,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-9e7420b0-78c7-42ce-9f40-3fabaaea29f4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-a6138952-d246-4623-b8bf-8125bef97d47,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-9e7420b0-78c7-42ce-9f40-3fabaaea29f4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45406,DS-8d542c78-6ce0-4bba-9c43-11dfdf46e76a,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-d7b63b36-ecdf-4f2e-a75d-8d5101078dad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45406,DS-8d542c78-6ce0-4bba-9c43-11dfdf46e76a,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-d7b63b36-ecdf-4f2e-a75d-8d5101078dad,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45406,DS-8d542c78-6ce0-4bba-9c43-11dfdf46e76a,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-d7b63b36-ecdf-4f2e-a75d-8d5101078dad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45406,DS-8d542c78-6ce0-4bba-9c43-11dfdf46e76a,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-d7b63b36-ecdf-4f2e-a75d-8d5101078dad,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2203
