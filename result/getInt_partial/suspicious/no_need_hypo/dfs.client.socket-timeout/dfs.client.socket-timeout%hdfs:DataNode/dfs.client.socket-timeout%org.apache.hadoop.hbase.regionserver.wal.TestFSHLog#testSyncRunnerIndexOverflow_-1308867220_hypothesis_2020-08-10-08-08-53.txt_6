reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36938,DS-29775057-78f1-41cb-855f-3f36a86e62fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-5617c87c-8aac-4e60-9d6d-fbfef94dbfbd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36938,DS-29775057-78f1-41cb-855f-3f36a86e62fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-5617c87c-8aac-4e60-9d6d-fbfef94dbfbd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36938,DS-29775057-78f1-41cb-855f-3f36a86e62fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-5617c87c-8aac-4e60-9d6d-fbfef94dbfbd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36938,DS-29775057-78f1-41cb-855f-3f36a86e62fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-5617c87c-8aac-4e60-9d6d-fbfef94dbfbd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-2dd3b3ee-526f-446f-afc9-94786a0cb747,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-8a9725ff-854a-4dc4-9bbb-fe95f6b914a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-8a9725ff-854a-4dc4-9bbb-fe95f6b914a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-2dd3b3ee-526f-446f-afc9-94786a0cb747,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-2dd3b3ee-526f-446f-afc9-94786a0cb747,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-8a9725ff-854a-4dc4-9bbb-fe95f6b914a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-8a9725ff-854a-4dc4-9bbb-fe95f6b914a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-2dd3b3ee-526f-446f-afc9-94786a0cb747,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36141,DS-a551fcf9-e259-4347-89eb-dda67aea6831,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-8c42c6ce-0932-43c0-8c63-8e8f62224691,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44632,DS-8c42c6ce-0932-43c0-8c63-8e8f62224691,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-a551fcf9-e259-4347-89eb-dda67aea6831,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36141,DS-a551fcf9-e259-4347-89eb-dda67aea6831,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-8c42c6ce-0932-43c0-8c63-8e8f62224691,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44632,DS-8c42c6ce-0932-43c0-8c63-8e8f62224691,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-a551fcf9-e259-4347-89eb-dda67aea6831,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35355,DS-e216a423-a78d-45da-88d1-eb8f18d00792,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-d95f3d74-ee92-45f1-a8aa-66f564d5da8b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35355,DS-e216a423-a78d-45da-88d1-eb8f18d00792,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-d95f3d74-ee92-45f1-a8aa-66f564d5da8b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35355,DS-e216a423-a78d-45da-88d1-eb8f18d00792,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-d95f3d74-ee92-45f1-a8aa-66f564d5da8b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35355,DS-e216a423-a78d-45da-88d1-eb8f18d00792,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-d95f3d74-ee92-45f1-a8aa-66f564d5da8b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-fa60bcd2-f0bd-4c3c-a93a-8d710f95962f,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-93be2520-d8b8-40bb-ba68-8e4338607e8b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-fa60bcd2-f0bd-4c3c-a93a-8d710f95962f,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-93be2520-d8b8-40bb-ba68-8e4338607e8b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-fa60bcd2-f0bd-4c3c-a93a-8d710f95962f,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-93be2520-d8b8-40bb-ba68-8e4338607e8b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-fa60bcd2-f0bd-4c3c-a93a-8d710f95962f,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-93be2520-d8b8-40bb-ba68-8e4338607e8b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-f607a903-0c68-480c-8195-77327ad0f3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-67e4efc3-839e-428a-bbab-8fc5a91e324a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-f607a903-0c68-480c-8195-77327ad0f3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-67e4efc3-839e-428a-bbab-8fc5a91e324a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-f607a903-0c68-480c-8195-77327ad0f3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-67e4efc3-839e-428a-bbab-8fc5a91e324a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-f607a903-0c68-480c-8195-77327ad0f3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-67e4efc3-839e-428a-bbab-8fc5a91e324a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-d3d88ec0-5351-4b48-8a4c-de5f4e3a3727,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-290906b5-e7ac-4bdd-8b1e-bed110615ba6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-290906b5-e7ac-4bdd-8b1e-bed110615ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-d3d88ec0-5351-4b48-8a4c-de5f4e3a3727,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-d3d88ec0-5351-4b48-8a4c-de5f4e3a3727,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-290906b5-e7ac-4bdd-8b1e-bed110615ba6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-290906b5-e7ac-4bdd-8b1e-bed110615ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-d3d88ec0-5351-4b48-8a4c-de5f4e3a3727,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37689,DS-ac2e8ee8-f435-473a-95c8-20d3d0b6087d,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-ef082189-e402-46ca-ab55-141c2511d1a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37689,DS-ac2e8ee8-f435-473a-95c8-20d3d0b6087d,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-ef082189-e402-46ca-ab55-141c2511d1a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37689,DS-ac2e8ee8-f435-473a-95c8-20d3d0b6087d,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-ef082189-e402-46ca-ab55-141c2511d1a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37689,DS-ac2e8ee8-f435-473a-95c8-20d3d0b6087d,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-ef082189-e402-46ca-ab55-141c2511d1a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-324a0e8b-b03a-42c4-b123-c7eddd0d4865,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-ea336885-2175-4dfd-8c90-fde76e8515d8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-324a0e8b-b03a-42c4-b123-c7eddd0d4865,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-ea336885-2175-4dfd-8c90-fde76e8515d8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-324a0e8b-b03a-42c4-b123-c7eddd0d4865,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-ea336885-2175-4dfd-8c90-fde76e8515d8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-324a0e8b-b03a-42c4-b123-c7eddd0d4865,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-ea336885-2175-4dfd-8c90-fde76e8515d8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testSyncRunnerIndexOverflow
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34883,DS-df2635b0-ef01-4ccc-8430-df46999e6b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-375437ab-5a29-4813-9c69-8eeed4403798,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39638,DS-375437ab-5a29-4813-9c69-8eeed4403798,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-df2635b0-ef01-4ccc-8430-df46999e6b23,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34883,DS-df2635b0-ef01-4ccc-8430-df46999e6b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-375437ab-5a29-4813-9c69-8eeed4403798,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39638,DS-375437ab-5a29-4813-9c69-8eeed4403798,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-df2635b0-ef01-4ccc-8430-df46999e6b23,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 11
v1v1v2v2 failed with probability 0 out of 11
result: might be true error
Total execution time in seconds : 1612
