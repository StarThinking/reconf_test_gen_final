reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-4afeb81e-b1e0-4f87-a790-eab6a160354e,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-74603614-05d5-4057-8b23-0e9d1f798dd6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-4afeb81e-b1e0-4f87-a790-eab6a160354e,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-74603614-05d5-4057-8b23-0e9d1f798dd6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-4afeb81e-b1e0-4f87-a790-eab6a160354e,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-74603614-05d5-4057-8b23-0e9d1f798dd6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-4afeb81e-b1e0-4f87-a790-eab6a160354e,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-74603614-05d5-4057-8b23-0e9d1f798dd6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-670b1692-6f9d-42bb-baa7-2615c2dd3bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-7309e180-5294-4875-a440-3430db88e8ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-670b1692-6f9d-42bb-baa7-2615c2dd3bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-7309e180-5294-4875-a440-3430db88e8ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-670b1692-6f9d-42bb-baa7-2615c2dd3bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-7309e180-5294-4875-a440-3430db88e8ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-670b1692-6f9d-42bb-baa7-2615c2dd3bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-7309e180-5294-4875-a440-3430db88e8ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37906,DS-695fb043-c75d-41b2-9413-5c8b2c377e08,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-693ac4b9-d4e2-46a1-8cf0-7bf2718e7cb9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37906,DS-695fb043-c75d-41b2-9413-5c8b2c377e08,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-693ac4b9-d4e2-46a1-8cf0-7bf2718e7cb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37906,DS-695fb043-c75d-41b2-9413-5c8b2c377e08,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-693ac4b9-d4e2-46a1-8cf0-7bf2718e7cb9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37906,DS-695fb043-c75d-41b2-9413-5c8b2c377e08,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-693ac4b9-d4e2-46a1-8cf0-7bf2718e7cb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-570ca859-6d1b-4e6b-8d89-cd18a3f748a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-85743b17-9cd2-4fed-9cab-a19696e2ac60,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-570ca859-6d1b-4e6b-8d89-cd18a3f748a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-85743b17-9cd2-4fed-9cab-a19696e2ac60,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-570ca859-6d1b-4e6b-8d89-cd18a3f748a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-85743b17-9cd2-4fed-9cab-a19696e2ac60,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-570ca859-6d1b-4e6b-8d89-cd18a3f748a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-85743b17-9cd2-4fed-9cab-a19696e2ac60,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-2643f774-34c2-4a95-9527-276925f10521,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-63ba560f-f257-45cd-9970-c6520760ab1e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-2643f774-34c2-4a95-9527-276925f10521,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-63ba560f-f257-45cd-9970-c6520760ab1e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-2643f774-34c2-4a95-9527-276925f10521,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-63ba560f-f257-45cd-9970-c6520760ab1e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-2643f774-34c2-4a95-9527-276925f10521,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-63ba560f-f257-45cd-9970-c6520760ab1e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-f92c5b99-567a-47bf-ae07-28e62c6538f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-3e8c6ae9-cf21-4594-9b68-64cc0b6cc92a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-f92c5b99-567a-47bf-ae07-28e62c6538f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-3e8c6ae9-cf21-4594-9b68-64cc0b6cc92a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-f92c5b99-567a-47bf-ae07-28e62c6538f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-3e8c6ae9-cf21-4594-9b68-64cc0b6cc92a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-f92c5b99-567a-47bf-ae07-28e62c6538f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-3e8c6ae9-cf21-4594-9b68-64cc0b6cc92a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41576,DS-0f8d5032-fc0a-4ada-adae-8f35b5fd7cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-4a586c69-bdef-4121-82ab-4c21ba02d616,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41576,DS-0f8d5032-fc0a-4ada-adae-8f35b5fd7cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-4a586c69-bdef-4121-82ab-4c21ba02d616,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41576,DS-0f8d5032-fc0a-4ada-adae-8f35b5fd7cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-4a586c69-bdef-4121-82ab-4c21ba02d616,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41576,DS-0f8d5032-fc0a-4ada-adae-8f35b5fd7cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-4a586c69-bdef-4121-82ab-4c21ba02d616,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-6224f4ad-0aa6-4d14-a4de-1a8d56467a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-4a3f3568-5e2c-4f45-9e59-6fb366010877,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-6224f4ad-0aa6-4d14-a4de-1a8d56467a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-4a3f3568-5e2c-4f45-9e59-6fb366010877,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-6224f4ad-0aa6-4d14-a4de-1a8d56467a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-4a3f3568-5e2c-4f45-9e59-6fb366010877,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-6224f4ad-0aa6-4d14-a4de-1a8d56467a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-4a3f3568-5e2c-4f45-9e59-6fb366010877,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-0d3b820d-7902-4f89-85c2-b61bb888ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-6dce7579-1b11-4e33-801d-5cc86d86a2c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-0d3b820d-7902-4f89-85c2-b61bb888ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-6dce7579-1b11-4e33-801d-5cc86d86a2c8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-0d3b820d-7902-4f89-85c2-b61bb888ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-6dce7579-1b11-4e33-801d-5cc86d86a2c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-0d3b820d-7902-4f89-85c2-b61bb888ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-6dce7579-1b11-4e33-801d-5cc86d86a2c8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testRecoverFinalizedBlock
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-7bb32211-6f7a-4bf3-aabc-6655a4c7cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-ca461923-1d07-4308-8c36-a887bde2d687,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-ca461923-1d07-4308-8c36-a887bde2d687,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-7bb32211-6f7a-4bf3-aabc-6655a4c7cde5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-7bb32211-6f7a-4bf3-aabc-6655a4c7cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-ca461923-1d07-4308-8c36-a887bde2d687,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-ca461923-1d07-4308-8c36-a887bde2d687,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-7bb32211-6f7a-4bf3-aabc-6655a4c7cde5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 784
