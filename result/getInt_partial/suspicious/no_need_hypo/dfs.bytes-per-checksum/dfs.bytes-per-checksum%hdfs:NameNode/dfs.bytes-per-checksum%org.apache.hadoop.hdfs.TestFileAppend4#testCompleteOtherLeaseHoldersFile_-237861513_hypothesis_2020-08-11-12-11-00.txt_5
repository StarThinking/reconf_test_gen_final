reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38642,DS-1d65ef15-a2dc-430a-b42b-9c7cccaf0e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-7a3b41d8-ed84-4ef5-89f4-6477b4d9c85d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42403,DS-7a3b41d8-ed84-4ef5-89f4-6477b4d9c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-1d65ef15-a2dc-430a-b42b-9c7cccaf0e4c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38642,DS-1d65ef15-a2dc-430a-b42b-9c7cccaf0e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-7a3b41d8-ed84-4ef5-89f4-6477b4d9c85d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42403,DS-7a3b41d8-ed84-4ef5-89f4-6477b4d9c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-1d65ef15-a2dc-430a-b42b-9c7cccaf0e4c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-4f46e2f3-50b4-4d66-8712-24b6731ada3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-45dd4e7a-7d51-4545-8601-57d87efe29a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-4f46e2f3-50b4-4d66-8712-24b6731ada3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-45dd4e7a-7d51-4545-8601-57d87efe29a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-4f46e2f3-50b4-4d66-8712-24b6731ada3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-45dd4e7a-7d51-4545-8601-57d87efe29a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-4f46e2f3-50b4-4d66-8712-24b6731ada3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-45dd4e7a-7d51-4545-8601-57d87efe29a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-a93ff282-bb9d-43b0-a75e-d2c56d5a8124,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-d9b5a96c-7f26-4cd1-a3dc-4142e33497ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37020,DS-d9b5a96c-7f26-4cd1-a3dc-4142e33497ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-a93ff282-bb9d-43b0-a75e-d2c56d5a8124,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-a93ff282-bb9d-43b0-a75e-d2c56d5a8124,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-d9b5a96c-7f26-4cd1-a3dc-4142e33497ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37020,DS-d9b5a96c-7f26-4cd1-a3dc-4142e33497ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-a93ff282-bb9d-43b0-a75e-d2c56d5a8124,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-fcf50e15-590d-4a00-9751-e77f999da542,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-407524e1-2faf-4694-85c4-a4af6c07e157,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-fcf50e15-590d-4a00-9751-e77f999da542,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-407524e1-2faf-4694-85c4-a4af6c07e157,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-fcf50e15-590d-4a00-9751-e77f999da542,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-407524e1-2faf-4694-85c4-a4af6c07e157,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-fcf50e15-590d-4a00-9751-e77f999da542,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-407524e1-2faf-4694-85c4-a4af6c07e157,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-4b2349cb-81c3-47d2-91c9-e19d3134c917,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-b4198f4b-b178-409e-9f5c-c532603687c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-4b2349cb-81c3-47d2-91c9-e19d3134c917,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-b4198f4b-b178-409e-9f5c-c532603687c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-4b2349cb-81c3-47d2-91c9-e19d3134c917,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-b4198f4b-b178-409e-9f5c-c532603687c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-4b2349cb-81c3-47d2-91c9-e19d3134c917,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-b4198f4b-b178-409e-9f5c-c532603687c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-ca3b11c6-5539-4563-9eff-31ac8fc7b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-3de71845-75cf-4bae-b9bf-0bdb9434290c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-ca3b11c6-5539-4563-9eff-31ac8fc7b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-3de71845-75cf-4bae-b9bf-0bdb9434290c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-ca3b11c6-5539-4563-9eff-31ac8fc7b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-3de71845-75cf-4bae-b9bf-0bdb9434290c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-ca3b11c6-5539-4563-9eff-31ac8fc7b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-3de71845-75cf-4bae-b9bf-0bdb9434290c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40392,DS-965ec708-33ad-41e9-88f2-ed36707cf61c,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-e72d103e-47a1-4b4d-bfcf-591085020b0a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35879,DS-e72d103e-47a1-4b4d-bfcf-591085020b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-965ec708-33ad-41e9-88f2-ed36707cf61c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40392,DS-965ec708-33ad-41e9-88f2-ed36707cf61c,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-e72d103e-47a1-4b4d-bfcf-591085020b0a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35879,DS-e72d103e-47a1-4b4d-bfcf-591085020b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-965ec708-33ad-41e9-88f2-ed36707cf61c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-bb58b9d7-a9a9-49dd-839f-5ebbde3f946a,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-a35f5ef0-aad5-43d3-9e7a-12f51829fce1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-bb58b9d7-a9a9-49dd-839f-5ebbde3f946a,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-a35f5ef0-aad5-43d3-9e7a-12f51829fce1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-bb58b9d7-a9a9-49dd-839f-5ebbde3f946a,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-a35f5ef0-aad5-43d3-9e7a-12f51829fce1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-bb58b9d7-a9a9-49dd-839f-5ebbde3f946a,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-a35f5ef0-aad5-43d3-9e7a-12f51829fce1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-715434d4-3ac4-429a-a54e-d4ba022ff143,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-95b8322d-0f63-4589-ab6c-e448ff47adad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-715434d4-3ac4-429a-a54e-d4ba022ff143,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-95b8322d-0f63-4589-ab6c-e448ff47adad,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-715434d4-3ac4-429a-a54e-d4ba022ff143,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-95b8322d-0f63-4589-ab6c-e448ff47adad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-715434d4-3ac4-429a-a54e-d4ba022ff143,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-95b8322d-0f63-4589-ab6c-e448ff47adad,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileAppend4#testCompleteOtherLeaseHoldersFile
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-08033551-f1a4-4455-9402-3a2ccaadd06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-118bd71e-5c4d-4d95-83c0-d3f50514470d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-08033551-f1a4-4455-9402-3a2ccaadd06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-118bd71e-5c4d-4d95-83c0-d3f50514470d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-08033551-f1a4-4455-9402-3a2ccaadd06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-118bd71e-5c4d-4d95-83c0-d3f50514470d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-08033551-f1a4-4455-9402-3a2ccaadd06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-118bd71e-5c4d-4d95-83c0-d3f50514470d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 767
