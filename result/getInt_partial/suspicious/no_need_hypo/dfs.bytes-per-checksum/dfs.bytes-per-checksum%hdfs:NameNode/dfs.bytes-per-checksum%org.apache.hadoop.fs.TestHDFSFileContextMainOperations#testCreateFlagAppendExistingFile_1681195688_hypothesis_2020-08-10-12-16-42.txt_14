reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:46436,DS-af370b61-2537-4800-be26-9dadbe9702a4,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:46436,DS-af370b61-2537-4800-be26-9dadbe9702a4,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:45689,DS-57f3a72a-9b50-417e-8a11-ffc2d36b824c,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:45689,DS-57f3a72a-9b50-417e-8a11-ffc2d36b824c,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:42230,DS-e6cf489b-1d59-4c0f-be7c-6412211cd2e3,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:42230,DS-e6cf489b-1d59-4c0f-be7c-6412211cd2e3,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:46802,DS-ddb410a4-64a9-45ab-990c-5992c529b2fd,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:46802,DS-ddb410a4-64a9-45ab-990c-5992c529b2fd,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:38270,DS-dfe099fe-182b-43ce-8722-f41b522c8219,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:38270,DS-dfe099fe-182b-43ce-8722-f41b522c8219,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:43249,DS-adea4de9-13e9-4d22-ad09-08dec5134d20,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:43249,DS-adea4de9-13e9-4d22-ad09-08dec5134d20,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36245,DS-d62cbb20-f1ee-4c2d-802d-0171d5015f5e,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36245,DS-d62cbb20-f1ee-4c2d-802d-0171d5015f5e,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:42894,DS-551370c0-58cb-4bb9-97eb-907d620ef2e0,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:42894,DS-551370c0-58cb-4bb9-97eb-907d620ef2e0,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:45075,DS-efa0443c-b0a1-42f8-bfb0-583701345c4e,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:45075,DS-efa0443c-b0a1-42f8-bfb0-583701345c4e,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:46554,DS-81ac0cb1-c9d1-40ac-9d9e-d7bfc53c04b4,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:46554,DS-81ac0cb1-c9d1-40ac-9d9e-d7bfc53c04b4,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 905
