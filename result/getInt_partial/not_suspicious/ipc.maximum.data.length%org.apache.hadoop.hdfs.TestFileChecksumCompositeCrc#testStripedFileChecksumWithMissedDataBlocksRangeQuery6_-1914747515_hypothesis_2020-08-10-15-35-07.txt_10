reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097621379-172.17.0.20-1597073994777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36581,DS-e3394bdf-d3fa-462f-b957-b7b6da63afc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-1fcd2c35-d71c-4a52-8694-1d9c92ac1418,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-f3558fc0-2fe9-413d-a497-2f15bc3d1af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-3c25cdd6-1531-414b-934c-a2160df34ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-20de0fb3-57e7-4ae1-990a-320494fb12b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-b4914726-8f3f-44d1-8478-2e1f8af77f43,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-29f8a228-18f5-4ce7-b9eb-96c81e8ff6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-cb3b0ab1-ca3f-499e-9c4b-d92975fc28ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097621379-172.17.0.20-1597073994777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36581,DS-e3394bdf-d3fa-462f-b957-b7b6da63afc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-1fcd2c35-d71c-4a52-8694-1d9c92ac1418,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-f3558fc0-2fe9-413d-a497-2f15bc3d1af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-3c25cdd6-1531-414b-934c-a2160df34ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-20de0fb3-57e7-4ae1-990a-320494fb12b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-b4914726-8f3f-44d1-8478-2e1f8af77f43,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-29f8a228-18f5-4ce7-b9eb-96c81e8ff6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-cb3b0ab1-ca3f-499e-9c4b-d92975fc28ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974578661-172.17.0.20-1597074088206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40569,DS-56f286ad-95ea-4b1f-bb61-a76bf53fbb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-51a43a59-0586-4be1-8f87-10efc2b3eea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-cd5fba64-40f1-494c-bfdc-72d69771e092,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-87df7356-8693-45c7-ab86-84113c1af056,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-bb8488c5-47ba-4193-bdbf-d7f0e0329acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-5380087b-9ef0-4376-aafd-926de3264780,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-d2eb3eb0-11c0-4cbc-a1e8-48846cb31933,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-dd599688-46a1-495e-b0ec-912fa3d2d620,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974578661-172.17.0.20-1597074088206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40569,DS-56f286ad-95ea-4b1f-bb61-a76bf53fbb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-51a43a59-0586-4be1-8f87-10efc2b3eea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-cd5fba64-40f1-494c-bfdc-72d69771e092,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-87df7356-8693-45c7-ab86-84113c1af056,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-bb8488c5-47ba-4193-bdbf-d7f0e0329acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-5380087b-9ef0-4376-aafd-926de3264780,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-d2eb3eb0-11c0-4cbc-a1e8-48846cb31933,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-dd599688-46a1-495e-b0ec-912fa3d2d620,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613489495-172.17.0.20-1597074149604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43505,DS-6b7293fd-2423-4be8-9158-a2f86d55ec9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-9ae20f0b-5ac7-4f52-aeba-95dc09155061,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-bd940e1c-899c-4556-9c4a-1485afe2d2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-01da4b02-a7d5-4d05-9fde-4cd79b5130f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-519b4dc1-8c9f-43c3-8353-4ee4568dd15c,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-ca3150b9-45f5-4529-8380-2791a1f67803,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-f1c7ba19-f26a-4498-9a1a-378adb4f7368,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-efcd3328-b228-434e-abbf-263361f393a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613489495-172.17.0.20-1597074149604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43505,DS-6b7293fd-2423-4be8-9158-a2f86d55ec9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-9ae20f0b-5ac7-4f52-aeba-95dc09155061,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-bd940e1c-899c-4556-9c4a-1485afe2d2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-01da4b02-a7d5-4d05-9fde-4cd79b5130f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-519b4dc1-8c9f-43c3-8353-4ee4568dd15c,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-ca3150b9-45f5-4529-8380-2791a1f67803,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-f1c7ba19-f26a-4498-9a1a-378adb4f7368,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-efcd3328-b228-434e-abbf-263361f393a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938305855-172.17.0.20-1597074313325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34626,DS-57e3949f-1905-45b3-9dff-16a11d260649,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-036e2c80-b5a0-4e61-aa1a-2b0b80598c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-0865499d-e8ed-4031-945f-1799d38773d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-cd307e61-825e-4649-b09f-b8a030b23989,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-41c2b9f0-2f21-45b4-b4da-770578c699fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-10396c0f-048a-44c1-926c-d22d91142e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-b4444f35-aa92-4676-9045-83ec959b9773,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-72fd8f1b-5327-4c63-b0c6-a9019e92645a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938305855-172.17.0.20-1597074313325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34626,DS-57e3949f-1905-45b3-9dff-16a11d260649,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-036e2c80-b5a0-4e61-aa1a-2b0b80598c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-0865499d-e8ed-4031-945f-1799d38773d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-cd307e61-825e-4649-b09f-b8a030b23989,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-41c2b9f0-2f21-45b4-b4da-770578c699fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-10396c0f-048a-44c1-926c-d22d91142e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-b4444f35-aa92-4676-9045-83ec959b9773,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-72fd8f1b-5327-4c63-b0c6-a9019e92645a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118264538-172.17.0.20-1597074779319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-d06584e6-4374-4ffb-a3b5-a3e122872727,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-579d81a7-6ff8-4668-9545-2b83a8860fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-61c20a54-888f-449f-a55c-217bf8aa3fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-9a720330-3941-4500-abfe-658366ab7994,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-bb11689a-b9e9-42ea-9d83-57f867c9e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-8f3fb130-4b5f-47c3-a932-4151d1b786cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-3655b1b2-b414-4fff-ae2a-45ef7545dec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-15528e10-f3ca-4245-86cb-263519157994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118264538-172.17.0.20-1597074779319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-d06584e6-4374-4ffb-a3b5-a3e122872727,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-579d81a7-6ff8-4668-9545-2b83a8860fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-61c20a54-888f-449f-a55c-217bf8aa3fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-9a720330-3941-4500-abfe-658366ab7994,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-bb11689a-b9e9-42ea-9d83-57f867c9e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-8f3fb130-4b5f-47c3-a932-4151d1b786cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-3655b1b2-b414-4fff-ae2a-45ef7545dec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-15528e10-f3ca-4245-86cb-263519157994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726114520-172.17.0.20-1597074854462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40979,DS-46524bb6-457f-44be-bc13-85ff85db0b71,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-2d8dad60-fbf8-49b1-98ee-51f31582df88,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-203b6807-d14e-4836-ab4e-17986655a108,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-b094066e-b7ab-4a5a-8c2b-d06640e9f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-935a79df-4990-4c22-9882-7e42ec28b763,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-7eef3921-daac-47b7-914d-01efca595c95,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-7885d9f3-5301-4215-bcda-e6842055b8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-f75a074a-2e73-48b2-ba28-b5ab46271f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726114520-172.17.0.20-1597074854462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40979,DS-46524bb6-457f-44be-bc13-85ff85db0b71,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-2d8dad60-fbf8-49b1-98ee-51f31582df88,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-203b6807-d14e-4836-ab4e-17986655a108,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-b094066e-b7ab-4a5a-8c2b-d06640e9f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-935a79df-4990-4c22-9882-7e42ec28b763,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-7eef3921-daac-47b7-914d-01efca595c95,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-7885d9f3-5301-4215-bcda-e6842055b8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-f75a074a-2e73-48b2-ba28-b5ab46271f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410842798-172.17.0.20-1597074899095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34689,DS-3273624f-be52-427e-b17f-16ab9990da4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-e99cc403-8bd2-4f3c-8758-71ac54c6d619,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-4b66418b-4e7a-48df-be33-9e3584539d82,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-54d80893-7e26-4fc4-9016-3d16fc53e7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-514e9227-7049-4eed-96d6-4822fd398b93,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-8efdf933-5efa-476e-9dcc-7fafb328bdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-3f0713f9-3cd5-446e-97b1-5895a2b758fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-b4ede3da-6ac8-4cff-b3bb-f3321657682f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410842798-172.17.0.20-1597074899095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34689,DS-3273624f-be52-427e-b17f-16ab9990da4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-e99cc403-8bd2-4f3c-8758-71ac54c6d619,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-4b66418b-4e7a-48df-be33-9e3584539d82,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-54d80893-7e26-4fc4-9016-3d16fc53e7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-514e9227-7049-4eed-96d6-4822fd398b93,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-8efdf933-5efa-476e-9dcc-7fafb328bdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-3f0713f9-3cd5-446e-97b1-5895a2b758fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-b4ede3da-6ac8-4cff-b3bb-f3321657682f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441960894-172.17.0.20-1597075086372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-73959164-ae2d-4236-a795-0ef2bd611073,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-812cae33-9c7f-4e0c-a2bb-0f7d61c1f9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-794a2182-83ab-4d6a-9667-28b128b85e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-8cc56adb-e6a5-4500-b7a8-1d978f227989,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-e008ab06-9c57-42c1-8be3-bf2af4d362e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-9d558cae-9af4-4388-a5ef-6045cc2112f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-52a48a02-d849-4e11-aebe-d2a23b6ebfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-3562c4c2-b81c-4f6b-b0e2-06bd505c0be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441960894-172.17.0.20-1597075086372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-73959164-ae2d-4236-a795-0ef2bd611073,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-812cae33-9c7f-4e0c-a2bb-0f7d61c1f9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-794a2182-83ab-4d6a-9667-28b128b85e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-8cc56adb-e6a5-4500-b7a8-1d978f227989,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-e008ab06-9c57-42c1-8be3-bf2af4d362e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-9d558cae-9af4-4388-a5ef-6045cc2112f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-52a48a02-d849-4e11-aebe-d2a23b6ebfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-3562c4c2-b81c-4f6b-b0e2-06bd505c0be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059057000-172.17.0.20-1597075167449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-4d94cbbc-7042-4aa3-b6f3-0f0e97e3eaea,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-3fb9fb03-d1ee-43c7-889d-28c929a25d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-e54265e6-4342-4553-b66b-41b3a37399e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-d52f25cb-b588-4f46-8e47-37b13d79cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-21be12bb-fbdb-40d5-93a7-a469b10c2f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-5b587354-e2da-453e-86c4-8fc7e7135d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-733baf14-83d8-41aa-b9c6-b7a58d3285ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-e1cbd292-6b48-4a91-b9bc-c3422455356c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059057000-172.17.0.20-1597075167449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-4d94cbbc-7042-4aa3-b6f3-0f0e97e3eaea,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-3fb9fb03-d1ee-43c7-889d-28c929a25d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-e54265e6-4342-4553-b66b-41b3a37399e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-d52f25cb-b588-4f46-8e47-37b13d79cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-21be12bb-fbdb-40d5-93a7-a469b10c2f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-5b587354-e2da-453e-86c4-8fc7e7135d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-733baf14-83d8-41aa-b9c6-b7a58d3285ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-e1cbd292-6b48-4a91-b9bc-c3422455356c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783111269-172.17.0.20-1597075245658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-5158adbc-300e-401c-8371-37f8cfd899f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-1866f000-82d2-44cc-b1ad-34a5994a50a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-e73a654c-3057-409d-a690-a2b2c3c8dfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-70cac367-4b8d-471e-8396-006eb2c79ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-7fe273d3-42cf-4670-97b6-b68684e93f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-6164bd8f-bedb-48d7-a501-0d53066f6be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-a625c4b7-eb68-4863-a19f-45f34371fe92,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-ec81c123-4fb1-4850-878e-9dcfd0570e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783111269-172.17.0.20-1597075245658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-5158adbc-300e-401c-8371-37f8cfd899f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-1866f000-82d2-44cc-b1ad-34a5994a50a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-e73a654c-3057-409d-a690-a2b2c3c8dfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-70cac367-4b8d-471e-8396-006eb2c79ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-7fe273d3-42cf-4670-97b6-b68684e93f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-6164bd8f-bedb-48d7-a501-0d53066f6be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-a625c4b7-eb68-4863-a19f-45f34371fe92,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-ec81c123-4fb1-4850-878e-9dcfd0570e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464639075-172.17.0.20-1597075320880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38757,DS-8e905b2b-dc78-48f0-8a98-de36aa5e9839,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-fd3d85bf-6671-45d2-a54d-7abcc2b11b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-ea825333-e667-4d3a-bf52-c0503f3e5190,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-299b6fed-5fed-40af-b446-dda933cf1ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-b6626837-0c3a-48e3-8658-342eccedabb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-974c3b65-3886-4d2c-b352-8a5e9dddcde3,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-1ebf38ac-3723-4a05-8e7d-96e78b98a3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-7748da6f-f2b2-408f-b726-1a4ffae06fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464639075-172.17.0.20-1597075320880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38757,DS-8e905b2b-dc78-48f0-8a98-de36aa5e9839,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-fd3d85bf-6671-45d2-a54d-7abcc2b11b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-ea825333-e667-4d3a-bf52-c0503f3e5190,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-299b6fed-5fed-40af-b446-dda933cf1ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-b6626837-0c3a-48e3-8658-342eccedabb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-974c3b65-3886-4d2c-b352-8a5e9dddcde3,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-1ebf38ac-3723-4a05-8e7d-96e78b98a3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-7748da6f-f2b2-408f-b726-1a4ffae06fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981458546-172.17.0.20-1597075436003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44743,DS-7216655b-796f-4171-96bd-c761e4d99b35,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-5dc0cc0e-d3ec-41e0-8861-8c6f8c01fd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-83df40f3-9cb1-4995-b28c-3f0fee63ccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-b295859a-6943-462f-ba09-d5a08afb02a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-933eabb0-ebc2-4e60-99e7-44d436d662f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-0bdfd0b7-a231-44a2-9f50-4f65ca13f8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-65f8f899-57a3-4ec1-85a1-41f3fa3faa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-4041fa56-4d6a-4b56-b09d-6c29f0a2fcb3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981458546-172.17.0.20-1597075436003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44743,DS-7216655b-796f-4171-96bd-c761e4d99b35,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-5dc0cc0e-d3ec-41e0-8861-8c6f8c01fd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-83df40f3-9cb1-4995-b28c-3f0fee63ccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-b295859a-6943-462f-ba09-d5a08afb02a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-933eabb0-ebc2-4e60-99e7-44d436d662f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-0bdfd0b7-a231-44a2-9f50-4f65ca13f8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-65f8f899-57a3-4ec1-85a1-41f3fa3faa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-4041fa56-4d6a-4b56-b09d-6c29f0a2fcb3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461249224-172.17.0.20-1597075626433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45047,DS-16c9dd53-0e53-4679-abfc-e21780a27d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-85ace24a-657e-4b94-9edf-287a59cea98e,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-aa7cbb4a-6d7e-4cc6-aa08-2cc778f97bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-b90ccb4a-0b0e-4b53-8b73-b6d8008f0378,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-82ae8ea3-2c95-4405-acd8-86f48db94b59,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-cdbac718-14e4-4f79-8a2e-8fb72cef2faa,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-1e7a9713-fb6d-4727-972a-829c10b9b3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-e6c350bf-092f-4d56-be3e-dec2361573d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461249224-172.17.0.20-1597075626433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45047,DS-16c9dd53-0e53-4679-abfc-e21780a27d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-85ace24a-657e-4b94-9edf-287a59cea98e,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-aa7cbb4a-6d7e-4cc6-aa08-2cc778f97bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-b90ccb4a-0b0e-4b53-8b73-b6d8008f0378,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-82ae8ea3-2c95-4405-acd8-86f48db94b59,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-cdbac718-14e4-4f79-8a2e-8fb72cef2faa,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-1e7a9713-fb6d-4727-972a-829c10b9b3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-e6c350bf-092f-4d56-be3e-dec2361573d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991148045-172.17.0.20-1597075817244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-127b023d-19d8-4f83-b7bd-90b399a6042d,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-51ce8bd8-0fd8-4d88-a92a-c2dd5393739e,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-63093d63-9f47-42e5-9c44-e94e83ebcb56,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-39ecee8e-b24f-4e45-82ff-ada9044f5dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-0f6c8be5-2b00-4bdd-9ac2-84b292dba799,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-22251be4-7eb9-4fc9-933e-a99f00b83b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-23c6354a-e385-413a-9014-21079feb73ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-a4c07028-2869-4386-b4a8-6022f35c8988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991148045-172.17.0.20-1597075817244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-127b023d-19d8-4f83-b7bd-90b399a6042d,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-51ce8bd8-0fd8-4d88-a92a-c2dd5393739e,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-63093d63-9f47-42e5-9c44-e94e83ebcb56,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-39ecee8e-b24f-4e45-82ff-ada9044f5dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-0f6c8be5-2b00-4bdd-9ac2-84b292dba799,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-22251be4-7eb9-4fc9-933e-a99f00b83b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-23c6354a-e385-413a-9014-21079feb73ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-a4c07028-2869-4386-b4a8-6022f35c8988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201014260-172.17.0.20-1597075960364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-1e66a098-7173-4b90-a0c3-70cefd6e9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-1ad9569c-7f03-4d05-b642-699685bc7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-59918a69-b8d3-4a00-b12e-89719ca687d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-ea4fa88e-8768-49f6-b5c1-a30584b98456,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-e519ef9a-00f0-4e80-9969-2022fd6af486,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-077ec6ab-81d1-48e7-b1b7-65a32da3e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-4959fc22-11d1-447f-9cef-71d222b0fb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-7912a895-721e-4623-91df-a55e1f3a7503,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201014260-172.17.0.20-1597075960364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-1e66a098-7173-4b90-a0c3-70cefd6e9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-1ad9569c-7f03-4d05-b642-699685bc7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-59918a69-b8d3-4a00-b12e-89719ca687d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-ea4fa88e-8768-49f6-b5c1-a30584b98456,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-e519ef9a-00f0-4e80-9969-2022fd6af486,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-077ec6ab-81d1-48e7-b1b7-65a32da3e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-4959fc22-11d1-447f-9cef-71d222b0fb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-7912a895-721e-4623-91df-a55e1f3a7503,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967639159-172.17.0.20-1597076001636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34684,DS-20b903f9-2b85-405e-80f7-e28cce264cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-b80b2ed6-7b50-4029-bc25-df6f0818ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-3be29915-3bf8-4ff7-8024-a4e6f6d79134,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-69b98f55-00ad-4037-8eeb-e613a995a9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-c197994d-9856-460d-a88d-c73966d8c553,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-8c3fdd09-9e43-4387-9d95-01659fe5897e,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-72606cb1-ec51-46a3-982b-6fa116ff8917,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-13fe3278-4410-4e78-b87f-3e3193710fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967639159-172.17.0.20-1597076001636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34684,DS-20b903f9-2b85-405e-80f7-e28cce264cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-b80b2ed6-7b50-4029-bc25-df6f0818ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-3be29915-3bf8-4ff7-8024-a4e6f6d79134,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-69b98f55-00ad-4037-8eeb-e613a995a9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-c197994d-9856-460d-a88d-c73966d8c553,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-8c3fdd09-9e43-4387-9d95-01659fe5897e,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-72606cb1-ec51-46a3-982b-6fa116ff8917,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-13fe3278-4410-4e78-b87f-3e3193710fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774463675-172.17.0.20-1597076071365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44631,DS-c9165beb-835b-4b86-9ed5-1e5fbd262f76,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-0ba3384f-4ced-4867-ac86-8294ca76036d,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-db0b552d-452a-42e3-93bf-bf0676a4f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-252d4bca-a95a-4a98-9f6e-2fb95bf833df,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-84811f9e-d361-4474-a135-daeb16262051,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-4c0444ff-9699-4b0d-9b6c-2e5b7db10bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-2e7eee4f-e84b-4e8c-8dac-e0f6be6b3625,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-750657da-ea51-4112-88e8-71479f94b1e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774463675-172.17.0.20-1597076071365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44631,DS-c9165beb-835b-4b86-9ed5-1e5fbd262f76,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-0ba3384f-4ced-4867-ac86-8294ca76036d,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-db0b552d-452a-42e3-93bf-bf0676a4f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-252d4bca-a95a-4a98-9f6e-2fb95bf833df,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-84811f9e-d361-4474-a135-daeb16262051,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-4c0444ff-9699-4b0d-9b6c-2e5b7db10bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-2e7eee4f-e84b-4e8c-8dac-e0f6be6b3625,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-750657da-ea51-4112-88e8-71479f94b1e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019740764-172.17.0.20-1597076134146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37866,DS-cbb3c3ae-75d1-4f92-b7ff-77e2bc26540c,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-7985008b-88bb-4a28-8184-a4d88725462e,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-7fc3e420-8af4-4dcb-8c53-776124994649,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-6760e25e-a713-4585-b40e-e5f75a248460,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-60939d69-3923-4a04-8647-b129114999e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-3964eb14-ca29-4f8e-bdcb-6f89167ef3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-ad95dc12-4627-4166-980b-a04aed46cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-75e7c976-ce31-478f-83a7-230bf6578cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019740764-172.17.0.20-1597076134146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37866,DS-cbb3c3ae-75d1-4f92-b7ff-77e2bc26540c,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-7985008b-88bb-4a28-8184-a4d88725462e,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-7fc3e420-8af4-4dcb-8c53-776124994649,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-6760e25e-a713-4585-b40e-e5f75a248460,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-60939d69-3923-4a04-8647-b129114999e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-3964eb14-ca29-4f8e-bdcb-6f89167ef3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-ad95dc12-4627-4166-980b-a04aed46cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-75e7c976-ce31-478f-83a7-230bf6578cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33777407-172.17.0.20-1597076180514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-06d94bf6-9019-4f5a-b5dd-dcdca9800e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-39a842c4-6fe1-42c4-93b0-eec333bbe029,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-4565fa85-a410-42e1-993b-a83ac7c2eeab,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-57626937-3828-4c34-a8a8-6766be9b217b,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-447342e9-bb96-4678-9b38-4b7658045fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-ce183110-1419-44fa-9c66-a540be285d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-24fd9fff-37f7-4df6-97a8-a33981ac749b,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-7653cd36-230f-4c8a-ae7f-9e7502eb7671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33777407-172.17.0.20-1597076180514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-06d94bf6-9019-4f5a-b5dd-dcdca9800e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-39a842c4-6fe1-42c4-93b0-eec333bbe029,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-4565fa85-a410-42e1-993b-a83ac7c2eeab,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-57626937-3828-4c34-a8a8-6766be9b217b,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-447342e9-bb96-4678-9b38-4b7658045fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-ce183110-1419-44fa-9c66-a540be285d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-24fd9fff-37f7-4df6-97a8-a33981ac749b,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-7653cd36-230f-4c8a-ae7f-9e7502eb7671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464939072-172.17.0.20-1597076340672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-cc866123-66fa-4291-8da7-50e7578566f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-0cf260f4-d3fd-4f98-9451-cdd456c07a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-9fb43502-b26d-47fc-a4c3-41b8910eb836,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-756797de-ecab-497a-88eb-d118cfa74433,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-ec806ab7-51f1-4104-b396-79cdc03a881e,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-41eb7d2d-c109-4570-9438-70374b86f816,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-ad0dbb6d-d2a6-48c6-aec8-72848121f835,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-5da3faa9-d067-472a-adf0-61a8dd777603,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464939072-172.17.0.20-1597076340672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-cc866123-66fa-4291-8da7-50e7578566f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-0cf260f4-d3fd-4f98-9451-cdd456c07a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-9fb43502-b26d-47fc-a4c3-41b8910eb836,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-756797de-ecab-497a-88eb-d118cfa74433,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-ec806ab7-51f1-4104-b396-79cdc03a881e,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-41eb7d2d-c109-4570-9438-70374b86f816,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-ad0dbb6d-d2a6-48c6-aec8-72848121f835,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-5da3faa9-d067-472a-adf0-61a8dd777603,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184445652-172.17.0.20-1597076453384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38989,DS-c7b24920-1823-4fe9-8097-fc87d1901a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-e1dde07c-bf7d-4a44-9e40-07188e0c3690,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-2f62c30e-28de-479d-9ead-87dc56ab8daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-135ccd4b-cd9a-40b2-b9b7-79a058916f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-39f3551d-8817-41aa-bc37-32845b46f58f,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-ea5f33ee-c0a3-496d-a7cc-47748b92b08f,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-8c9263b2-d2aa-4ca8-9703-ce60c5725ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-19a8be1a-9ae2-4702-b2f7-f74974d92e91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184445652-172.17.0.20-1597076453384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38989,DS-c7b24920-1823-4fe9-8097-fc87d1901a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-e1dde07c-bf7d-4a44-9e40-07188e0c3690,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-2f62c30e-28de-479d-9ead-87dc56ab8daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-135ccd4b-cd9a-40b2-b9b7-79a058916f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-39f3551d-8817-41aa-bc37-32845b46f58f,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-ea5f33ee-c0a3-496d-a7cc-47748b92b08f,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-8c9263b2-d2aa-4ca8-9703-ce60c5725ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-19a8be1a-9ae2-4702-b2f7-f74974d92e91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519839491-172.17.0.20-1597076597207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-ae9668f2-638f-41a2-9881-45b15b330992,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-23bdce31-1e4f-4acf-b0d8-204c5e4454ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-e1955b42-732b-41bd-8094-68af86b795a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-f3cc09cb-88ba-4c16-9f9a-619329ac16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-56060d21-f0cd-4d45-8669-413e923de992,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-21516438-5151-48f5-9f06-52b5da032ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-f0eb1a8d-4876-42dd-8d4d-2acbb22d2491,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-7c59b54a-f494-415b-8bd9-908c3e518fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519839491-172.17.0.20-1597076597207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-ae9668f2-638f-41a2-9881-45b15b330992,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-23bdce31-1e4f-4acf-b0d8-204c5e4454ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-e1955b42-732b-41bd-8094-68af86b795a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-f3cc09cb-88ba-4c16-9f9a-619329ac16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-56060d21-f0cd-4d45-8669-413e923de992,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-21516438-5151-48f5-9f06-52b5da032ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-f0eb1a8d-4876-42dd-8d4d-2acbb22d2491,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-7c59b54a-f494-415b-8bd9-908c3e518fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011334402-172.17.0.20-1597076629749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39259,DS-fe560e84-e777-4ba7-acbf-176e53a18cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-898ad0cc-17b8-404c-8709-d088424447a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-cc7b5753-0d0b-4ad0-a7ca-75b4a6492943,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-860fede3-ccc9-4edc-8854-1b93d02d1322,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-db1fe522-4c6f-41cb-ad2d-c2f4a117ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-96810b6d-f73c-4d84-9019-fcef7383f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-1da41fca-2b10-4bfa-83dd-6abb277c92cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-0c638bb4-56f1-4c97-a353-be3793024ae6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011334402-172.17.0.20-1597076629749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39259,DS-fe560e84-e777-4ba7-acbf-176e53a18cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-898ad0cc-17b8-404c-8709-d088424447a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-cc7b5753-0d0b-4ad0-a7ca-75b4a6492943,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-860fede3-ccc9-4edc-8854-1b93d02d1322,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-db1fe522-4c6f-41cb-ad2d-c2f4a117ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-96810b6d-f73c-4d84-9019-fcef7383f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-1da41fca-2b10-4bfa-83dd-6abb277c92cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-0c638bb4-56f1-4c97-a353-be3793024ae6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424305618-172.17.0.20-1597077750979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45089,DS-43a8a3ae-0e77-492f-8d4d-c6502898b944,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-17588e78-a817-4eb4-8165-ac70e026ba9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-1957a55b-d297-4cd1-82af-02cc42289f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-958e1dec-1d08-469d-8a13-4f5975a482a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-f69397e3-7b33-4893-9dcb-1d701636451d,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-b708b96e-20a8-4ee5-9335-af1022458dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-55301446-9d2d-413b-8de0-270f45a46e62,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-e8a03152-2cca-4584-bf99-7d271e3b5977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424305618-172.17.0.20-1597077750979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45089,DS-43a8a3ae-0e77-492f-8d4d-c6502898b944,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-17588e78-a817-4eb4-8165-ac70e026ba9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-1957a55b-d297-4cd1-82af-02cc42289f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-958e1dec-1d08-469d-8a13-4f5975a482a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-f69397e3-7b33-4893-9dcb-1d701636451d,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-b708b96e-20a8-4ee5-9335-af1022458dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-55301446-9d2d-413b-8de0-270f45a46e62,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-e8a03152-2cca-4584-bf99-7d271e3b5977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579962657-172.17.0.20-1597078504867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34035,DS-53fabd2f-fd01-4100-b267-e0641193b9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-dfd4af4f-e292-42b6-9164-142a06fabc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-f5d879ec-7c65-4430-a399-4a6461eba473,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-f651ce4f-883f-4bcf-9e8f-d278832d98fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-ef788c58-3935-4743-ac5f-53e6b742be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-4da7a72c-fc8e-4023-9cf1-f68527680db5,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-54db5c87-c247-441c-a498-bee0161c6397,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-b2d9f56b-c3c9-4ec1-8c07-a0982a1712db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579962657-172.17.0.20-1597078504867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34035,DS-53fabd2f-fd01-4100-b267-e0641193b9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-dfd4af4f-e292-42b6-9164-142a06fabc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-f5d879ec-7c65-4430-a399-4a6461eba473,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-f651ce4f-883f-4bcf-9e8f-d278832d98fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-ef788c58-3935-4743-ac5f-53e6b742be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-4da7a72c-fc8e-4023-9cf1-f68527680db5,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-54db5c87-c247-441c-a498-bee0161c6397,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-b2d9f56b-c3c9-4ec1-8c07-a0982a1712db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563191167-172.17.0.20-1597078545324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-fb9cf1b7-4400-41a4-87c8-3c837e3cb129,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-435557ab-9c3f-4ab9-86b6-e3f2f51bb111,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-bd213656-b155-4ecb-bf46-116622802487,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-c8680207-814f-4bf9-a193-dcff5be3a6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-0e968f74-48f2-48b5-9828-ca0d14895f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-51c1a0f5-df0e-481f-947f-4a418d897cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-a6d41898-e1ec-4adf-802a-96b162fa7449,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-cd4717df-1fc8-4a10-aa16-c9465b478a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563191167-172.17.0.20-1597078545324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-fb9cf1b7-4400-41a4-87c8-3c837e3cb129,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-435557ab-9c3f-4ab9-86b6-e3f2f51bb111,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-bd213656-b155-4ecb-bf46-116622802487,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-c8680207-814f-4bf9-a193-dcff5be3a6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-0e968f74-48f2-48b5-9828-ca0d14895f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-51c1a0f5-df0e-481f-947f-4a418d897cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-a6d41898-e1ec-4adf-802a-96b162fa7449,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-cd4717df-1fc8-4a10-aa16-c9465b478a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333800472-172.17.0.20-1597078697414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-5ba67458-ec6f-4d4b-8638-6123a1c9c137,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-8f3c9af2-bb1c-4ec8-84b9-db3a415a5c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-4fc68c6d-56d1-4a84-bfc8-9d3987b16095,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-65d67fc2-4520-4079-986e-b679a3b23417,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-f48946ec-3167-416e-9845-eac9a6ffe51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-9931893e-a279-4680-954d-36aacdc1d3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-ccfb9f0c-3257-4423-9462-1f7b03f4e4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-09338c12-f139-489b-a2b0-e09e210e9009,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333800472-172.17.0.20-1597078697414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-5ba67458-ec6f-4d4b-8638-6123a1c9c137,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-8f3c9af2-bb1c-4ec8-84b9-db3a415a5c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-4fc68c6d-56d1-4a84-bfc8-9d3987b16095,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-65d67fc2-4520-4079-986e-b679a3b23417,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-f48946ec-3167-416e-9845-eac9a6ffe51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-9931893e-a279-4680-954d-36aacdc1d3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-ccfb9f0c-3257-4423-9462-1f7b03f4e4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-09338c12-f139-489b-a2b0-e09e210e9009,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747573763-172.17.0.20-1597078836243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43648,DS-35cf86d4-1ac7-4f17-bb9d-b5bf302aa0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-914383f5-f8a5-49d2-b7dd-5e335b3cfbae,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-1ba30fdd-819f-401c-84f8-83bd47fd5f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-2b3da48a-cffc-46bb-8648-a313a4139ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-785386a4-22cc-4342-bf71-5d5994f23cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-d63cd539-0e59-4245-abad-bded1583eeca,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-d0518326-2806-4cfb-aaa1-491584aaf0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-5f119974-6edf-43df-aae3-e006122fa36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747573763-172.17.0.20-1597078836243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43648,DS-35cf86d4-1ac7-4f17-bb9d-b5bf302aa0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-914383f5-f8a5-49d2-b7dd-5e335b3cfbae,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-1ba30fdd-819f-401c-84f8-83bd47fd5f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-2b3da48a-cffc-46bb-8648-a313a4139ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-785386a4-22cc-4342-bf71-5d5994f23cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-d63cd539-0e59-4245-abad-bded1583eeca,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-d0518326-2806-4cfb-aaa1-491584aaf0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-5f119974-6edf-43df-aae3-e006122fa36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453426598-172.17.0.20-1597078874878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39891,DS-58eae56a-6fda-451c-b09e-34f5b4b172fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-fcdb4f84-0a55-4ed6-8304-e36314c710d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-7cc09140-d5dc-4ee8-97f4-30059b8bdc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-dab362e1-a208-4034-a2ed-438e2010edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-1a3ab879-e06f-429a-a21d-d3873dabf4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-8bacd9ef-724f-4671-8ad9-b5a47e699d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-021f4d27-66fb-4231-8a14-6aed4ebba8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-1a83d8af-2db1-4a64-aad6-f319a6d50e93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453426598-172.17.0.20-1597078874878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39891,DS-58eae56a-6fda-451c-b09e-34f5b4b172fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-fcdb4f84-0a55-4ed6-8304-e36314c710d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-7cc09140-d5dc-4ee8-97f4-30059b8bdc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-dab362e1-a208-4034-a2ed-438e2010edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-1a3ab879-e06f-429a-a21d-d3873dabf4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-8bacd9ef-724f-4671-8ad9-b5a47e699d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-021f4d27-66fb-4231-8a14-6aed4ebba8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-1a83d8af-2db1-4a64-aad6-f319a6d50e93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5523
