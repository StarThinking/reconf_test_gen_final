reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805634244-172.17.0.21-1597103945229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-5c204abc-c84e-4870-b94a-4bd9e2a12412,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-e979128e-4350-4f67-a99b-222ecc3b9f28,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-dabbe688-f02b-4e70-9767-4e1af0ae4298,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-4114c73a-eb26-415f-b9c3-c89cc6e4e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-4cbd2607-bfc8-4817-a6f5-12a1aee7dd23,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-d01729db-97ba-49c6-98f0-d8401d30e685,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-ae2227ea-ae3d-4a18-8028-1c25a845762c,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-565f1f67-3d0f-4b7e-8b08-81989e4455d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805634244-172.17.0.21-1597103945229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-5c204abc-c84e-4870-b94a-4bd9e2a12412,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-e979128e-4350-4f67-a99b-222ecc3b9f28,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-dabbe688-f02b-4e70-9767-4e1af0ae4298,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-4114c73a-eb26-415f-b9c3-c89cc6e4e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-4cbd2607-bfc8-4817-a6f5-12a1aee7dd23,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-d01729db-97ba-49c6-98f0-d8401d30e685,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-ae2227ea-ae3d-4a18-8028-1c25a845762c,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-565f1f67-3d0f-4b7e-8b08-81989e4455d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933310075-172.17.0.21-1597104286729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43218,DS-828b9162-1950-46a5-9ece-04d581449cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-3c737585-f799-4590-a1d4-3f8b4a65d398,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-e9d92d5c-e978-4c60-864a-87e91474c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-ad4ad272-992e-48c1-85bd-96f7dd112bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-2aed0335-a5ed-4bc4-86a4-26f2cdb77540,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-feda01a4-a8e9-4784-a915-cc5f4305bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-4022d312-33fb-4a8d-bb34-733ca594914d,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-afdfb64a-6da7-4410-8d41-cf844f077a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933310075-172.17.0.21-1597104286729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43218,DS-828b9162-1950-46a5-9ece-04d581449cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-3c737585-f799-4590-a1d4-3f8b4a65d398,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-e9d92d5c-e978-4c60-864a-87e91474c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-ad4ad272-992e-48c1-85bd-96f7dd112bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-2aed0335-a5ed-4bc4-86a4-26f2cdb77540,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-feda01a4-a8e9-4784-a915-cc5f4305bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-4022d312-33fb-4a8d-bb34-733ca594914d,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-afdfb64a-6da7-4410-8d41-cf844f077a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023161155-172.17.0.21-1597104676186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-faafcadb-db30-4d14-81ef-dcd5da83aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-694efb64-d8b9-4862-b689-b93b7edee74d,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-823d8f0f-10a5-49eb-a648-b807424d294c,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-741f27bf-efc7-4166-b4d1-7c64c777481e,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-67d9df9d-a12f-42ab-8730-0a7caa052ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-ad866785-8e51-4fcb-9f6d-69631e632bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-56b00d9f-d120-49bf-a22f-db2dba5fdbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-d8420a1b-9960-4744-8363-c2075f2a311c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023161155-172.17.0.21-1597104676186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-faafcadb-db30-4d14-81ef-dcd5da83aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-694efb64-d8b9-4862-b689-b93b7edee74d,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-823d8f0f-10a5-49eb-a648-b807424d294c,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-741f27bf-efc7-4166-b4d1-7c64c777481e,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-67d9df9d-a12f-42ab-8730-0a7caa052ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-ad866785-8e51-4fcb-9f6d-69631e632bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-56b00d9f-d120-49bf-a22f-db2dba5fdbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-d8420a1b-9960-4744-8363-c2075f2a311c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824465050-172.17.0.21-1597105140670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-3dc00b75-98de-449a-b8f9-be7c63830c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-0cdb1ccd-a4ed-4734-b5e4-d86e3d14276d,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-3b78ff52-cb36-4128-9f8f-acd8c8db2597,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-14723302-4003-4573-b077-470d671463fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-d6d967cb-4886-431a-8514-6b828db827b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-b91dfdcc-73cd-4932-bf38-773e3f1e59d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-5e8cb5cf-c1f7-41ad-a45e-aeb2c481332e,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-e13d4fbb-04a0-47fb-bcd3-c9fc0cc728dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824465050-172.17.0.21-1597105140670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-3dc00b75-98de-449a-b8f9-be7c63830c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-0cdb1ccd-a4ed-4734-b5e4-d86e3d14276d,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-3b78ff52-cb36-4128-9f8f-acd8c8db2597,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-14723302-4003-4573-b077-470d671463fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-d6d967cb-4886-431a-8514-6b828db827b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-b91dfdcc-73cd-4932-bf38-773e3f1e59d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-5e8cb5cf-c1f7-41ad-a45e-aeb2c481332e,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-e13d4fbb-04a0-47fb-bcd3-c9fc0cc728dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899866437-172.17.0.21-1597105389437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46707,DS-f1e1f425-da31-4711-be24-6cad6ae97c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-6e52e13f-b43b-4847-8b0d-9d1263de5285,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-ca03699e-f2a8-48ca-8e5f-eda9621cdf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-84a2820e-4117-4356-9759-af9f0eaed903,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-555c0e8f-3bd7-473f-8161-1d3c05d11d39,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-541810f2-91b5-483e-887c-4016fe7a22e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-ef0da185-df12-49df-851d-84a17a3f190c,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-c3143826-1dc2-4c5a-9c86-210660ceb21d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899866437-172.17.0.21-1597105389437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46707,DS-f1e1f425-da31-4711-be24-6cad6ae97c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-6e52e13f-b43b-4847-8b0d-9d1263de5285,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-ca03699e-f2a8-48ca-8e5f-eda9621cdf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-84a2820e-4117-4356-9759-af9f0eaed903,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-555c0e8f-3bd7-473f-8161-1d3c05d11d39,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-541810f2-91b5-483e-887c-4016fe7a22e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-ef0da185-df12-49df-851d-84a17a3f190c,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-c3143826-1dc2-4c5a-9c86-210660ceb21d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912012216-172.17.0.21-1597105970738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46633,DS-1ebf0d8e-5443-4a5d-bf8e-4eb3794be1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-a0645475-095b-4b6c-8070-79b3904703f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-623e4046-fc39-4b1f-b4e2-c9f17af64509,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-6776f116-5a61-4e7d-ab22-b7f228bbd512,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1fb95e64-9145-4925-a761-6a742ec720c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-28dc6079-6886-4a48-8f7d-7c75cb22c6be,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-51b09ff0-1e9b-407f-bd81-e8c59456dc18,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-bd0a60e8-ae66-4fbc-98c9-0437b9dacdef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912012216-172.17.0.21-1597105970738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46633,DS-1ebf0d8e-5443-4a5d-bf8e-4eb3794be1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-a0645475-095b-4b6c-8070-79b3904703f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-623e4046-fc39-4b1f-b4e2-c9f17af64509,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-6776f116-5a61-4e7d-ab22-b7f228bbd512,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1fb95e64-9145-4925-a761-6a742ec720c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-28dc6079-6886-4a48-8f7d-7c75cb22c6be,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-51b09ff0-1e9b-407f-bd81-e8c59456dc18,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-bd0a60e8-ae66-4fbc-98c9-0437b9dacdef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538247632-172.17.0.21-1597106006720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40227,DS-47dcdbe1-b05f-4d9e-8dd6-8022a80fb135,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-7cbcfe67-69c8-4f30-b033-34b8f3c82e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-47d9db45-7786-4688-8050-71c1ed738c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-e5c87e68-369b-43da-9041-6ca54ad39703,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-eda283fe-b5d7-4882-8526-c8a72351eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-a8471da7-50db-4733-9c4b-c63c7a5002bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-e590ac85-be2d-4c98-ae8f-fe61f9b72355,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-b7c50799-3e9b-4cd9-bdd5-3bbffc11dc97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538247632-172.17.0.21-1597106006720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40227,DS-47dcdbe1-b05f-4d9e-8dd6-8022a80fb135,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-7cbcfe67-69c8-4f30-b033-34b8f3c82e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-47d9db45-7786-4688-8050-71c1ed738c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-e5c87e68-369b-43da-9041-6ca54ad39703,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-eda283fe-b5d7-4882-8526-c8a72351eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-a8471da7-50db-4733-9c4b-c63c7a5002bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-e590ac85-be2d-4c98-ae8f-fe61f9b72355,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-b7c50799-3e9b-4cd9-bdd5-3bbffc11dc97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498161827-172.17.0.21-1597106242185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38927,DS-ebf03f0e-defe-4509-8598-e60d9f2347ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-c71c4d66-624d-4686-acbb-731e08b74ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-c24870b3-6501-4395-81de-1f3b3ab9b6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-01f7fafa-e6d6-448d-8bd8-81289a6926af,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-bd73076b-c9fd-494c-a692-1762343fb10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-ca8c38a1-1416-4468-b340-5e64f0bd4dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-d4f5b8ee-e944-4269-af17-7964db36c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-20a71860-289c-4a44-b3e4-8356c8417a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498161827-172.17.0.21-1597106242185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38927,DS-ebf03f0e-defe-4509-8598-e60d9f2347ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-c71c4d66-624d-4686-acbb-731e08b74ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-c24870b3-6501-4395-81de-1f3b3ab9b6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-01f7fafa-e6d6-448d-8bd8-81289a6926af,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-bd73076b-c9fd-494c-a692-1762343fb10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-ca8c38a1-1416-4468-b340-5e64f0bd4dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-d4f5b8ee-e944-4269-af17-7964db36c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-20a71860-289c-4a44-b3e4-8356c8417a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353352767-172.17.0.21-1597106278516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-d65f9c4d-8a07-4916-a844-52c167e318bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-9415ccc8-0bff-4c4c-b521-787482c5f43e,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-1a41cda8-e758-4bfc-a0b5-60f8d3df1d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-f96ce0bb-4b3e-49e1-8b97-253d8a031741,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-3bb8b9fd-e1c6-4be9-a3fc-09b2d19e5dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-f7bad5d2-8dda-4602-bf7f-9d6861a20311,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-ec48d22f-89e4-4fae-904c-5cda3b17c862,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-edbeb53e-578c-4bbc-8648-b977f979c586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353352767-172.17.0.21-1597106278516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-d65f9c4d-8a07-4916-a844-52c167e318bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-9415ccc8-0bff-4c4c-b521-787482c5f43e,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-1a41cda8-e758-4bfc-a0b5-60f8d3df1d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-f96ce0bb-4b3e-49e1-8b97-253d8a031741,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-3bb8b9fd-e1c6-4be9-a3fc-09b2d19e5dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-f7bad5d2-8dda-4602-bf7f-9d6861a20311,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-ec48d22f-89e4-4fae-904c-5cda3b17c862,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-edbeb53e-578c-4bbc-8648-b977f979c586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585719478-172.17.0.21-1597106398171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-7cd2deec-f035-4cc6-a29d-b3cd14a34bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-0b91232f-389f-4334-b624-de5d7d15bd20,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-668700ed-6e73-4185-a184-7d5cf955f98e,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-65fa4de8-b486-480f-9f52-819ce62755db,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-2009feae-26a7-402d-9a58-8d1ec28acf69,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-645ae200-931a-41cc-af1d-d86b8c4f356e,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-b474cc30-7eaa-41c9-bc0b-5ab613aabdff,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-78c2c671-c0fa-49a4-88e0-34b6bbada67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585719478-172.17.0.21-1597106398171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-7cd2deec-f035-4cc6-a29d-b3cd14a34bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-0b91232f-389f-4334-b624-de5d7d15bd20,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-668700ed-6e73-4185-a184-7d5cf955f98e,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-65fa4de8-b486-480f-9f52-819ce62755db,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-2009feae-26a7-402d-9a58-8d1ec28acf69,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-645ae200-931a-41cc-af1d-d86b8c4f356e,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-b474cc30-7eaa-41c9-bc0b-5ab613aabdff,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-78c2c671-c0fa-49a4-88e0-34b6bbada67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627560752-172.17.0.21-1597107584338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43165,DS-a4fc0a43-abb7-47cd-811b-fbb7970f8f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-81184b96-712b-4da5-9f3b-19e1f83dc650,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-12f73dd0-e1f6-4070-a6a9-8919bcaff911,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-c8dfa3df-eec4-4838-8976-e24cc102b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-7baab0d5-3def-44ab-b09d-83ec087889b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-0af5dcd0-3ec4-49b3-8d76-927f5cb3cb94,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-f0c63315-a896-415d-aa92-9ba75e19c5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-9d6d9947-a20b-48f4-9f09-6e99769c40b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627560752-172.17.0.21-1597107584338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43165,DS-a4fc0a43-abb7-47cd-811b-fbb7970f8f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-81184b96-712b-4da5-9f3b-19e1f83dc650,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-12f73dd0-e1f6-4070-a6a9-8919bcaff911,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-c8dfa3df-eec4-4838-8976-e24cc102b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-7baab0d5-3def-44ab-b09d-83ec087889b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-0af5dcd0-3ec4-49b3-8d76-927f5cb3cb94,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-f0c63315-a896-415d-aa92-9ba75e19c5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-9d6d9947-a20b-48f4-9f09-6e99769c40b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116224351-172.17.0.21-1597107753394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-36154ff7-f513-48b3-ae37-8ede293b13ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-b21ca4e3-1b0c-4d5b-b149-0ced9fedde57,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-6f0b2c89-392b-42d3-9a17-2970bdd77153,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-cff9d722-b5a8-4b82-96bf-22d76e64e783,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-79702554-9a7c-435b-8b27-bcf2a980b06c,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-6a5b8190-22c7-4b00-9e8a-7e580d4f365d,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-e6ec8f1f-f8ab-4f84-b268-beb05d7e4f78,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-1efeef5a-13bd-4f90-a561-e7347417bdb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116224351-172.17.0.21-1597107753394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-36154ff7-f513-48b3-ae37-8ede293b13ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-b21ca4e3-1b0c-4d5b-b149-0ced9fedde57,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-6f0b2c89-392b-42d3-9a17-2970bdd77153,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-cff9d722-b5a8-4b82-96bf-22d76e64e783,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-79702554-9a7c-435b-8b27-bcf2a980b06c,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-6a5b8190-22c7-4b00-9e8a-7e580d4f365d,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-e6ec8f1f-f8ab-4f84-b268-beb05d7e4f78,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-1efeef5a-13bd-4f90-a561-e7347417bdb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489279941-172.17.0.21-1597107818473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-0681c63c-ab87-4751-90b6-5a248e1554d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-49a0ba64-fb3c-4efd-a3d8-a1bf9b7e8ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-564271aa-0afd-4c1a-a6db-9f4baeceaf77,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-b9a5e8e7-9de7-4bb1-993d-94e9e782a8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-12fdd0be-21e4-48c8-9108-b1ff110dacb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-bc4d32c9-c473-4fda-ba9c-274c5e8804c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-13ba73c2-2832-4b5a-90b4-d8add604abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-e3b31630-058e-4ecb-b7ec-8da9aeea2de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489279941-172.17.0.21-1597107818473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-0681c63c-ab87-4751-90b6-5a248e1554d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-49a0ba64-fb3c-4efd-a3d8-a1bf9b7e8ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-564271aa-0afd-4c1a-a6db-9f4baeceaf77,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-b9a5e8e7-9de7-4bb1-993d-94e9e782a8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-12fdd0be-21e4-48c8-9108-b1ff110dacb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-bc4d32c9-c473-4fda-ba9c-274c5e8804c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-13ba73c2-2832-4b5a-90b4-d8add604abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-e3b31630-058e-4ecb-b7ec-8da9aeea2de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982693266-172.17.0.21-1597107982653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-bcbc9ce6-1457-460e-9239-5d3270c7e1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-589f6843-80fd-415e-9717-70a75661867c,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-aada4782-d0f0-4672-813a-fb06e6e12728,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-bfa4cafe-060a-423a-b2e7-52bbd262fea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-6268d798-554e-46cb-b106-c219129e3098,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-548d6a4c-d7ea-4c7d-ab11-5e656738d9be,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-d9902fba-ede9-4444-a5b1-9acf6d862ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-c4b92ee8-6513-4476-87e2-c9abab16cf6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982693266-172.17.0.21-1597107982653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-bcbc9ce6-1457-460e-9239-5d3270c7e1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-589f6843-80fd-415e-9717-70a75661867c,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-aada4782-d0f0-4672-813a-fb06e6e12728,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-bfa4cafe-060a-423a-b2e7-52bbd262fea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-6268d798-554e-46cb-b106-c219129e3098,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-548d6a4c-d7ea-4c7d-ab11-5e656738d9be,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-d9902fba-ede9-4444-a5b1-9acf6d862ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-c4b92ee8-6513-4476-87e2-c9abab16cf6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307720744-172.17.0.21-1597108288673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-8913bdb9-87de-4fa2-9743-1cb47606df23,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-56985024-b599-43c2-ad34-33add50111a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-6101b380-4c4b-43ba-a94e-d9cf26f01a98,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-78a46377-3beb-4b92-aec7-326747d65200,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-e21ebb96-2c45-43d1-8949-aab37266f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-d5e773a3-bbf4-40cb-be85-ae69a1b77676,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-73aa65b9-68cd-4e24-b141-f0a9de9a7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-aa42b29c-a2db-497c-9991-28754a177d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307720744-172.17.0.21-1597108288673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-8913bdb9-87de-4fa2-9743-1cb47606df23,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-56985024-b599-43c2-ad34-33add50111a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-6101b380-4c4b-43ba-a94e-d9cf26f01a98,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-78a46377-3beb-4b92-aec7-326747d65200,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-e21ebb96-2c45-43d1-8949-aab37266f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-d5e773a3-bbf4-40cb-be85-ae69a1b77676,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-73aa65b9-68cd-4e24-b141-f0a9de9a7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-aa42b29c-a2db-497c-9991-28754a177d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5318
