reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477190034-172.17.0.19-1597136350675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38079,DS-a479bbb1-b1dc-42b1-b6fd-d442bc637244,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-0f8ee850-e7de-4b86-b365-48be4fef2320,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-a1a83724-f065-4517-8573-97bcd8b198a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-c07a25e5-7371-4c0b-b379-bc88831c7400,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-9abb20be-7971-4762-a415-940b652009a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-0c837314-0850-4349-9613-a72434a09328,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-9454c4fb-afcf-4b96-8315-4eddaf047ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-06c80c9e-8fa4-443d-b869-cfcf8f22181b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477190034-172.17.0.19-1597136350675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38079,DS-a479bbb1-b1dc-42b1-b6fd-d442bc637244,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-0f8ee850-e7de-4b86-b365-48be4fef2320,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-a1a83724-f065-4517-8573-97bcd8b198a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-c07a25e5-7371-4c0b-b379-bc88831c7400,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-9abb20be-7971-4762-a415-940b652009a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-0c837314-0850-4349-9613-a72434a09328,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-9454c4fb-afcf-4b96-8315-4eddaf047ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-06c80c9e-8fa4-443d-b869-cfcf8f22181b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25156034-172.17.0.19-1597136384107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-36d3b559-fdcd-40fb-8dd3-0268da2145dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-8248f49a-b67b-4a92-8bfc-adabc7ce515a,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-022c0e41-fd9d-41d1-8fea-9f43c40e9753,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-6f457202-99d7-416d-8b15-88a24d9e5472,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-93ce2ed7-3f56-4295-92b1-b51abc3cd701,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-31f5d240-f136-4ce8-a0e8-fe02d01411ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-93179180-112e-4201-a6c7-dd3aeb6d701a,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-27125f12-0984-4a21-ac40-14a3f284b92e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25156034-172.17.0.19-1597136384107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-36d3b559-fdcd-40fb-8dd3-0268da2145dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-8248f49a-b67b-4a92-8bfc-adabc7ce515a,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-022c0e41-fd9d-41d1-8fea-9f43c40e9753,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-6f457202-99d7-416d-8b15-88a24d9e5472,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-93ce2ed7-3f56-4295-92b1-b51abc3cd701,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-31f5d240-f136-4ce8-a0e8-fe02d01411ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-93179180-112e-4201-a6c7-dd3aeb6d701a,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-27125f12-0984-4a21-ac40-14a3f284b92e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459822815-172.17.0.19-1597136547690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38602,DS-ff3da545-9bea-4559-adf8-b62fd3cbde86,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-4fbd91fc-eb2d-445d-8dc5-6d000ae4df71,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-6ce8ec44-27d1-4093-9c79-366b2c89fce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-e46ad8d2-f17a-4f00-8442-d63344681894,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-bdf41782-70f5-4b1c-9a78-fb4eb8060278,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-65ac8f82-e0fc-47ad-b3a3-55aa2ab7f524,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-9a1ee339-a3fa-4e67-977d-c0d0db0274da,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-b54fd10f-06e7-4d71-a026-158a0fbeb459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459822815-172.17.0.19-1597136547690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38602,DS-ff3da545-9bea-4559-adf8-b62fd3cbde86,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-4fbd91fc-eb2d-445d-8dc5-6d000ae4df71,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-6ce8ec44-27d1-4093-9c79-366b2c89fce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-e46ad8d2-f17a-4f00-8442-d63344681894,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-bdf41782-70f5-4b1c-9a78-fb4eb8060278,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-65ac8f82-e0fc-47ad-b3a3-55aa2ab7f524,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-9a1ee339-a3fa-4e67-977d-c0d0db0274da,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-b54fd10f-06e7-4d71-a026-158a0fbeb459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55593229-172.17.0.19-1597136825434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-d3eacd2d-bb43-4862-9c5d-f071ff7afc92,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-d76bc00a-42f4-44e8-816c-904bd6dc1b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-28530ede-b502-457a-92a6-15823b1f8588,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-116e2405-6fbd-405c-8646-587336e6e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-7cdf5013-8774-4520-9e58-2cd5025dd5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-7bf434d1-0c27-4e44-b107-817e58abecf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-c569ecd5-3c7f-4c19-8eab-02421e0053e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-a269c2c9-a503-4c3a-b929-5ba0492aae70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55593229-172.17.0.19-1597136825434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-d3eacd2d-bb43-4862-9c5d-f071ff7afc92,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-d76bc00a-42f4-44e8-816c-904bd6dc1b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-28530ede-b502-457a-92a6-15823b1f8588,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-116e2405-6fbd-405c-8646-587336e6e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-7cdf5013-8774-4520-9e58-2cd5025dd5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-7bf434d1-0c27-4e44-b107-817e58abecf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-c569ecd5-3c7f-4c19-8eab-02421e0053e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-a269c2c9-a503-4c3a-b929-5ba0492aae70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140722965-172.17.0.19-1597136865629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-11c84270-5a11-434b-83eb-51e4905deb55,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-4a7170d8-54e8-44c6-b0b5-5dd2043a1c04,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-6921f565-7ac4-481b-89c1-40bd296eab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-eb363e2e-da80-4ad6-9a4e-bbbd78a22f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-9578bda4-1a9d-40ab-87c1-02220b54b43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-8ea4cd5a-722b-4c02-8815-f64683346ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-6e1f0d75-70fd-43e8-942e-f661caa4af42,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-d9452b89-d97a-4ee2-806c-38aa92c55562,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140722965-172.17.0.19-1597136865629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-11c84270-5a11-434b-83eb-51e4905deb55,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-4a7170d8-54e8-44c6-b0b5-5dd2043a1c04,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-6921f565-7ac4-481b-89c1-40bd296eab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-eb363e2e-da80-4ad6-9a4e-bbbd78a22f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-9578bda4-1a9d-40ab-87c1-02220b54b43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-8ea4cd5a-722b-4c02-8815-f64683346ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-6e1f0d75-70fd-43e8-942e-f661caa4af42,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-d9452b89-d97a-4ee2-806c-38aa92c55562,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028491440-172.17.0.19-1597137021027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-aa6b7b06-ee80-4cb9-b95e-9944b16f80ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-f5823f61-cc20-44fc-bd18-e9ac7143ed78,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-620b9f15-31b0-4846-a0c4-7f5f5b7a2c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-d954df14-b160-4efa-8799-272cb05f1112,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-01871a1e-ccdf-4c96-a815-8453c6c998a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-ee964b80-ac7a-4379-aaec-78fde15fb9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-ce03a5b2-759c-45f3-b933-081b593e84cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-dba3ad07-4266-4524-b3fb-1d4d721e634c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028491440-172.17.0.19-1597137021027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-aa6b7b06-ee80-4cb9-b95e-9944b16f80ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-f5823f61-cc20-44fc-bd18-e9ac7143ed78,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-620b9f15-31b0-4846-a0c4-7f5f5b7a2c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-d954df14-b160-4efa-8799-272cb05f1112,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-01871a1e-ccdf-4c96-a815-8453c6c998a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-ee964b80-ac7a-4379-aaec-78fde15fb9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-ce03a5b2-759c-45f3-b933-081b593e84cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-dba3ad07-4266-4524-b3fb-1d4d721e634c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484581011-172.17.0.19-1597137270483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-e971b08c-8a26-41fa-a93e-1082bb64f684,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-7d47cf33-81b2-432f-b6ea-9dfc9df6af76,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-f5acfd2d-6a7d-456e-8e0f-752bb7eae41f,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-013a6810-33fe-4566-8b1b-764ee8b66f23,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-08e2b737-1891-4fc5-9c48-4166108d73ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-9a9eb754-4fbe-48b9-931b-10333c01f2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-613f9dfd-2cf8-4689-8296-f956c445d4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-f2ce9764-c9ad-4a3c-a40f-9d7b75bda3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484581011-172.17.0.19-1597137270483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-e971b08c-8a26-41fa-a93e-1082bb64f684,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-7d47cf33-81b2-432f-b6ea-9dfc9df6af76,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-f5acfd2d-6a7d-456e-8e0f-752bb7eae41f,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-013a6810-33fe-4566-8b1b-764ee8b66f23,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-08e2b737-1891-4fc5-9c48-4166108d73ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-9a9eb754-4fbe-48b9-931b-10333c01f2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-613f9dfd-2cf8-4689-8296-f956c445d4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-f2ce9764-c9ad-4a3c-a40f-9d7b75bda3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628437111-172.17.0.19-1597137384840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37331,DS-1d21e5ec-5d7d-411f-8edd-100bf363ce7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-41169519-0afa-438f-a253-2e2303c8fdda,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-665b00f7-219c-468a-ae4c-ae4fc5815365,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-8670d977-5b91-4384-81be-9a1b8f09937b,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-aaa12f29-3c41-4ab1-ab79-5ee634d4c34f,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-1a0a2a15-fdda-44c6-b016-657653877c24,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-41dcd6fe-9ce2-49a2-a09e-662b8762bf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-17a189b3-9ad1-4ee4-8165-c1c449aea7ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628437111-172.17.0.19-1597137384840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37331,DS-1d21e5ec-5d7d-411f-8edd-100bf363ce7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-41169519-0afa-438f-a253-2e2303c8fdda,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-665b00f7-219c-468a-ae4c-ae4fc5815365,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-8670d977-5b91-4384-81be-9a1b8f09937b,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-aaa12f29-3c41-4ab1-ab79-5ee634d4c34f,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-1a0a2a15-fdda-44c6-b016-657653877c24,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-41dcd6fe-9ce2-49a2-a09e-662b8762bf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-17a189b3-9ad1-4ee4-8165-c1c449aea7ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330770331-172.17.0.19-1597137575286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-5e5e6085-11ea-4392-8c58-eec5cd46c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-2709f28a-91b8-48bf-b452-2c6dad7592dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-3f7d992e-d65c-408a-b544-23b1c8fe031c,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-5a532508-22d8-4e5f-8ae6-13c788596aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-bb6d66d7-9227-492e-b9b3-a9267f359e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-bfcd7dff-6c7a-4f8f-b728-fcc152bd21d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-63a8d3ee-9be8-428c-8c49-95c32c224509,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-049dadbc-aa0c-4b6e-937d-0b0c8d7c660d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330770331-172.17.0.19-1597137575286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-5e5e6085-11ea-4392-8c58-eec5cd46c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-2709f28a-91b8-48bf-b452-2c6dad7592dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-3f7d992e-d65c-408a-b544-23b1c8fe031c,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-5a532508-22d8-4e5f-8ae6-13c788596aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-bb6d66d7-9227-492e-b9b3-a9267f359e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-bfcd7dff-6c7a-4f8f-b728-fcc152bd21d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-63a8d3ee-9be8-428c-8c49-95c32c224509,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-049dadbc-aa0c-4b6e-937d-0b0c8d7c660d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465553280-172.17.0.19-1597137763595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43868,DS-a5aefa12-210a-45bb-a7cf-d08f41eae317,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-553b8607-c8b6-4fb5-b232-fba3d027ec97,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-f2983e7b-7f9e-4815-bf25-8fb7a96d8369,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-17000643-6e86-4457-b142-35f71bcc0ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-c54523c3-f294-4553-b19c-ae93506d862d,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-592c41bb-3b93-44c1-b2af-94b27f2b617e,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-f07b0224-4b98-48cf-9c71-2d3eae756fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-00c0fd0b-3b82-4c4a-8281-3cf007f418e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465553280-172.17.0.19-1597137763595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43868,DS-a5aefa12-210a-45bb-a7cf-d08f41eae317,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-553b8607-c8b6-4fb5-b232-fba3d027ec97,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-f2983e7b-7f9e-4815-bf25-8fb7a96d8369,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-17000643-6e86-4457-b142-35f71bcc0ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-c54523c3-f294-4553-b19c-ae93506d862d,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-592c41bb-3b93-44c1-b2af-94b27f2b617e,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-f07b0224-4b98-48cf-9c71-2d3eae756fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-00c0fd0b-3b82-4c4a-8281-3cf007f418e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091987310-172.17.0.19-1597138194085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-c3123a40-1fc1-40d1-8a0d-940738c9d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-0f05f152-3b1a-41ed-aaf3-62d83d38d812,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-58cc7d9c-47e0-424d-a3e9-45af35d954a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-37186183-4b13-4a27-84b5-f3f96cc9fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-5d254ebf-8b97-4914-96b2-9810dc26bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-187fd2eb-5b27-4829-88b2-2d520168a6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-d16dfe49-a88a-4d17-b723-70f9c58b990c,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-4cc20b28-0dcb-4db0-becc-48265f92cbe5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091987310-172.17.0.19-1597138194085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-c3123a40-1fc1-40d1-8a0d-940738c9d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-0f05f152-3b1a-41ed-aaf3-62d83d38d812,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-58cc7d9c-47e0-424d-a3e9-45af35d954a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-37186183-4b13-4a27-84b5-f3f96cc9fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-5d254ebf-8b97-4914-96b2-9810dc26bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-187fd2eb-5b27-4829-88b2-2d520168a6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-d16dfe49-a88a-4d17-b723-70f9c58b990c,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-4cc20b28-0dcb-4db0-becc-48265f92cbe5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850852279-172.17.0.19-1597138225607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37260,DS-62422260-5bcb-4b93-91f7-1670b7993a05,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-8f2dc512-e93c-476f-93c4-e12dbc8663b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-9374cf0a-f717-4e80-ae2a-bb1f741b4f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-2e116f12-a206-4dd4-a793-231e7a6e5473,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-fb705e10-4947-40ce-8267-60ea0480dba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-970c1a31-5813-4616-be25-d51e5a44717c,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-9b7dfa3b-e1bf-4b6d-bcf0-2cad67460caf,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-34024155-d861-4492-bd23-aabc6d1bd1d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850852279-172.17.0.19-1597138225607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37260,DS-62422260-5bcb-4b93-91f7-1670b7993a05,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-8f2dc512-e93c-476f-93c4-e12dbc8663b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-9374cf0a-f717-4e80-ae2a-bb1f741b4f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-2e116f12-a206-4dd4-a793-231e7a6e5473,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-fb705e10-4947-40ce-8267-60ea0480dba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-970c1a31-5813-4616-be25-d51e5a44717c,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-9b7dfa3b-e1bf-4b6d-bcf0-2cad67460caf,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-34024155-d861-4492-bd23-aabc6d1bd1d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297428148-172.17.0.19-1597138298204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-16bd2e45-6f11-4441-a88a-3a506f4e1400,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-c066d57a-6a92-486c-9835-3f3bcad2a473,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-faa32e7d-ceab-44c0-b79e-0084eaaa4b43,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-9a7f91c0-4a33-44ea-938b-d52786f0db88,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-b3932f34-29aa-40d5-83e2-836bda9d6308,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-afdf8cde-1c5a-4855-8b5b-076eaa0b32cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-152835de-4c3f-48ba-81df-a52774f360ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-765c4731-c94a-4f20-85aa-a5893cf71c7f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297428148-172.17.0.19-1597138298204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-16bd2e45-6f11-4441-a88a-3a506f4e1400,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-c066d57a-6a92-486c-9835-3f3bcad2a473,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-faa32e7d-ceab-44c0-b79e-0084eaaa4b43,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-9a7f91c0-4a33-44ea-938b-d52786f0db88,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-b3932f34-29aa-40d5-83e2-836bda9d6308,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-afdf8cde-1c5a-4855-8b5b-076eaa0b32cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-152835de-4c3f-48ba-81df-a52774f360ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-765c4731-c94a-4f20-85aa-a5893cf71c7f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030261071-172.17.0.19-1597138540429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42743,DS-b043b1c8-3c96-485d-92b3-7a4b29c092b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f7f37e13-6c33-478d-8f03-128612664647,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-554dffeb-cdb5-4e60-bf8a-0d7a0459cd06,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-ebbd7ec0-dcdd-4982-b824-394c13e00257,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-60018e5d-9d80-4873-a161-dabf8c3e0501,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-e8aed19f-ec1e-4417-b0f9-dacdbf62bceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-b887e41a-0211-4798-b741-1e8e31ad4f31,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-02e40a6d-f5ee-49ae-b0e4-9cf3b6289fcf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030261071-172.17.0.19-1597138540429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42743,DS-b043b1c8-3c96-485d-92b3-7a4b29c092b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f7f37e13-6c33-478d-8f03-128612664647,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-554dffeb-cdb5-4e60-bf8a-0d7a0459cd06,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-ebbd7ec0-dcdd-4982-b824-394c13e00257,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-60018e5d-9d80-4873-a161-dabf8c3e0501,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-e8aed19f-ec1e-4417-b0f9-dacdbf62bceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-b887e41a-0211-4798-b741-1e8e31ad4f31,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-02e40a6d-f5ee-49ae-b0e4-9cf3b6289fcf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905663066-172.17.0.19-1597138741013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-dd58b1a5-4aa5-4e2f-8a54-24d241342edf,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-6a21bdca-0932-4101-9def-9df6086fa608,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-775552bf-debf-4381-8908-44c1b566619a,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-00f8bc95-5840-4615-887e-e478bed77c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-5d2ae535-0002-4377-af66-db31b47dadcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-dae49287-542f-4a31-a950-54fb05a957cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-2ea94cdf-b56a-4769-9803-57afe87dab57,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-d4eb4109-67fa-4dbc-be29-582cadf6c96f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905663066-172.17.0.19-1597138741013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-dd58b1a5-4aa5-4e2f-8a54-24d241342edf,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-6a21bdca-0932-4101-9def-9df6086fa608,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-775552bf-debf-4381-8908-44c1b566619a,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-00f8bc95-5840-4615-887e-e478bed77c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-5d2ae535-0002-4377-af66-db31b47dadcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-dae49287-542f-4a31-a950-54fb05a957cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-2ea94cdf-b56a-4769-9803-57afe87dab57,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-d4eb4109-67fa-4dbc-be29-582cadf6c96f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3820327-172.17.0.19-1597138780691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-2fa26e42-5562-45f4-b34f-bc6cdde118ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-c1039a81-5fbc-4c13-9f24-3cfcd8aa8d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-3f60a0b8-b663-4071-9e3e-cda7a8dc8e88,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-5516c1c7-807e-4211-bba2-dbc67ba14e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-f0cc39eb-eb78-46e8-ae4d-48f0634b3b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-6424224c-bbd4-4998-946b-0a40eb6df6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-cb831e41-8e80-4728-a4e6-64a105f530f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-d560be44-9e9e-4e5f-9fbe-e5c2141f15e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3820327-172.17.0.19-1597138780691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-2fa26e42-5562-45f4-b34f-bc6cdde118ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-c1039a81-5fbc-4c13-9f24-3cfcd8aa8d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-3f60a0b8-b663-4071-9e3e-cda7a8dc8e88,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-5516c1c7-807e-4211-bba2-dbc67ba14e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-f0cc39eb-eb78-46e8-ae4d-48f0634b3b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-6424224c-bbd4-4998-946b-0a40eb6df6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-cb831e41-8e80-4728-a4e6-64a105f530f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-d560be44-9e9e-4e5f-9fbe-e5c2141f15e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174442969-172.17.0.19-1597139326559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39603,DS-f2415c07-ac0b-4bb7-803b-27f19b79ef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-cb63f9e2-de8a-4c4d-a244-d99a3cafeb82,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-38dde57b-1de9-48e7-995e-b7c3e65c3146,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-318daf54-d500-4255-82f2-213931be1bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-d1576d70-bcaa-4604-89e7-20ad5df7865c,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-1af39a5e-9b3b-43cc-b8f3-7f045089b200,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-f8470230-3f76-45ad-b952-c19091693cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-f5d82812-be53-47de-a4c2-e63a50fac7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174442969-172.17.0.19-1597139326559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39603,DS-f2415c07-ac0b-4bb7-803b-27f19b79ef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-cb63f9e2-de8a-4c4d-a244-d99a3cafeb82,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-38dde57b-1de9-48e7-995e-b7c3e65c3146,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-318daf54-d500-4255-82f2-213931be1bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-d1576d70-bcaa-4604-89e7-20ad5df7865c,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-1af39a5e-9b3b-43cc-b8f3-7f045089b200,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-f8470230-3f76-45ad-b952-c19091693cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-f5d82812-be53-47de-a4c2-e63a50fac7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328970524-172.17.0.19-1597139938231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-61f46dd5-2bbf-4413-8bc3-4176206bb300,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-661d859d-5048-4508-96ed-4b262a90435f,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-ddfa5def-ecf4-4b87-9c68-70f11fab520e,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-cfb40b68-c96d-4b39-8ed5-639ff132bced,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-c83528e9-526a-4ea7-8070-fc7798ff5998,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-e6dc8af2-f137-4d21-8d63-be702ec5201a,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-2e58c68b-bc10-42ae-afc9-66dcbfd703ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-8d2f7dbd-7478-4bea-a7d7-b089bc877a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328970524-172.17.0.19-1597139938231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-61f46dd5-2bbf-4413-8bc3-4176206bb300,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-661d859d-5048-4508-96ed-4b262a90435f,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-ddfa5def-ecf4-4b87-9c68-70f11fab520e,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-cfb40b68-c96d-4b39-8ed5-639ff132bced,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-c83528e9-526a-4ea7-8070-fc7798ff5998,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-e6dc8af2-f137-4d21-8d63-be702ec5201a,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-2e58c68b-bc10-42ae-afc9-66dcbfd703ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-8d2f7dbd-7478-4bea-a7d7-b089bc877a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92889290-172.17.0.19-1597140310989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36109,DS-7e71cee9-cb96-4575-a99f-85eb98c5c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-e3116c75-5eb1-4c57-9967-acc9f465bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-e1239a53-82ec-414f-8e4e-a5d80d742dee,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-6958def5-084b-4a78-9c4e-c7197bd95218,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-02d65fb7-97b9-454e-b3d4-735fb6e4061b,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-f03bbe2b-7d83-4fa7-a97c-6af284d73a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-c4d4905e-c1b9-4af8-99c4-1de68d6bfb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-bc4130ce-48f4-4166-b371-bd42dabe8c1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92889290-172.17.0.19-1597140310989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36109,DS-7e71cee9-cb96-4575-a99f-85eb98c5c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-e3116c75-5eb1-4c57-9967-acc9f465bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-e1239a53-82ec-414f-8e4e-a5d80d742dee,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-6958def5-084b-4a78-9c4e-c7197bd95218,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-02d65fb7-97b9-454e-b3d4-735fb6e4061b,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-f03bbe2b-7d83-4fa7-a97c-6af284d73a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-c4d4905e-c1b9-4af8-99c4-1de68d6bfb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-bc4130ce-48f4-4166-b371-bd42dabe8c1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052376354-172.17.0.19-1597140881339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44461,DS-44027d78-d12b-4999-8ef4-3ab6a6727632,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-33546057-8eff-4356-b3ec-1c53e2bd54db,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-ac1627c5-dd1e-4036-bb01-4231e1c8cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-afab17fe-bac8-4dfe-86a0-cc08278921fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-391ffa82-8b2b-4f70-a403-aaaf6b667db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-84e15d4e-b534-49da-9dcb-9984fbc7371f,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-54c7bacd-11fb-427a-a2e4-c1eb83a9c1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-ca2c9321-a53a-4f85-a49f-e17bf0b9ecb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052376354-172.17.0.19-1597140881339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44461,DS-44027d78-d12b-4999-8ef4-3ab6a6727632,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-33546057-8eff-4356-b3ec-1c53e2bd54db,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-ac1627c5-dd1e-4036-bb01-4231e1c8cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-afab17fe-bac8-4dfe-86a0-cc08278921fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-391ffa82-8b2b-4f70-a403-aaaf6b667db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-84e15d4e-b534-49da-9dcb-9984fbc7371f,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-54c7bacd-11fb-427a-a2e4-c1eb83a9c1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-ca2c9321-a53a-4f85-a49f-e17bf0b9ecb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092210931-172.17.0.19-1597140915847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41685,DS-b69adaac-e16a-4e6f-ad62-23f3c48b1e12,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-c785717d-bc16-4a53-97b3-f676cc8b5321,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-8742759e-128f-4fea-8040-c2ed6271cbad,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-24748d14-1e2f-47ce-a929-f36400607b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-4e52b454-78ba-490a-b7e1-b84a626019fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-5915692c-b185-4330-8c58-3aaaab2d7488,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-b937d9c7-6aa0-43b4-901c-23564f2a297b,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-2aa65891-3682-47ef-aea1-3170ec6f2aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092210931-172.17.0.19-1597140915847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41685,DS-b69adaac-e16a-4e6f-ad62-23f3c48b1e12,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-c785717d-bc16-4a53-97b3-f676cc8b5321,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-8742759e-128f-4fea-8040-c2ed6271cbad,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-24748d14-1e2f-47ce-a929-f36400607b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-4e52b454-78ba-490a-b7e1-b84a626019fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-5915692c-b185-4330-8c58-3aaaab2d7488,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-b937d9c7-6aa0-43b4-901c-23564f2a297b,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-2aa65891-3682-47ef-aea1-3170ec6f2aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492783028-172.17.0.19-1597141143419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38622,DS-2bf201da-8d1c-458b-8616-142238c25c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-a58d3a38-15c1-4eb7-8d5c-a165c3683b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-c9f53dc5-898a-4df3-ad17-d853fb781c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-28f9554a-020b-47f9-81d2-67fcac4c7a58,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-d452828e-c60a-4269-8847-16a6098dd154,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-e12c07cc-d3ec-4c42-807f-b83626381d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-276a5a3c-eaa7-4e45-995a-261e5adc06d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-8961f3b6-f1ec-469b-b589-a0d37ae0f72f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492783028-172.17.0.19-1597141143419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38622,DS-2bf201da-8d1c-458b-8616-142238c25c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-a58d3a38-15c1-4eb7-8d5c-a165c3683b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-c9f53dc5-898a-4df3-ad17-d853fb781c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-28f9554a-020b-47f9-81d2-67fcac4c7a58,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-d452828e-c60a-4269-8847-16a6098dd154,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-e12c07cc-d3ec-4c42-807f-b83626381d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-276a5a3c-eaa7-4e45-995a-261e5adc06d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-8961f3b6-f1ec-469b-b589-a0d37ae0f72f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001696831-172.17.0.19-1597141180502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33459,DS-5c29f9c7-1cac-4a5f-bb24-dd90e94752d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-2c0f32e3-5f42-404b-b9fb-f01b80da45cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-f66c39dc-3fea-472a-84ba-4e7cb2504172,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-a2954544-3494-4355-89cc-b8041d5f2b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-e5978031-8aa8-43e4-a14d-f6d0f68db08b,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-539737e2-21d5-48b1-969a-a3423b649d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-55edbdc7-590f-4a84-982e-1be3a6985937,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-937ea1dd-ef15-4c88-a7d0-f8b79ac8ee75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001696831-172.17.0.19-1597141180502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33459,DS-5c29f9c7-1cac-4a5f-bb24-dd90e94752d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-2c0f32e3-5f42-404b-b9fb-f01b80da45cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-f66c39dc-3fea-472a-84ba-4e7cb2504172,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-a2954544-3494-4355-89cc-b8041d5f2b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-e5978031-8aa8-43e4-a14d-f6d0f68db08b,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-539737e2-21d5-48b1-969a-a3423b649d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-55edbdc7-590f-4a84-982e-1be3a6985937,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-937ea1dd-ef15-4c88-a7d0-f8b79ac8ee75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359823360-172.17.0.19-1597141259642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37479,DS-b32ae402-bee2-4a13-bd32-bbfee0cd4295,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-9f505f80-c0c1-4309-8afa-1cf853f577dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-99a00f51-06e8-4c1f-b2f2-e12eaf62ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-7708b35d-eeff-4107-aa55-a288049541b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-3ca260f0-4dbb-4a61-a857-bfe7ee71c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-cfca7d0d-4f8a-4dc4-9a9b-200a6429d2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-f95791dc-e562-463b-8df9-0559ae98dbef,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-96808877-591a-41e3-bb90-1d617e12d57b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359823360-172.17.0.19-1597141259642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37479,DS-b32ae402-bee2-4a13-bd32-bbfee0cd4295,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-9f505f80-c0c1-4309-8afa-1cf853f577dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-99a00f51-06e8-4c1f-b2f2-e12eaf62ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-7708b35d-eeff-4107-aa55-a288049541b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-3ca260f0-4dbb-4a61-a857-bfe7ee71c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-cfca7d0d-4f8a-4dc4-9a9b-200a6429d2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-f95791dc-e562-463b-8df9-0559ae98dbef,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-96808877-591a-41e3-bb90-1d617e12d57b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243838259-172.17.0.19-1597141297755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38778,DS-d6313640-8b74-4aaa-a1e2-2bf4bacf2903,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-4cc98566-3f9f-4ffb-b920-43cbaeb19866,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-bf4b2831-a2f9-43b6-a32d-2b3803f1b749,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-c0faf219-64f8-48ee-a686-2ce0eaa5343b,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-adfa8ed2-678b-49a1-9970-405cd58a3365,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-0b657bfe-dcc3-4548-8e95-f57ca01374fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-a0de53bc-dd20-40c4-aae2-2b18ba02b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-381c19a6-3a4d-4b4f-be5b-31c92dd140df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243838259-172.17.0.19-1597141297755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38778,DS-d6313640-8b74-4aaa-a1e2-2bf4bacf2903,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-4cc98566-3f9f-4ffb-b920-43cbaeb19866,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-bf4b2831-a2f9-43b6-a32d-2b3803f1b749,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-c0faf219-64f8-48ee-a686-2ce0eaa5343b,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-adfa8ed2-678b-49a1-9970-405cd58a3365,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-0b657bfe-dcc3-4548-8e95-f57ca01374fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-a0de53bc-dd20-40c4-aae2-2b18ba02b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-381c19a6-3a4d-4b4f-be5b-31c92dd140df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499325344-172.17.0.19-1597141382438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-684a6f8c-eba7-4d59-97e2-119dbd90f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-58c69f4c-e921-4b29-99bc-9f5a59d5e992,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-dc667281-0c8a-470d-bfcd-c10673fe9355,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-79c35b58-9517-4b62-b805-db28044cbbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-d3bc98f0-251e-404c-9662-f6dd115114e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-e4f2292d-9d66-44b8-8f45-bd0c10d76749,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-b7f19310-8647-40ef-bdde-afc056f56182,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-1ecc3819-bc81-4846-b783-5c99e9fff860,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499325344-172.17.0.19-1597141382438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-684a6f8c-eba7-4d59-97e2-119dbd90f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-58c69f4c-e921-4b29-99bc-9f5a59d5e992,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-dc667281-0c8a-470d-bfcd-c10673fe9355,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-79c35b58-9517-4b62-b805-db28044cbbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-d3bc98f0-251e-404c-9662-f6dd115114e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-e4f2292d-9d66-44b8-8f45-bd0c10d76749,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-b7f19310-8647-40ef-bdde-afc056f56182,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-1ecc3819-bc81-4846-b783-5c99e9fff860,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258866481-172.17.0.19-1597141411040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-aa65481b-152f-435c-b7fc-a0458318f39b,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-860708bc-2493-4746-90ef-1ae510753fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-f8f15553-20ce-456d-a902-00e129b264a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-07eb6c11-fb4c-4e5a-bedc-ef0ef6a4ff93,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-b41c3616-9962-4d28-943c-f9ca68a9fd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-0e5640d8-beb7-41b0-aea3-24dac4283997,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-142380a3-cb00-4b7a-a883-467b14958c71,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-6c7171fd-30ea-4ed7-8999-fd640a9bd96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258866481-172.17.0.19-1597141411040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-aa65481b-152f-435c-b7fc-a0458318f39b,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-860708bc-2493-4746-90ef-1ae510753fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-f8f15553-20ce-456d-a902-00e129b264a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-07eb6c11-fb4c-4e5a-bedc-ef0ef6a4ff93,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-b41c3616-9962-4d28-943c-f9ca68a9fd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-0e5640d8-beb7-41b0-aea3-24dac4283997,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-142380a3-cb00-4b7a-a883-467b14958c71,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-6c7171fd-30ea-4ed7-8999-fd640a9bd96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379539002-172.17.0.19-1597141663649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-c28375a2-1497-4e82-91bf-eb040b2b5b92,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-8850bda1-913a-4240-bbee-f393db09da98,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-2757f789-df9d-44b5-b83f-bf63bd632af3,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-64c0bb98-fc5d-4dbf-857d-ed9be7f50c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f5f453ec-4b46-4df8-8ac3-0ab2fe23542c,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-76fcefe5-daeb-48e4-929e-bc78ba94cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-089a4287-ad60-411a-8121-43860add444a,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-5af583f5-7d8f-402f-824e-ce05b50a3e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379539002-172.17.0.19-1597141663649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-c28375a2-1497-4e82-91bf-eb040b2b5b92,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-8850bda1-913a-4240-bbee-f393db09da98,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-2757f789-df9d-44b5-b83f-bf63bd632af3,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-64c0bb98-fc5d-4dbf-857d-ed9be7f50c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f5f453ec-4b46-4df8-8ac3-0ab2fe23542c,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-76fcefe5-daeb-48e4-929e-bc78ba94cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-089a4287-ad60-411a-8121-43860add444a,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-5af583f5-7d8f-402f-824e-ce05b50a3e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050308025-172.17.0.19-1597141772297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38459,DS-3fac3e2e-b72d-4740-a8ba-c5f8b4bd5310,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-79913134-9449-4000-bc1a-5c2094ef6dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-e56fa421-dee8-47c2-8897-e2e2774a5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-fb9b065f-23e4-465b-bdfd-395a0fa84893,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-738c7733-d93c-4f43-9cf8-3f8ab8c29fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-02af912b-4abc-462e-96a6-5f4e6680f5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-f940d452-d6ad-44ed-8937-c038fc9ea667,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-7e46d0fe-3672-4d48-8c8c-b3f8283e3119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050308025-172.17.0.19-1597141772297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38459,DS-3fac3e2e-b72d-4740-a8ba-c5f8b4bd5310,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-79913134-9449-4000-bc1a-5c2094ef6dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-e56fa421-dee8-47c2-8897-e2e2774a5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-fb9b065f-23e4-465b-bdfd-395a0fa84893,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-738c7733-d93c-4f43-9cf8-3f8ab8c29fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-02af912b-4abc-462e-96a6-5f4e6680f5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-f940d452-d6ad-44ed-8937-c038fc9ea667,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-7e46d0fe-3672-4d48-8c8c-b3f8283e3119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5749
