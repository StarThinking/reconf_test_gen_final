reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637836099-172.17.0.15-1597116457211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33662,DS-7d2a2612-11af-4409-8ff0-427e30e32086,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-67a43c90-a9d8-464e-beab-79267c94249a,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-7b567af4-38d9-4f3f-bfc6-1e0278c62be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-6dd73b58-d0b6-46e7-bee2-ffd2a07e33d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-dff7e411-81a8-49dd-89f2-15abf2730624,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-4d9dd9c9-da96-441b-96d0-b1ffb2ac303d,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-01e9e0ce-84ff-41e2-b4bd-9c5658b051ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-e6858f8d-5654-4e04-9b4d-8f858105a173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637836099-172.17.0.15-1597116457211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33662,DS-7d2a2612-11af-4409-8ff0-427e30e32086,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-67a43c90-a9d8-464e-beab-79267c94249a,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-7b567af4-38d9-4f3f-bfc6-1e0278c62be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-6dd73b58-d0b6-46e7-bee2-ffd2a07e33d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-dff7e411-81a8-49dd-89f2-15abf2730624,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-4d9dd9c9-da96-441b-96d0-b1ffb2ac303d,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-01e9e0ce-84ff-41e2-b4bd-9c5658b051ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-e6858f8d-5654-4e04-9b4d-8f858105a173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582339053-172.17.0.15-1597116523740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40649,DS-56da41de-189f-441a-b73f-e9965ea9cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-66fe7b18-f9f9-4979-8bd7-b98e834ba366,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-31d03939-23ac-4df3-a0a8-955e4b840700,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-e57d1991-715e-44d7-b9a6-26e4b85529ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-84e22625-c736-409a-91be-6eab74ef5117,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-4cc17b41-6890-4e11-8ac4-3c1363c4eb81,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-df60ed58-af99-4154-b2ff-38b582940644,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-55975958-9193-464e-814e-e7c772150c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582339053-172.17.0.15-1597116523740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40649,DS-56da41de-189f-441a-b73f-e9965ea9cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-66fe7b18-f9f9-4979-8bd7-b98e834ba366,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-31d03939-23ac-4df3-a0a8-955e4b840700,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-e57d1991-715e-44d7-b9a6-26e4b85529ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-84e22625-c736-409a-91be-6eab74ef5117,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-4cc17b41-6890-4e11-8ac4-3c1363c4eb81,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-df60ed58-af99-4154-b2ff-38b582940644,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-55975958-9193-464e-814e-e7c772150c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443374931-172.17.0.15-1597116949867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35859,DS-944dd35e-fa36-438d-b863-41bed0e88c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-533bf8eb-ff92-45b6-9591-92daf4fba133,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-9896cfdf-4930-4f1f-85e9-6a76e294e890,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-2c1af14d-63f7-4a23-a3c2-54877fd7ffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-e0348620-19da-48ff-9aa1-5f81055aef54,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-6e16cf65-e33e-4e89-aff2-7638b5406d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-c30ad496-9717-4b57-abd4-7ec4c7163dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-2636ab3d-30f1-4a5b-bdf5-3b03541baadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443374931-172.17.0.15-1597116949867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35859,DS-944dd35e-fa36-438d-b863-41bed0e88c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-533bf8eb-ff92-45b6-9591-92daf4fba133,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-9896cfdf-4930-4f1f-85e9-6a76e294e890,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-2c1af14d-63f7-4a23-a3c2-54877fd7ffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-e0348620-19da-48ff-9aa1-5f81055aef54,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-6e16cf65-e33e-4e89-aff2-7638b5406d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-c30ad496-9717-4b57-abd4-7ec4c7163dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-2636ab3d-30f1-4a5b-bdf5-3b03541baadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965051238-172.17.0.15-1597117172423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-aebf569e-36cc-40e8-93bc-0e30c45ec5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-66377435-86f3-41fe-8987-224a9c584309,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-6a0e7ed4-677b-44a9-be6e-042bc8b8b38e,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-c6a24657-7dd1-4cc1-a9e8-dc6074c991bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-ed09a8fa-6838-41aa-b576-60904391fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-35f62a9c-3374-4582-95c4-2d5bc3633011,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-e1094378-0909-46e4-92f9-83b07bd74dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-4d608829-63c4-4522-bc00-f37a8d36bcc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965051238-172.17.0.15-1597117172423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-aebf569e-36cc-40e8-93bc-0e30c45ec5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-66377435-86f3-41fe-8987-224a9c584309,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-6a0e7ed4-677b-44a9-be6e-042bc8b8b38e,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-c6a24657-7dd1-4cc1-a9e8-dc6074c991bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-ed09a8fa-6838-41aa-b576-60904391fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-35f62a9c-3374-4582-95c4-2d5bc3633011,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-e1094378-0909-46e4-92f9-83b07bd74dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-4d608829-63c4-4522-bc00-f37a8d36bcc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855501580-172.17.0.15-1597117486101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33840,DS-c1bb5763-7b50-4de6-85a7-c3da77246ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-713e3a20-f7b3-41bd-9c34-9a4c5c093feb,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-020cdd24-7908-44f8-9fd5-58ee61eec43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-f92e500b-24df-4056-9dcf-14feb5770af0,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-3bd45d26-220b-426e-9bc1-3199f70879bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-d422411b-f913-43de-b701-0a831e757769,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-e60ab09f-b1c4-4240-9548-33bda5d86c46,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-e629f34e-1cab-4550-b1e8-74e80f9e0dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855501580-172.17.0.15-1597117486101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33840,DS-c1bb5763-7b50-4de6-85a7-c3da77246ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-713e3a20-f7b3-41bd-9c34-9a4c5c093feb,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-020cdd24-7908-44f8-9fd5-58ee61eec43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-f92e500b-24df-4056-9dcf-14feb5770af0,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-3bd45d26-220b-426e-9bc1-3199f70879bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-d422411b-f913-43de-b701-0a831e757769,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-e60ab09f-b1c4-4240-9548-33bda5d86c46,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-e629f34e-1cab-4550-b1e8-74e80f9e0dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568190987-172.17.0.15-1597117520081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33254,DS-5b9837cf-c9f2-4153-96e3-61d896dc931b,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-c882a6a8-dbda-4d85-9b3e-d2515646f390,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-4e7e39bd-4121-4990-9e8c-045b88ae24ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-1ff6f6d9-8cae-415c-bf7f-efd59ff8985d,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-3d51dc1e-539c-4a00-aaf2-215bd8c83573,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-626e3abd-fd38-4b79-9db8-be7b6ab04693,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-e894edc2-dd32-49be-9643-03f135807181,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-7225d94e-89c4-42f9-b9e8-7e1d2580b9eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568190987-172.17.0.15-1597117520081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33254,DS-5b9837cf-c9f2-4153-96e3-61d896dc931b,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-c882a6a8-dbda-4d85-9b3e-d2515646f390,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-4e7e39bd-4121-4990-9e8c-045b88ae24ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-1ff6f6d9-8cae-415c-bf7f-efd59ff8985d,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-3d51dc1e-539c-4a00-aaf2-215bd8c83573,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-626e3abd-fd38-4b79-9db8-be7b6ab04693,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-e894edc2-dd32-49be-9643-03f135807181,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-7225d94e-89c4-42f9-b9e8-7e1d2580b9eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97888988-172.17.0.15-1597117619841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-e181f087-e93c-4a44-a21d-0f1b761849c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-18edea72-32ae-434a-ad5d-a1a6d731d138,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-1120009d-13b8-4cfc-b407-b8ab9d7cfdff,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-47e19085-569c-4b13-b0f7-df0205080ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-166f0638-d172-4671-984f-28af542c0fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-46204212-464a-4028-a51a-17e2ce18b4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-f245d51b-2de6-4e20-835f-8d6d0d36a850,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-cf2775db-5522-4f8a-8c34-24e610a0d268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97888988-172.17.0.15-1597117619841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-e181f087-e93c-4a44-a21d-0f1b761849c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-18edea72-32ae-434a-ad5d-a1a6d731d138,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-1120009d-13b8-4cfc-b407-b8ab9d7cfdff,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-47e19085-569c-4b13-b0f7-df0205080ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-166f0638-d172-4671-984f-28af542c0fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-46204212-464a-4028-a51a-17e2ce18b4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-f245d51b-2de6-4e20-835f-8d6d0d36a850,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-cf2775db-5522-4f8a-8c34-24e610a0d268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583194915-172.17.0.15-1597118309485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46877,DS-5608361b-a8d9-4e62-9194-8f50512f25e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-ebf3c643-a8fa-4fe0-bd06-2c5b3d3d51e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-ba50a260-ac0f-4cbd-8c11-d4618d067ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-32fd4d14-88a2-4487-ac2a-6b0077721cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-4e1e8bd5-a19b-4059-aad8-16751d57693e,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-be4f0293-a662-42e9-a917-048557ba8fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-37c4cd1a-760e-4191-8e75-86f17b69345c,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-1217c8fc-c190-40b0-988c-77e233b494b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583194915-172.17.0.15-1597118309485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46877,DS-5608361b-a8d9-4e62-9194-8f50512f25e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-ebf3c643-a8fa-4fe0-bd06-2c5b3d3d51e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-ba50a260-ac0f-4cbd-8c11-d4618d067ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-32fd4d14-88a2-4487-ac2a-6b0077721cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-4e1e8bd5-a19b-4059-aad8-16751d57693e,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-be4f0293-a662-42e9-a917-048557ba8fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-37c4cd1a-760e-4191-8e75-86f17b69345c,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-1217c8fc-c190-40b0-988c-77e233b494b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442825396-172.17.0.15-1597118346000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-69034351-92cb-4117-b7ac-78ea4ccc0994,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-0e1dbd67-a4fe-4137-a16c-58971d446b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-1880f79f-26d7-4a21-a485-f8e3d59fd48a,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-85f3f494-f056-403b-b70f-e4e517d9fc45,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-9b0c991f-65c5-4dbc-af68-b854565e7a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-e32c0e98-e3d5-487b-9f12-477017ff0cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-273bc24f-080f-4358-a088-d77ad23fbcad,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-69515756-15f0-49b5-96f0-93f3e628343c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442825396-172.17.0.15-1597118346000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-69034351-92cb-4117-b7ac-78ea4ccc0994,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-0e1dbd67-a4fe-4137-a16c-58971d446b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-1880f79f-26d7-4a21-a485-f8e3d59fd48a,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-85f3f494-f056-403b-b70f-e4e517d9fc45,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-9b0c991f-65c5-4dbc-af68-b854565e7a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-e32c0e98-e3d5-487b-9f12-477017ff0cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-273bc24f-080f-4358-a088-d77ad23fbcad,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-69515756-15f0-49b5-96f0-93f3e628343c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587957293-172.17.0.15-1597118576707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-ece856e1-6455-4c5c-b7f0-08821d250563,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e0ad4caa-e942-4071-816c-c24bd46d3383,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-26242ea6-b189-470d-bf3c-2f45847d465b,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-4d773f61-a37c-4326-b9d7-a2ace7428fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-a88b6824-6350-4de2-8690-30af46950f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-21a8454d-5aab-4593-9f15-341f7981afdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-82d36947-9d96-47ea-8ea8-185d663b3c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-c0d7ec84-2ac0-4269-b4a7-f5f3f0f2b585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587957293-172.17.0.15-1597118576707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-ece856e1-6455-4c5c-b7f0-08821d250563,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e0ad4caa-e942-4071-816c-c24bd46d3383,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-26242ea6-b189-470d-bf3c-2f45847d465b,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-4d773f61-a37c-4326-b9d7-a2ace7428fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-a88b6824-6350-4de2-8690-30af46950f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-21a8454d-5aab-4593-9f15-341f7981afdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-82d36947-9d96-47ea-8ea8-185d663b3c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-c0d7ec84-2ac0-4269-b4a7-f5f3f0f2b585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952956261-172.17.0.15-1597119096027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-1319f91b-1aa6-465e-a492-7dbc81577f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-9f0d84b8-4db0-4430-abf0-60936da08e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-9d8de7b8-7655-4b66-98cd-ec4b5e1c3d62,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-43c31d76-9f79-4a8c-930b-cbda99ae25f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-10b8faa8-b77c-4eff-b482-8d9e6238f557,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-150be353-f8cc-4334-85fc-40bf0a38fe16,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-0dbf70a5-9e12-438c-9ab4-4b34130dcd08,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-be8fef04-0099-42bf-95be-ba788aa7cd49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952956261-172.17.0.15-1597119096027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-1319f91b-1aa6-465e-a492-7dbc81577f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-9f0d84b8-4db0-4430-abf0-60936da08e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-9d8de7b8-7655-4b66-98cd-ec4b5e1c3d62,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-43c31d76-9f79-4a8c-930b-cbda99ae25f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-10b8faa8-b77c-4eff-b482-8d9e6238f557,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-150be353-f8cc-4334-85fc-40bf0a38fe16,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-0dbf70a5-9e12-438c-9ab4-4b34130dcd08,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-be8fef04-0099-42bf-95be-ba788aa7cd49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683263212-172.17.0.15-1597119494918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43907,DS-8b61dc14-96a3-4bbd-9a21-1a74b2b09dee,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-b7cb5a5a-a7f7-432e-90f3-f836bb8bed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-6b10ca7a-f5da-471e-9eb9-0fd5810b1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-df98f4a7-fae9-40c9-ba48-402733be31e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-57931718-e624-45f7-8eef-f6d5ee01330d,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-15f7d5fd-605a-4a51-b209-84ed741604fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-3d540d35-cc54-4932-9334-a86ef64ae60b,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-69cf7a51-d94c-48b9-aaf3-32527f1eeb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683263212-172.17.0.15-1597119494918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43907,DS-8b61dc14-96a3-4bbd-9a21-1a74b2b09dee,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-b7cb5a5a-a7f7-432e-90f3-f836bb8bed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-6b10ca7a-f5da-471e-9eb9-0fd5810b1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-df98f4a7-fae9-40c9-ba48-402733be31e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-57931718-e624-45f7-8eef-f6d5ee01330d,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-15f7d5fd-605a-4a51-b209-84ed741604fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-3d540d35-cc54-4932-9334-a86ef64ae60b,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-69cf7a51-d94c-48b9-aaf3-32527f1eeb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83102067-172.17.0.15-1597119860369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33514,DS-99a3fc3b-adc7-4b62-9467-92d7a1a51baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-54b5de93-763e-4dc6-afcc-883f5e9ba98f,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-b8ac9c27-721f-44c6-b098-08b151a193c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-45bbeb58-8872-4474-b688-9a86dd8d4cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-a025bee7-caf2-4b15-a50e-026c3e1d86cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-e719c871-48cd-4095-8016-dd612d9a76da,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-eca91657-e84d-4dea-aa3e-e384237be21c,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-523684be-3569-455e-b64b-b8fec12f5e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83102067-172.17.0.15-1597119860369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33514,DS-99a3fc3b-adc7-4b62-9467-92d7a1a51baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-54b5de93-763e-4dc6-afcc-883f5e9ba98f,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-b8ac9c27-721f-44c6-b098-08b151a193c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-45bbeb58-8872-4474-b688-9a86dd8d4cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-a025bee7-caf2-4b15-a50e-026c3e1d86cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-e719c871-48cd-4095-8016-dd612d9a76da,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-eca91657-e84d-4dea-aa3e-e384237be21c,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-523684be-3569-455e-b64b-b8fec12f5e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443041556-172.17.0.15-1597119960495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-c55f359b-a544-4112-b763-9182d03cece1,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-4f3b68ac-b5c1-4cf7-b342-98c0c85fd5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-93850a5b-534f-4312-8746-852468802568,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-3020c2dd-470c-4164-ba98-7559bee52937,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-4932408a-e1c9-4edd-9a3e-92250cb2d31d,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-d8063e61-3bbc-4267-82a0-12cdadc02a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-06a9b1de-1994-4775-ace8-40623f3e8211,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-b96d2a5e-ce96-4ca1-aa01-b4ab798924dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443041556-172.17.0.15-1597119960495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-c55f359b-a544-4112-b763-9182d03cece1,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-4f3b68ac-b5c1-4cf7-b342-98c0c85fd5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-93850a5b-534f-4312-8746-852468802568,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-3020c2dd-470c-4164-ba98-7559bee52937,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-4932408a-e1c9-4edd-9a3e-92250cb2d31d,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-d8063e61-3bbc-4267-82a0-12cdadc02a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-06a9b1de-1994-4775-ace8-40623f3e8211,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-b96d2a5e-ce96-4ca1-aa01-b4ab798924dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107819575-172.17.0.15-1597120158612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-b243681c-f525-4a32-9353-0af431b8127d,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-a85573d5-7bfc-47fb-907a-ad87897d781e,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-624d7980-0708-47e4-9c7f-1eab42cb0487,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-e82096b5-ef1e-47ea-831e-d18e080a5f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-f32d2489-701e-4958-a3b3-13f400b65870,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-b4c1e07e-26ed-4991-9b2f-f0b99cf792ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-adfe9963-98b2-4f8d-b868-39bbdf600bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-f175e9f0-a74c-40ed-b668-ffa7e5438701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107819575-172.17.0.15-1597120158612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-b243681c-f525-4a32-9353-0af431b8127d,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-a85573d5-7bfc-47fb-907a-ad87897d781e,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-624d7980-0708-47e4-9c7f-1eab42cb0487,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-e82096b5-ef1e-47ea-831e-d18e080a5f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-f32d2489-701e-4958-a3b3-13f400b65870,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-b4c1e07e-26ed-4991-9b2f-f0b99cf792ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-adfe9963-98b2-4f8d-b868-39bbdf600bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-f175e9f0-a74c-40ed-b668-ffa7e5438701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829306436-172.17.0.15-1597120601822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-dcaea947-5b82-4d70-bcd6-f249a56814be,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-a686f8c1-58fd-4a1d-a6ed-04e1a08de787,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-45e835b0-bd3c-4bf9-8ac5-0e9bd1936573,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-50ff5143-6b17-40d7-829c-d9ce819d1d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-96695305-a767-4542-8d33-ef0e0cbdc194,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-3a2cf4d5-5fc1-4ea7-9352-124afd3f5c30,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-dfd654d4-ee87-4dc1-9b10-190da33961d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-6ab7750b-f6e6-46cc-b496-422ab7f8f729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829306436-172.17.0.15-1597120601822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-dcaea947-5b82-4d70-bcd6-f249a56814be,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-a686f8c1-58fd-4a1d-a6ed-04e1a08de787,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-45e835b0-bd3c-4bf9-8ac5-0e9bd1936573,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-50ff5143-6b17-40d7-829c-d9ce819d1d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-96695305-a767-4542-8d33-ef0e0cbdc194,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-3a2cf4d5-5fc1-4ea7-9352-124afd3f5c30,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-dfd654d4-ee87-4dc1-9b10-190da33961d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-6ab7750b-f6e6-46cc-b496-422ab7f8f729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672984267-172.17.0.15-1597120683139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-9e8ceec9-f006-46ed-8d7d-5735ce83b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-da2a8115-2203-4000-b213-cc819dab7230,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-cef05c61-ac34-4be4-8eb3-ef196e83266b,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-49d85d79-e6b7-427e-9618-0c7abe1d4c97,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-e338ad7f-c64e-4565-b0ab-8dc7b29541ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-dc5f359b-56a7-4f6b-8879-afc3aa9c344f,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-458c0c3e-8d24-4fc5-a41d-eb88602c95ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-ae0850ae-bc07-468a-86fc-32376c3dd0c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672984267-172.17.0.15-1597120683139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-9e8ceec9-f006-46ed-8d7d-5735ce83b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-da2a8115-2203-4000-b213-cc819dab7230,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-cef05c61-ac34-4be4-8eb3-ef196e83266b,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-49d85d79-e6b7-427e-9618-0c7abe1d4c97,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-e338ad7f-c64e-4565-b0ab-8dc7b29541ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-dc5f359b-56a7-4f6b-8879-afc3aa9c344f,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-458c0c3e-8d24-4fc5-a41d-eb88602c95ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-ae0850ae-bc07-468a-86fc-32376c3dd0c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202388509-172.17.0.15-1597121025294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40964,DS-7e189372-5d81-43f7-9cf9-84185756c552,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-251c1168-1abd-4bdc-9cbc-fe10178bb88d,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-ad664a16-2df6-4100-8602-2335c8fd6dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-3ef65f46-b841-48e4-b88f-4803c8227d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-85ad5224-9012-4b47-ae7d-f21c5cf6633f,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-d8a56d10-0458-4c00-9560-35961c61bf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-e68d17db-f6a3-4c5e-8fa6-1dcc9168938c,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-70e0366f-aba4-430b-96ea-c3b4ee20fd6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202388509-172.17.0.15-1597121025294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40964,DS-7e189372-5d81-43f7-9cf9-84185756c552,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-251c1168-1abd-4bdc-9cbc-fe10178bb88d,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-ad664a16-2df6-4100-8602-2335c8fd6dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-3ef65f46-b841-48e4-b88f-4803c8227d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-85ad5224-9012-4b47-ae7d-f21c5cf6633f,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-d8a56d10-0458-4c00-9560-35961c61bf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-e68d17db-f6a3-4c5e-8fa6-1dcc9168938c,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-70e0366f-aba4-430b-96ea-c3b4ee20fd6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438418162-172.17.0.15-1597121189748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35356,DS-ac93a076-8f2f-4a77-9cfa-90db82649aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-3d24aa4a-d17f-4694-b6ec-090addc1d243,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-c14f7cb5-f68a-430d-a7d5-84ce2145b9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-fb6165d1-3431-45a7-aa12-a55b697fe6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-e57028dc-eac4-4007-b242-d20ba9126937,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-a2258878-d130-4c38-968f-36becc9efe64,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-c1d37773-d3ba-464c-9c72-307239ab8f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-e2b0c2a3-751c-4701-9c8c-3d49f3c294d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438418162-172.17.0.15-1597121189748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35356,DS-ac93a076-8f2f-4a77-9cfa-90db82649aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-3d24aa4a-d17f-4694-b6ec-090addc1d243,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-c14f7cb5-f68a-430d-a7d5-84ce2145b9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-fb6165d1-3431-45a7-aa12-a55b697fe6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-e57028dc-eac4-4007-b242-d20ba9126937,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-a2258878-d130-4c38-968f-36becc9efe64,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-c1d37773-d3ba-464c-9c72-307239ab8f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-e2b0c2a3-751c-4701-9c8c-3d49f3c294d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128146296-172.17.0.15-1597121378763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33923,DS-ce6c943f-4e45-4def-99dd-c45bb0fc467a,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-a17e19f0-f331-48d0-a085-c3b43b2b1721,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-ba007f32-f1cc-4f3a-b3cf-999f6947b107,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-aed5de80-c65a-44c0-bbb7-63fd2f481ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-dd42c974-bc4d-43f4-a409-6e9591a93e16,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-1d7ad471-302e-4101-ba98-b393ad17514d,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-1a0a7f1d-1279-489f-90bf-85a3e77e0013,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-9bd33367-3d16-4c1f-9ac4-ea9e7d713e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128146296-172.17.0.15-1597121378763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33923,DS-ce6c943f-4e45-4def-99dd-c45bb0fc467a,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-a17e19f0-f331-48d0-a085-c3b43b2b1721,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-ba007f32-f1cc-4f3a-b3cf-999f6947b107,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-aed5de80-c65a-44c0-bbb7-63fd2f481ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-dd42c974-bc4d-43f4-a409-6e9591a93e16,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-1d7ad471-302e-4101-ba98-b393ad17514d,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-1a0a7f1d-1279-489f-90bf-85a3e77e0013,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-9bd33367-3d16-4c1f-9ac4-ea9e7d713e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5285
