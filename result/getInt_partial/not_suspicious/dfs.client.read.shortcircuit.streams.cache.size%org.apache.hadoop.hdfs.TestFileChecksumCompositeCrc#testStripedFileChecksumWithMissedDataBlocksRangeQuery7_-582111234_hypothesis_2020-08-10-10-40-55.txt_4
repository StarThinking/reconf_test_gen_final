reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669542341-172.17.0.14-1597056142181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38997,DS-8e8d2265-d27f-4169-85c0-f5ca2853e4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-afb6b15c-f87a-4f39-9555-ecad421ece20,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-9a1b6081-898e-45bb-b554-e20b106a7484,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-9acb0855-5c6d-495b-9911-d3f5a21b8eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-f989282b-40a3-4228-aa4c-da30c6370df2,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-b1b97767-57fc-4c8b-b022-1c602f4c94ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-a7d509b5-0300-4afc-850b-0088ad85a966,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-17a26fce-5e3b-4506-b1fc-86daa363c34e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669542341-172.17.0.14-1597056142181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38997,DS-8e8d2265-d27f-4169-85c0-f5ca2853e4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-afb6b15c-f87a-4f39-9555-ecad421ece20,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-9a1b6081-898e-45bb-b554-e20b106a7484,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-9acb0855-5c6d-495b-9911-d3f5a21b8eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-f989282b-40a3-4228-aa4c-da30c6370df2,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-b1b97767-57fc-4c8b-b022-1c602f4c94ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-a7d509b5-0300-4afc-850b-0088ad85a966,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-17a26fce-5e3b-4506-b1fc-86daa363c34e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382679723-172.17.0.14-1597056377346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46563,DS-122b580b-efdb-4278-af0e-4ad3bca5bce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-6f69670c-64dd-462b-a83b-1774f55fe432,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-0f0fff26-04b3-4056-9b85-d263cd3422f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-19108e78-1c4a-473c-82a2-1f05af202d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-b6275a47-347f-4edc-abd7-356b639acc49,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-ab65a5ec-d7f0-4443-beaa-997f89804e46,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-95e96d4a-4020-4bd4-a7f6-6093ca19b88c,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-7398f55d-afdf-47fb-b778-f4354681bfdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382679723-172.17.0.14-1597056377346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46563,DS-122b580b-efdb-4278-af0e-4ad3bca5bce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-6f69670c-64dd-462b-a83b-1774f55fe432,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-0f0fff26-04b3-4056-9b85-d263cd3422f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-19108e78-1c4a-473c-82a2-1f05af202d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-b6275a47-347f-4edc-abd7-356b639acc49,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-ab65a5ec-d7f0-4443-beaa-997f89804e46,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-95e96d4a-4020-4bd4-a7f6-6093ca19b88c,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-7398f55d-afdf-47fb-b778-f4354681bfdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099600668-172.17.0.14-1597056414070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-d1c2f9b0-fb1a-4797-a8ab-8851e2d295ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-530cf0d7-1d87-4742-93d9-f10640c7125a,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-077cf173-bcfb-44b6-83cc-20975b4ea6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-d593e5a7-0e0e-4592-ab25-4615a9183a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-cd7eebbe-ab2a-40fc-8bbe-97c0df5d1b92,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-c7931a3e-e6d6-41f6-9dcf-2080c103c6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-db19815e-cf0f-4d0c-ad54-d70cc85bf0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-ccacc68b-ae60-4b99-b01d-db5849e2befc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099600668-172.17.0.14-1597056414070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-d1c2f9b0-fb1a-4797-a8ab-8851e2d295ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-530cf0d7-1d87-4742-93d9-f10640c7125a,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-077cf173-bcfb-44b6-83cc-20975b4ea6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-d593e5a7-0e0e-4592-ab25-4615a9183a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-cd7eebbe-ab2a-40fc-8bbe-97c0df5d1b92,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-c7931a3e-e6d6-41f6-9dcf-2080c103c6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-db19815e-cf0f-4d0c-ad54-d70cc85bf0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-ccacc68b-ae60-4b99-b01d-db5849e2befc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580942128-172.17.0.14-1597056456760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35999,DS-6820c675-da14-4889-b439-ac015702291f,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-b0f2fd78-bea9-4aaf-8262-2d0e8248478e,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-6696bab8-36bc-4cd8-8762-85a8ea146920,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-58955c48-b251-498f-8476-e354fd78032e,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-3dc4c418-a106-4449-aa6d-71ba469961b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-5f401446-2498-4b8d-a0fd-d47c3846dccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-24ac6060-8261-42f2-a23f-791e39a89cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-68329870-6047-4434-8e30-c670f73d3f24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580942128-172.17.0.14-1597056456760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35999,DS-6820c675-da14-4889-b439-ac015702291f,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-b0f2fd78-bea9-4aaf-8262-2d0e8248478e,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-6696bab8-36bc-4cd8-8762-85a8ea146920,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-58955c48-b251-498f-8476-e354fd78032e,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-3dc4c418-a106-4449-aa6d-71ba469961b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-5f401446-2498-4b8d-a0fd-d47c3846dccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-24ac6060-8261-42f2-a23f-791e39a89cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-68329870-6047-4434-8e30-c670f73d3f24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418811392-172.17.0.14-1597056595493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-4adc87da-934b-4346-848a-ae4e2f55600e,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-88712148-686b-4133-9a40-376d46cd022b,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-88afaafe-07eb-4fe9-9c04-00cabb6472f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-dbee5904-1c09-40f4-8c42-a38f0e7fc662,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-3e6028a4-b414-4db5-9613-7d007efb89ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-c0efd612-6628-49da-963d-a31f32483ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-02d4250f-8cd1-47fb-8847-73b67d600d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-bcb54bbe-9e11-4b9c-9006-42bede3248f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418811392-172.17.0.14-1597056595493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-4adc87da-934b-4346-848a-ae4e2f55600e,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-88712148-686b-4133-9a40-376d46cd022b,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-88afaafe-07eb-4fe9-9c04-00cabb6472f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-dbee5904-1c09-40f4-8c42-a38f0e7fc662,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-3e6028a4-b414-4db5-9613-7d007efb89ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-c0efd612-6628-49da-963d-a31f32483ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-02d4250f-8cd1-47fb-8847-73b67d600d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-bcb54bbe-9e11-4b9c-9006-42bede3248f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814212091-172.17.0.14-1597056827978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-2cfa7fd9-3b28-4bfd-93bd-3b7ced6557b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-ca685605-c33d-430d-832b-6e878e92bc58,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-7a3f6f66-434e-448c-b1ae-b96b1878c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-49b54440-1fca-431b-8ce2-317a3a45b766,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-258e78bf-98b8-439d-b1e1-5fa54fd4c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-2f30ccca-9da7-4797-bcb9-2a2390590792,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-02dd5c51-2106-43d6-80ec-8fa5032a33d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-ce7839e0-3172-4d03-be44-bda1be5792f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814212091-172.17.0.14-1597056827978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-2cfa7fd9-3b28-4bfd-93bd-3b7ced6557b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-ca685605-c33d-430d-832b-6e878e92bc58,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-7a3f6f66-434e-448c-b1ae-b96b1878c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-49b54440-1fca-431b-8ce2-317a3a45b766,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-258e78bf-98b8-439d-b1e1-5fa54fd4c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-2f30ccca-9da7-4797-bcb9-2a2390590792,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-02dd5c51-2106-43d6-80ec-8fa5032a33d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-ce7839e0-3172-4d03-be44-bda1be5792f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059391028-172.17.0.14-1597057143763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45470,DS-96e80562-5237-4edb-98a1-35aedc556869,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-492a13e2-d359-424a-a5a5-0b62a703a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-5f40ec36-cdc5-4574-b76f-fc83e3a5ae41,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-1a19e467-c88b-44ee-a07a-22cabaa7d3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-06211b43-e10b-420c-8d0e-99f16edea5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-fff73e60-be14-408c-a4bf-e81c4c9733d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-43642949-f2cb-4704-b015-916dbc0d1fce,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-166aeb74-d32b-4d74-a197-d6618867b1e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059391028-172.17.0.14-1597057143763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45470,DS-96e80562-5237-4edb-98a1-35aedc556869,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-492a13e2-d359-424a-a5a5-0b62a703a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-5f40ec36-cdc5-4574-b76f-fc83e3a5ae41,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-1a19e467-c88b-44ee-a07a-22cabaa7d3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-06211b43-e10b-420c-8d0e-99f16edea5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-fff73e60-be14-408c-a4bf-e81c4c9733d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-43642949-f2cb-4704-b015-916dbc0d1fce,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-166aeb74-d32b-4d74-a197-d6618867b1e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218654563-172.17.0.14-1597057475275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44595,DS-fcd98c33-29e0-4994-94c2-11dbad86bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-e27ea59b-dbff-4f9e-8e71-8e5e6e6bf0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-f1e65741-b21c-4acc-b0be-0e4ab4df4087,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-40244300-4bad-493c-b0e2-388071b4607f,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-01ff75d3-0ae6-44e9-aab9-71ec3c468ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-971aef73-29a8-4bf3-b4bf-467baa3db47d,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-90a59a31-db06-4e9d-a343-57d6d44efdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-4e4a5a45-a3e8-4cbb-809e-01d719c0ca2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218654563-172.17.0.14-1597057475275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44595,DS-fcd98c33-29e0-4994-94c2-11dbad86bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-e27ea59b-dbff-4f9e-8e71-8e5e6e6bf0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-f1e65741-b21c-4acc-b0be-0e4ab4df4087,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-40244300-4bad-493c-b0e2-388071b4607f,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-01ff75d3-0ae6-44e9-aab9-71ec3c468ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-971aef73-29a8-4bf3-b4bf-467baa3db47d,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-90a59a31-db06-4e9d-a343-57d6d44efdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-4e4a5a45-a3e8-4cbb-809e-01d719c0ca2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806747307-172.17.0.14-1597057819396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46004,DS-ae15a80e-8a82-42f0-b347-37d63b6009c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-bc22bd29-4f3c-4b76-94d2-39504718914c,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-994075b1-11a9-4ae0-8f4f-a34f8c7cdeef,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-cceefdec-a239-4936-9c43-ad91c3747532,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-feab1c6f-01ed-4a46-98e7-fc33daad3b76,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-bea92995-6881-4cae-99db-8b35f5f4608d,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-14dfa401-a58a-43eb-895f-21aabb1cf84f,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-35b7b336-e519-4694-a993-39132fd964f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806747307-172.17.0.14-1597057819396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46004,DS-ae15a80e-8a82-42f0-b347-37d63b6009c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-bc22bd29-4f3c-4b76-94d2-39504718914c,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-994075b1-11a9-4ae0-8f4f-a34f8c7cdeef,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-cceefdec-a239-4936-9c43-ad91c3747532,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-feab1c6f-01ed-4a46-98e7-fc33daad3b76,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-bea92995-6881-4cae-99db-8b35f5f4608d,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-14dfa401-a58a-43eb-895f-21aabb1cf84f,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-35b7b336-e519-4694-a993-39132fd964f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131712561-172.17.0.14-1597057954781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32783,DS-b6902cdb-352c-452b-9dbe-abe99f941b86,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-de1f5f90-1652-46e2-aa17-6ddcde0fb223,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-47a9900c-1c0e-42cb-83d2-d9f496254caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-073b0130-0ed0-4947-9c12-cd56f8d2648c,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-6fd87530-b497-4b54-b85c-b7b055ec151d,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-42f72bac-cdbd-42c6-b128-d575e195f5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-ac707d3a-c4e9-4ec0-bcf9-dfcf0973211d,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-15cad057-394a-4a19-bbfa-497f5c877ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131712561-172.17.0.14-1597057954781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32783,DS-b6902cdb-352c-452b-9dbe-abe99f941b86,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-de1f5f90-1652-46e2-aa17-6ddcde0fb223,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-47a9900c-1c0e-42cb-83d2-d9f496254caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-073b0130-0ed0-4947-9c12-cd56f8d2648c,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-6fd87530-b497-4b54-b85c-b7b055ec151d,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-42f72bac-cdbd-42c6-b128-d575e195f5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-ac707d3a-c4e9-4ec0-bcf9-dfcf0973211d,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-15cad057-394a-4a19-bbfa-497f5c877ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253780923-172.17.0.14-1597057981574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45607,DS-b5ce525d-4128-4bdf-a3b2-e8552b24b824,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-2291c2a8-7573-436a-9f20-b07143012b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-5c75ba95-5c75-459a-aa9e-a48c9930e5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-43a057e2-d8f2-4421-b7c3-881e6a951115,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-d9cbb4c2-66c5-4389-83ec-47c2df5921d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-ef1beaf0-1ffd-4f5c-be3d-aa9a4981c835,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-8e614804-a5c9-4074-87d5-fbe029b23f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-b1669c9d-58ea-4be2-8cdd-0809b44b5942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253780923-172.17.0.14-1597057981574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45607,DS-b5ce525d-4128-4bdf-a3b2-e8552b24b824,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-2291c2a8-7573-436a-9f20-b07143012b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-5c75ba95-5c75-459a-aa9e-a48c9930e5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-43a057e2-d8f2-4421-b7c3-881e6a951115,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-d9cbb4c2-66c5-4389-83ec-47c2df5921d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-ef1beaf0-1ffd-4f5c-be3d-aa9a4981c835,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-8e614804-a5c9-4074-87d5-fbe029b23f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-b1669c9d-58ea-4be2-8cdd-0809b44b5942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602012145-172.17.0.14-1597058119223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38149,DS-4d5478a9-d1cf-4cd8-93a6-f8940dce453b,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-9b73fe02-585f-4a22-a9a4-2f1356111b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-3f4e7b67-b0d7-426b-b734-a390e7ac1058,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-883a56fa-e724-4cc1-ba9e-5c81546af2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-d7a29043-59ce-49dd-8160-ed7d74e09ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-8d72a871-b411-4385-8662-9addd2cc663f,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-86d2918b-649c-4f5a-a10a-a1661acc6893,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-783ec1fe-d990-4edd-98bc-cbe28d807ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602012145-172.17.0.14-1597058119223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38149,DS-4d5478a9-d1cf-4cd8-93a6-f8940dce453b,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-9b73fe02-585f-4a22-a9a4-2f1356111b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-3f4e7b67-b0d7-426b-b734-a390e7ac1058,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-883a56fa-e724-4cc1-ba9e-5c81546af2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-d7a29043-59ce-49dd-8160-ed7d74e09ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-8d72a871-b411-4385-8662-9addd2cc663f,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-86d2918b-649c-4f5a-a10a-a1661acc6893,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-783ec1fe-d990-4edd-98bc-cbe28d807ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906412062-172.17.0.14-1597058154027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40132,DS-49497e12-b0dc-4983-9c70-d3aa4085cf51,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-56392907-83d6-4517-b691-a924b5ba8d23,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-36106519-cdb5-43a1-b056-34acd49e9e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-7aa98832-6477-4514-987a-c1c1c9ef6407,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-ae72ff52-fbb3-4eec-919c-97a1c6c987ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-83e68cfe-34f4-4b93-9d41-c3d3fd1b15d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-aecfee00-38a5-438d-af48-3e942972ed29,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-3402eea2-41b8-417f-bdff-0ac911a4bf2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906412062-172.17.0.14-1597058154027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40132,DS-49497e12-b0dc-4983-9c70-d3aa4085cf51,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-56392907-83d6-4517-b691-a924b5ba8d23,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-36106519-cdb5-43a1-b056-34acd49e9e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-7aa98832-6477-4514-987a-c1c1c9ef6407,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-ae72ff52-fbb3-4eec-919c-97a1c6c987ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-83e68cfe-34f4-4b93-9d41-c3d3fd1b15d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-aecfee00-38a5-438d-af48-3e942972ed29,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-3402eea2-41b8-417f-bdff-0ac911a4bf2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110645671-172.17.0.14-1597058186640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41594,DS-e9e1922e-d1cc-4092-95c0-104623dc87fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-a47781d0-576c-4028-8a7f-e8b114d0a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-5466695d-0d31-44c5-9b09-50cc4648deec,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-e2f9e290-3fa6-4815-a60b-acd60862f389,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-37fa666c-7a12-4410-8e13-068a6ecc81c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-9db9ccf6-34df-4203-b8a7-0c039adc759e,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-c8b4435d-53aa-46fe-aa0b-314a189fa3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-d6b95994-e554-488f-a7a8-6cb8802b8fa3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110645671-172.17.0.14-1597058186640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41594,DS-e9e1922e-d1cc-4092-95c0-104623dc87fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-a47781d0-576c-4028-8a7f-e8b114d0a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-5466695d-0d31-44c5-9b09-50cc4648deec,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-e2f9e290-3fa6-4815-a60b-acd60862f389,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-37fa666c-7a12-4410-8e13-068a6ecc81c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-9db9ccf6-34df-4203-b8a7-0c039adc759e,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-c8b4435d-53aa-46fe-aa0b-314a189fa3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-d6b95994-e554-488f-a7a8-6cb8802b8fa3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897160122-172.17.0.14-1597058214187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-ce497e3d-fa06-4b8d-8a4b-fd21f8a8f2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-4542b3d8-a73f-4e02-8f68-5c49317bb58a,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-e0efab1d-ce12-431d-be64-fa865183e194,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-26a8c679-70f6-44ad-98e0-96f743d215d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-a79f0c2f-1062-440e-abc7-d4eca1e43264,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-f5e52305-ecdf-4c21-8ffe-156ce20f36da,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-425df2dc-904f-4687-90e4-e467ee8204d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-964391dd-ad7a-41d9-838d-3b784aa87394,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897160122-172.17.0.14-1597058214187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-ce497e3d-fa06-4b8d-8a4b-fd21f8a8f2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-4542b3d8-a73f-4e02-8f68-5c49317bb58a,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-e0efab1d-ce12-431d-be64-fa865183e194,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-26a8c679-70f6-44ad-98e0-96f743d215d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-a79f0c2f-1062-440e-abc7-d4eca1e43264,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-f5e52305-ecdf-4c21-8ffe-156ce20f36da,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-425df2dc-904f-4687-90e4-e467ee8204d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-964391dd-ad7a-41d9-838d-3b784aa87394,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728129270-172.17.0.14-1597058286740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-1c196d2f-d56b-4f4d-bafd-500651b17b60,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-7c8c1621-57df-4855-8dde-dc3a21d39d56,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-e29f6393-6142-4b18-9d58-43840e09fe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-01cbe3c8-2180-4762-b13c-52df25d97b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-696009e0-9c34-4093-aae4-4144282c6273,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-18a385b1-febc-4a41-ae37-e3616584eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-9376fa9a-431e-421d-b85e-8dd027d9ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-0de34be1-59b0-4308-8450-0811d3433324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728129270-172.17.0.14-1597058286740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-1c196d2f-d56b-4f4d-bafd-500651b17b60,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-7c8c1621-57df-4855-8dde-dc3a21d39d56,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-e29f6393-6142-4b18-9d58-43840e09fe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-01cbe3c8-2180-4762-b13c-52df25d97b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-696009e0-9c34-4093-aae4-4144282c6273,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-18a385b1-febc-4a41-ae37-e3616584eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-9376fa9a-431e-421d-b85e-8dd027d9ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-0de34be1-59b0-4308-8450-0811d3433324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562039662-172.17.0.14-1597058359634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-912ef202-2ee0-4be0-8062-f0a75e5d150a,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-feb3707e-2c1b-4be4-9b45-6fbb3d042983,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-8efcaf99-75c8-46c5-951c-0bafb6c17ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-e5cce8b6-412f-4578-8a0f-78880b395bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-a727d6bc-db9e-4c26-89b0-ecb75326753c,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-8031cda0-74e8-427f-b922-58c6de9a86ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-8de22850-e96e-49f6-ba5b-1c356d3ef0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-77a5fe5d-443d-47f1-ac8c-22982684b0a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562039662-172.17.0.14-1597058359634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-912ef202-2ee0-4be0-8062-f0a75e5d150a,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-feb3707e-2c1b-4be4-9b45-6fbb3d042983,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-8efcaf99-75c8-46c5-951c-0bafb6c17ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-e5cce8b6-412f-4578-8a0f-78880b395bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-a727d6bc-db9e-4c26-89b0-ecb75326753c,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-8031cda0-74e8-427f-b922-58c6de9a86ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-8de22850-e96e-49f6-ba5b-1c356d3ef0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-77a5fe5d-443d-47f1-ac8c-22982684b0a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96090136-172.17.0.14-1597058490297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-4140d307-b090-4fef-9200-f45bc98e2b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-c31bfdc6-deb0-4399-9788-ebd66b9ff825,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-501fec27-4ec2-45bb-9fcd-a8d5da8830a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-9f54d042-737e-4906-b296-2f0798fa0108,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-6d922a88-826a-4399-9d2d-b206f453d449,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-ded6764c-b970-43b4-9253-b1c0943892ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-2866493e-9621-4b24-b98c-2db280e82694,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-4e40ee74-65c6-4f8d-ba05-af88127db60d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96090136-172.17.0.14-1597058490297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-4140d307-b090-4fef-9200-f45bc98e2b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-c31bfdc6-deb0-4399-9788-ebd66b9ff825,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-501fec27-4ec2-45bb-9fcd-a8d5da8830a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-9f54d042-737e-4906-b296-2f0798fa0108,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-6d922a88-826a-4399-9d2d-b206f453d449,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-ded6764c-b970-43b4-9253-b1c0943892ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-2866493e-9621-4b24-b98c-2db280e82694,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-4e40ee74-65c6-4f8d-ba05-af88127db60d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997899178-172.17.0.14-1597058869687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-b3f5d0d2-425b-44e7-84fd-76f8f7be4223,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-4b26d0e7-feb6-4c84-a0c2-898cd90786f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-f8045982-df74-4b0e-8bdb-c8f74d9f1830,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-7479e68c-8e58-46c7-b9e8-ac1b74286ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-bc251118-7dd6-4c5a-ac79-ccf384daf0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-73c964ba-e07a-4cf6-ab6e-6e094c2ce095,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-f23be0d8-5b68-4a28-8edf-af353161e3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-c19d78d8-02f9-448f-8163-26b8b715701c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997899178-172.17.0.14-1597058869687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-b3f5d0d2-425b-44e7-84fd-76f8f7be4223,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-4b26d0e7-feb6-4c84-a0c2-898cd90786f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-f8045982-df74-4b0e-8bdb-c8f74d9f1830,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-7479e68c-8e58-46c7-b9e8-ac1b74286ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-bc251118-7dd6-4c5a-ac79-ccf384daf0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-73c964ba-e07a-4cf6-ab6e-6e094c2ce095,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-f23be0d8-5b68-4a28-8edf-af353161e3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-c19d78d8-02f9-448f-8163-26b8b715701c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965995102-172.17.0.14-1597059150164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-09fdd888-f99e-4c6e-b520-d5127f0a8bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-ad5f0cba-e63c-4d62-a61e-4a2a7051b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-5ad121e6-7ef5-4cb8-92a0-062449b3730f,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-9d0ab5a8-ad28-47e3-b0eb-351e572a5d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-0547ae5e-812d-4831-aa87-ee6374694579,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-057223f0-5cd1-4d8d-a7a8-a64eda3bfcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-37e94827-78c8-41c7-bbe3-a4d3fa792ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-9ab7b30d-74f0-4b80-a2fb-3cdf8210bab2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965995102-172.17.0.14-1597059150164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-09fdd888-f99e-4c6e-b520-d5127f0a8bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-ad5f0cba-e63c-4d62-a61e-4a2a7051b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-5ad121e6-7ef5-4cb8-92a0-062449b3730f,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-9d0ab5a8-ad28-47e3-b0eb-351e572a5d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-0547ae5e-812d-4831-aa87-ee6374694579,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-057223f0-5cd1-4d8d-a7a8-a64eda3bfcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-37e94827-78c8-41c7-bbe3-a4d3fa792ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-9ab7b30d-74f0-4b80-a2fb-3cdf8210bab2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615073048-172.17.0.14-1597059806574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-9f4a8724-43cc-4581-99e3-bd5856122745,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-9ac371c4-5cb7-43e9-81a6-b5fab0a8d6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-93f0ecc2-c7ad-4ab9-b27b-0d3e8ba24563,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-2113e005-10ea-4bf7-bf91-c0d0cce4a2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-5d61c222-d054-4686-8137-1e2bf3ca44f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-4e886036-b39a-4441-87cf-eaddbdd961be,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-674c59e0-fb54-4d73-9ce6-b94c520a2ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-a1d89ebd-8701-4d13-9dfa-dd5b9d1b06dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615073048-172.17.0.14-1597059806574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-9f4a8724-43cc-4581-99e3-bd5856122745,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-9ac371c4-5cb7-43e9-81a6-b5fab0a8d6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-93f0ecc2-c7ad-4ab9-b27b-0d3e8ba24563,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-2113e005-10ea-4bf7-bf91-c0d0cce4a2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-5d61c222-d054-4686-8137-1e2bf3ca44f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-4e886036-b39a-4441-87cf-eaddbdd961be,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-674c59e0-fb54-4d73-9ce6-b94c520a2ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-a1d89ebd-8701-4d13-9dfa-dd5b9d1b06dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822091514-172.17.0.14-1597060094833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-74207664-40db-4240-8b29-7cdb679865ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-ad566a4e-b3e4-46cb-95ed-326a467bb2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-3e26f760-8edb-4ed7-b13e-5544d774335c,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-fbe78083-b2ad-4ce4-a96b-3c251daa68b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-94870a97-7702-4b02-b370-3f7e7dca0348,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-f0c1272c-8a74-4e5a-80ae-df4f5cdbd501,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-613f3cdf-e61d-4b9d-bf34-d5b19f1fb0be,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-1d767295-245c-4285-89f9-c1d558cf37d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822091514-172.17.0.14-1597060094833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-74207664-40db-4240-8b29-7cdb679865ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-ad566a4e-b3e4-46cb-95ed-326a467bb2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-3e26f760-8edb-4ed7-b13e-5544d774335c,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-fbe78083-b2ad-4ce4-a96b-3c251daa68b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-94870a97-7702-4b02-b370-3f7e7dca0348,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-f0c1272c-8a74-4e5a-80ae-df4f5cdbd501,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-613f3cdf-e61d-4b9d-bf34-d5b19f1fb0be,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-1d767295-245c-4285-89f9-c1d558cf37d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077316593-172.17.0.14-1597060269126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-1375e74a-e6ee-4f44-964a-ff064d16698b,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-d261d9ac-8403-4dda-aa3c-b84d06c3d229,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-980db5b2-0835-42a3-92cb-06e6b1574653,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-2f6c7eeb-4b17-4e98-8c11-7ac004c47fea,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-49177dce-9a40-4178-887b-b93ffdf6f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-0727d29e-c331-4280-a26d-129899174786,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-9a30f5b5-1e1b-4fca-a03e-17243bd2cd70,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-995b1124-a763-4e85-aa92-6d7def56de46,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077316593-172.17.0.14-1597060269126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-1375e74a-e6ee-4f44-964a-ff064d16698b,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-d261d9ac-8403-4dda-aa3c-b84d06c3d229,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-980db5b2-0835-42a3-92cb-06e6b1574653,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-2f6c7eeb-4b17-4e98-8c11-7ac004c47fea,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-49177dce-9a40-4178-887b-b93ffdf6f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-0727d29e-c331-4280-a26d-129899174786,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-9a30f5b5-1e1b-4fca-a03e-17243bd2cd70,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-995b1124-a763-4e85-aa92-6d7def56de46,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548896552-172.17.0.14-1597060511053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36020,DS-a76a43ad-8fce-47e8-8f5c-7f8fbfd89f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-105893c3-1d70-4782-bde7-d224f0d76cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-e16c04ac-394d-4bf1-a164-e8aa73d0a562,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-4797f509-0414-4f67-b8fa-3dd7fc88feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-003c7901-df51-4ba8-b92a-2d097736d988,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-f83a467b-5bd8-41f5-8851-3ac3e958354a,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-08a59d4f-dddc-4fdb-9e2f-18b3c36fcaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-56474fbc-e022-420f-b0c7-16ad2e3b4f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548896552-172.17.0.14-1597060511053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36020,DS-a76a43ad-8fce-47e8-8f5c-7f8fbfd89f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-105893c3-1d70-4782-bde7-d224f0d76cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-e16c04ac-394d-4bf1-a164-e8aa73d0a562,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-4797f509-0414-4f67-b8fa-3dd7fc88feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-003c7901-df51-4ba8-b92a-2d097736d988,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-f83a467b-5bd8-41f5-8851-3ac3e958354a,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-08a59d4f-dddc-4fdb-9e2f-18b3c36fcaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-56474fbc-e022-420f-b0c7-16ad2e3b4f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5240
