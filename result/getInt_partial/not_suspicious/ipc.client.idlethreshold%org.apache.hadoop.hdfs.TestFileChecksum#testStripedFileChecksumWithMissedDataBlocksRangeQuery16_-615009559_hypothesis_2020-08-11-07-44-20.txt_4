reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860392829-172.17.0.8-1597133039445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-024d77ca-dde1-4c7d-b2a0-b0fbf5b13c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-d3375e99-e20e-48a4-9394-76c073393e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-4edfc1d3-aa3f-466d-9e5f-19ed8fec5b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-2f50b683-7e99-473e-b53f-204a1bb0b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-f9072e4f-20f0-4491-9e7a-f56398dc2681,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-815837bf-078e-4ce1-8009-1c8f56815a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-ec378706-e6e3-4a13-9a7e-17a3f7ae96d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-99847d47-f4fe-4b16-8653-6db586c0e396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860392829-172.17.0.8-1597133039445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-024d77ca-dde1-4c7d-b2a0-b0fbf5b13c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-d3375e99-e20e-48a4-9394-76c073393e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-4edfc1d3-aa3f-466d-9e5f-19ed8fec5b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-2f50b683-7e99-473e-b53f-204a1bb0b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-f9072e4f-20f0-4491-9e7a-f56398dc2681,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-815837bf-078e-4ce1-8009-1c8f56815a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-ec378706-e6e3-4a13-9a7e-17a3f7ae96d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-99847d47-f4fe-4b16-8653-6db586c0e396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916379174-172.17.0.8-1597133404594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33517,DS-c6e81494-d0b3-4505-af45-01c8b25c8574,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-a19dda36-4850-427b-be75-108817d5c93d,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-7373fe09-be57-4624-bb98-faae1c6c5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-c80f0a0a-757f-4108-8dc8-3b72ccd4c7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-3860fb6b-4b95-4324-a566-5e802e9db69b,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-d9c4f50f-fd00-4d39-9fd1-446bf5af7491,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-0bf4113c-181a-4432-9f73-b98799a094da,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-c4fee158-2baa-48e1-9884-2ff613e11241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916379174-172.17.0.8-1597133404594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33517,DS-c6e81494-d0b3-4505-af45-01c8b25c8574,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-a19dda36-4850-427b-be75-108817d5c93d,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-7373fe09-be57-4624-bb98-faae1c6c5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-c80f0a0a-757f-4108-8dc8-3b72ccd4c7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-3860fb6b-4b95-4324-a566-5e802e9db69b,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-d9c4f50f-fd00-4d39-9fd1-446bf5af7491,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-0bf4113c-181a-4432-9f73-b98799a094da,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-c4fee158-2baa-48e1-9884-2ff613e11241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075386821-172.17.0.8-1597133722773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-510b7b03-ea95-47fc-a167-115d89ddf197,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-101db7ab-fe60-4dcc-b57a-e21372745b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-8f334707-6d8f-4b3a-8632-4aba519e02c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-56e27d1b-a280-4736-af67-9162d7054042,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-77c98976-8dae-410a-b746-00061dfb267f,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-bddfa7bf-e17f-4380-a878-a667d4c9e660,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-7c4f0052-50d0-4a3f-89d1-54862632e18d,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-7b3872df-2974-409b-936a-79f858cb5881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075386821-172.17.0.8-1597133722773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-510b7b03-ea95-47fc-a167-115d89ddf197,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-101db7ab-fe60-4dcc-b57a-e21372745b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-8f334707-6d8f-4b3a-8632-4aba519e02c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-56e27d1b-a280-4736-af67-9162d7054042,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-77c98976-8dae-410a-b746-00061dfb267f,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-bddfa7bf-e17f-4380-a878-a667d4c9e660,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-7c4f0052-50d0-4a3f-89d1-54862632e18d,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-7b3872df-2974-409b-936a-79f858cb5881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532494-172.17.0.8-1597134176067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-db6dddad-6fd3-4ca1-8e1c-68676b4c57eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-a2c4728f-9dd9-4e76-8ef5-4e113a779490,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-707c873f-9fdc-428f-99b2-9273e44bbb10,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-a34abc00-86e6-4a6d-a16f-d8c61520caab,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-443a5ba3-ff73-4bc6-a0a5-59eb180a76ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-c5df8b35-a77d-4bfb-9b49-7f1b29cd1ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-7f37443f-074c-4779-89b0-ecb23ecc30f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-f6492265-8857-431d-a8d4-2f7697846f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532494-172.17.0.8-1597134176067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-db6dddad-6fd3-4ca1-8e1c-68676b4c57eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-a2c4728f-9dd9-4e76-8ef5-4e113a779490,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-707c873f-9fdc-428f-99b2-9273e44bbb10,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-a34abc00-86e6-4a6d-a16f-d8c61520caab,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-443a5ba3-ff73-4bc6-a0a5-59eb180a76ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-c5df8b35-a77d-4bfb-9b49-7f1b29cd1ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-7f37443f-074c-4779-89b0-ecb23ecc30f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-f6492265-8857-431d-a8d4-2f7697846f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2040176323-172.17.0.8-1597135091831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38566,DS-db668429-a001-4876-baf9-257fd7b7960d,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-397d72e0-2b8f-4c69-90ac-b34f86d3ff7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-2ef08895-2085-4834-8fc5-e86f16d8ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-9b25330c-928c-4cb8-883c-9b6eb3eb1a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-bb272460-090f-44c1-a7c3-70e93da3ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-fa397449-fd8d-458b-9b57-f818ac3e36ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-05fa2ac1-7317-4535-aefd-937b56fd04bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-84cd8317-da7a-477a-9e0e-b810fd94ed05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2040176323-172.17.0.8-1597135091831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38566,DS-db668429-a001-4876-baf9-257fd7b7960d,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-397d72e0-2b8f-4c69-90ac-b34f86d3ff7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-2ef08895-2085-4834-8fc5-e86f16d8ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-9b25330c-928c-4cb8-883c-9b6eb3eb1a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-bb272460-090f-44c1-a7c3-70e93da3ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-fa397449-fd8d-458b-9b57-f818ac3e36ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-05fa2ac1-7317-4535-aefd-937b56fd04bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-84cd8317-da7a-477a-9e0e-b810fd94ed05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409759723-172.17.0.8-1597135177261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35516,DS-38c5878c-5344-4e01-9547-78fc9079cd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-b6384d5b-3d2c-464f-ad6f-eaf4907c8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-98926a74-5aa9-4563-9069-c4ac7e8e1624,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-3042db77-d602-48ae-ad61-141a12b692e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-03458670-dee7-4eea-ac62-70750c733eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-8e96c45b-711f-4716-a3fe-350aeeaebc16,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-4102d85b-27f4-45b4-93db-cc5cbfb39c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-dfa84c5d-b093-46bf-8624-c3a1e08307e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409759723-172.17.0.8-1597135177261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35516,DS-38c5878c-5344-4e01-9547-78fc9079cd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-b6384d5b-3d2c-464f-ad6f-eaf4907c8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-98926a74-5aa9-4563-9069-c4ac7e8e1624,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-3042db77-d602-48ae-ad61-141a12b692e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-03458670-dee7-4eea-ac62-70750c733eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-8e96c45b-711f-4716-a3fe-350aeeaebc16,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-4102d85b-27f4-45b4-93db-cc5cbfb39c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-dfa84c5d-b093-46bf-8624-c3a1e08307e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946150115-172.17.0.8-1597135528822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36192,DS-aef69426-e615-4a9d-9eab-58d6c831eaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-49273b7b-a7f7-4ccc-b00c-2e59dadaab16,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-5ec2a8d0-062d-4238-82b5-f76dd37ccc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-05166dcb-9b22-43c2-9e4f-d7482e8863ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-9c840e83-2ce0-4e0e-89ed-04fdccb1d0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-c44754b8-55c0-44b8-91c8-b9d2f2efb5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-86fc3b7b-317b-4c34-aa69-00d3017e5ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-a7f47a48-e624-4d75-b7d7-9aab70cf47ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946150115-172.17.0.8-1597135528822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36192,DS-aef69426-e615-4a9d-9eab-58d6c831eaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-49273b7b-a7f7-4ccc-b00c-2e59dadaab16,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-5ec2a8d0-062d-4238-82b5-f76dd37ccc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-05166dcb-9b22-43c2-9e4f-d7482e8863ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-9c840e83-2ce0-4e0e-89ed-04fdccb1d0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-c44754b8-55c0-44b8-91c8-b9d2f2efb5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-86fc3b7b-317b-4c34-aa69-00d3017e5ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-a7f47a48-e624-4d75-b7d7-9aab70cf47ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119311560-172.17.0.8-1597136122352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38069,DS-0eddce79-d2de-4452-b82d-44c9b2f46c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-d54a9a07-7a63-4242-87c2-9a41ca6116b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-3c252c52-678f-4967-ad11-031a8b4b092b,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-9c0fef2f-2482-46f8-b21c-b684e1bfe898,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-ae0b3073-cf3a-4c64-8534-b05cd57d7e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-7630d544-c75b-40b6-862c-549eee8be3af,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-342f95de-bb63-4500-b84b-96733f1eb5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-aa2e186b-7719-4161-a51c-7a6f3bd78bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119311560-172.17.0.8-1597136122352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38069,DS-0eddce79-d2de-4452-b82d-44c9b2f46c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-d54a9a07-7a63-4242-87c2-9a41ca6116b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-3c252c52-678f-4967-ad11-031a8b4b092b,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-9c0fef2f-2482-46f8-b21c-b684e1bfe898,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-ae0b3073-cf3a-4c64-8534-b05cd57d7e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-7630d544-c75b-40b6-862c-549eee8be3af,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-342f95de-bb63-4500-b84b-96733f1eb5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-aa2e186b-7719-4161-a51c-7a6f3bd78bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110823516-172.17.0.8-1597136181512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41507,DS-f1cbed6a-63d6-4b90-91fa-3b719d26869f,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-f95fdcf4-fe83-46da-9cab-6f3256181326,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-ec58591c-e2ab-441a-a34b-e8c077397a06,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-b3455ac0-17d0-487d-a5ec-c124dcbf6a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-0d67c837-8f0d-4627-a382-46321f8e4e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-700eb38c-5570-4bd1-b60b-30113c6fe947,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-5b996346-da2a-454e-91db-c2d87a0f1591,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-0c719227-38d0-4e4e-a69a-d62b0e813651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110823516-172.17.0.8-1597136181512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41507,DS-f1cbed6a-63d6-4b90-91fa-3b719d26869f,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-f95fdcf4-fe83-46da-9cab-6f3256181326,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-ec58591c-e2ab-441a-a34b-e8c077397a06,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-b3455ac0-17d0-487d-a5ec-c124dcbf6a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-0d67c837-8f0d-4627-a382-46321f8e4e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-700eb38c-5570-4bd1-b60b-30113c6fe947,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-5b996346-da2a-454e-91db-c2d87a0f1591,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-0c719227-38d0-4e4e-a69a-d62b0e813651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415516050-172.17.0.8-1597136393158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45371,DS-e4ba97b3-5f7b-41a7-89ba-2ee846d2fd57,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-35a72756-2d64-4d1c-afab-0aeac0df19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-0ea03256-b69c-4158-87c3-669013d066bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-ceedbd59-2e98-4f90-a8d7-b7c1eed29ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-ad4f21e9-bf9e-454f-8c95-a6a91708d2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-380aa9aa-23f3-4bb2-a33c-53cdbcea9e96,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-c52cd401-4c48-4d26-9a93-874509fafb90,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-232366fc-0cb0-4573-8ad0-2eb29e5973f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415516050-172.17.0.8-1597136393158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45371,DS-e4ba97b3-5f7b-41a7-89ba-2ee846d2fd57,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-35a72756-2d64-4d1c-afab-0aeac0df19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-0ea03256-b69c-4158-87c3-669013d066bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-ceedbd59-2e98-4f90-a8d7-b7c1eed29ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-ad4f21e9-bf9e-454f-8c95-a6a91708d2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-380aa9aa-23f3-4bb2-a33c-53cdbcea9e96,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-c52cd401-4c48-4d26-9a93-874509fafb90,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-232366fc-0cb0-4573-8ad0-2eb29e5973f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580206552-172.17.0.8-1597136478148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46574,DS-af7e28b6-a9f4-4e80-a824-7b3a4376e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-2e5d55ee-97ee-4bfe-bd54-ad896c1c7f26,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-c4cb37b0-3f47-4edb-84a9-e7024fca9804,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-3e4b0da3-96a9-4b75-a5ac-df2c5f97bd98,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-7b460574-ba93-4f07-a5de-54f787f0e763,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-c79f13fa-77d1-4848-9b24-7659b8903a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-9f2fe4c5-e73d-4d0b-8de7-df802d5553b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-49269b4c-68c9-4e27-a2c5-789a8ee7bf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580206552-172.17.0.8-1597136478148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46574,DS-af7e28b6-a9f4-4e80-a824-7b3a4376e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-2e5d55ee-97ee-4bfe-bd54-ad896c1c7f26,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-c4cb37b0-3f47-4edb-84a9-e7024fca9804,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-3e4b0da3-96a9-4b75-a5ac-df2c5f97bd98,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-7b460574-ba93-4f07-a5de-54f787f0e763,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-c79f13fa-77d1-4848-9b24-7659b8903a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-9f2fe4c5-e73d-4d0b-8de7-df802d5553b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-49269b4c-68c9-4e27-a2c5-789a8ee7bf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6772
