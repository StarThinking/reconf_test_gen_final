reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220720574-172.17.0.18-1597203081163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44647,DS-cfe89f83-766a-4f81-bd29-96627eb5c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-55aa66f7-f970-498d-bf37-0d4a40943be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-21a621a6-2339-4c1c-b757-c42bd52b3a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-12950fe5-2133-4674-8b24-bd4d1f944dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-c0d8e106-d856-476f-a2c9-caf819c68373,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-29a0f4c2-34be-4178-a54a-45191778f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-ff8612be-0fcc-4a1d-b217-86e64fe45303,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-e5454fa9-6d7a-4eee-be83-101485fb5cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220720574-172.17.0.18-1597203081163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44647,DS-cfe89f83-766a-4f81-bd29-96627eb5c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-55aa66f7-f970-498d-bf37-0d4a40943be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-21a621a6-2339-4c1c-b757-c42bd52b3a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-12950fe5-2133-4674-8b24-bd4d1f944dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-c0d8e106-d856-476f-a2c9-caf819c68373,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-29a0f4c2-34be-4178-a54a-45191778f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-ff8612be-0fcc-4a1d-b217-86e64fe45303,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-e5454fa9-6d7a-4eee-be83-101485fb5cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171791535-172.17.0.18-1597203256723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-70784a08-9799-4326-b458-36955de07d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-26952492-8aef-4eb8-b3ea-46cb09b04abc,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-d5c2e2aa-5972-4cbe-9160-4c2e90e8dddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-b90f70af-1f26-419f-a1fc-84738a4dac11,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-83948685-f220-4859-99ab-ff92d5de45b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-d9642c56-3414-4259-8952-dfc21a24c77e,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-db312755-d4c6-4cbd-9a3e-afc56268683a,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-bfccf72c-3947-49f9-b56f-fb29422259cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171791535-172.17.0.18-1597203256723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-70784a08-9799-4326-b458-36955de07d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-26952492-8aef-4eb8-b3ea-46cb09b04abc,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-d5c2e2aa-5972-4cbe-9160-4c2e90e8dddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-b90f70af-1f26-419f-a1fc-84738a4dac11,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-83948685-f220-4859-99ab-ff92d5de45b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-d9642c56-3414-4259-8952-dfc21a24c77e,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-db312755-d4c6-4cbd-9a3e-afc56268683a,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-bfccf72c-3947-49f9-b56f-fb29422259cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253627387-172.17.0.18-1597203446248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46573,DS-61f1dcd0-7cbd-481e-bbb1-2ca8f56638d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-02ce9b8b-439d-4f49-85d9-851e6e85f953,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-fb8e46ad-87e9-42c8-b954-72afab4343db,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-5810754a-aad5-4ad9-9b40-59d07b1b805d,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-d2ba104d-d79e-4479-989e-9996be8794a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-05c3414c-ab8d-41d4-add4-e5eaf38b54ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-e43819f1-3b54-44f7-98ac-1ad523eba09a,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-a070047e-6680-4543-a259-3987f3508166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253627387-172.17.0.18-1597203446248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46573,DS-61f1dcd0-7cbd-481e-bbb1-2ca8f56638d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-02ce9b8b-439d-4f49-85d9-851e6e85f953,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-fb8e46ad-87e9-42c8-b954-72afab4343db,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-5810754a-aad5-4ad9-9b40-59d07b1b805d,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-d2ba104d-d79e-4479-989e-9996be8794a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-05c3414c-ab8d-41d4-add4-e5eaf38b54ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-e43819f1-3b54-44f7-98ac-1ad523eba09a,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-a070047e-6680-4543-a259-3987f3508166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973851780-172.17.0.18-1597204157844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-abdbff9a-ba11-444c-96f3-0d7f486fc14d,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-88d491ee-dfc0-483a-89ff-287fdabb8196,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-15d59fd7-eb0d-47f6-a9f3-14881813f211,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-a21923f5-12a7-46bd-bde5-36f40390cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-1ba6a374-da58-4a7d-b9b7-717c2adaa0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-89b4c0da-ca9f-4f85-86e6-dfa851e1e109,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-b0bff1f5-8967-484d-a88a-3146239b08dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-4dfda030-d189-4745-a52c-42b6d955f800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973851780-172.17.0.18-1597204157844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-abdbff9a-ba11-444c-96f3-0d7f486fc14d,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-88d491ee-dfc0-483a-89ff-287fdabb8196,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-15d59fd7-eb0d-47f6-a9f3-14881813f211,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-a21923f5-12a7-46bd-bde5-36f40390cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-1ba6a374-da58-4a7d-b9b7-717c2adaa0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-89b4c0da-ca9f-4f85-86e6-dfa851e1e109,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-b0bff1f5-8967-484d-a88a-3146239b08dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-4dfda030-d189-4745-a52c-42b6d955f800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133680396-172.17.0.18-1597204340161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-b5c9389c-040b-46e2-9aa4-0675a77f09c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-850d5b4d-07ee-44ab-b779-4042bb75289a,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-d022e82a-d42b-4406-b285-3fc81eea3fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-b67934c3-bedb-41ba-abd2-0ffd07925ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-97704364-1466-45a7-a949-49db40cb0a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-712fd7a1-5822-4a5f-9f77-23a4a8acbb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-af32d73f-3db7-4b28-8ebe-5800fae042b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-0b40f807-73e3-495c-9966-e4ccedafb958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133680396-172.17.0.18-1597204340161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-b5c9389c-040b-46e2-9aa4-0675a77f09c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-850d5b4d-07ee-44ab-b779-4042bb75289a,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-d022e82a-d42b-4406-b285-3fc81eea3fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-b67934c3-bedb-41ba-abd2-0ffd07925ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-97704364-1466-45a7-a949-49db40cb0a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-712fd7a1-5822-4a5f-9f77-23a4a8acbb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-af32d73f-3db7-4b28-8ebe-5800fae042b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-0b40f807-73e3-495c-9966-e4ccedafb958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291538856-172.17.0.18-1597208114492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37855,DS-149d5f8f-7d2b-49fe-91af-cc7b99900cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-65d02c25-3a3d-4554-8d3f-84e56723b813,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-602129aa-d5eb-42ad-bd76-5d18ba18f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-279fcb68-0f92-4c66-8a5e-f45c59537ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-816217d1-7321-4e1c-a6ba-e27f3fe233db,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-f0197ab0-93a0-4f70-ad71-c2bb816626e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-32330eb7-d063-42a8-85a6-2e3db3bc3922,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-5b1c1154-46f7-4f1f-922c-93ff1140b8b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291538856-172.17.0.18-1597208114492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37855,DS-149d5f8f-7d2b-49fe-91af-cc7b99900cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-65d02c25-3a3d-4554-8d3f-84e56723b813,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-602129aa-d5eb-42ad-bd76-5d18ba18f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-279fcb68-0f92-4c66-8a5e-f45c59537ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-816217d1-7321-4e1c-a6ba-e27f3fe233db,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-f0197ab0-93a0-4f70-ad71-c2bb816626e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-32330eb7-d063-42a8-85a6-2e3db3bc3922,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-5b1c1154-46f7-4f1f-922c-93ff1140b8b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341035392-172.17.0.18-1597208153318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32768,DS-504779e4-5bb1-4b53-9e3c-fa40bf3b0a65,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-c3e30a34-29cb-4f41-9dc7-9310fd9a50d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-374a5fe3-975f-47a9-ad86-35797f26951f,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-39be1f4c-2e7f-4723-bf72-8b0c8eb53f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-d56d0850-777d-4ecd-862a-e3afe7999956,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-ecf6412b-38fd-4451-94e2-bb12512c2caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-755341c2-26d3-44b4-8ee7-fdbfc1ef2e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-71b34881-37e2-4323-bf20-a9c46d110908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341035392-172.17.0.18-1597208153318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32768,DS-504779e4-5bb1-4b53-9e3c-fa40bf3b0a65,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-c3e30a34-29cb-4f41-9dc7-9310fd9a50d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-374a5fe3-975f-47a9-ad86-35797f26951f,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-39be1f4c-2e7f-4723-bf72-8b0c8eb53f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-d56d0850-777d-4ecd-862a-e3afe7999956,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-ecf6412b-38fd-4451-94e2-bb12512c2caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-755341c2-26d3-44b4-8ee7-fdbfc1ef2e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-71b34881-37e2-4323-bf20-a9c46d110908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209506245-172.17.0.18-1597208199028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-a96f1747-46ce-4c43-8e59-04da6c1b19ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-f3357c8d-2d6d-4b66-a8ca-7e556925d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-e3b8a5c4-8297-4957-9644-01d8e7952ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-8e8f24a5-fab9-4fdc-b307-53c86d981586,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-8d8b9066-229d-4024-97e5-90f8f5e181c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-ec14b7bd-144b-4a5d-ab9c-cfc56e545edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-d08414ce-b5cb-4f4d-bb2f-cf0b15c508d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-1ff9d694-b83b-4c0d-966e-4e2bc3f67d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209506245-172.17.0.18-1597208199028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-a96f1747-46ce-4c43-8e59-04da6c1b19ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-f3357c8d-2d6d-4b66-a8ca-7e556925d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-e3b8a5c4-8297-4957-9644-01d8e7952ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-8e8f24a5-fab9-4fdc-b307-53c86d981586,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-8d8b9066-229d-4024-97e5-90f8f5e181c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-ec14b7bd-144b-4a5d-ab9c-cfc56e545edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-d08414ce-b5cb-4f4d-bb2f-cf0b15c508d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-1ff9d694-b83b-4c0d-966e-4e2bc3f67d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564214754-172.17.0.18-1597208465670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-a4a60dd1-301a-4483-a7cf-e02808095f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-b3bb56b9-4c8a-4530-8e0f-f665de63d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-7a783853-6816-4f56-80e8-66c149bc1894,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-18e68496-d8b7-4534-a3cf-a983b5274ded,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-68b3fc4b-3bbe-46b2-b3db-8c2fc0f26706,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-d6f47925-78e9-4f5c-ab76-42bccc4035e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-6a679b3b-15ae-4721-bcc5-749b880ec13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-426f0067-e8b7-4ed4-bf02-57e827bde3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564214754-172.17.0.18-1597208465670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-a4a60dd1-301a-4483-a7cf-e02808095f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-b3bb56b9-4c8a-4530-8e0f-f665de63d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-7a783853-6816-4f56-80e8-66c149bc1894,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-18e68496-d8b7-4534-a3cf-a983b5274ded,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-68b3fc4b-3bbe-46b2-b3db-8c2fc0f26706,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-d6f47925-78e9-4f5c-ab76-42bccc4035e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-6a679b3b-15ae-4721-bcc5-749b880ec13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-426f0067-e8b7-4ed4-bf02-57e827bde3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745258362-172.17.0.18-1597208954565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43104,DS-c8409814-05a1-40c5-905e-088b03fac67f,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-38870828-6aca-45ef-a121-cff7a8b86429,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-13002e1b-4f8a-44dd-b3d1-fbe0896bee29,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-b6ddd049-cca5-40ff-815d-b35e42c22663,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-7da5ab2f-71c2-4c28-988c-7214dd8f5341,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-562a46f9-3974-440f-8192-ead519f9ef11,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-8d3fe69a-7545-48e5-9bbe-49eeab4138b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-d24995a2-c8a3-485e-b881-c74f4d55d782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745258362-172.17.0.18-1597208954565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43104,DS-c8409814-05a1-40c5-905e-088b03fac67f,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-38870828-6aca-45ef-a121-cff7a8b86429,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-13002e1b-4f8a-44dd-b3d1-fbe0896bee29,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-b6ddd049-cca5-40ff-815d-b35e42c22663,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-7da5ab2f-71c2-4c28-988c-7214dd8f5341,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-562a46f9-3974-440f-8192-ead519f9ef11,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-8d3fe69a-7545-48e5-9bbe-49eeab4138b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-d24995a2-c8a3-485e-b881-c74f4d55d782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 10
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140332041-172.17.0.18-1597209235099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43642,DS-e84678d5-f222-48c4-aae0-7c46b54cb0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-1fd95529-7d50-404d-9ad7-960e2053c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-050c57a5-d3b7-4534-9e8c-e2640c8d960f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-0de20b19-978a-4d9d-a31b-ee2b6bbcca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-08b5e886-a11b-442a-99f0-860adfbc5b80,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-99a44b1f-dc44-48e1-9acd-7c8fae0c9ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-4600805e-fad2-402d-900b-d358ca16c795,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-bd2ecc26-7cf7-445c-a8c1-41266c55cc04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140332041-172.17.0.18-1597209235099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43642,DS-e84678d5-f222-48c4-aae0-7c46b54cb0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-1fd95529-7d50-404d-9ad7-960e2053c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-050c57a5-d3b7-4534-9e8c-e2640c8d960f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-0de20b19-978a-4d9d-a31b-ee2b6bbcca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-08b5e886-a11b-442a-99f0-860adfbc5b80,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-99a44b1f-dc44-48e1-9acd-7c8fae0c9ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-4600805e-fad2-402d-900b-d358ca16c795,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-bd2ecc26-7cf7-445c-a8c1-41266c55cc04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6762
