reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964138834-172.17.0.20-1597094848498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-2e076ea5-048f-4d80-b0af-464e1ca8aaad,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-aff1c327-defc-4969-8877-559590fb2e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-db32623e-8101-4295-ac85-c7d78d78e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-0ff2e3cf-da0c-4df6-8df8-99ff209be660,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-0b76d52e-161f-4d78-8175-bc0c2adf822c,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-13aadc2f-984d-40d0-b7fc-536682686128,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-5f6f5c6b-cd1a-423f-9f8e-917a20bf6afc,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-9170f37a-0111-4a94-9f2c-9ae404af7bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964138834-172.17.0.20-1597094848498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-2e076ea5-048f-4d80-b0af-464e1ca8aaad,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-aff1c327-defc-4969-8877-559590fb2e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-db32623e-8101-4295-ac85-c7d78d78e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-0ff2e3cf-da0c-4df6-8df8-99ff209be660,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-0b76d52e-161f-4d78-8175-bc0c2adf822c,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-13aadc2f-984d-40d0-b7fc-536682686128,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-5f6f5c6b-cd1a-423f-9f8e-917a20bf6afc,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-9170f37a-0111-4a94-9f2c-9ae404af7bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020184673-172.17.0.20-1597095071302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45869,DS-d0081faa-5ae9-4136-b8a3-f678853e97fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-43f93e21-8ace-4ab8-a455-99603367270e,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-5f248100-497e-412e-854b-b72f917b0f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-f725a6b2-1579-4e8a-899b-812c1350a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-e6dc412e-1d91-425c-b703-33df771d8bab,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-f697a07c-4214-4ed8-8740-276ec97222f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-9c4cb0c6-12cb-433e-84ae-a6482f716dec,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-82ee2054-88fb-4a56-8876-ddb82ae68077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020184673-172.17.0.20-1597095071302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45869,DS-d0081faa-5ae9-4136-b8a3-f678853e97fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-43f93e21-8ace-4ab8-a455-99603367270e,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-5f248100-497e-412e-854b-b72f917b0f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-f725a6b2-1579-4e8a-899b-812c1350a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-e6dc412e-1d91-425c-b703-33df771d8bab,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-f697a07c-4214-4ed8-8740-276ec97222f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-9c4cb0c6-12cb-433e-84ae-a6482f716dec,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-82ee2054-88fb-4a56-8876-ddb82ae68077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473472289-172.17.0.20-1597095341162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46740,DS-dcc11e93-d8d3-4a8a-8679-34b2ba7272bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-bd5a9206-1eb9-4d30-80ed-cb11de1d3ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-af397df1-1f5a-4b70-ad0e-f9b6e2a67400,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-65a3108f-191b-4d4d-be27-626be550aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-d2e68262-a675-49af-a3ce-e0503edbed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-f3b508b7-4eef-438d-9d13-e6d33dc7600d,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-b7d24a63-46e3-40dd-8305-aff8554e4c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-5072d937-b258-49f2-94c7-8404272a9da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473472289-172.17.0.20-1597095341162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46740,DS-dcc11e93-d8d3-4a8a-8679-34b2ba7272bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-bd5a9206-1eb9-4d30-80ed-cb11de1d3ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-af397df1-1f5a-4b70-ad0e-f9b6e2a67400,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-65a3108f-191b-4d4d-be27-626be550aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-d2e68262-a675-49af-a3ce-e0503edbed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-f3b508b7-4eef-438d-9d13-e6d33dc7600d,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-b7d24a63-46e3-40dd-8305-aff8554e4c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-5072d937-b258-49f2-94c7-8404272a9da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575615941-172.17.0.20-1597095376612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-91b19180-84d0-4446-a14b-f092c1032dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-cc74ca17-c043-42a3-a512-3c2d7ba6e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-caa4a18b-4f48-4877-948c-9197b2f3511d,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-c0b57986-e932-46ba-8ce1-c1a1abb7f67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-d00b4822-8935-4222-ae48-b0aa0eb62ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-254e72b8-5c59-4cef-9925-3a691f745db1,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-58131f04-4d9d-4b1b-95b8-e29f5122176b,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-773e0193-033e-4bcb-99ea-38130a6c6be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575615941-172.17.0.20-1597095376612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-91b19180-84d0-4446-a14b-f092c1032dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-cc74ca17-c043-42a3-a512-3c2d7ba6e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-caa4a18b-4f48-4877-948c-9197b2f3511d,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-c0b57986-e932-46ba-8ce1-c1a1abb7f67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-d00b4822-8935-4222-ae48-b0aa0eb62ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-254e72b8-5c59-4cef-9925-3a691f745db1,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-58131f04-4d9d-4b1b-95b8-e29f5122176b,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-773e0193-033e-4bcb-99ea-38130a6c6be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794523517-172.17.0.20-1597095492323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38290,DS-6aa19411-8f05-4fa5-aafd-a7d751a7a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-c14eff1c-5518-49f7-acb1-672e4cf9e852,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-ea822eac-a506-4c76-a28f-147dc2e2547d,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-d6e9c153-e690-4c1b-9f67-2776630c328b,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-3972657f-91af-4f82-a3ea-8f977e3400b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-1d459364-54e6-4013-aa9b-b9f05c85637b,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-097293e2-e575-47fd-9c3a-35167fbf4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-4805d703-70b6-4e25-bb50-8f4def828889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794523517-172.17.0.20-1597095492323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38290,DS-6aa19411-8f05-4fa5-aafd-a7d751a7a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-c14eff1c-5518-49f7-acb1-672e4cf9e852,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-ea822eac-a506-4c76-a28f-147dc2e2547d,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-d6e9c153-e690-4c1b-9f67-2776630c328b,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-3972657f-91af-4f82-a3ea-8f977e3400b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-1d459364-54e6-4013-aa9b-b9f05c85637b,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-097293e2-e575-47fd-9c3a-35167fbf4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-4805d703-70b6-4e25-bb50-8f4def828889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776222170-172.17.0.20-1597095720908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45895,DS-09162332-acd3-454b-853b-10594de7db5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-c8334361-58e3-4d8b-bfe5-f92d13efa54c,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-38d385df-cf79-4ec4-a6d1-08b4a6f7a433,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-00defaa5-efc3-4c51-aa2a-8c3b58a26a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-998a7993-4848-4790-bd25-2b380c09bde7,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-7c1db952-3838-4962-898c-367aaaf053e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-9e0ea545-7fd8-4726-91b4-248556d6c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-c4a27d56-afa4-4041-ac37-c7ac4f6692a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776222170-172.17.0.20-1597095720908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45895,DS-09162332-acd3-454b-853b-10594de7db5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-c8334361-58e3-4d8b-bfe5-f92d13efa54c,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-38d385df-cf79-4ec4-a6d1-08b4a6f7a433,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-00defaa5-efc3-4c51-aa2a-8c3b58a26a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-998a7993-4848-4790-bd25-2b380c09bde7,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-7c1db952-3838-4962-898c-367aaaf053e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-9e0ea545-7fd8-4726-91b4-248556d6c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-c4a27d56-afa4-4041-ac37-c7ac4f6692a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873049304-172.17.0.20-1597095801400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37498,DS-88f3b3d9-b0c3-46b2-a005-6b378c582c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-6197c703-2b24-43a6-be4f-5d41013036b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-74635e9d-82bd-4356-b1b3-0d78fb1a9384,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-d8d8531c-f1ae-45af-b666-5d6163f923b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-a4a896a9-612b-4d5d-92a7-0f50c4248a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-9c941ea2-c8b8-4a17-9f88-a5d571fdf404,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-b693c11e-f1f2-4eae-974d-af1680191029,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-22831452-2f48-4e99-8755-66c732f4a61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873049304-172.17.0.20-1597095801400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37498,DS-88f3b3d9-b0c3-46b2-a005-6b378c582c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-6197c703-2b24-43a6-be4f-5d41013036b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-74635e9d-82bd-4356-b1b3-0d78fb1a9384,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-d8d8531c-f1ae-45af-b666-5d6163f923b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-a4a896a9-612b-4d5d-92a7-0f50c4248a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-9c941ea2-c8b8-4a17-9f88-a5d571fdf404,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-b693c11e-f1f2-4eae-974d-af1680191029,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-22831452-2f48-4e99-8755-66c732f4a61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327887340-172.17.0.20-1597096487836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-36095fc4-607e-4257-ab81-448eab2bc30c,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-e7b37626-af71-45f4-9b30-6c56799d72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-1dda88b9-7790-4aa9-9a07-49cb75c89ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-6be826d9-f906-46d4-b231-a13b3cbe09a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-1c2f0733-7081-4668-a8e6-80fd3f671413,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-c6003c96-290c-4525-8784-266e30232c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-3aec669e-beff-4d11-be32-b86b1bc6f893,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-301eb96c-b09e-462e-915e-60faef150b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327887340-172.17.0.20-1597096487836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-36095fc4-607e-4257-ab81-448eab2bc30c,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-e7b37626-af71-45f4-9b30-6c56799d72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-1dda88b9-7790-4aa9-9a07-49cb75c89ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-6be826d9-f906-46d4-b231-a13b3cbe09a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-1c2f0733-7081-4668-a8e6-80fd3f671413,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-c6003c96-290c-4525-8784-266e30232c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-3aec669e-beff-4d11-be32-b86b1bc6f893,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-301eb96c-b09e-462e-915e-60faef150b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111887342-172.17.0.20-1597096528488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36927,DS-7b513caa-c61b-466e-b555-229fdebb7d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-f0986d17-6375-43b8-a9c1-fb118c081049,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-a99d0afe-30f9-4d19-8b69-8bd9ee9661d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-145a6609-cc57-46ec-8dcb-432fe6edeaca,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-b0acae49-37ca-484c-af8c-a63b3fe783b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-7e4cece8-5a61-4c3d-825c-0e347d54c124,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-ddb82ed2-9e64-4ed6-8f46-e3fa0fcce4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-43368c8b-a147-4817-bbc9-e80e2184c195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111887342-172.17.0.20-1597096528488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36927,DS-7b513caa-c61b-466e-b555-229fdebb7d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-f0986d17-6375-43b8-a9c1-fb118c081049,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-a99d0afe-30f9-4d19-8b69-8bd9ee9661d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-145a6609-cc57-46ec-8dcb-432fe6edeaca,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-b0acae49-37ca-484c-af8c-a63b3fe783b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-7e4cece8-5a61-4c3d-825c-0e347d54c124,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-ddb82ed2-9e64-4ed6-8f46-e3fa0fcce4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-43368c8b-a147-4817-bbc9-e80e2184c195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378446563-172.17.0.20-1597096568563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-32cef12f-6b02-49f6-92fe-2c6e753a077b,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-4ae6b607-2312-4bd4-ac71-272b335cce59,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-4c39a2e4-488e-4812-a5d2-fd2aeb3c9b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-4196c0cd-66b8-42b4-a846-4737bdc790c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-4e5bcfc1-1b24-44a2-9013-a9bedd4a55c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-324d1ab4-50e2-4a9c-b257-819c2d581efd,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-e46933ef-fce9-4fb7-85c1-07cf38bda35f,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-d4fdcb25-e87c-4efb-a9b0-c32bfb905f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378446563-172.17.0.20-1597096568563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-32cef12f-6b02-49f6-92fe-2c6e753a077b,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-4ae6b607-2312-4bd4-ac71-272b335cce59,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-4c39a2e4-488e-4812-a5d2-fd2aeb3c9b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-4196c0cd-66b8-42b4-a846-4737bdc790c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-4e5bcfc1-1b24-44a2-9013-a9bedd4a55c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-324d1ab4-50e2-4a9c-b257-819c2d581efd,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-e46933ef-fce9-4fb7-85c1-07cf38bda35f,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-d4fdcb25-e87c-4efb-a9b0-c32bfb905f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160018168-172.17.0.20-1597096832028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44172,DS-0fa1508b-1838-407e-9c78-12928eeece17,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-eb65a37b-07ca-4fe9-a368-7541abbcd1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-0b342dc0-3bd3-417f-a0aa-3aa41071d9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-35b65dae-b9cf-4254-b8ff-a4967cc611d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-443abc3d-1374-482c-a34f-4c95f6f48974,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-d4f6235d-dbe7-416f-8e2c-06821ed4f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-89202263-db41-4161-8187-c076e56ca2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-7e47261a-9df5-4f94-8b5e-3c8ff16c9f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160018168-172.17.0.20-1597096832028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44172,DS-0fa1508b-1838-407e-9c78-12928eeece17,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-eb65a37b-07ca-4fe9-a368-7541abbcd1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-0b342dc0-3bd3-417f-a0aa-3aa41071d9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-35b65dae-b9cf-4254-b8ff-a4967cc611d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-443abc3d-1374-482c-a34f-4c95f6f48974,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-d4f6235d-dbe7-416f-8e2c-06821ed4f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-89202263-db41-4161-8187-c076e56ca2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-7e47261a-9df5-4f94-8b5e-3c8ff16c9f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739590688-172.17.0.20-1597096965781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37119,DS-361f731c-880e-4be1-a9a0-b97d9bb7bfda,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-7235fc10-8039-4b9c-85c7-34bbdcd143c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-27d4ecc3-8d4e-47ee-b1f9-0c1b098c641a,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-2aa0fb94-233f-41bb-8ddc-61d567ed0c85,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-70d6af5f-8d92-458b-bfe8-833c19546a78,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-d8d76689-8c57-411b-b15f-7e51f4ee4b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-10637751-4bae-46c2-9bac-554b9f870813,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-102b7723-10bd-4c35-b440-7f4c2eb0d2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739590688-172.17.0.20-1597096965781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37119,DS-361f731c-880e-4be1-a9a0-b97d9bb7bfda,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-7235fc10-8039-4b9c-85c7-34bbdcd143c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-27d4ecc3-8d4e-47ee-b1f9-0c1b098c641a,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-2aa0fb94-233f-41bb-8ddc-61d567ed0c85,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-70d6af5f-8d92-458b-bfe8-833c19546a78,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-d8d76689-8c57-411b-b15f-7e51f4ee4b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-10637751-4bae-46c2-9bac-554b9f870813,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-102b7723-10bd-4c35-b440-7f4c2eb0d2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131381957-172.17.0.20-1597097197296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-1b5bf6fa-bf74-478f-bf34-7e63a8d266c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-e27373e6-c326-4073-a76d-0a61dd5f82dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-653981eb-7c96-4024-a59d-f60a728de8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-aba29e52-a750-45fc-891e-0aef6a44cb68,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-ab7e051d-5780-4c35-8ded-bfe1b7e63b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-6e7b6e76-e433-40d0-8d72-86dab6c6c544,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-235dcf89-62de-4263-b0f8-edeb6144e577,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-f9e48d66-ba76-41cd-92e0-bdb41a91cbd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131381957-172.17.0.20-1597097197296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-1b5bf6fa-bf74-478f-bf34-7e63a8d266c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-e27373e6-c326-4073-a76d-0a61dd5f82dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-653981eb-7c96-4024-a59d-f60a728de8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-aba29e52-a750-45fc-891e-0aef6a44cb68,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-ab7e051d-5780-4c35-8ded-bfe1b7e63b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-6e7b6e76-e433-40d0-8d72-86dab6c6c544,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-235dcf89-62de-4263-b0f8-edeb6144e577,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-f9e48d66-ba76-41cd-92e0-bdb41a91cbd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839452491-172.17.0.20-1597097338168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46351,DS-a147b113-fcb9-460c-9d91-6427a2cdccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-d1dee4ad-5f0f-4929-a942-bd0e25c538c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-c7ef7a92-702e-4a1c-8c5a-3870e1650859,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-a798f0a8-4e3f-49a2-9eea-f92588731867,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-a5d3cda2-d7c4-43e6-a69f-01405226d08d,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-9c53b587-1569-41ce-9450-f49e815ad273,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-3de9611d-ec67-4813-b13d-feb4ffdf782c,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-e04668af-b662-466e-9185-cec391358753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839452491-172.17.0.20-1597097338168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46351,DS-a147b113-fcb9-460c-9d91-6427a2cdccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-d1dee4ad-5f0f-4929-a942-bd0e25c538c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-c7ef7a92-702e-4a1c-8c5a-3870e1650859,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-a798f0a8-4e3f-49a2-9eea-f92588731867,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-a5d3cda2-d7c4-43e6-a69f-01405226d08d,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-9c53b587-1569-41ce-9450-f49e815ad273,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-3de9611d-ec67-4813-b13d-feb4ffdf782c,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-e04668af-b662-466e-9185-cec391358753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649396598-172.17.0.20-1597097562977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40266,DS-e10c38c6-c096-46f0-a07a-cfcf2b63cd59,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-52ed78ea-c0c0-48a9-b0fa-2afda5310d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-c7ef2968-8364-4992-b1ab-2957ae28bd41,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-432003a4-5f50-414b-be7b-4ddedfece9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-00f13fc3-393f-4d47-b75a-ec2c0720464a,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-4b09864c-aa4c-481a-9116-fadfa85bd863,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-6032b103-4d22-4d15-aa41-972fa8f421ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-5c80c5c0-0614-4e03-ab74-ea8a4cb15bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649396598-172.17.0.20-1597097562977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40266,DS-e10c38c6-c096-46f0-a07a-cfcf2b63cd59,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-52ed78ea-c0c0-48a9-b0fa-2afda5310d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-c7ef2968-8364-4992-b1ab-2957ae28bd41,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-432003a4-5f50-414b-be7b-4ddedfece9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-00f13fc3-393f-4d47-b75a-ec2c0720464a,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-4b09864c-aa4c-481a-9116-fadfa85bd863,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-6032b103-4d22-4d15-aa41-972fa8f421ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-5c80c5c0-0614-4e03-ab74-ea8a4cb15bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840601494-172.17.0.20-1597097707429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-5f5fab57-ec28-4569-af0b-14e7c896dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-4cd534c3-da51-4ef0-a8dc-67291b8c1d08,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-419fd986-ac9e-4544-978b-52584c4fbfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-fec5b5ba-b3c0-49da-85c1-941c0313f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-c30eed1e-8388-4cfb-b2ac-5288148d0999,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-f0d22350-27f4-46bc-8bd0-287a7976faba,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-20665550-59c8-40f1-8b3d-4b520e7eccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-ca05cfe6-8b1d-42e4-8bbb-5cc4ee63841c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840601494-172.17.0.20-1597097707429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-5f5fab57-ec28-4569-af0b-14e7c896dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-4cd534c3-da51-4ef0-a8dc-67291b8c1d08,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-419fd986-ac9e-4544-978b-52584c4fbfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-fec5b5ba-b3c0-49da-85c1-941c0313f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-c30eed1e-8388-4cfb-b2ac-5288148d0999,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-f0d22350-27f4-46bc-8bd0-287a7976faba,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-20665550-59c8-40f1-8b3d-4b520e7eccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-ca05cfe6-8b1d-42e4-8bbb-5cc4ee63841c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255176467-172.17.0.20-1597098476858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-74f8c3e2-3b9b-41e9-a9a4-9185667d8b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-278d0b1a-15a3-4ea5-b773-3e0d6b27f1be,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-81d20661-780b-4c3f-8eec-97b166408772,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-c96c2fd8-1713-434b-9803-d7bedca602b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-701a6b1a-3efd-4317-9e66-98226643a758,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-5455f7b2-9402-43b6-aad1-6e7a00a301a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-cf79c47b-8ffb-4d6f-98f1-8b71412a3591,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-396e6e8e-9850-45f7-81cc-65a1a42d0597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255176467-172.17.0.20-1597098476858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-74f8c3e2-3b9b-41e9-a9a4-9185667d8b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-278d0b1a-15a3-4ea5-b773-3e0d6b27f1be,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-81d20661-780b-4c3f-8eec-97b166408772,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-c96c2fd8-1713-434b-9803-d7bedca602b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-701a6b1a-3efd-4317-9e66-98226643a758,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-5455f7b2-9402-43b6-aad1-6e7a00a301a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-cf79c47b-8ffb-4d6f-98f1-8b71412a3591,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-396e6e8e-9850-45f7-81cc-65a1a42d0597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066706054-172.17.0.20-1597098599413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36086,DS-76c00192-33a5-4519-a7e3-8b3b1bb5a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-28331478-80e0-43c3-851f-1f90a015f622,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-5ed58fba-5602-4aa9-a92e-80a6505472e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-342fc4b9-3520-4f6f-b01a-c437ffc50ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-81ba18f4-962c-4a30-aa17-4ba4a37a687f,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-09e42414-c49e-4e77-9b0f-6312ff62ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-451dfe12-2ecb-4034-849c-489e03407162,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-b3c06bc3-92ff-46d3-81b0-8021cf9935ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066706054-172.17.0.20-1597098599413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36086,DS-76c00192-33a5-4519-a7e3-8b3b1bb5a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-28331478-80e0-43c3-851f-1f90a015f622,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-5ed58fba-5602-4aa9-a92e-80a6505472e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-342fc4b9-3520-4f6f-b01a-c437ffc50ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-81ba18f4-962c-4a30-aa17-4ba4a37a687f,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-09e42414-c49e-4e77-9b0f-6312ff62ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-451dfe12-2ecb-4034-849c-489e03407162,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-b3c06bc3-92ff-46d3-81b0-8021cf9935ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069158424-172.17.0.20-1597098754643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32958,DS-eb961812-59a9-4602-a960-0c417b7ef3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-828b3cec-bee0-45b4-83d2-fab232c2ba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-1dc79f66-b282-4742-b318-d392b18efc37,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-4b7a395e-29d8-4d65-a6bd-32f2efa8f074,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-50d1810a-d37c-4602-9c04-40dabcd2dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-9602c68c-96ad-406f-a65a-f58249e2c7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-1a0438b5-be0d-426b-9fa7-df6079e00139,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-7756a56d-a54f-4bf1-b7d2-e93351e027c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069158424-172.17.0.20-1597098754643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32958,DS-eb961812-59a9-4602-a960-0c417b7ef3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-828b3cec-bee0-45b4-83d2-fab232c2ba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-1dc79f66-b282-4742-b318-d392b18efc37,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-4b7a395e-29d8-4d65-a6bd-32f2efa8f074,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-50d1810a-d37c-4602-9c04-40dabcd2dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-9602c68c-96ad-406f-a65a-f58249e2c7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-1a0438b5-be0d-426b-9fa7-df6079e00139,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-7756a56d-a54f-4bf1-b7d2-e93351e027c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5453
