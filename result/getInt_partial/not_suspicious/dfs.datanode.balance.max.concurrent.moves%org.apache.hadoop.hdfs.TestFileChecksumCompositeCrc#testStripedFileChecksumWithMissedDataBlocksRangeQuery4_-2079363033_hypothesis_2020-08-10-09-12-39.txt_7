reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173689805-172.17.0.14-1597051030087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36328,DS-0aa22527-7bcb-4200-a467-d601b0e0e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-6ded959e-811f-48f4-96a8-f3b2b8daec33,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-3b4771ab-af3d-465a-99e3-db8c07ab37ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-33ff6347-da82-4a02-abe3-da5376e79c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-c770a19e-9107-41ad-a10b-0535ff288ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-499a1558-c2e4-49c7-be3f-b247f2e25efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-79b5c1fe-246f-43cf-bceb-d6ae91d0b747,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-5182ead7-8c16-46b6-afa1-5dd468773e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173689805-172.17.0.14-1597051030087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36328,DS-0aa22527-7bcb-4200-a467-d601b0e0e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-6ded959e-811f-48f4-96a8-f3b2b8daec33,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-3b4771ab-af3d-465a-99e3-db8c07ab37ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-33ff6347-da82-4a02-abe3-da5376e79c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-c770a19e-9107-41ad-a10b-0535ff288ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-499a1558-c2e4-49c7-be3f-b247f2e25efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-79b5c1fe-246f-43cf-bceb-d6ae91d0b747,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-5182ead7-8c16-46b6-afa1-5dd468773e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325405796-172.17.0.14-1597052443528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-d774f5f7-2a60-4595-a4d9-728e5e319290,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-33db0d00-aba8-4ef6-945a-31102d59e9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-5c57c211-1159-4d00-a406-7aaecd85877e,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-557202a9-3a82-40cd-ab9b-829cde85d776,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-d5b4bb2f-0878-4c0f-b0c0-ae4d96de8bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-e396e032-6e87-4a01-ad8f-58a659a6a5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-e7b0f386-6654-4c8b-afd8-f6da52e256c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-503ce5c8-bb7f-47b3-8509-cff31f74cb12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325405796-172.17.0.14-1597052443528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-d774f5f7-2a60-4595-a4d9-728e5e319290,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-33db0d00-aba8-4ef6-945a-31102d59e9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-5c57c211-1159-4d00-a406-7aaecd85877e,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-557202a9-3a82-40cd-ab9b-829cde85d776,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-d5b4bb2f-0878-4c0f-b0c0-ae4d96de8bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-e396e032-6e87-4a01-ad8f-58a659a6a5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-e7b0f386-6654-4c8b-afd8-f6da52e256c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-503ce5c8-bb7f-47b3-8509-cff31f74cb12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649324482-172.17.0.14-1597052549665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-b0dbf08a-9992-4708-ad77-5d61551abe54,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-492995a0-ab0e-4366-9e8f-2263f629dd99,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-28a85c8a-8f77-4ce4-aa43-a144a91bd0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-8b768df9-5e88-43ab-8630-09cf62654031,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-a39b5ea2-ba4b-4c45-b707-4dce485d4c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-f2a1c89a-122f-454f-9976-cb3c6264653e,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-b3174b73-e589-4066-85c3-da94b06080a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-e10a1d55-187a-4bc6-939a-24c63688797f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649324482-172.17.0.14-1597052549665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-b0dbf08a-9992-4708-ad77-5d61551abe54,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-492995a0-ab0e-4366-9e8f-2263f629dd99,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-28a85c8a-8f77-4ce4-aa43-a144a91bd0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-8b768df9-5e88-43ab-8630-09cf62654031,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-a39b5ea2-ba4b-4c45-b707-4dce485d4c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-f2a1c89a-122f-454f-9976-cb3c6264653e,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-b3174b73-e589-4066-85c3-da94b06080a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-e10a1d55-187a-4bc6-939a-24c63688797f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118796674-172.17.0.14-1597052588757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33115,DS-3359381c-e3c1-4fa6-becd-7e44c66dbafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-1a07db44-30ae-4283-9361-8a13c65dfdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-0f37ae94-1d63-41ba-8933-ddbb93c98535,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-ea71ee95-8df7-4dfd-b59b-a9571db63ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-732803b2-cc4b-4f07-9793-8bf380f2b5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-5f242f35-fc24-459c-87bb-79e48f455a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-7376992a-8773-4248-ab14-e0e92a0711e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-bec72e45-ff42-4f66-921d-11863a6f6e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118796674-172.17.0.14-1597052588757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33115,DS-3359381c-e3c1-4fa6-becd-7e44c66dbafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-1a07db44-30ae-4283-9361-8a13c65dfdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-0f37ae94-1d63-41ba-8933-ddbb93c98535,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-ea71ee95-8df7-4dfd-b59b-a9571db63ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-732803b2-cc4b-4f07-9793-8bf380f2b5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-5f242f35-fc24-459c-87bb-79e48f455a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-7376992a-8773-4248-ab14-e0e92a0711e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-bec72e45-ff42-4f66-921d-11863a6f6e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166366370-172.17.0.14-1597053211898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-acdbb67f-fc1a-4ecd-bab2-df5af30e0119,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-1190aa04-b273-4737-838c-aef1562020c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-543a8662-3d7c-46b4-a901-51b0b80abd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-b6cf0b05-b8fe-4434-93eb-d7891c32ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-666f2ac6-e1ba-4565-9916-0571b1e38984,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-60cc092b-d89d-4cc3-9c84-c542d8366952,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-7c8511c5-1a24-4aed-aef8-d0198a0ed4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-690914e0-d1dc-4afc-a613-e09a11ade564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166366370-172.17.0.14-1597053211898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-acdbb67f-fc1a-4ecd-bab2-df5af30e0119,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-1190aa04-b273-4737-838c-aef1562020c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-543a8662-3d7c-46b4-a901-51b0b80abd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-b6cf0b05-b8fe-4434-93eb-d7891c32ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-666f2ac6-e1ba-4565-9916-0571b1e38984,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-60cc092b-d89d-4cc3-9c84-c542d8366952,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-7c8511c5-1a24-4aed-aef8-d0198a0ed4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-690914e0-d1dc-4afc-a613-e09a11ade564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225797967-172.17.0.14-1597053566321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42683,DS-e34835f0-5523-438f-8393-de621b260f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-24094976-5af2-4a38-90f9-f1ca10ab54a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-8f285423-ff79-4cca-ae73-cb5b29bdc3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-4dbf49e2-2a2d-4f92-811d-24ebff01aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-3aee8f58-0698-45c2-aae3-c163b6ac6efd,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-6a720f97-7903-4c3b-9d59-c14e8b07a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-052b63f9-e827-4bb8-b7b3-00add2277fee,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-c5c18e2a-bfee-4fa6-b2fe-dfc916fdcca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225797967-172.17.0.14-1597053566321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42683,DS-e34835f0-5523-438f-8393-de621b260f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-24094976-5af2-4a38-90f9-f1ca10ab54a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-8f285423-ff79-4cca-ae73-cb5b29bdc3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-4dbf49e2-2a2d-4f92-811d-24ebff01aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-3aee8f58-0698-45c2-aae3-c163b6ac6efd,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-6a720f97-7903-4c3b-9d59-c14e8b07a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-052b63f9-e827-4bb8-b7b3-00add2277fee,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-c5c18e2a-bfee-4fa6-b2fe-dfc916fdcca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549919311-172.17.0.14-1597054143061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-d5240585-9eaf-4c8c-b9df-66b6a115663c,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-cbc28487-1145-449b-b374-fbe9f6ff7dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-0baa7991-beab-4ed1-9844-512e9ab82ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-2eb89647-794c-43ff-8e3f-0ed5f5cd6ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-2a407f18-80ba-4176-a7ca-b4fa80dcaa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-d07aba4c-c5f1-4ccf-b7dc-4cefd8fcbd18,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-ea960d6a-35d3-4a9d-9151-3352558746fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-44351dad-d21e-44b0-ba52-c97cef564bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549919311-172.17.0.14-1597054143061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-d5240585-9eaf-4c8c-b9df-66b6a115663c,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-cbc28487-1145-449b-b374-fbe9f6ff7dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-0baa7991-beab-4ed1-9844-512e9ab82ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-2eb89647-794c-43ff-8e3f-0ed5f5cd6ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-2a407f18-80ba-4176-a7ca-b4fa80dcaa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-d07aba4c-c5f1-4ccf-b7dc-4cefd8fcbd18,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-ea960d6a-35d3-4a9d-9151-3352558746fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-44351dad-d21e-44b0-ba52-c97cef564bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292546825-172.17.0.14-1597054204763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-6b5de0e6-ca66-47d8-a7e1-eaf0316ae31d,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-d708bba0-ac3f-4c31-8ee7-de76e2f9107d,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-2103315e-cb22-48e8-93c2-cc8a587fab40,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-06681cd5-5870-4915-8c5a-a8d022b32fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-50a5a889-6af9-40b3-9bac-a67a77ed58f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-10c85d8b-8900-4a4f-a5e7-bb9068b13407,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-08739a63-99b6-400d-be92-5f9094890a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-60a5e106-b701-483c-8f69-ed0bc24e6c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292546825-172.17.0.14-1597054204763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-6b5de0e6-ca66-47d8-a7e1-eaf0316ae31d,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-d708bba0-ac3f-4c31-8ee7-de76e2f9107d,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-2103315e-cb22-48e8-93c2-cc8a587fab40,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-06681cd5-5870-4915-8c5a-a8d022b32fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-50a5a889-6af9-40b3-9bac-a67a77ed58f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-10c85d8b-8900-4a4f-a5e7-bb9068b13407,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-08739a63-99b6-400d-be92-5f9094890a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-60a5e106-b701-483c-8f69-ed0bc24e6c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447438572-172.17.0.14-1597054443821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-8907c938-9d26-40ee-a9e4-4c778eaf0589,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-22d2a449-358e-4268-a69d-72a294499c23,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-25da3e8c-d418-4452-a7b7-30d0f1a1a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-e287495c-647b-4f40-b969-ee203d214ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-0b211b27-d7d3-4c70-9ab0-b2a427a0c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-6d786e4c-7c6f-4c91-b6a9-c1172611613f,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-4ab3d3c5-d975-4336-9ef8-f33becc762b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-0328912b-a291-4873-82f6-b3dd76a77671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447438572-172.17.0.14-1597054443821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-8907c938-9d26-40ee-a9e4-4c778eaf0589,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-22d2a449-358e-4268-a69d-72a294499c23,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-25da3e8c-d418-4452-a7b7-30d0f1a1a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-e287495c-647b-4f40-b969-ee203d214ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-0b211b27-d7d3-4c70-9ab0-b2a427a0c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-6d786e4c-7c6f-4c91-b6a9-c1172611613f,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-4ab3d3c5-d975-4336-9ef8-f33becc762b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-0328912b-a291-4873-82f6-b3dd76a77671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740013430-172.17.0.14-1597055157792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-7a2bc56d-786e-4070-94fb-4f04f3c1a995,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-40fc982f-b3c6-4f68-8ddc-f2e6c33a9c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-21f77d27-92d9-481c-b477-2936e6ccf055,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-0018cad5-dfd3-4aac-ac13-f91624796c40,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-fd868a52-c1e2-4b70-8f0a-66057bb83c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-1b6ac23f-0b59-410c-bc7d-255735e8f229,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-67ac4a01-1045-43f8-aa91-2ca8f1acac0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-5b8cb670-2384-4e21-a193-8f71971f36a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740013430-172.17.0.14-1597055157792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-7a2bc56d-786e-4070-94fb-4f04f3c1a995,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-40fc982f-b3c6-4f68-8ddc-f2e6c33a9c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-21f77d27-92d9-481c-b477-2936e6ccf055,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-0018cad5-dfd3-4aac-ac13-f91624796c40,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-fd868a52-c1e2-4b70-8f0a-66057bb83c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-1b6ac23f-0b59-410c-bc7d-255735e8f229,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-67ac4a01-1045-43f8-aa91-2ca8f1acac0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-5b8cb670-2384-4e21-a193-8f71971f36a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49765213-172.17.0.14-1597055525195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44409,DS-a70659ec-3ca8-4762-a8e5-8fb93fef2cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-a9729e8b-7b36-4fd6-b084-4e30903e7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e6856875-94ff-4102-8420-62d9fb138d18,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-a804008e-2d43-4db2-828a-8f631bdafbac,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-a88e3d94-f9cd-42d1-80ba-22ca02fb27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-1f84e456-2156-4594-911b-431d54683fda,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-ce23e971-0708-4b38-8d3f-2f6b4905e654,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-1ca2560f-b465-48c5-867e-e156239bcfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49765213-172.17.0.14-1597055525195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44409,DS-a70659ec-3ca8-4762-a8e5-8fb93fef2cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-a9729e8b-7b36-4fd6-b084-4e30903e7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e6856875-94ff-4102-8420-62d9fb138d18,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-a804008e-2d43-4db2-828a-8f631bdafbac,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-a88e3d94-f9cd-42d1-80ba-22ca02fb27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-1f84e456-2156-4594-911b-431d54683fda,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-ce23e971-0708-4b38-8d3f-2f6b4905e654,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-1ca2560f-b465-48c5-867e-e156239bcfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435339871-172.17.0.14-1597055702975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42599,DS-1b28e424-6d9a-48fe-898f-861564a4ddca,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-c3e3df11-b686-438c-826b-e546efc13162,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-4509f30e-620a-4c01-bc95-a04d19f47fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-e2b619a5-b3e1-49f4-83f2-1da0ef897690,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-eb757748-9070-49dc-8dd5-d3166c91c843,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-4d414715-77d7-43d0-ba9b-0a5f3bdf91c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-0e1dccf1-ad2b-4e41-8000-2673ed7e9ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-6a04f945-fe63-46c6-9d3f-4b2b9080e707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435339871-172.17.0.14-1597055702975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42599,DS-1b28e424-6d9a-48fe-898f-861564a4ddca,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-c3e3df11-b686-438c-826b-e546efc13162,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-4509f30e-620a-4c01-bc95-a04d19f47fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-e2b619a5-b3e1-49f4-83f2-1da0ef897690,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-eb757748-9070-49dc-8dd5-d3166c91c843,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-4d414715-77d7-43d0-ba9b-0a5f3bdf91c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-0e1dccf1-ad2b-4e41-8000-2673ed7e9ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-6a04f945-fe63-46c6-9d3f-4b2b9080e707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5317
