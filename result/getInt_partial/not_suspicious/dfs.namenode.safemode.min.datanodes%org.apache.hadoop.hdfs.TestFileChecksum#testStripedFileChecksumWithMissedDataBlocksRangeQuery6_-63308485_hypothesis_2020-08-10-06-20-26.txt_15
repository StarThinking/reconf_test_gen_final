reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779362175-172.17.0.11-1597040508045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40629,DS-a13530a6-fe10-4e44-a499-71557bd4551d,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-c5746779-2694-4109-af95-f8dce55f2c48,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-ed52f35a-5b00-41f4-86d6-ee387f5f9326,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-ea7236da-0423-49f8-b00a-2f7ec3d164ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-75ae1b5c-f71b-452f-96f1-85e333619436,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-732b287f-1a1c-46d1-8563-849b91f99b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-7881cbb8-3067-45ec-b2df-e3d56b3dfb36,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-5702a95a-0e6c-494f-9cc1-f6bbbfbfd04e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779362175-172.17.0.11-1597040508045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40629,DS-a13530a6-fe10-4e44-a499-71557bd4551d,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-c5746779-2694-4109-af95-f8dce55f2c48,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-ed52f35a-5b00-41f4-86d6-ee387f5f9326,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-ea7236da-0423-49f8-b00a-2f7ec3d164ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-75ae1b5c-f71b-452f-96f1-85e333619436,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-732b287f-1a1c-46d1-8563-849b91f99b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-7881cbb8-3067-45ec-b2df-e3d56b3dfb36,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-5702a95a-0e6c-494f-9cc1-f6bbbfbfd04e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235361432-172.17.0.11-1597040739959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-3ea0e3a0-f90b-4232-a978-fb682a6429e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-24615209-33a7-418c-8984-bb26cfb3a3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-2a93f744-42af-423a-9b75-9ff2835c7524,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-506db200-027a-41ac-b205-0e11644e3813,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-3babcfef-e2d4-42e9-8ce8-5f7546243e68,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-ac09214c-aed1-4701-bb04-58162ed501a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-ec634f70-7136-4c92-94fc-8d4598054d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-5708340c-14cf-4e5a-9bd2-92d913fd45ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235361432-172.17.0.11-1597040739959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-3ea0e3a0-f90b-4232-a978-fb682a6429e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-24615209-33a7-418c-8984-bb26cfb3a3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-2a93f744-42af-423a-9b75-9ff2835c7524,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-506db200-027a-41ac-b205-0e11644e3813,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-3babcfef-e2d4-42e9-8ce8-5f7546243e68,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-ac09214c-aed1-4701-bb04-58162ed501a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-ec634f70-7136-4c92-94fc-8d4598054d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-5708340c-14cf-4e5a-9bd2-92d913fd45ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060597875-172.17.0.11-1597040990965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-48e84bf5-1bce-4bec-a931-99234a4288a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-d12176ff-51ee-4084-8392-ae8014d98ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-371a71c1-0d19-46a1-bab9-d4d91eb67f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-c22a0a3d-a170-455b-89bb-89c2ac1e8b09,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-041890cf-5bff-4f99-b78f-41a99414b887,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-ace56ddc-aac0-42ec-b7a3-6c077721b370,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-eade07ca-d70f-4bd5-8410-30d4982fe8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-0ce48760-38c4-4b9d-8f0a-917843176a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060597875-172.17.0.11-1597040990965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-48e84bf5-1bce-4bec-a931-99234a4288a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-d12176ff-51ee-4084-8392-ae8014d98ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-371a71c1-0d19-46a1-bab9-d4d91eb67f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-c22a0a3d-a170-455b-89bb-89c2ac1e8b09,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-041890cf-5bff-4f99-b78f-41a99414b887,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-ace56ddc-aac0-42ec-b7a3-6c077721b370,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-eade07ca-d70f-4bd5-8410-30d4982fe8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-0ce48760-38c4-4b9d-8f0a-917843176a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464752301-172.17.0.11-1597041071492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-54a59bda-81f2-4239-8bc1-31ecc354ee8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-70e08ce5-a8f5-4636-a2d3-88979930db5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-c3579644-fea7-4eac-9e82-223a258a26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-f1b03ea4-a69e-4cdf-86db-ac45993c85da,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-a8a28b35-74f6-4f51-a336-7664d7b81db2,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-d5cd5751-d0c9-40e5-9c73-d9cd3326d42a,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-7c592e92-6c8a-44b9-aa24-e9a02aaf8b70,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-64c0b021-cce6-4552-9002-b412158520a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464752301-172.17.0.11-1597041071492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-54a59bda-81f2-4239-8bc1-31ecc354ee8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-70e08ce5-a8f5-4636-a2d3-88979930db5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-c3579644-fea7-4eac-9e82-223a258a26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-f1b03ea4-a69e-4cdf-86db-ac45993c85da,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-a8a28b35-74f6-4f51-a336-7664d7b81db2,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-d5cd5751-d0c9-40e5-9c73-d9cd3326d42a,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-7c592e92-6c8a-44b9-aa24-e9a02aaf8b70,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-64c0b021-cce6-4552-9002-b412158520a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568783501-172.17.0.11-1597041106742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39481,DS-76d68c88-988e-49f0-aee2-97bdfffd9239,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-e2ad9198-5cd3-4a1e-b193-909769cd228b,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-585c35ff-1c22-4b90-bf76-43bc58f51e74,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-3931835c-290c-4912-a094-d367e269d834,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-e462c9e0-d42e-460e-815a-fbeb05acba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-0ba9122f-7073-4357-a474-d37ff5517c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-6979f58b-ac9e-4995-8574-af943ecfb3da,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-187e4747-e6fe-47d5-a64b-1388551ab67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568783501-172.17.0.11-1597041106742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39481,DS-76d68c88-988e-49f0-aee2-97bdfffd9239,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-e2ad9198-5cd3-4a1e-b193-909769cd228b,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-585c35ff-1c22-4b90-bf76-43bc58f51e74,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-3931835c-290c-4912-a094-d367e269d834,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-e462c9e0-d42e-460e-815a-fbeb05acba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-0ba9122f-7073-4357-a474-d37ff5517c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-6979f58b-ac9e-4995-8574-af943ecfb3da,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-187e4747-e6fe-47d5-a64b-1388551ab67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22667612-172.17.0.11-1597041253473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-ac543d76-80e7-479c-9c64-f821dc2a2614,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-bf13936d-e0e5-44fb-b667-ed7ba10ffd02,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-a43b1325-c8f9-4ae4-bcd0-9f1d5d50d843,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-1c6c532b-6f3d-4df9-9e3b-62ecba9a5845,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-dc268d67-3ee5-4f46-8c10-ee74d32ad5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-ef627c38-6c04-48c1-90d0-50bff1250ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-9a4d07e7-03ed-44dc-b454-b32f5c44c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-5534cd97-8090-4790-8e6b-53837420ae1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22667612-172.17.0.11-1597041253473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-ac543d76-80e7-479c-9c64-f821dc2a2614,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-bf13936d-e0e5-44fb-b667-ed7ba10ffd02,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-a43b1325-c8f9-4ae4-bcd0-9f1d5d50d843,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-1c6c532b-6f3d-4df9-9e3b-62ecba9a5845,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-dc268d67-3ee5-4f46-8c10-ee74d32ad5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-ef627c38-6c04-48c1-90d0-50bff1250ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-9a4d07e7-03ed-44dc-b454-b32f5c44c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-5534cd97-8090-4790-8e6b-53837420ae1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422452185-172.17.0.11-1597041338278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41574,DS-12c937d2-e724-40af-9fe1-254f908b74ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-bb9ba5d7-4fbc-4321-8814-a12159c5ac16,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-4d414fd2-84c2-4ae1-b791-895fbd2401fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-4026119d-3d58-4b43-9707-a869385c8054,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-95f9b802-a61d-4ab1-be8e-b5f51b784efa,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-d21d7d36-fe25-41bc-8afc-a26e9b76ae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-9233f57a-ad3e-487e-9032-e00db25c907c,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-74f76c2a-3422-4970-a2ab-9fb7b27e45f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422452185-172.17.0.11-1597041338278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41574,DS-12c937d2-e724-40af-9fe1-254f908b74ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-bb9ba5d7-4fbc-4321-8814-a12159c5ac16,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-4d414fd2-84c2-4ae1-b791-895fbd2401fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-4026119d-3d58-4b43-9707-a869385c8054,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-95f9b802-a61d-4ab1-be8e-b5f51b784efa,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-d21d7d36-fe25-41bc-8afc-a26e9b76ae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-9233f57a-ad3e-487e-9032-e00db25c907c,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-74f76c2a-3422-4970-a2ab-9fb7b27e45f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957642267-172.17.0.11-1597041490687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-38653b85-80aa-4389-b83e-a3281673ac52,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-61ff022f-b888-47d5-ac8e-bf8fe4fe61da,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-924f466f-6ea4-4f1d-8041-d0c4f5f84c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-2fd1146a-b10a-4dfe-a581-41f811e78804,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-b0f82425-b955-4eda-afae-7333a9839abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-d19ae161-7a4d-4f4f-9a7c-0189f5450341,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-64f837a3-79b7-491b-a29f-327226c9eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-8a85f2a5-5e49-482f-8843-c3053725a94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957642267-172.17.0.11-1597041490687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-38653b85-80aa-4389-b83e-a3281673ac52,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-61ff022f-b888-47d5-ac8e-bf8fe4fe61da,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-924f466f-6ea4-4f1d-8041-d0c4f5f84c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-2fd1146a-b10a-4dfe-a581-41f811e78804,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-b0f82425-b955-4eda-afae-7333a9839abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-d19ae161-7a4d-4f4f-9a7c-0189f5450341,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-64f837a3-79b7-491b-a29f-327226c9eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-8a85f2a5-5e49-482f-8843-c3053725a94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984259652-172.17.0.11-1597041530960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-e535874a-0f2e-47aa-a84b-67a4f781e995,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-74bcf005-e462-43fe-96fe-2480c14915fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-ccd0bdc1-d484-400c-a0b7-30b0878886af,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-ec23bc3c-7cc5-4db9-aaa6-e1aadbee0edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-3811165b-5a4a-44f1-95d1-0c10c165d88b,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-f5819991-247c-4e23-ad4c-088357ba4272,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-6e66524b-4b49-4cf5-b0f0-1c6b9f016569,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-402beaf4-22f7-422a-b93a-f30e9f16c583,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984259652-172.17.0.11-1597041530960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-e535874a-0f2e-47aa-a84b-67a4f781e995,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-74bcf005-e462-43fe-96fe-2480c14915fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-ccd0bdc1-d484-400c-a0b7-30b0878886af,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-ec23bc3c-7cc5-4db9-aaa6-e1aadbee0edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-3811165b-5a4a-44f1-95d1-0c10c165d88b,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-f5819991-247c-4e23-ad4c-088357ba4272,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-6e66524b-4b49-4cf5-b0f0-1c6b9f016569,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-402beaf4-22f7-422a-b93a-f30e9f16c583,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184087801-172.17.0.11-1597041767415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-c52d864f-f797-4c27-b81a-4311ef0b7d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-cdfbbf26-417b-4b68-a52b-2c3bc35d1f63,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-e1f996d9-4f48-4e51-93ec-3be2869d43d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-5122f9ee-2bfe-4d50-a512-e095b3d96744,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-5436cfa6-8b0e-4df2-a06f-54b097dbbbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-bbc2aee9-7d30-458d-85f8-df45090ac9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-f3fbbbf5-2e5f-42f8-9784-f432f00a4d37,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-1b92323c-781c-4e47-9e54-6d059a2976cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184087801-172.17.0.11-1597041767415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-c52d864f-f797-4c27-b81a-4311ef0b7d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-cdfbbf26-417b-4b68-a52b-2c3bc35d1f63,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-e1f996d9-4f48-4e51-93ec-3be2869d43d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-5122f9ee-2bfe-4d50-a512-e095b3d96744,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-5436cfa6-8b0e-4df2-a06f-54b097dbbbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-bbc2aee9-7d30-458d-85f8-df45090ac9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-f3fbbbf5-2e5f-42f8-9784-f432f00a4d37,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-1b92323c-781c-4e47-9e54-6d059a2976cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311170901-172.17.0.11-1597041796481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34765,DS-a177a297-7283-4385-bb55-54bafc5bed47,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-85706371-11bb-4069-bae2-42cec981d509,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-33c798a3-4146-4c35-92de-b371f8392872,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-b406832c-5f7b-4de0-b5e7-910a756fec39,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-73f381b1-7295-4f38-ba8b-5430001ee0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-f7ae3774-cf15-4b46-bf78-10b5f6ed0613,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-f81a7ab5-d344-4ce7-bd1c-64c2a0fb5289,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-ec59292e-48e7-473a-b761-bf6b3b98eef3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311170901-172.17.0.11-1597041796481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34765,DS-a177a297-7283-4385-bb55-54bafc5bed47,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-85706371-11bb-4069-bae2-42cec981d509,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-33c798a3-4146-4c35-92de-b371f8392872,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-b406832c-5f7b-4de0-b5e7-910a756fec39,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-73f381b1-7295-4f38-ba8b-5430001ee0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-f7ae3774-cf15-4b46-bf78-10b5f6ed0613,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-f81a7ab5-d344-4ce7-bd1c-64c2a0fb5289,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-ec59292e-48e7-473a-b761-bf6b3b98eef3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346392927-172.17.0.11-1597042206571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34315,DS-9d2664df-cb85-43e7-8ed6-23213f4215fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-6e40c54d-0bbb-46cb-b053-71e9aad6f365,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-604ba5ca-7e44-47fb-b8ad-6dee558a9695,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-7a8c8b09-c4e6-4921-b925-6b32cb772937,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-ef77d6fa-779d-4cdd-b85a-24a1ec58be78,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-537ab1aa-8060-4042-925b-fc9000fe9b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-b7f6c0d2-256b-4ebc-9128-771677b05c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-1a18b5a2-81e7-4f60-b913-57cb90bb68ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346392927-172.17.0.11-1597042206571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34315,DS-9d2664df-cb85-43e7-8ed6-23213f4215fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-6e40c54d-0bbb-46cb-b053-71e9aad6f365,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-604ba5ca-7e44-47fb-b8ad-6dee558a9695,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-7a8c8b09-c4e6-4921-b925-6b32cb772937,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-ef77d6fa-779d-4cdd-b85a-24a1ec58be78,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-537ab1aa-8060-4042-925b-fc9000fe9b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-b7f6c0d2-256b-4ebc-9128-771677b05c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-1a18b5a2-81e7-4f60-b913-57cb90bb68ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875240065-172.17.0.11-1597042506144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-c96d4c56-ddb4-48de-9e09-5d0c7e4841b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-067ea9c3-9427-4246-a557-3bc356d1c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-58730558-c0bb-4fa0-8a12-1f5c5004e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-ff8c7e3d-be5e-4c6e-a162-e03b2c2ee722,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-cfa5e80b-ef1f-42ba-ab58-bc348e24d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-72edf57f-8d28-4015-b09e-01aca62368ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-af9aeb4b-ac2d-4dc5-af95-43c808a69dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-2222bb05-ecae-4ede-8945-4eba1dbe3179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875240065-172.17.0.11-1597042506144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-c96d4c56-ddb4-48de-9e09-5d0c7e4841b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-067ea9c3-9427-4246-a557-3bc356d1c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-58730558-c0bb-4fa0-8a12-1f5c5004e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-ff8c7e3d-be5e-4c6e-a162-e03b2c2ee722,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-cfa5e80b-ef1f-42ba-ab58-bc348e24d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-72edf57f-8d28-4015-b09e-01aca62368ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-af9aeb4b-ac2d-4dc5-af95-43c808a69dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-2222bb05-ecae-4ede-8945-4eba1dbe3179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870981492-172.17.0.11-1597042578644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-d7f9930b-de0f-45b0-8a47-4c391f4c0abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-d63c9073-b702-4ab4-8f1c-24e9fed5fa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-5bce2e34-bbce-4c3a-b671-66b72486e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-c48f4e70-61b4-4cc7-b519-099b97f7c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-d2f2e4a6-e432-4f5a-8e35-41d3dae2186d,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-decd3ee4-9112-4691-98a6-01790eec2707,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-dcdb2b2d-eeed-4f80-9cca-9d7f797962fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-da7eb8cf-9a97-4c70-80ed-0ff276122dca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870981492-172.17.0.11-1597042578644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-d7f9930b-de0f-45b0-8a47-4c391f4c0abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-d63c9073-b702-4ab4-8f1c-24e9fed5fa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-5bce2e34-bbce-4c3a-b671-66b72486e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-c48f4e70-61b4-4cc7-b519-099b97f7c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-d2f2e4a6-e432-4f5a-8e35-41d3dae2186d,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-decd3ee4-9112-4691-98a6-01790eec2707,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-dcdb2b2d-eeed-4f80-9cca-9d7f797962fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-da7eb8cf-9a97-4c70-80ed-0ff276122dca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312592897-172.17.0.11-1597042726755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33477,DS-b95231a3-d15e-41a4-bbeb-e5a95444a72a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-4d77a5f0-8628-49f4-bcd3-8b12dc22223d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-22a0af76-efcb-41b4-831e-394cda902f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-4f277109-f098-497b-8dae-1dba39e76342,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-25a569ca-a101-4b53-91dc-d8fe3704b07f,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-12ecaaae-e4fc-4fde-a5b9-3cbab63d059c,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-7fb207b2-b36b-4fbe-ae7f-9aca6a18c9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-966fc1e5-07e9-44c5-adbd-a4e4bf26506d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312592897-172.17.0.11-1597042726755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33477,DS-b95231a3-d15e-41a4-bbeb-e5a95444a72a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-4d77a5f0-8628-49f4-bcd3-8b12dc22223d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-22a0af76-efcb-41b4-831e-394cda902f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-4f277109-f098-497b-8dae-1dba39e76342,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-25a569ca-a101-4b53-91dc-d8fe3704b07f,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-12ecaaae-e4fc-4fde-a5b9-3cbab63d059c,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-7fb207b2-b36b-4fbe-ae7f-9aca6a18c9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-966fc1e5-07e9-44c5-adbd-a4e4bf26506d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977700975-172.17.0.11-1597042763638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-80b838d8-ddde-497c-b110-ebfd963f5251,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-dcc9a4b8-cd6b-4beb-a39e-0ca6cc5b08b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-dc7b095e-329f-4cde-a80c-6427078f0949,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-7a8b4f01-e108-40fa-a117-0274ca837bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-e3f23c59-13bc-4a40-96a1-75acf0710937,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-923814a8-e3bc-4085-a954-d5f483edb8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-d0681579-f912-40bb-be3f-35b9445420bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-ac87cec3-ad9e-4da3-9947-318b124f27d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977700975-172.17.0.11-1597042763638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-80b838d8-ddde-497c-b110-ebfd963f5251,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-dcc9a4b8-cd6b-4beb-a39e-0ca6cc5b08b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-dc7b095e-329f-4cde-a80c-6427078f0949,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-7a8b4f01-e108-40fa-a117-0274ca837bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-e3f23c59-13bc-4a40-96a1-75acf0710937,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-923814a8-e3bc-4085-a954-d5f483edb8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-d0681579-f912-40bb-be3f-35b9445420bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-ac87cec3-ad9e-4da3-9947-318b124f27d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929276952-172.17.0.11-1597042866340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44494,DS-13160237-c214-4d7d-87a7-e150425e5666,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-b5fd11d0-7bad-4c98-af2c-952458c4554e,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-b3192aa1-90bb-4e4a-a395-1d65e56e0614,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-53dbf784-3ec5-4585-810d-a40453169a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-fe37d1f3-6a9c-4e27-8f31-1158d4884bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-5690da09-d368-40f7-866d-8b287f212341,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-8df3006f-dfe9-4347-922b-7e4761dd069f,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-061a6a36-b1a2-4a86-bac9-1d3055b721a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929276952-172.17.0.11-1597042866340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44494,DS-13160237-c214-4d7d-87a7-e150425e5666,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-b5fd11d0-7bad-4c98-af2c-952458c4554e,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-b3192aa1-90bb-4e4a-a395-1d65e56e0614,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-53dbf784-3ec5-4585-810d-a40453169a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-fe37d1f3-6a9c-4e27-8f31-1158d4884bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-5690da09-d368-40f7-866d-8b287f212341,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-8df3006f-dfe9-4347-922b-7e4761dd069f,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-061a6a36-b1a2-4a86-bac9-1d3055b721a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843377586-172.17.0.11-1597042973989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42300,DS-1a916426-86b0-40ac-ba0f-005748f5f669,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-bd1baec5-12fa-46aa-9bb1-236db4064f52,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-97cda93f-81f3-47da-a1e4-0155758b9112,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-361ab218-78fc-42c2-aa4f-b783e526a784,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-6d210c83-9980-47dc-bf1a-3aef70629900,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-95f6502a-05a2-4994-afcd-5a63d8d27fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-5dfd60db-169b-496b-81ff-6764abf06922,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-4a5d0cda-3220-4f42-8b5f-a81f35217346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843377586-172.17.0.11-1597042973989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42300,DS-1a916426-86b0-40ac-ba0f-005748f5f669,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-bd1baec5-12fa-46aa-9bb1-236db4064f52,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-97cda93f-81f3-47da-a1e4-0155758b9112,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-361ab218-78fc-42c2-aa4f-b783e526a784,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-6d210c83-9980-47dc-bf1a-3aef70629900,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-95f6502a-05a2-4994-afcd-5a63d8d27fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-5dfd60db-169b-496b-81ff-6764abf06922,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-4a5d0cda-3220-4f42-8b5f-a81f35217346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150269863-172.17.0.11-1597043043343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41736,DS-5c5e7d38-fecb-41ed-a76f-a05ff338afd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-ca7f6a4c-7f2a-478f-a729-609d24005465,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-70bd5da8-ba5d-4a01-8377-ea3242b2832b,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-7b39dec1-7f65-496f-bb79-594b69273b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-09d3b375-47d4-4d8c-a5db-17f1cbf40079,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-50c80fb1-490c-461b-bd6c-2702fbc97977,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-3edbac56-7a72-40a6-9cb4-ade1b8d62958,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-c26241cd-ee8d-42bb-9c5b-52b7eb114ae4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150269863-172.17.0.11-1597043043343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41736,DS-5c5e7d38-fecb-41ed-a76f-a05ff338afd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-ca7f6a4c-7f2a-478f-a729-609d24005465,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-70bd5da8-ba5d-4a01-8377-ea3242b2832b,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-7b39dec1-7f65-496f-bb79-594b69273b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-09d3b375-47d4-4d8c-a5db-17f1cbf40079,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-50c80fb1-490c-461b-bd6c-2702fbc97977,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-3edbac56-7a72-40a6-9cb4-ade1b8d62958,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-c26241cd-ee8d-42bb-9c5b-52b7eb114ae4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689695645-172.17.0.11-1597043162698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-b66d6919-7ef2-4c4a-9e14-65d1f78e3b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-7cd2f3d4-9f1f-4126-8bb7-fbc17e95aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-7b1d42b9-c883-4432-b29a-9ade0f05af39,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-3281eafa-2154-4869-9690-309f1121e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-a8887541-f4f4-4903-9339-b2ee85f8ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-3521f0b4-1f15-41ab-adab-b350789a4151,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-9f13c9e9-5a1c-4243-af5e-8c51b2d53ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-374afbd5-041d-4053-adba-f7da1f087b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689695645-172.17.0.11-1597043162698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-b66d6919-7ef2-4c4a-9e14-65d1f78e3b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-7cd2f3d4-9f1f-4126-8bb7-fbc17e95aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-7b1d42b9-c883-4432-b29a-9ade0f05af39,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-3281eafa-2154-4869-9690-309f1121e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-a8887541-f4f4-4903-9339-b2ee85f8ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-3521f0b4-1f15-41ab-adab-b350789a4151,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-9f13c9e9-5a1c-4243-af5e-8c51b2d53ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-374afbd5-041d-4053-adba-f7da1f087b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027145601-172.17.0.11-1597043272404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-c5940d03-5949-43c4-b20e-6fc3b2d11796,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-bafc9b0f-1315-4318-9524-7635ab67362f,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-da859a72-1023-438b-b43e-45e7bc43dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-2b504408-8463-4fd2-b961-03d40ec1ff07,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-b3d49071-73f3-4658-bc4c-efd60e21c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-df7f878c-105c-468c-af1e-6fc5e515745c,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-46f39ef6-7693-4be4-ae7f-9af0b8b68dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-a90b5169-6cd6-4cf6-ab18-74c6a65e9e91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027145601-172.17.0.11-1597043272404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-c5940d03-5949-43c4-b20e-6fc3b2d11796,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-bafc9b0f-1315-4318-9524-7635ab67362f,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-da859a72-1023-438b-b43e-45e7bc43dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-2b504408-8463-4fd2-b961-03d40ec1ff07,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-b3d49071-73f3-4658-bc4c-efd60e21c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-df7f878c-105c-468c-af1e-6fc5e515745c,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-46f39ef6-7693-4be4-ae7f-9af0b8b68dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-a90b5169-6cd6-4cf6-ab18-74c6a65e9e91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834514244-172.17.0.11-1597043458432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-e40df458-6e34-432f-a418-35bee8a803b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-b8a9317e-ed24-4400-8ddf-e91363488f94,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-3d5992b8-150d-45d1-8429-c7d62b5a011f,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-dde4b916-d589-4c5c-8c80-6376284b5bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-8e7dc4ec-513c-4a4e-b1db-cdff9914c3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-e5312340-638e-4a0a-98fb-f2927b4a6455,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-6811124c-48ea-4566-8399-c3fd3b516773,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-36234932-dae3-425c-9c9f-1b5f969f0d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834514244-172.17.0.11-1597043458432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-e40df458-6e34-432f-a418-35bee8a803b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-b8a9317e-ed24-4400-8ddf-e91363488f94,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-3d5992b8-150d-45d1-8429-c7d62b5a011f,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-dde4b916-d589-4c5c-8c80-6376284b5bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-8e7dc4ec-513c-4a4e-b1db-cdff9914c3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-e5312340-638e-4a0a-98fb-f2927b4a6455,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-6811124c-48ea-4566-8399-c3fd3b516773,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-36234932-dae3-425c-9c9f-1b5f969f0d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268825059-172.17.0.11-1597043537732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44872,DS-d7d12897-0564-41f3-8e78-62e4155ec2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-168b58c4-b4d3-497d-90da-0763ce75d087,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-99a5704a-c5bc-4e13-8255-34b3bf826f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-a99dafd0-8f7a-41be-8655-6dcdfc939ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-e6b37e81-1353-4584-ba83-a50045749e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-b1b705cc-7640-4b0b-94f3-c0b3164bdec8,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-eeb007fe-a945-4baf-aecd-23816c3cfe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-5989b8e9-7afe-47d5-a2c2-fff670b2872d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268825059-172.17.0.11-1597043537732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44872,DS-d7d12897-0564-41f3-8e78-62e4155ec2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-168b58c4-b4d3-497d-90da-0763ce75d087,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-99a5704a-c5bc-4e13-8255-34b3bf826f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-a99dafd0-8f7a-41be-8655-6dcdfc939ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-e6b37e81-1353-4584-ba83-a50045749e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-b1b705cc-7640-4b0b-94f3-c0b3164bdec8,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-eeb007fe-a945-4baf-aecd-23816c3cfe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-5989b8e9-7afe-47d5-a2c2-fff670b2872d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589340053-172.17.0.11-1597043961588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39339,DS-443d1683-2ece-4e21-8620-43ffdd7ae149,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-74c07de0-b584-4d4a-9f97-73a20459ddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-3d824b7d-cd0b-4d85-b74f-35f0b1552139,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-c5e2703a-4b64-48c0-ac72-78dd4b2d5752,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-926d723b-8696-4818-8c62-9d6739d0a6be,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-dad3cdf7-b450-4c5f-8ec6-0c1a45bada49,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-2b7e3d26-5728-49aa-a486-a32a934c4bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-1301a8af-fdb9-4070-a621-ba797f89a31a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589340053-172.17.0.11-1597043961588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39339,DS-443d1683-2ece-4e21-8620-43ffdd7ae149,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-74c07de0-b584-4d4a-9f97-73a20459ddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-3d824b7d-cd0b-4d85-b74f-35f0b1552139,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-c5e2703a-4b64-48c0-ac72-78dd4b2d5752,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-926d723b-8696-4818-8c62-9d6739d0a6be,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-dad3cdf7-b450-4c5f-8ec6-0c1a45bada49,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-2b7e3d26-5728-49aa-a486-a32a934c4bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-1301a8af-fdb9-4070-a621-ba797f89a31a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589734762-172.17.0.11-1597044042993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-cda347a0-d07c-4633-a29d-23515c3c0406,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-be136117-2440-40b0-b703-13db41bbcb46,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-7e78075a-3f35-4e22-be41-49cb80160b49,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-37d3a393-cced-4404-adc2-1b936e47b3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-13eca2bc-80e4-4ea5-a5a4-cd7c139ebb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-04e589ea-3fbd-4ec7-8e91-c68cd86482f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-3d15728e-b058-4c4c-8396-7bf562f27a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-a6faa1da-7689-4bdc-bffa-b163bde204bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589734762-172.17.0.11-1597044042993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-cda347a0-d07c-4633-a29d-23515c3c0406,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-be136117-2440-40b0-b703-13db41bbcb46,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-7e78075a-3f35-4e22-be41-49cb80160b49,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-37d3a393-cced-4404-adc2-1b936e47b3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-13eca2bc-80e4-4ea5-a5a4-cd7c139ebb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-04e589ea-3fbd-4ec7-8e91-c68cd86482f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-3d15728e-b058-4c4c-8396-7bf562f27a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-a6faa1da-7689-4bdc-bffa-b163bde204bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825910738-172.17.0.11-1597044220250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43444,DS-196793a8-23e8-4ae9-b241-7913010e7de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-6d9191e2-aa4a-456a-adab-17780eebb756,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-b24c149c-34cf-47fd-9dc4-d4e7fcfa22af,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-c30326b6-b497-4869-ad3f-fc6d7fd4a8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-f904c71a-932f-43fb-8493-a1c44ff48ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-80ce1cdb-89e8-441d-914e-36483f2fe47d,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-2acdda58-3a74-4d26-8d41-526f55f7d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-915ac835-3b8f-4a45-a38d-6b2778a0f72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825910738-172.17.0.11-1597044220250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43444,DS-196793a8-23e8-4ae9-b241-7913010e7de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-6d9191e2-aa4a-456a-adab-17780eebb756,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-b24c149c-34cf-47fd-9dc4-d4e7fcfa22af,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-c30326b6-b497-4869-ad3f-fc6d7fd4a8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-f904c71a-932f-43fb-8493-a1c44ff48ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-80ce1cdb-89e8-441d-914e-36483f2fe47d,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-2acdda58-3a74-4d26-8d41-526f55f7d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-915ac835-3b8f-4a45-a38d-6b2778a0f72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327118942-172.17.0.11-1597044253108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-e6599b28-c07f-4c4f-8848-aa5b70437a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-7464e979-4a4f-45fc-a37d-c41ebdc0a674,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-a6e4deec-5789-4aa5-8867-5a8b233ecc17,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-0d06ed04-f0c0-4647-ab75-e68b9246a974,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-13bcd80b-7507-475d-84c3-7017c59b3800,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-e3152f3a-4d9b-4f5d-8737-a78946accaef,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-3d997a0b-82c5-4f7c-9174-a95cf5a0077d,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-249ea4f0-1a42-423a-bc40-95e68097f9e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327118942-172.17.0.11-1597044253108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-e6599b28-c07f-4c4f-8848-aa5b70437a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-7464e979-4a4f-45fc-a37d-c41ebdc0a674,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-a6e4deec-5789-4aa5-8867-5a8b233ecc17,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-0d06ed04-f0c0-4647-ab75-e68b9246a974,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-13bcd80b-7507-475d-84c3-7017c59b3800,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-e3152f3a-4d9b-4f5d-8737-a78946accaef,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-3d997a0b-82c5-4f7c-9174-a95cf5a0077d,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-249ea4f0-1a42-423a-bc40-95e68097f9e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511645534-172.17.0.11-1597044296037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38963,DS-c3a16ab7-6acd-42ce-b490-2f92dd5b69e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-61c48e6a-56db-42ac-9a35-06f021f054bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-cb86f596-087d-4a93-8005-ab49b981bf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-211632fd-b3fa-47a3-8584-9ba8bfb8fbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-6f84320d-f562-41a1-9997-16f99ddc5d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-080aa877-663b-4c91-91e3-4ddfde7349a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-cce9db7d-a2b9-469a-b437-566e272c9dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-83542cd9-ada4-4666-b6ea-650792b6fa3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511645534-172.17.0.11-1597044296037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38963,DS-c3a16ab7-6acd-42ce-b490-2f92dd5b69e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-61c48e6a-56db-42ac-9a35-06f021f054bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-cb86f596-087d-4a93-8005-ab49b981bf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-211632fd-b3fa-47a3-8584-9ba8bfb8fbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-6f84320d-f562-41a1-9997-16f99ddc5d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-080aa877-663b-4c91-91e3-4ddfde7349a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-cce9db7d-a2b9-469a-b437-566e272c9dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-83542cd9-ada4-4666-b6ea-650792b6fa3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052577170-172.17.0.11-1597044636459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-28ed793e-e2da-4fb0-9adf-4c1222f7f973,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-d32fc093-0619-4cfb-88be-49dead43b279,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-dbab4385-b0da-45d7-9826-c22bdd8ff2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-7190c47a-34c3-4b31-a3cd-086b8d2952cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-eb7dbe6e-2d27-4871-930c-9c6ecbe5c1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-1ac419c4-b0c3-4563-9401-ece463d90484,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-955eb92b-705a-465a-aa26-5a3016cc50c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-dc766352-91a6-44d3-848e-9f77d7d65fb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052577170-172.17.0.11-1597044636459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-28ed793e-e2da-4fb0-9adf-4c1222f7f973,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-d32fc093-0619-4cfb-88be-49dead43b279,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-dbab4385-b0da-45d7-9826-c22bdd8ff2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-7190c47a-34c3-4b31-a3cd-086b8d2952cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-eb7dbe6e-2d27-4871-930c-9c6ecbe5c1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-1ac419c4-b0c3-4563-9401-ece463d90484,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-955eb92b-705a-465a-aa26-5a3016cc50c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-dc766352-91a6-44d3-848e-9f77d7d65fb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882983253-172.17.0.11-1597044667379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46201,DS-31398c64-5c6e-4374-ae62-a30a1b3e05e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-c8068e8c-36a0-48da-8346-34b8895f3bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-25583b4e-9d3e-4765-8690-50dc7606ae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-85145f47-d127-4795-887a-a2ac23df2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-996cdcb1-223d-4bb2-8f97-d900019c986a,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-ee9ea9c0-b6d4-4ff2-b969-dbfae7c7e995,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-346b7884-6d9b-4f0b-b955-c882fb159881,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-e6974ec2-8f02-4aaf-88c7-2304c98a7813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882983253-172.17.0.11-1597044667379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46201,DS-31398c64-5c6e-4374-ae62-a30a1b3e05e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-c8068e8c-36a0-48da-8346-34b8895f3bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-25583b4e-9d3e-4765-8690-50dc7606ae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-85145f47-d127-4795-887a-a2ac23df2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-996cdcb1-223d-4bb2-8f97-d900019c986a,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-ee9ea9c0-b6d4-4ff2-b969-dbfae7c7e995,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-346b7884-6d9b-4f0b-b955-c882fb159881,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-e6974ec2-8f02-4aaf-88c7-2304c98a7813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143830121-172.17.0.11-1597044707408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-fd8b8be2-a886-4f92-8a97-4b8bd264ed2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-3c65293a-864a-448b-90e8-513c9461869e,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-15b6fe62-faa4-4334-9587-1409c3b91713,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-de108890-86d0-46a8-be8b-8172bb4bfb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-c6449edd-75bb-47d9-8731-871811740294,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-29c3fcf3-4e30-4837-86fb-319bcf07303d,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-98259e83-b403-4211-9d4a-90a0d4c4bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-5400b578-a83f-48ee-9389-16afe394b486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143830121-172.17.0.11-1597044707408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-fd8b8be2-a886-4f92-8a97-4b8bd264ed2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-3c65293a-864a-448b-90e8-513c9461869e,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-15b6fe62-faa4-4334-9587-1409c3b91713,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-de108890-86d0-46a8-be8b-8172bb4bfb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-c6449edd-75bb-47d9-8731-871811740294,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-29c3fcf3-4e30-4837-86fb-319bcf07303d,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-98259e83-b403-4211-9d4a-90a0d4c4bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-5400b578-a83f-48ee-9389-16afe394b486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259547987-172.17.0.11-1597044900037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-4b6958ea-608a-4f8c-8b39-b225c6ac07dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-2eabf03e-8210-44ef-bcb3-f478b5abcc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-37bb32f1-29c8-4798-83f1-b04a47a2d927,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-87f82d23-35d0-4339-b0c5-aaedc34b31c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-73a398b3-1554-4378-84fd-1f680cc59cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-f6e0e594-6f66-46db-a7d4-60fab351b13d,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-b169ec67-d6e1-4e55-b1bf-46fa9809cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-713507a9-6924-4f3c-b01b-a395278bc674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259547987-172.17.0.11-1597044900037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-4b6958ea-608a-4f8c-8b39-b225c6ac07dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-2eabf03e-8210-44ef-bcb3-f478b5abcc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-37bb32f1-29c8-4798-83f1-b04a47a2d927,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-87f82d23-35d0-4339-b0c5-aaedc34b31c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-73a398b3-1554-4378-84fd-1f680cc59cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-f6e0e594-6f66-46db-a7d4-60fab351b13d,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-b169ec67-d6e1-4e55-b1bf-46fa9809cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-713507a9-6924-4f3c-b01b-a395278bc674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090486161-172.17.0.11-1597044932064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-9e5ded73-91c4-49f9-b0ec-1223fba48fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-c660e4a8-a160-4f17-9d69-449880d6073e,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-54c6d996-244b-4683-887c-60c22673e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-7d1e5846-0af7-4cf8-ae44-da40909961f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-24434a79-a0dd-4ed4-990a-0a92d003179f,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-1110a5c3-c7c5-4672-b916-a0e04ffd051e,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-c94e95f2-f9de-47b3-8acc-26b4c1bd3e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-519c4907-3103-4c5f-b571-eec9a9c2a082,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090486161-172.17.0.11-1597044932064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-9e5ded73-91c4-49f9-b0ec-1223fba48fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-c660e4a8-a160-4f17-9d69-449880d6073e,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-54c6d996-244b-4683-887c-60c22673e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-7d1e5846-0af7-4cf8-ae44-da40909961f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-24434a79-a0dd-4ed4-990a-0a92d003179f,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-1110a5c3-c7c5-4672-b916-a0e04ffd051e,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-c94e95f2-f9de-47b3-8acc-26b4c1bd3e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-519c4907-3103-4c5f-b571-eec9a9c2a082,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282835114-172.17.0.11-1597045004403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37555,DS-6f82ac7e-0994-4548-b711-e1e99f714abe,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-a01b8bf4-0b49-43ae-9c09-725187598bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-090ff83d-74de-4fa2-9a58-08700c145330,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-68d6ed35-704c-4dd5-bd5c-ebca21e10a60,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-914e76ac-4dea-4449-b8eb-b2e890e88fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-2ca853f8-b09f-4b7b-9e27-f9e2b373c028,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-32ab6754-358e-495a-af93-269e8b526dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-35b7bd8a-57d3-4c6f-9be4-3a74f88a1479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282835114-172.17.0.11-1597045004403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37555,DS-6f82ac7e-0994-4548-b711-e1e99f714abe,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-a01b8bf4-0b49-43ae-9c09-725187598bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-090ff83d-74de-4fa2-9a58-08700c145330,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-68d6ed35-704c-4dd5-bd5c-ebca21e10a60,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-914e76ac-4dea-4449-b8eb-b2e890e88fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-2ca853f8-b09f-4b7b-9e27-f9e2b373c028,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-32ab6754-358e-495a-af93-269e8b526dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-35b7bd8a-57d3-4c6f-9be4-3a74f88a1479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246893689-172.17.0.11-1597045690721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-09c5ad77-ee02-4755-be66-aac3175d981e,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-99d4cf53-2f4f-4c65-bf74-7c145048da17,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-5f2f1971-5a26-4487-90c2-7746d991405b,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-15fc5953-2971-4580-87bd-4b975cbf56dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-d82f1097-d59a-4ba9-8854-02d309cba356,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-d8787293-bcb5-4c39-a12c-9c02e9f89e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-70612ce9-1254-4df8-bbfb-419f6607180a,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-cf2d5630-107a-4720-a1d0-617ff911a785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246893689-172.17.0.11-1597045690721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-09c5ad77-ee02-4755-be66-aac3175d981e,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-99d4cf53-2f4f-4c65-bf74-7c145048da17,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-5f2f1971-5a26-4487-90c2-7746d991405b,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-15fc5953-2971-4580-87bd-4b975cbf56dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-d82f1097-d59a-4ba9-8854-02d309cba356,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-d8787293-bcb5-4c39-a12c-9c02e9f89e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-70612ce9-1254-4df8-bbfb-419f6607180a,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-cf2d5630-107a-4720-a1d0-617ff911a785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381489135-172.17.0.11-1597045727174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41017,DS-95ad9182-4df7-4f20-9c07-891e8f620532,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-7659165d-4ec4-4f1c-b7b9-4003750e5250,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-af7f0e71-23b3-49aa-961d-3496a5310fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-784c1467-77f5-460b-8bfd-5c56663471b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-da781b6a-9d31-4ce6-8f1e-085f5fba6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-dd8745d7-741b-4092-be18-34cb054972b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-007324cb-968f-486e-ba2b-2070b88fcf78,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-1e2a5c9e-2d36-464f-a634-f01c4e6811af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381489135-172.17.0.11-1597045727174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41017,DS-95ad9182-4df7-4f20-9c07-891e8f620532,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-7659165d-4ec4-4f1c-b7b9-4003750e5250,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-af7f0e71-23b3-49aa-961d-3496a5310fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-784c1467-77f5-460b-8bfd-5c56663471b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-da781b6a-9d31-4ce6-8f1e-085f5fba6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-dd8745d7-741b-4092-be18-34cb054972b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-007324cb-968f-486e-ba2b-2070b88fcf78,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-1e2a5c9e-2d36-464f-a634-f01c4e6811af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387144858-172.17.0.11-1597045804639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-37cee9f2-1e4d-49db-b677-3accfca5c570,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-abbea91a-6744-4f00-98dd-03eac10d50ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-4528bf2f-38ed-420e-96ad-b05968b90f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-0fe686dc-1e67-40cf-9b72-bdc3f99c19dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-b3ee51bc-6af2-46f4-9532-87d99d54ae55,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-7b255fa0-c63f-49b7-8b78-6047195b8fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-99e6ec44-f7db-4317-907e-7791d22f850e,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-d1053591-c2e9-4e05-a73a-516d1ca71f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387144858-172.17.0.11-1597045804639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-37cee9f2-1e4d-49db-b677-3accfca5c570,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-abbea91a-6744-4f00-98dd-03eac10d50ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-4528bf2f-38ed-420e-96ad-b05968b90f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-0fe686dc-1e67-40cf-9b72-bdc3f99c19dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-b3ee51bc-6af2-46f4-9532-87d99d54ae55,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-7b255fa0-c63f-49b7-8b78-6047195b8fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-99e6ec44-f7db-4317-907e-7791d22f850e,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-d1053591-c2e9-4e05-a73a-516d1ca71f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5546
