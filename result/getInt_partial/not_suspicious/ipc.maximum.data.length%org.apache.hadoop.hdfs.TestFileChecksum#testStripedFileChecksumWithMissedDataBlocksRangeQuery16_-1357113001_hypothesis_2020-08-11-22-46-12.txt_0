reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273542041-172.17.0.14-1597185987814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-71529f06-804e-4f4e-af66-395b2a823c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-ec005488-bc14-442e-8514-174712def92d,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-d4571a94-6b3f-4be6-9515-87b0627d2d55,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-445c3c79-a8c1-4da6-8f60-282da7127116,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-66e4ab80-a066-40b8-a56c-5f92ef848502,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-6b7edd82-77bd-4b66-a903-f8a4f6e9ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-2fcc970a-0113-4f20-8b54-c531cc4e4cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-06cf03b1-2b17-43ee-8544-acd7c7950793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273542041-172.17.0.14-1597185987814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-71529f06-804e-4f4e-af66-395b2a823c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-ec005488-bc14-442e-8514-174712def92d,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-d4571a94-6b3f-4be6-9515-87b0627d2d55,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-445c3c79-a8c1-4da6-8f60-282da7127116,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-66e4ab80-a066-40b8-a56c-5f92ef848502,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-6b7edd82-77bd-4b66-a903-f8a4f6e9ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-2fcc970a-0113-4f20-8b54-c531cc4e4cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-06cf03b1-2b17-43ee-8544-acd7c7950793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222615384-172.17.0.14-1597186146135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39562,DS-95ed6a43-8f08-415e-8d99-6375a6136d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-1bfb97f1-b003-48e5-a9f7-ae8e1e5843c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-dd20ac6b-8499-4da5-906c-1d330f79c3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-5a479a16-83a5-4f70-a5e4-e85c8e3aa995,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-35c0caa9-3a8c-404d-8ac2-df89a339d4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-dd973b91-7219-4f83-bbfe-86d64658bec5,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-0a176460-f98c-4c42-ab07-ac8834c67e97,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-733aad00-a7ac-46c2-8ec0-b06a1f5d7538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222615384-172.17.0.14-1597186146135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39562,DS-95ed6a43-8f08-415e-8d99-6375a6136d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-1bfb97f1-b003-48e5-a9f7-ae8e1e5843c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-dd20ac6b-8499-4da5-906c-1d330f79c3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-5a479a16-83a5-4f70-a5e4-e85c8e3aa995,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-35c0caa9-3a8c-404d-8ac2-df89a339d4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-dd973b91-7219-4f83-bbfe-86d64658bec5,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-0a176460-f98c-4c42-ab07-ac8834c67e97,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-733aad00-a7ac-46c2-8ec0-b06a1f5d7538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466556098-172.17.0.14-1597186503372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-3b02327c-348e-48b7-8d86-0fe5659f9bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-4fb6bcbc-20f2-4c51-aeaf-42bfc015e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-36d10db4-7591-4727-b450-9de477abaac8,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-d6a16715-5b47-48f5-8e05-bd72a5180248,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-8d4c97b5-d66d-42d1-9fb6-655d98b2c248,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-b7d5a885-9de6-45f1-91cd-c04f33ce2736,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-c73ad075-a2fb-43c7-b186-6570dff5956b,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-7cc480e5-47f5-4788-ab8a-3acd826a25ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466556098-172.17.0.14-1597186503372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-3b02327c-348e-48b7-8d86-0fe5659f9bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-4fb6bcbc-20f2-4c51-aeaf-42bfc015e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-36d10db4-7591-4727-b450-9de477abaac8,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-d6a16715-5b47-48f5-8e05-bd72a5180248,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-8d4c97b5-d66d-42d1-9fb6-655d98b2c248,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-b7d5a885-9de6-45f1-91cd-c04f33ce2736,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-c73ad075-a2fb-43c7-b186-6570dff5956b,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-7cc480e5-47f5-4788-ab8a-3acd826a25ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811279032-172.17.0.14-1597186681638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43446,DS-1c3b39c6-7c7d-44fe-ac84-20bb18049ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-13ee68a3-c151-402a-949e-de80dd1c806f,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-f4fec38a-bb80-448c-aa47-a8c71cc38c20,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-7402cdbc-731c-4789-8ac2-e39c18955b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-4c6b37ec-9a56-4b81-b836-1b8cd4ae2171,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-a6c46faa-8dac-42bb-bfb7-67486e05c544,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-6d720378-4cf8-42c3-a27c-96785bf22f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-92068734-c236-4439-ac06-dabc50fa614d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811279032-172.17.0.14-1597186681638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43446,DS-1c3b39c6-7c7d-44fe-ac84-20bb18049ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-13ee68a3-c151-402a-949e-de80dd1c806f,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-f4fec38a-bb80-448c-aa47-a8c71cc38c20,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-7402cdbc-731c-4789-8ac2-e39c18955b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-4c6b37ec-9a56-4b81-b836-1b8cd4ae2171,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-a6c46faa-8dac-42bb-bfb7-67486e05c544,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-6d720378-4cf8-42c3-a27c-96785bf22f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-92068734-c236-4439-ac06-dabc50fa614d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256315221-172.17.0.14-1597186975575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37352,DS-28bfb763-ab0a-4f4e-91e7-e30e3776b52a,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-81e48d34-de2b-4e71-97dd-e6b6c2258696,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-3affc314-124b-4f7b-b1bd-40f93a1681c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-5fe0d557-d8fc-4648-81c4-e2e474ea62de,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-0e4c1b05-4715-422d-ab3e-f65c90dcd35a,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-d54add17-6d0a-43f0-be18-7f084dc926e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-48865f72-2708-4b3d-b7b9-b5a9b4e86a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-4d24bf7a-ff05-47e7-a27e-aa5a91e246e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256315221-172.17.0.14-1597186975575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37352,DS-28bfb763-ab0a-4f4e-91e7-e30e3776b52a,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-81e48d34-de2b-4e71-97dd-e6b6c2258696,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-3affc314-124b-4f7b-b1bd-40f93a1681c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-5fe0d557-d8fc-4648-81c4-e2e474ea62de,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-0e4c1b05-4715-422d-ab3e-f65c90dcd35a,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-d54add17-6d0a-43f0-be18-7f084dc926e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-48865f72-2708-4b3d-b7b9-b5a9b4e86a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-4d24bf7a-ff05-47e7-a27e-aa5a91e246e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066827386-172.17.0.14-1597187094532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40084,DS-623f1ba2-0d14-4b1a-a89d-07f0cfcc4ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-ae9748b6-7343-4cbc-a45d-bda36a146fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-86299e58-21bd-461e-bb7e-9792f536527a,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-d5f74c49-a2db-4308-a980-e68d135fdbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-3070c896-6059-45ee-8b6c-5d3b0383dc64,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-8204431f-499a-41f9-ab80-5722676b644b,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-949bcd46-9043-497f-a6b5-1a39d208b54a,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-33c82f59-8c96-43e0-aa8d-99c8297f5c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066827386-172.17.0.14-1597187094532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40084,DS-623f1ba2-0d14-4b1a-a89d-07f0cfcc4ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-ae9748b6-7343-4cbc-a45d-bda36a146fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-86299e58-21bd-461e-bb7e-9792f536527a,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-d5f74c49-a2db-4308-a980-e68d135fdbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-3070c896-6059-45ee-8b6c-5d3b0383dc64,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-8204431f-499a-41f9-ab80-5722676b644b,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-949bcd46-9043-497f-a6b5-1a39d208b54a,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-33c82f59-8c96-43e0-aa8d-99c8297f5c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310577226-172.17.0.14-1597187282300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-52c4b2f0-927f-4c3b-b89a-af7d07a0c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-0a29b847-e99c-47d2-b1e3-edeba63e3b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-48c87152-78e0-4645-880c-13985b2ab6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4e377e80-df9f-41bd-9ea9-d599d4278bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-61eb520a-7eed-42f6-99e8-592582c73035,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-88c91648-7f15-4eb6-9f75-2e2951e1f593,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-75a25e34-eed4-4b8d-b9bf-35524f17791a,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-80c9e99a-4ca1-46f5-9af6-67b96c12566e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310577226-172.17.0.14-1597187282300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-52c4b2f0-927f-4c3b-b89a-af7d07a0c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-0a29b847-e99c-47d2-b1e3-edeba63e3b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-48c87152-78e0-4645-880c-13985b2ab6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4e377e80-df9f-41bd-9ea9-d599d4278bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-61eb520a-7eed-42f6-99e8-592582c73035,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-88c91648-7f15-4eb6-9f75-2e2951e1f593,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-75a25e34-eed4-4b8d-b9bf-35524f17791a,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-80c9e99a-4ca1-46f5-9af6-67b96c12566e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359159504-172.17.0.14-1597187317291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38055,DS-490725a6-e3dc-4ba1-8941-8c448a704307,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-2be8e3f0-427c-4627-a680-0ee7029e3707,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-313cff9e-e55c-4f3a-aaf7-eee3508637f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-dbf11a54-ff68-4ada-b955-24ff62cbf127,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-68e55dc2-dc43-439b-9ddb-047a496bb019,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-2d9bed0b-f0ca-4e0c-ba61-78c8784e1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-91a25566-a890-4c6b-9036-e3f7aecac1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-cb037e95-f599-4b54-a044-04f97d579f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359159504-172.17.0.14-1597187317291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38055,DS-490725a6-e3dc-4ba1-8941-8c448a704307,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-2be8e3f0-427c-4627-a680-0ee7029e3707,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-313cff9e-e55c-4f3a-aaf7-eee3508637f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-dbf11a54-ff68-4ada-b955-24ff62cbf127,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-68e55dc2-dc43-439b-9ddb-047a496bb019,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-2d9bed0b-f0ca-4e0c-ba61-78c8784e1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-91a25566-a890-4c6b-9036-e3f7aecac1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-cb037e95-f599-4b54-a044-04f97d579f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540408167-172.17.0.14-1597187515171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-60681758-6289-4043-b0a7-86b1652c145f,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-bb9e9cf8-9343-4786-b1f5-ab06c8eaaadd,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-d5efdae9-d836-4c18-a303-0e427bd5ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-cdcfb3ef-f120-444c-89ac-9a638df79da2,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-24713dd7-74b3-41a7-a8df-d07bea501285,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-359aa88b-bb36-429e-8dcc-67be75915a09,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-5055290b-6b1d-4916-b4a8-0ba36a649de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-81eb7cf8-a163-436c-8a46-b852accef259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540408167-172.17.0.14-1597187515171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-60681758-6289-4043-b0a7-86b1652c145f,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-bb9e9cf8-9343-4786-b1f5-ab06c8eaaadd,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-d5efdae9-d836-4c18-a303-0e427bd5ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-cdcfb3ef-f120-444c-89ac-9a638df79da2,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-24713dd7-74b3-41a7-a8df-d07bea501285,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-359aa88b-bb36-429e-8dcc-67be75915a09,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-5055290b-6b1d-4916-b4a8-0ba36a649de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-81eb7cf8-a163-436c-8a46-b852accef259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070741163-172.17.0.14-1597188301663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-f6b4f815-6db6-48a8-a7f6-83e28d2e62dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-79fb1d4f-da80-40ee-88ea-7aa9ca16e44f,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-e39af003-a738-4d5a-b968-6a5c511cfbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-09ac5662-91b3-43f5-8e5d-40470c5fa9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-a81c652d-e6df-46ad-8017-1f88a1962223,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-d58f4292-78c7-4e4a-bea3-5ea05a983c48,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-027563d1-40da-4f73-9401-bd212239ef61,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-daf81ef9-2c38-4530-8fc8-9065f5e4373d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070741163-172.17.0.14-1597188301663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-f6b4f815-6db6-48a8-a7f6-83e28d2e62dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-79fb1d4f-da80-40ee-88ea-7aa9ca16e44f,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-e39af003-a738-4d5a-b968-6a5c511cfbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-09ac5662-91b3-43f5-8e5d-40470c5fa9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-a81c652d-e6df-46ad-8017-1f88a1962223,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-d58f4292-78c7-4e4a-bea3-5ea05a983c48,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-027563d1-40da-4f73-9401-bd212239ef61,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-daf81ef9-2c38-4530-8fc8-9065f5e4373d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989093334-172.17.0.14-1597188470014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43038,DS-47592421-fc87-4216-be9e-a17b45b12121,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-fe616b2f-55ea-46d3-857e-5cd70ad797ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-41cd2e6b-ea5d-4de9-b970-9c80c4a3457a,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-c2111020-559a-47fa-b8ad-914d25cee265,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-8b5e806c-2bab-438b-824f-0667cb60e53a,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-ac497f61-6f48-486f-96c4-e51d55e29b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-46135f1f-ff0f-4c94-8445-31e5442a2d19,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-e5729b58-fc6d-486c-bdd1-d5a4f11989e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989093334-172.17.0.14-1597188470014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43038,DS-47592421-fc87-4216-be9e-a17b45b12121,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-fe616b2f-55ea-46d3-857e-5cd70ad797ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-41cd2e6b-ea5d-4de9-b970-9c80c4a3457a,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-c2111020-559a-47fa-b8ad-914d25cee265,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-8b5e806c-2bab-438b-824f-0667cb60e53a,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-ac497f61-6f48-486f-96c4-e51d55e29b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-46135f1f-ff0f-4c94-8445-31e5442a2d19,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-e5729b58-fc6d-486c-bdd1-d5a4f11989e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298664908-172.17.0.14-1597188505363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35361,DS-0ce0c234-2790-455b-900e-362ce01c8126,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-4dab8164-f33f-4a9a-be79-5134194ff6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-ec271074-8b4f-43f1-9659-b88c9af1ac3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-73bb5fac-bf20-400e-aa52-55e0d1be6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-176ad04c-950b-471b-ae90-1b3930293e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-d5077c37-435a-4a6e-b8e9-7a641f15d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-833f113d-54b4-405c-bcb2-ae5ccfe15e07,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-d853cfbb-2bcb-41ea-af70-19f4bfa30d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298664908-172.17.0.14-1597188505363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35361,DS-0ce0c234-2790-455b-900e-362ce01c8126,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-4dab8164-f33f-4a9a-be79-5134194ff6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-ec271074-8b4f-43f1-9659-b88c9af1ac3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-73bb5fac-bf20-400e-aa52-55e0d1be6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-176ad04c-950b-471b-ae90-1b3930293e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-d5077c37-435a-4a6e-b8e9-7a641f15d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-833f113d-54b4-405c-bcb2-ae5ccfe15e07,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-d853cfbb-2bcb-41ea-af70-19f4bfa30d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680940008-172.17.0.14-1597188539382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37350,DS-df90bc2a-e301-4060-a4d4-0945f2c9c1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-a522c881-44cb-47c3-b287-161b93cb906b,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-cf4f7047-51d3-4a4f-baca-089676ffe55e,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-6f788457-0937-41bb-81fd-7c0962c9620d,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-e8a84da0-1af2-4cd4-a22d-aec6ca42cfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-932922a9-fb49-4a90-b1d8-b1671600931d,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-d3773015-3d63-4376-8b44-e9a238742a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-82e53767-fa15-4eb5-be2f-8f8214615f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680940008-172.17.0.14-1597188539382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37350,DS-df90bc2a-e301-4060-a4d4-0945f2c9c1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-a522c881-44cb-47c3-b287-161b93cb906b,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-cf4f7047-51d3-4a4f-baca-089676ffe55e,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-6f788457-0937-41bb-81fd-7c0962c9620d,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-e8a84da0-1af2-4cd4-a22d-aec6ca42cfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-932922a9-fb49-4a90-b1d8-b1671600931d,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-d3773015-3d63-4376-8b44-e9a238742a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-82e53767-fa15-4eb5-be2f-8f8214615f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186556280-172.17.0.14-1597188609494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42707,DS-996ba12d-c8c6-4ba6-8511-0dea8bb40058,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-b953255d-ba06-491f-858c-1824cb79bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-8ea1fc63-6d7b-4516-82d5-bdbf89371368,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-b414ce0b-a3e2-4f4f-a7be-23a57ee6ea0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-968fbca2-8b06-4fbc-be32-2f22e073aafa,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-b7fd7d04-c0c5-4487-86fe-76a7d3a8f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-10106079-d534-40bb-b442-c293b10b2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-c16de53a-f8f7-4477-872b-688d3a52b020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186556280-172.17.0.14-1597188609494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42707,DS-996ba12d-c8c6-4ba6-8511-0dea8bb40058,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-b953255d-ba06-491f-858c-1824cb79bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-8ea1fc63-6d7b-4516-82d5-bdbf89371368,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-b414ce0b-a3e2-4f4f-a7be-23a57ee6ea0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-968fbca2-8b06-4fbc-be32-2f22e073aafa,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-b7fd7d04-c0c5-4487-86fe-76a7d3a8f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-10106079-d534-40bb-b442-c293b10b2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-c16de53a-f8f7-4477-872b-688d3a52b020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934808262-172.17.0.14-1597188764674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43483,DS-030d44f6-0578-4f88-b739-82d42ae54d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-114e1a83-f807-4d87-90cd-656e89842cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-4e666c51-ddef-451a-a264-99cb7130f59e,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-8ab58f39-85cd-4132-81cc-87effdaf9757,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-4df6c9f2-b21c-4218-ae5f-2a6b86d455c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-72d2c7e9-7372-4c61-8965-b58edc6ae997,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-46897f35-2734-475f-9474-fe72f84cf830,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-e0b04812-64c5-496e-bcf2-bfc435dcf882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934808262-172.17.0.14-1597188764674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43483,DS-030d44f6-0578-4f88-b739-82d42ae54d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-114e1a83-f807-4d87-90cd-656e89842cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-4e666c51-ddef-451a-a264-99cb7130f59e,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-8ab58f39-85cd-4132-81cc-87effdaf9757,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-4df6c9f2-b21c-4218-ae5f-2a6b86d455c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-72d2c7e9-7372-4c61-8965-b58edc6ae997,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-46897f35-2734-475f-9474-fe72f84cf830,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-e0b04812-64c5-496e-bcf2-bfc435dcf882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030825153-172.17.0.14-1597188928438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39829,DS-5acc5401-056c-4686-a405-f22a1601f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-a8dd3d30-4f00-47cd-8e44-6e7949ea55d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-618c8303-6f6d-40f9-ba41-8ba225ddfd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-d5886e42-922b-4ec3-950e-e429e77e9cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-08b2e933-669f-4889-9567-8bdf3f92b356,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-fca84f79-409f-411d-b92f-097a4bb12028,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-4e9cc359-1b87-45c1-bbe8-24051f43081b,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-9adbe449-c491-460a-b04b-2e6871986a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030825153-172.17.0.14-1597188928438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39829,DS-5acc5401-056c-4686-a405-f22a1601f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-a8dd3d30-4f00-47cd-8e44-6e7949ea55d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-618c8303-6f6d-40f9-ba41-8ba225ddfd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-d5886e42-922b-4ec3-950e-e429e77e9cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-08b2e933-669f-4889-9567-8bdf3f92b356,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-fca84f79-409f-411d-b92f-097a4bb12028,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-4e9cc359-1b87-45c1-bbe8-24051f43081b,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-9adbe449-c491-460a-b04b-2e6871986a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059414839-172.17.0.14-1597188998999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35824,DS-1326c83c-acc6-4949-b87e-140bbe83cbef,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-93fedb91-b14d-4df5-bf2f-2d94cec119f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-ce9d0331-9180-40eb-a667-088767c4ecf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-1cf31c6d-4afb-4747-807e-37e456476e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-dd8b5711-5e6c-4b44-852c-9d06b4853ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-9598b216-72d2-4d15-be2e-c932829ebad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-1b23d0bc-ce8b-46a8-9dee-ef3e1078aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-143916fb-34f6-4989-8252-d2c7765cfdfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059414839-172.17.0.14-1597188998999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35824,DS-1326c83c-acc6-4949-b87e-140bbe83cbef,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-93fedb91-b14d-4df5-bf2f-2d94cec119f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-ce9d0331-9180-40eb-a667-088767c4ecf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-1cf31c6d-4afb-4747-807e-37e456476e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-dd8b5711-5e6c-4b44-852c-9d06b4853ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-9598b216-72d2-4d15-be2e-c932829ebad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-1b23d0bc-ce8b-46a8-9dee-ef3e1078aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-143916fb-34f6-4989-8252-d2c7765cfdfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699475831-172.17.0.14-1597189272109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-856e8caa-f312-402c-b0ef-57abe38a939d,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-6b62677b-fb94-4096-8a03-67df9d6ef01e,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-c85a9921-73f9-4164-8f2e-e12b7ecced7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-2dc047e3-f708-4d75-943c-0d3ccfcf88e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-dc1422c4-cf2b-4543-9201-abc51f2addb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-ca076384-fd0a-42f8-aef6-a06f79440e52,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-38d4e095-a24a-4c23-8ef0-e74006b681b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-2ad046b6-18d4-4ed4-942e-b9d228b70b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699475831-172.17.0.14-1597189272109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-856e8caa-f312-402c-b0ef-57abe38a939d,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-6b62677b-fb94-4096-8a03-67df9d6ef01e,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-c85a9921-73f9-4164-8f2e-e12b7ecced7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-2dc047e3-f708-4d75-943c-0d3ccfcf88e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-dc1422c4-cf2b-4543-9201-abc51f2addb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-ca076384-fd0a-42f8-aef6-a06f79440e52,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-38d4e095-a24a-4c23-8ef0-e74006b681b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-2ad046b6-18d4-4ed4-942e-b9d228b70b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35310863-172.17.0.14-1597189361065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37206,DS-41b42c7a-b6db-41f5-ab55-16c8f04b6780,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-0a9bfaa7-7469-423d-8af4-620c09ab4fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-b79b1af3-08d7-40ac-82b0-a32c2a95c181,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-e5152a71-e2ff-4b2f-89d3-bc991482b249,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-e20f2959-6e45-4599-822d-b010233b321e,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-e95ebff2-d521-4be1-bc02-d3f70ed47d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-b53831a6-207c-4cb5-bb8a-c665177e10a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-a36bdea9-a22a-411c-9a74-ac0a2ce0d5a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35310863-172.17.0.14-1597189361065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37206,DS-41b42c7a-b6db-41f5-ab55-16c8f04b6780,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-0a9bfaa7-7469-423d-8af4-620c09ab4fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-b79b1af3-08d7-40ac-82b0-a32c2a95c181,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-e5152a71-e2ff-4b2f-89d3-bc991482b249,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-e20f2959-6e45-4599-822d-b010233b321e,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-e95ebff2-d521-4be1-bc02-d3f70ed47d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-b53831a6-207c-4cb5-bb8a-c665177e10a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-a36bdea9-a22a-411c-9a74-ac0a2ce0d5a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-856391440-172.17.0.14-1597189574812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-764ce791-e497-413f-893a-8b524f73a516,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-ac50f792-e806-438e-a857-2215de70aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-4abf06eb-79e5-453d-8a94-327586391e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-0db6d7f8-4e9e-4bb4-9fee-3cce21ccc1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-55a8b29e-f269-4aef-b037-29ba5cbbad18,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-d302eb25-1d5c-46fb-95df-c039a3fac8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-a9c310e3-8a28-4e1f-9ba7-b2027f5aee01,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-3b940296-96ea-4706-8cba-511284545f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-856391440-172.17.0.14-1597189574812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-764ce791-e497-413f-893a-8b524f73a516,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-ac50f792-e806-438e-a857-2215de70aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-4abf06eb-79e5-453d-8a94-327586391e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-0db6d7f8-4e9e-4bb4-9fee-3cce21ccc1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-55a8b29e-f269-4aef-b037-29ba5cbbad18,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-d302eb25-1d5c-46fb-95df-c039a3fac8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-a9c310e3-8a28-4e1f-9ba7-b2027f5aee01,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-3b940296-96ea-4706-8cba-511284545f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702832142-172.17.0.14-1597189899478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-1c5602a1-1553-450c-9a4b-4f282a40b404,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-0f47332b-e33f-49bb-8ab3-4d62d7e8227e,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-5fe6e099-258f-49ab-99f2-a463f5f7e571,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-ba9067d8-35ad-44cf-b836-4ddc3a76058c,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-bcdfebb5-32ab-4d14-85a5-74e87bc20b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-1353992c-5889-41ca-8fe8-96d5ee840f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-2c8461e8-7c08-4687-b99b-03020211f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-71df7d7d-aec3-46a7-ae55-62397bd4724f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702832142-172.17.0.14-1597189899478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-1c5602a1-1553-450c-9a4b-4f282a40b404,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-0f47332b-e33f-49bb-8ab3-4d62d7e8227e,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-5fe6e099-258f-49ab-99f2-a463f5f7e571,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-ba9067d8-35ad-44cf-b836-4ddc3a76058c,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-bcdfebb5-32ab-4d14-85a5-74e87bc20b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-1353992c-5889-41ca-8fe8-96d5ee840f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-2c8461e8-7c08-4687-b99b-03020211f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-71df7d7d-aec3-46a7-ae55-62397bd4724f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475313721-172.17.0.14-1597190191782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45772,DS-2795af5c-a1dc-4d5e-bb87-09fe4b6afbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-d9c50fe4-9f8e-4c79-a553-33c335cfb5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-368205ad-ac7f-452a-8afa-ae1e1270e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-cb1f3158-ec19-4b5c-bbd4-395e64ad9537,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-e3c84b3d-d7c1-4236-9567-77ae9338421e,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-dec374d6-54fa-41db-9d11-1d7ba43cd57c,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-cfe1fa04-8ed8-4ce9-8013-82818be5786a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-c987ad24-0f58-483d-aeb9-2b4aa03338af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475313721-172.17.0.14-1597190191782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45772,DS-2795af5c-a1dc-4d5e-bb87-09fe4b6afbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-d9c50fe4-9f8e-4c79-a553-33c335cfb5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-368205ad-ac7f-452a-8afa-ae1e1270e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-cb1f3158-ec19-4b5c-bbd4-395e64ad9537,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-e3c84b3d-d7c1-4236-9567-77ae9338421e,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-dec374d6-54fa-41db-9d11-1d7ba43cd57c,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-cfe1fa04-8ed8-4ce9-8013-82818be5786a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-c987ad24-0f58-483d-aeb9-2b4aa03338af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4785
