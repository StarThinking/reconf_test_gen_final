reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352779471-172.17.0.2-1597150849410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45222,DS-3f4e86e1-1012-4505-a04f-44a63353cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-e8ead17a-1034-464c-ac9c-a88f93aa7bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-04dcb170-f9f4-481b-91cb-b42568c4986e,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-eb4f0e1e-1c54-4767-9254-64cc72e15aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-dac2ed0c-8091-483e-b588-a42bbc89f156,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-b413e009-6d55-41cf-9d5e-262ce21ed195,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-66a92958-c068-4613-847b-25ed12b6d57c,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-0f104892-b52e-48a9-b7c0-c56b0a3858d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352779471-172.17.0.2-1597150849410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45222,DS-3f4e86e1-1012-4505-a04f-44a63353cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-e8ead17a-1034-464c-ac9c-a88f93aa7bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-04dcb170-f9f4-481b-91cb-b42568c4986e,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-eb4f0e1e-1c54-4767-9254-64cc72e15aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-dac2ed0c-8091-483e-b588-a42bbc89f156,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-b413e009-6d55-41cf-9d5e-262ce21ed195,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-66a92958-c068-4613-847b-25ed12b6d57c,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-0f104892-b52e-48a9-b7c0-c56b0a3858d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334679975-172.17.0.2-1597151366500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33872,DS-6b3c608a-0ed0-4eed-972f-4687cbf123ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-548ea379-1226-4161-ac5c-eb465ba905c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-18e2eaad-3363-48ac-8521-a3cd55baf820,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-d6d38c85-b072-433d-a869-6d6ccfc654d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-ddf4dd12-2b65-40c2-87c5-3519618687ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-cb7eac97-0a96-4b17-a12a-56b36d63b512,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-3d43a526-cc0c-45d1-ad5f-7a89f77cdd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-ebd1b3bd-07b9-4067-91c3-82b20464007d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334679975-172.17.0.2-1597151366500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33872,DS-6b3c608a-0ed0-4eed-972f-4687cbf123ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-548ea379-1226-4161-ac5c-eb465ba905c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-18e2eaad-3363-48ac-8521-a3cd55baf820,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-d6d38c85-b072-433d-a869-6d6ccfc654d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-ddf4dd12-2b65-40c2-87c5-3519618687ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-cb7eac97-0a96-4b17-a12a-56b36d63b512,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-3d43a526-cc0c-45d1-ad5f-7a89f77cdd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-ebd1b3bd-07b9-4067-91c3-82b20464007d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420982547-172.17.0.2-1597153561719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-6d074d22-3491-47b3-8b9c-9d6b805b95be,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-cda97bd3-ee10-4c02-952e-df9515b62081,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-27176afc-a39c-40e6-87d2-49d976629a41,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-27a42116-116d-4491-a854-69b08b5c2a31,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-ba3697bf-852c-47ad-a082-2f29308bc940,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-692de409-3d34-4d54-9fcb-cf303860205f,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-585166b9-2dc9-470f-ba20-c8e6df78bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-4a1909e8-abbb-4572-88ba-d743fce48005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420982547-172.17.0.2-1597153561719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-6d074d22-3491-47b3-8b9c-9d6b805b95be,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-cda97bd3-ee10-4c02-952e-df9515b62081,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-27176afc-a39c-40e6-87d2-49d976629a41,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-27a42116-116d-4491-a854-69b08b5c2a31,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-ba3697bf-852c-47ad-a082-2f29308bc940,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-692de409-3d34-4d54-9fcb-cf303860205f,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-585166b9-2dc9-470f-ba20-c8e6df78bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-4a1909e8-abbb-4572-88ba-d743fce48005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142734678-172.17.0.2-1597154058305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-4962120b-00c3-47e0-8ded-86dd625ab6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-25666e9e-0ac1-461f-9b27-0f1b5de1c5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-c07bf05c-0541-4374-8b91-1c17a49c7c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-3c8ba9ea-f599-4abd-a858-0a9938157d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-91d4e29f-05c4-4d32-a674-d71f07bc521f,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-e7aaef58-312f-4e6b-aed5-e1b9064d0545,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-36d4982a-69ed-4b66-94a2-9031f625bf42,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-0ec6b8aa-97a2-4234-ba50-91289503dd53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142734678-172.17.0.2-1597154058305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-4962120b-00c3-47e0-8ded-86dd625ab6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-25666e9e-0ac1-461f-9b27-0f1b5de1c5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-c07bf05c-0541-4374-8b91-1c17a49c7c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-3c8ba9ea-f599-4abd-a858-0a9938157d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-91d4e29f-05c4-4d32-a674-d71f07bc521f,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-e7aaef58-312f-4e6b-aed5-e1b9064d0545,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-36d4982a-69ed-4b66-94a2-9031f625bf42,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-0ec6b8aa-97a2-4234-ba50-91289503dd53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874849497-172.17.0.2-1597154232354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34829,DS-822bb92f-8007-4de1-8580-5eecfa714f47,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-b87439a4-f7da-4d46-9496-6153eddcdf31,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-5a3953ae-4164-4407-a9dc-4044e3e630eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-c89e53dd-ff35-42d5-bd8d-39069530878e,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-c28dd988-64e6-4a90-8b05-796bdd969fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-8f62694a-c951-4173-ae63-9e857168d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-b3b323e8-b51d-453e-94fb-b7815a626980,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-606d22d2-05b3-4ba8-af3b-c81d99e1ee58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874849497-172.17.0.2-1597154232354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34829,DS-822bb92f-8007-4de1-8580-5eecfa714f47,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-b87439a4-f7da-4d46-9496-6153eddcdf31,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-5a3953ae-4164-4407-a9dc-4044e3e630eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-c89e53dd-ff35-42d5-bd8d-39069530878e,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-c28dd988-64e6-4a90-8b05-796bdd969fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-8f62694a-c951-4173-ae63-9e857168d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-b3b323e8-b51d-453e-94fb-b7815a626980,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-606d22d2-05b3-4ba8-af3b-c81d99e1ee58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947611214-172.17.0.2-1597154281201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45962,DS-ea020e86-c0f5-43c2-aa18-9d759f4711b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-429b0dfe-a428-4f65-9a8f-ce3b2f07369e,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-4c555c67-049c-4ef4-9418-2020b1d71df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-d44fd0be-78de-46e2-8337-b4feb8183498,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-3cd496e9-6491-42c2-9e25-c7da7089b30a,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-4a540ee1-b646-4173-b460-904a14f85a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-a025809f-5cc3-41be-a4a9-eb77000c7a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-dba9496f-8d00-4629-ae92-e28d77114472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947611214-172.17.0.2-1597154281201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45962,DS-ea020e86-c0f5-43c2-aa18-9d759f4711b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-429b0dfe-a428-4f65-9a8f-ce3b2f07369e,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-4c555c67-049c-4ef4-9418-2020b1d71df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-d44fd0be-78de-46e2-8337-b4feb8183498,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-3cd496e9-6491-42c2-9e25-c7da7089b30a,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-4a540ee1-b646-4173-b460-904a14f85a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-a025809f-5cc3-41be-a4a9-eb77000c7a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-dba9496f-8d00-4629-ae92-e28d77114472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421056633-172.17.0.2-1597154559543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40798,DS-f7a11eb6-2a47-42ed-8778-313ae3421833,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-9110a8ba-9181-4d75-b41e-9d18e835765b,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-6b1644e5-4000-4d37-b17b-cad04483cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-241e72f9-abc8-4f9d-9995-1a283f46f459,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-5a2a4817-f60a-41f6-82d3-4ee229a3f49f,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-091a3024-005b-4808-acc0-247da1de5749,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-ad6bed36-1e3d-44cd-8037-0933c31c0ead,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-aae907b5-7dc9-4345-966c-b334d2b06348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421056633-172.17.0.2-1597154559543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40798,DS-f7a11eb6-2a47-42ed-8778-313ae3421833,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-9110a8ba-9181-4d75-b41e-9d18e835765b,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-6b1644e5-4000-4d37-b17b-cad04483cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-241e72f9-abc8-4f9d-9995-1a283f46f459,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-5a2a4817-f60a-41f6-82d3-4ee229a3f49f,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-091a3024-005b-4808-acc0-247da1de5749,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-ad6bed36-1e3d-44cd-8037-0933c31c0ead,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-aae907b5-7dc9-4345-966c-b334d2b06348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55264522-172.17.0.2-1597155334720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37927,DS-4e1f48ee-cc31-4498-810c-1841b439b028,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-8662e0be-cd69-440e-b6e3-53624bbde248,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-9e31cc1f-58ec-400c-a8bc-9c180af4b5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-25b35f8c-0061-46db-acff-373b17916d59,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-61bae048-2a18-4869-8b45-95db2d41907f,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-314f2a6a-a34f-4613-820e-5eb26aedff63,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-0968c2f4-296d-45e2-b5e2-1357db2be004,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-fbeddcd2-4fb7-4818-b57a-7ae5ce2a388c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55264522-172.17.0.2-1597155334720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37927,DS-4e1f48ee-cc31-4498-810c-1841b439b028,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-8662e0be-cd69-440e-b6e3-53624bbde248,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-9e31cc1f-58ec-400c-a8bc-9c180af4b5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-25b35f8c-0061-46db-acff-373b17916d59,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-61bae048-2a18-4869-8b45-95db2d41907f,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-314f2a6a-a34f-4613-820e-5eb26aedff63,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-0968c2f4-296d-45e2-b5e2-1357db2be004,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-fbeddcd2-4fb7-4818-b57a-7ae5ce2a388c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957977651-172.17.0.2-1597155463562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-4dc42a97-5f09-4d07-8ba5-80fc6393999c,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-86c63681-5d93-40a7-99cd-21c84d29db94,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-8557a841-fca5-4c91-87d3-8bae2ebc4ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-718e7949-06b7-426b-b458-2998a5e8480c,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-37dd9d52-6d22-40b5-8aed-5554b2b9e15e,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-95ad1c8c-5d20-4f24-973e-0fb624f9f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-71fecab2-3de2-497b-929e-6aa86c1b7bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-498ac27a-98a0-4e55-a861-e00699211cee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957977651-172.17.0.2-1597155463562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-4dc42a97-5f09-4d07-8ba5-80fc6393999c,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-86c63681-5d93-40a7-99cd-21c84d29db94,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-8557a841-fca5-4c91-87d3-8bae2ebc4ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-718e7949-06b7-426b-b458-2998a5e8480c,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-37dd9d52-6d22-40b5-8aed-5554b2b9e15e,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-95ad1c8c-5d20-4f24-973e-0fb624f9f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-71fecab2-3de2-497b-929e-6aa86c1b7bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-498ac27a-98a0-4e55-a861-e00699211cee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428486180-172.17.0.2-1597156406800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36921,DS-517bd7c6-90f6-4a60-bbc9-a6d41a1fb6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-3b429e24-69b6-42f7-b9a7-948075d10ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-723297a6-e794-48f2-927d-c8cb976d57dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-8a15cca5-3039-4de4-a0a3-22d1648c875c,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-7bea82a9-6579-4fd1-8c09-8457a0fe72b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-2e70140b-1d92-4f66-9af9-2346e1e3d543,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-a3e99b73-ce61-49f3-99d6-62fe59247c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-d4961c08-c9fe-4060-9e6f-e2b2ddc98396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428486180-172.17.0.2-1597156406800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36921,DS-517bd7c6-90f6-4a60-bbc9-a6d41a1fb6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-3b429e24-69b6-42f7-b9a7-948075d10ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-723297a6-e794-48f2-927d-c8cb976d57dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-8a15cca5-3039-4de4-a0a3-22d1648c875c,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-7bea82a9-6579-4fd1-8c09-8457a0fe72b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-2e70140b-1d92-4f66-9af9-2346e1e3d543,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-a3e99b73-ce61-49f3-99d6-62fe59247c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-d4961c08-c9fe-4060-9e6f-e2b2ddc98396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131993839-172.17.0.2-1597156496596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38907,DS-516e739b-6c69-4788-8a71-c67bbde0cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-0ac401f2-4dad-4783-ab7e-d052cb72ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-1a6915cf-ecf0-46dd-87c3-1313ad11053a,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-4eea841b-fec5-4d3c-8f63-cc60333e6604,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-2a524cf4-c657-4b20-8d0c-476fcd000b65,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-897a1ee6-0c04-48b1-b150-a6154d1895a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-ee34aa71-a0d8-442a-bc86-88248b141a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-107aced3-2c13-4912-97f9-7201398f4abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131993839-172.17.0.2-1597156496596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38907,DS-516e739b-6c69-4788-8a71-c67bbde0cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-0ac401f2-4dad-4783-ab7e-d052cb72ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-1a6915cf-ecf0-46dd-87c3-1313ad11053a,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-4eea841b-fec5-4d3c-8f63-cc60333e6604,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-2a524cf4-c657-4b20-8d0c-476fcd000b65,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-897a1ee6-0c04-48b1-b150-a6154d1895a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-ee34aa71-a0d8-442a-bc86-88248b141a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-107aced3-2c13-4912-97f9-7201398f4abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6653
