reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086582628-172.17.0.8-1597060185870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42174,DS-2d63ea3e-489f-4aa9-9bf5-80e9e3525181,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-33a41139-4cb2-463c-a0f1-027bd690795a,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-94f6781f-75de-440a-bebb-390e05b4020e,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-b2b357b3-2f29-4c1a-8266-67c9336b1dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-5a55022c-fc41-47bf-94a2-a816080ee00d,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-09f220fe-85f5-481f-88b6-27513afeef7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-60eab674-07a5-44c6-8c91-99f9a587d5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-60f51a8a-6acf-427e-b04c-2a9ac9d57ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086582628-172.17.0.8-1597060185870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42174,DS-2d63ea3e-489f-4aa9-9bf5-80e9e3525181,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-33a41139-4cb2-463c-a0f1-027bd690795a,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-94f6781f-75de-440a-bebb-390e05b4020e,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-b2b357b3-2f29-4c1a-8266-67c9336b1dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-5a55022c-fc41-47bf-94a2-a816080ee00d,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-09f220fe-85f5-481f-88b6-27513afeef7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-60eab674-07a5-44c6-8c91-99f9a587d5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-60f51a8a-6acf-427e-b04c-2a9ac9d57ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649111566-172.17.0.8-1597061018122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-1fc1a33e-31a7-4bea-922e-1d6c3a2d9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-1ee11490-937d-435d-aa41-685fea555e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-aa3d4024-692d-4d94-80ff-adc66ccc4c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-1772cc28-da3f-4b5c-a77a-1cab20f997c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-48fa9379-1fd0-44c0-a69f-965a4b285ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-ab5c2cec-6c8d-4fa1-8607-34a95fcb8a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-7093db10-4f0d-4a49-8e61-ce3dd267c3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-14184a9f-accb-4a71-99bd-5cbce2306e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649111566-172.17.0.8-1597061018122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-1fc1a33e-31a7-4bea-922e-1d6c3a2d9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-1ee11490-937d-435d-aa41-685fea555e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-aa3d4024-692d-4d94-80ff-adc66ccc4c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-1772cc28-da3f-4b5c-a77a-1cab20f997c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-48fa9379-1fd0-44c0-a69f-965a4b285ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-ab5c2cec-6c8d-4fa1-8607-34a95fcb8a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-7093db10-4f0d-4a49-8e61-ce3dd267c3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-14184a9f-accb-4a71-99bd-5cbce2306e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51375819-172.17.0.8-1597061067128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46784,DS-fb954d7e-ac64-4325-b22b-bcb912fb3e72,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-67a823f4-51ed-4921-87ba-b6c87196ba25,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-2adbe15d-a4f3-449e-9988-f4cf849851ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-4c9e1f1b-b8ba-4446-a801-632c4c62bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-825dc8fb-97ed-43db-a18e-a75be3254c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-474cc609-6885-4a8d-b3af-6bd394d45b22,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-fe26ea92-87dd-4e6c-9212-3d4fdb54d482,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-1f57ecbb-c559-452e-918b-b4e8d9cb27e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51375819-172.17.0.8-1597061067128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46784,DS-fb954d7e-ac64-4325-b22b-bcb912fb3e72,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-67a823f4-51ed-4921-87ba-b6c87196ba25,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-2adbe15d-a4f3-449e-9988-f4cf849851ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-4c9e1f1b-b8ba-4446-a801-632c4c62bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-825dc8fb-97ed-43db-a18e-a75be3254c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-474cc609-6885-4a8d-b3af-6bd394d45b22,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-fe26ea92-87dd-4e6c-9212-3d4fdb54d482,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-1f57ecbb-c559-452e-918b-b4e8d9cb27e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27566189-172.17.0.8-1597061979127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-d6d25bd9-4c14-47dd-a9bb-f54538368d23,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-2ff94d4f-a172-4c56-b7de-cfcfca817449,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-e1250298-53e9-45c0-bd0b-41c3e15ca39c,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-bc4b2b9e-9937-419d-a2cc-97cfa1eef76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-909250ef-a85d-478d-8846-8a75c6a188a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-e992752a-c604-43a1-906e-5b6fe6f43875,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-e8de58ff-6a98-4562-9fe7-89ff9ad8d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-97a26719-56cb-42da-a63a-53c47c8ba328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27566189-172.17.0.8-1597061979127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-d6d25bd9-4c14-47dd-a9bb-f54538368d23,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-2ff94d4f-a172-4c56-b7de-cfcfca817449,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-e1250298-53e9-45c0-bd0b-41c3e15ca39c,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-bc4b2b9e-9937-419d-a2cc-97cfa1eef76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-909250ef-a85d-478d-8846-8a75c6a188a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-e992752a-c604-43a1-906e-5b6fe6f43875,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-e8de58ff-6a98-4562-9fe7-89ff9ad8d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-97a26719-56cb-42da-a63a-53c47c8ba328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613098856-172.17.0.8-1597062072089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-51455689-76a0-4f36-8e3c-de328ef7a5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-5c00c051-8a23-4016-a596-d8ac1b3fa8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-cac575a8-5846-4a75-80fe-04f6700dad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-17b1e603-9f99-4ca1-83ec-efdc334f71eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-d0e391d4-d326-4d08-8cb7-de52befd0736,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-e4a2a134-52fe-4aca-8334-a6ff9c8aff22,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-460cf6ad-d943-4fc3-89b1-f23a0e31b8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-404440ef-bc62-4390-b184-a03d762649b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613098856-172.17.0.8-1597062072089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-51455689-76a0-4f36-8e3c-de328ef7a5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-5c00c051-8a23-4016-a596-d8ac1b3fa8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-cac575a8-5846-4a75-80fe-04f6700dad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-17b1e603-9f99-4ca1-83ec-efdc334f71eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-d0e391d4-d326-4d08-8cb7-de52befd0736,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-e4a2a134-52fe-4aca-8334-a6ff9c8aff22,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-460cf6ad-d943-4fc3-89b1-f23a0e31b8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-404440ef-bc62-4390-b184-a03d762649b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028580882-172.17.0.8-1597062371634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35161,DS-ea63c94f-645c-486b-98f7-d8e955800a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-09873d32-5111-4a3b-972f-c93e81c0c05c,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-d3c3d8dd-6d2f-4a7c-bc1a-110b7e651b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-567aa448-b8a2-4b48-a575-f17cbfe4cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-9566e095-5b64-41b3-b243-a9cf832edebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-859ed52c-5391-4695-be17-ed5fc7170787,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-7be594d1-6c49-4332-8e86-0916509b26b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-509c190c-9617-4900-bd2f-100c3fcacfaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028580882-172.17.0.8-1597062371634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35161,DS-ea63c94f-645c-486b-98f7-d8e955800a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-09873d32-5111-4a3b-972f-c93e81c0c05c,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-d3c3d8dd-6d2f-4a7c-bc1a-110b7e651b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-567aa448-b8a2-4b48-a575-f17cbfe4cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-9566e095-5b64-41b3-b243-a9cf832edebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-859ed52c-5391-4695-be17-ed5fc7170787,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-7be594d1-6c49-4332-8e86-0916509b26b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-509c190c-9617-4900-bd2f-100c3fcacfaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823527752-172.17.0.8-1597063714840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-2dff9b26-9ef5-4e77-87a9-ab46056d9f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-204d45f5-6ed7-4eeb-a6b0-ac802d9157c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-cbd0f44a-3065-49dd-b242-1dee8d7b4526,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-5440f4ea-fec8-4d03-adc2-38a060738b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-11ecdd6f-9ce9-4018-aea8-e27a6da7277c,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-d3407c71-7f54-48c6-9a1a-c1a96e4a8daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-124d0345-876a-40ec-ac26-f5fed500753f,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-e550ec5f-0ea2-4f13-99a5-55aa7a04b58b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823527752-172.17.0.8-1597063714840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-2dff9b26-9ef5-4e77-87a9-ab46056d9f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-204d45f5-6ed7-4eeb-a6b0-ac802d9157c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-cbd0f44a-3065-49dd-b242-1dee8d7b4526,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-5440f4ea-fec8-4d03-adc2-38a060738b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-11ecdd6f-9ce9-4018-aea8-e27a6da7277c,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-d3407c71-7f54-48c6-9a1a-c1a96e4a8daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-124d0345-876a-40ec-ac26-f5fed500753f,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-e550ec5f-0ea2-4f13-99a5-55aa7a04b58b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544415530-172.17.0.8-1597064188850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-a5b95755-8820-4eb4-b84f-98c20343ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-dd71e7d4-66a6-4883-84a3-eaad784074c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-a192b8d6-8275-4c7b-b50d-0de59d8228e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-e5bf58fb-be91-4cca-a7b8-70ba42c74473,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-c0f62696-db32-4b6b-a3b7-223b19e0576f,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-cafd2dc4-bd90-4cd2-b9e3-ff9ce5ca7064,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-8592ec66-98d3-4a0c-8bd6-68d52468662c,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-a54edbd8-0821-4bcc-867e-028ed7552114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544415530-172.17.0.8-1597064188850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-a5b95755-8820-4eb4-b84f-98c20343ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-dd71e7d4-66a6-4883-84a3-eaad784074c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-a192b8d6-8275-4c7b-b50d-0de59d8228e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-e5bf58fb-be91-4cca-a7b8-70ba42c74473,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-c0f62696-db32-4b6b-a3b7-223b19e0576f,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-cafd2dc4-bd90-4cd2-b9e3-ff9ce5ca7064,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-8592ec66-98d3-4a0c-8bd6-68d52468662c,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-a54edbd8-0821-4bcc-867e-028ed7552114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970167597-172.17.0.8-1597064429237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-01e31d95-b51e-41ad-9b6e-08c9f6fcf4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-df79cad7-ea90-4e7f-a8c3-8f03a2b4232d,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-43a721ff-5a5a-4d35-bff6-95ee3dda077c,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-ed4282e2-06bf-4ee9-89d9-82bce12fc6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-71f8feef-d24f-437d-a21a-2e6aa3f678d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-58edc099-a653-4ba5-a761-440c1a17198d,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-923daa15-d918-40fe-aaac-8b081ee932af,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-248626fa-864b-4aca-a2e2-303770bc6588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970167597-172.17.0.8-1597064429237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-01e31d95-b51e-41ad-9b6e-08c9f6fcf4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-df79cad7-ea90-4e7f-a8c3-8f03a2b4232d,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-43a721ff-5a5a-4d35-bff6-95ee3dda077c,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-ed4282e2-06bf-4ee9-89d9-82bce12fc6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-71f8feef-d24f-437d-a21a-2e6aa3f678d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-58edc099-a653-4ba5-a761-440c1a17198d,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-923daa15-d918-40fe-aaac-8b081ee932af,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-248626fa-864b-4aca-a2e2-303770bc6588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392551921-172.17.0.8-1597064925419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44665,DS-1f92165f-429a-4461-a932-c17088e6907d,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-f7a4a0ea-15a4-4183-a56c-15fa22d6b735,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0bae7902-5047-4d76-be28-b3e40bdee8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-333dbb94-581a-479c-bbff-9665fc2e3870,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-f390a924-d0c8-48a0-82cc-07cdc5ed8b58,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-69c9f88d-9410-4003-a95d-a873f44b9e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-e0e47101-0f5d-4b5d-bfc1-b3fec51053ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-54c1da7a-3c2a-4a58-be74-5891bfae5e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392551921-172.17.0.8-1597064925419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44665,DS-1f92165f-429a-4461-a932-c17088e6907d,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-f7a4a0ea-15a4-4183-a56c-15fa22d6b735,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0bae7902-5047-4d76-be28-b3e40bdee8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-333dbb94-581a-479c-bbff-9665fc2e3870,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-f390a924-d0c8-48a0-82cc-07cdc5ed8b58,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-69c9f88d-9410-4003-a95d-a873f44b9e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-e0e47101-0f5d-4b5d-bfc1-b3fec51053ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-54c1da7a-3c2a-4a58-be74-5891bfae5e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572824777-172.17.0.8-1597065196577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38239,DS-357c1d54-823d-4d08-aa94-92bb862e3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-c88e32f8-832f-4002-bc16-8dca568536bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-8d3d093d-2659-4d90-8315-2999b9d61a05,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-a71a4830-4b46-4e0f-9523-f29ca82529ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-06713b5c-72f1-47eb-b741-06f64a2fd02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-ade44078-b597-4a4c-993a-581ab09acc16,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-215b767d-6666-4703-b54a-745ef210a34b,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-dd9fbe3b-5365-400b-b336-da954cf0d35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572824777-172.17.0.8-1597065196577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38239,DS-357c1d54-823d-4d08-aa94-92bb862e3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-c88e32f8-832f-4002-bc16-8dca568536bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-8d3d093d-2659-4d90-8315-2999b9d61a05,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-a71a4830-4b46-4e0f-9523-f29ca82529ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-06713b5c-72f1-47eb-b741-06f64a2fd02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-ade44078-b597-4a4c-993a-581ab09acc16,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-215b767d-6666-4703-b54a-745ef210a34b,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-dd9fbe3b-5365-400b-b336-da954cf0d35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305421380-172.17.0.8-1597065418033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43079,DS-5bb2c494-34bb-4e02-9636-89f4e71e8147,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-46649f7c-bc91-40fa-88f7-b34c8e6a3ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-39398af5-bb64-4616-b279-e66c49970bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-6fee9d2e-c846-4cba-9378-e4eb821ce3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-79fc165b-b2c5-48f6-b086-6e48d5dda270,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-f44806b9-3a72-44d9-93c4-eeac6d01c111,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-97e8390b-4d58-46ad-99b5-0d7fd6561f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-4dc680b4-66d0-4d64-bf33-ab2c5809da96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305421380-172.17.0.8-1597065418033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43079,DS-5bb2c494-34bb-4e02-9636-89f4e71e8147,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-46649f7c-bc91-40fa-88f7-b34c8e6a3ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-39398af5-bb64-4616-b279-e66c49970bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-6fee9d2e-c846-4cba-9378-e4eb821ce3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-79fc165b-b2c5-48f6-b086-6e48d5dda270,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-f44806b9-3a72-44d9-93c4-eeac6d01c111,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-97e8390b-4d58-46ad-99b5-0d7fd6561f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-4dc680b4-66d0-4d64-bf33-ab2c5809da96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224651267-172.17.0.8-1597065467507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37424,DS-871c2aac-ab0c-4f58-a694-e6c64caf1141,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-409ad607-3a8d-4a6e-813c-a81a52cbab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-9cbf1414-4a24-4d95-9534-8ad604aeb84b,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-ab44e900-6e99-4942-9e74-3b011faeb7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-f6a35646-dc8a-4636-b7a9-960e177c9eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-d880a3a2-4bdc-4598-af7b-d8bbd5f6f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-40f30b07-552a-452a-9d56-79232d78c4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-e573b3ed-c9fc-4dd9-97a3-75a8b299fd52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224651267-172.17.0.8-1597065467507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37424,DS-871c2aac-ab0c-4f58-a694-e6c64caf1141,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-409ad607-3a8d-4a6e-813c-a81a52cbab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-9cbf1414-4a24-4d95-9534-8ad604aeb84b,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-ab44e900-6e99-4942-9e74-3b011faeb7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-f6a35646-dc8a-4636-b7a9-960e177c9eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-d880a3a2-4bdc-4598-af7b-d8bbd5f6f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-40f30b07-552a-452a-9d56-79232d78c4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-e573b3ed-c9fc-4dd9-97a3-75a8b299fd52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376426639-172.17.0.8-1597065597418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-d30e7d05-6999-45b0-988e-f833d8cfd4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-6188b81d-5ca1-4201-89b6-95af441c8f27,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-eb484828-b702-42c2-b894-dbf3f6c4fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-02786934-9831-4efd-8b39-b2e12117d758,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-f308506a-ef89-4395-8f8d-e82ea4f1ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-0b7264cc-64c8-4796-acc6-807f6719f55f,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-ea1b39c7-2f98-4a27-abb0-987bd5a3db59,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-a4f55b48-46cc-449e-938a-ce18146c7018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376426639-172.17.0.8-1597065597418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-d30e7d05-6999-45b0-988e-f833d8cfd4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-6188b81d-5ca1-4201-89b6-95af441c8f27,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-eb484828-b702-42c2-b894-dbf3f6c4fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-02786934-9831-4efd-8b39-b2e12117d758,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-f308506a-ef89-4395-8f8d-e82ea4f1ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-0b7264cc-64c8-4796-acc6-807f6719f55f,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-ea1b39c7-2f98-4a27-abb0-987bd5a3db59,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-a4f55b48-46cc-449e-938a-ce18146c7018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329240067-172.17.0.8-1597065646635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41907,DS-bf39506b-7b27-469e-833a-53e31b22a4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-ef1a7394-9815-4027-a655-936c74044c21,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-5626da80-8b0c-4514-80a9-237ee9adc98c,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-04abe953-1915-4e6b-a7e2-fe4e41e220ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-37bf11d8-f560-440c-8b5e-1eb8ef790e11,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-0567aba6-2915-45a7-9d14-a641f6448bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-6ec7be0c-df12-4f1f-8416-554bba595e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-e60e2b63-4867-4095-b4f3-cbbda82960a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329240067-172.17.0.8-1597065646635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41907,DS-bf39506b-7b27-469e-833a-53e31b22a4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-ef1a7394-9815-4027-a655-936c74044c21,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-5626da80-8b0c-4514-80a9-237ee9adc98c,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-04abe953-1915-4e6b-a7e2-fe4e41e220ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-37bf11d8-f560-440c-8b5e-1eb8ef790e11,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-0567aba6-2915-45a7-9d14-a641f6448bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-6ec7be0c-df12-4f1f-8416-554bba595e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-e60e2b63-4867-4095-b4f3-cbbda82960a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584270915-172.17.0.8-1597065688820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34308,DS-90c53c75-cffb-43d6-b210-74e63fc387e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-fe159fec-d3ac-4a9c-8408-e69d45c02af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-da00e868-22dc-4a1d-9fff-d6eebb5b5fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-78758fa9-5c89-4024-b6c2-38894e6ee1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-75acaaa5-6725-4ce4-bd2d-5bb4b75f4b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-1cadedbf-7a04-4a09-acf7-4dccabea4e91,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-d97c4d84-bca4-45c4-9772-d76a93af391c,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-f75256e0-6f15-4865-979e-cd2d2bb224eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584270915-172.17.0.8-1597065688820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34308,DS-90c53c75-cffb-43d6-b210-74e63fc387e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-fe159fec-d3ac-4a9c-8408-e69d45c02af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-da00e868-22dc-4a1d-9fff-d6eebb5b5fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-78758fa9-5c89-4024-b6c2-38894e6ee1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-75acaaa5-6725-4ce4-bd2d-5bb4b75f4b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-1cadedbf-7a04-4a09-acf7-4dccabea4e91,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-d97c4d84-bca4-45c4-9772-d76a93af391c,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-f75256e0-6f15-4865-979e-cd2d2bb224eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580090731-172.17.0.8-1597065914985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40827,DS-ed1ab4da-4cdf-458b-8d99-df30f2412928,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-bcc6d8ae-f105-473a-b145-96549f42036a,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-06064893-df86-4d82-8d0e-30019ca96ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-0594ef64-e7c5-4688-8fbe-d4d67c0dbef6,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-38b47d26-1cce-46a8-8aea-a7215c75fdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-1ae59ca8-79b0-4c57-8825-b5d4870eacff,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-be598737-a872-4499-a726-ca02103f9fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-3bad555d-08fe-4d44-bd97-3ed2c1326d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580090731-172.17.0.8-1597065914985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40827,DS-ed1ab4da-4cdf-458b-8d99-df30f2412928,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-bcc6d8ae-f105-473a-b145-96549f42036a,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-06064893-df86-4d82-8d0e-30019ca96ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-0594ef64-e7c5-4688-8fbe-d4d67c0dbef6,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-38b47d26-1cce-46a8-8aea-a7215c75fdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-1ae59ca8-79b0-4c57-8825-b5d4870eacff,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-be598737-a872-4499-a726-ca02103f9fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-3bad555d-08fe-4d44-bd97-3ed2c1326d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413909357-172.17.0.8-1597066191517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33543,DS-7eae493b-01b4-47fb-8a29-1617e4208ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-05f51983-992f-49a9-ae66-5979d530ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-df9edc23-460d-4602-b08a-a141eeaff282,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-4d1bc726-d29d-432d-b220-d2e48b0b444e,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-82bbb895-a11b-430a-a55c-a841eae7d531,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-3294726d-d949-4e3a-8ec9-7ec9796d55b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-ac1670af-f4ec-455f-9dcf-30b8b3ca87bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-280d2cc9-1c9a-4576-bbff-e149fb61c7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413909357-172.17.0.8-1597066191517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33543,DS-7eae493b-01b4-47fb-8a29-1617e4208ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-05f51983-992f-49a9-ae66-5979d530ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-df9edc23-460d-4602-b08a-a141eeaff282,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-4d1bc726-d29d-432d-b220-d2e48b0b444e,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-82bbb895-a11b-430a-a55c-a841eae7d531,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-3294726d-d949-4e3a-8ec9-7ec9796d55b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-ac1670af-f4ec-455f-9dcf-30b8b3ca87bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-280d2cc9-1c9a-4576-bbff-e149fb61c7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921318550-172.17.0.8-1597066324534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-e0c4ecb0-94fd-4169-a723-b4e4ef048561,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-9af8d23f-4193-444f-84a3-893ff41e743a,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-5177f518-fa0b-42aa-bde8-8b6457add312,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-52d6351f-765c-4493-81d9-d0f115973cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-1a6bc52e-1e82-4cf7-a43e-50de75fb23d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-8be74b6c-bb39-4c26-aa36-fee4ce344f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-a8e2fc81-a4a8-45f4-9b58-ae8b9ee5ce3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-411f2d97-b6cb-4c5d-b393-20c797912cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921318550-172.17.0.8-1597066324534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-e0c4ecb0-94fd-4169-a723-b4e4ef048561,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-9af8d23f-4193-444f-84a3-893ff41e743a,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-5177f518-fa0b-42aa-bde8-8b6457add312,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-52d6351f-765c-4493-81d9-d0f115973cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-1a6bc52e-1e82-4cf7-a43e-50de75fb23d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-8be74b6c-bb39-4c26-aa36-fee4ce344f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-a8e2fc81-a4a8-45f4-9b58-ae8b9ee5ce3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-411f2d97-b6cb-4c5d-b393-20c797912cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655790705-172.17.0.8-1597066365682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35801,DS-5b4a3b30-56b7-4f4b-909a-0355eeae7944,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-d08fbb76-b44c-42fe-a980-90706c73da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-22fd8e6e-cdca-4742-9cb3-24a79308d046,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-dd26be36-8d5c-4ac8-a9b5-533805432575,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-c7ee67c0-8088-4907-844d-431e0a3a907d,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-322d57b1-ad35-4d06-92a0-908c9e387baf,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-eb6caaed-8af5-48e0-abac-8ed581760e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-a1a54d80-d721-4df5-aa30-922a777fa09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655790705-172.17.0.8-1597066365682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35801,DS-5b4a3b30-56b7-4f4b-909a-0355eeae7944,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-d08fbb76-b44c-42fe-a980-90706c73da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-22fd8e6e-cdca-4742-9cb3-24a79308d046,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-dd26be36-8d5c-4ac8-a9b5-533805432575,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-c7ee67c0-8088-4907-844d-431e0a3a907d,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-322d57b1-ad35-4d06-92a0-908c9e387baf,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-eb6caaed-8af5-48e0-abac-8ed581760e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-a1a54d80-d721-4df5-aa30-922a777fa09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128086027-172.17.0.8-1597066451400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33872,DS-48505e01-3b8b-4a4a-a771-01ffcec46766,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-302c8417-b64e-4f08-9668-288b601f7937,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-31b04e50-6cf2-466e-9447-17802da85f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-3fb8e74f-19fb-4dbd-a147-6dd1315d1b28,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-5eb9a0cb-8068-4dc1-bfa5-d232e7192f06,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-33dc25e4-4343-42a9-bf40-efaa98464b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-14a5cd29-72fd-4810-9538-c1c82e46377a,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-aac73567-89b4-4252-9789-1f6b9893301e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128086027-172.17.0.8-1597066451400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33872,DS-48505e01-3b8b-4a4a-a771-01ffcec46766,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-302c8417-b64e-4f08-9668-288b601f7937,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-31b04e50-6cf2-466e-9447-17802da85f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-3fb8e74f-19fb-4dbd-a147-6dd1315d1b28,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-5eb9a0cb-8068-4dc1-bfa5-d232e7192f06,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-33dc25e4-4343-42a9-bf40-efaa98464b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-14a5cd29-72fd-4810-9538-c1c82e46377a,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-aac73567-89b4-4252-9789-1f6b9893301e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866740674-172.17.0.8-1597066501411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-0e203696-9d70-4516-8b2a-113de40cebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-f8ec8ac8-6494-4d62-a3f2-572cf698d075,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-5afc6630-1666-4dac-8e4a-93e9b8eaee57,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-947285dd-617c-4aff-80c2-da04d5823666,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-6b17547b-54d9-4c9c-80b4-8d7ab1169500,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-1a4a9c96-740b-4b18-b6b5-a91d7965493a,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-06b566da-37ce-4616-a587-15203991eaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-021b2af8-1911-4c74-b581-3f01d708462c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866740674-172.17.0.8-1597066501411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-0e203696-9d70-4516-8b2a-113de40cebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-f8ec8ac8-6494-4d62-a3f2-572cf698d075,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-5afc6630-1666-4dac-8e4a-93e9b8eaee57,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-947285dd-617c-4aff-80c2-da04d5823666,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-6b17547b-54d9-4c9c-80b4-8d7ab1169500,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-1a4a9c96-740b-4b18-b6b5-a91d7965493a,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-06b566da-37ce-4616-a587-15203991eaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-021b2af8-1911-4c74-b581-3f01d708462c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6704
