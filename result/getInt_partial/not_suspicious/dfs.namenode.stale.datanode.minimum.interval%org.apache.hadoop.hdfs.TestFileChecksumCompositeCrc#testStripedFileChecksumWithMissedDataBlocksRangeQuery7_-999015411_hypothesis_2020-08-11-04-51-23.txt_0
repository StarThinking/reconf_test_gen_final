reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744450110-172.17.0.12-1597121571620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-d4a481f4-d480-43d8-955d-13d6b94c16d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-3bfc2ceb-6cb9-4f3b-ac23-ccf27c9dfbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-dfe4c237-f0d7-4bd0-9be5-e963b19063d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-eff85e94-9910-4661-9e69-2fe1bd6f0cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-a46209eb-d917-406c-b7cf-a56fb35675f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-58c85b80-a337-4968-9326-2be4eae3a45b,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-d15e3812-7116-4f35-8b10-657e5191003c,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-aa1f8260-4cb1-4cef-a712-efee1cebb8ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744450110-172.17.0.12-1597121571620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-d4a481f4-d480-43d8-955d-13d6b94c16d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-3bfc2ceb-6cb9-4f3b-ac23-ccf27c9dfbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-dfe4c237-f0d7-4bd0-9be5-e963b19063d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-eff85e94-9910-4661-9e69-2fe1bd6f0cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-a46209eb-d917-406c-b7cf-a56fb35675f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-58c85b80-a337-4968-9326-2be4eae3a45b,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-d15e3812-7116-4f35-8b10-657e5191003c,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-aa1f8260-4cb1-4cef-a712-efee1cebb8ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446082403-172.17.0.12-1597122177889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38593,DS-066aba9b-21e7-4745-9768-c05e9a61c8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-985c6b68-3bc1-4c26-9544-a8be0cd82428,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-e3fe0771-dca1-47bf-b486-c16369c005f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-27ffd1e5-9e37-4985-a6eb-dca52d23bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-b354dba3-60b9-4e74-b2b8-1fff2a878da0,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-24065bb2-9590-4ce6-a05e-91588937c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-7c1c1fe5-fb63-47c2-bc0b-86bc805b1326,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-e797b328-b2da-417a-a2ad-2f5361e309fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446082403-172.17.0.12-1597122177889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38593,DS-066aba9b-21e7-4745-9768-c05e9a61c8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-985c6b68-3bc1-4c26-9544-a8be0cd82428,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-e3fe0771-dca1-47bf-b486-c16369c005f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-27ffd1e5-9e37-4985-a6eb-dca52d23bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-b354dba3-60b9-4e74-b2b8-1fff2a878da0,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-24065bb2-9590-4ce6-a05e-91588937c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-7c1c1fe5-fb63-47c2-bc0b-86bc805b1326,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-e797b328-b2da-417a-a2ad-2f5361e309fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226140312-172.17.0.12-1597122403911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34566,DS-5e145d6d-bca7-49be-9c97-5aceb04eea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-e8ee6f19-45f4-473c-8661-38226509832e,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-39eccbcf-e041-4d35-a57c-d83633ac4986,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-3c392375-5b4e-4070-a591-77488c62c6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-58fbbe37-5efc-4701-9e21-ee737e732aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-71b8157d-282f-45c4-982e-4346c7d26933,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-2db24e5f-5ec9-4890-97d6-73d348eeaf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-4ad1a582-db05-4626-bf1a-3af2b66258cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226140312-172.17.0.12-1597122403911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34566,DS-5e145d6d-bca7-49be-9c97-5aceb04eea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-e8ee6f19-45f4-473c-8661-38226509832e,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-39eccbcf-e041-4d35-a57c-d83633ac4986,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-3c392375-5b4e-4070-a591-77488c62c6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-58fbbe37-5efc-4701-9e21-ee737e732aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-71b8157d-282f-45c4-982e-4346c7d26933,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-2db24e5f-5ec9-4890-97d6-73d348eeaf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-4ad1a582-db05-4626-bf1a-3af2b66258cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100778025-172.17.0.12-1597122491761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-47c21fd7-60ce-47ef-82ea-19d6af06cb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-e38e77a2-91ab-4262-a1a2-f9c3e596ccc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-b7bb50ae-a3c2-4b63-b6f2-251ae52b2f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-c74afbe9-69fe-4da7-8d0e-4acb52597d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-87b8c3e5-adcc-43fe-b574-dfe113bbe222,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-6e48d94f-5d8f-45a9-a952-9828157314f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-0c60cb08-f42f-4cab-90e8-153e6d386884,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-a6bae61c-1b15-44aa-b2c0-6f5661bb928e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100778025-172.17.0.12-1597122491761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-47c21fd7-60ce-47ef-82ea-19d6af06cb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-e38e77a2-91ab-4262-a1a2-f9c3e596ccc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-b7bb50ae-a3c2-4b63-b6f2-251ae52b2f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-c74afbe9-69fe-4da7-8d0e-4acb52597d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-87b8c3e5-adcc-43fe-b574-dfe113bbe222,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-6e48d94f-5d8f-45a9-a952-9828157314f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-0c60cb08-f42f-4cab-90e8-153e6d386884,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-a6bae61c-1b15-44aa-b2c0-6f5661bb928e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94616470-172.17.0.12-1597122557119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36559,DS-cbde33f9-2930-4f13-b674-cd380b8bcfed,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-b0682832-a619-4060-b0d6-275177d880f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-92cb1a30-ba21-46aa-90a2-09addb683ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-90f530e8-6dd5-4127-a396-a037075ebbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-f35dcf56-4e92-421f-93dc-d04371bbcf42,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-698c8efe-dde9-4d79-8505-79e79887b088,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-f37c07a1-130c-43a7-acfc-c898bdbea4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-45648914-3830-423e-8c22-3fee89218c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94616470-172.17.0.12-1597122557119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36559,DS-cbde33f9-2930-4f13-b674-cd380b8bcfed,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-b0682832-a619-4060-b0d6-275177d880f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-92cb1a30-ba21-46aa-90a2-09addb683ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-90f530e8-6dd5-4127-a396-a037075ebbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-f35dcf56-4e92-421f-93dc-d04371bbcf42,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-698c8efe-dde9-4d79-8505-79e79887b088,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-f37c07a1-130c-43a7-acfc-c898bdbea4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-45648914-3830-423e-8c22-3fee89218c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925356725-172.17.0.12-1597122864616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40320,DS-0dd76ea4-8daa-4c98-9a34-9ef939cd219b,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-0d97962d-6f5a-4ee4-9e1d-85a61608bc28,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-def52a21-ae72-4bc7-a738-9e315abf1810,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-b0e226ad-7efb-42a7-93fc-f42239d49d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-576c363a-df28-4bdc-a079-35e585e7cf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-0f830cc1-2ba9-44eb-9645-85be4302157d,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-de9dfd10-e535-4382-9e06-8b965fbcece1,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-67551493-dcb5-4657-9e10-aae8b1dde92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925356725-172.17.0.12-1597122864616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40320,DS-0dd76ea4-8daa-4c98-9a34-9ef939cd219b,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-0d97962d-6f5a-4ee4-9e1d-85a61608bc28,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-def52a21-ae72-4bc7-a738-9e315abf1810,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-b0e226ad-7efb-42a7-93fc-f42239d49d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-576c363a-df28-4bdc-a079-35e585e7cf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-0f830cc1-2ba9-44eb-9645-85be4302157d,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-de9dfd10-e535-4382-9e06-8b965fbcece1,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-67551493-dcb5-4657-9e10-aae8b1dde92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072767503-172.17.0.12-1597122941381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38246,DS-7e71b24f-5f00-4a71-a2b2-6bf7240403cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-d035bf20-cccd-430b-b4c3-da861a42eb87,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-e4a2b516-cbcf-439d-be99-ec50439d05f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-e672c2da-4693-4f16-93a7-4e7f0fb07558,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-95b07123-61d6-4cfe-a4ff-83a36c6b3591,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-2840a216-1d2d-416f-b9fb-885804f187e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-579ef824-8399-4480-9e15-cf1f5fd8fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-23a33f52-cd8e-4d87-a67f-9c925fbce607,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072767503-172.17.0.12-1597122941381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38246,DS-7e71b24f-5f00-4a71-a2b2-6bf7240403cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-d035bf20-cccd-430b-b4c3-da861a42eb87,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-e4a2b516-cbcf-439d-be99-ec50439d05f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-e672c2da-4693-4f16-93a7-4e7f0fb07558,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-95b07123-61d6-4cfe-a4ff-83a36c6b3591,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-2840a216-1d2d-416f-b9fb-885804f187e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-579ef824-8399-4480-9e15-cf1f5fd8fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-23a33f52-cd8e-4d87-a67f-9c925fbce607,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004771940-172.17.0.12-1597123051693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-8e26b2dc-bd10-4431-8ac5-7ae1fb31a852,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-ee18e5b6-2ce4-4247-9071-dc949b8eb71d,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-3a89cebb-6a92-452b-88f7-03639987c5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-840ee96a-ff85-41e4-a050-1bcb0d9f5461,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-25f279a1-f74b-4a29-8520-f62c6bc5eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-c376d409-e951-4a48-b503-9c054112ce16,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-8e125afe-a224-4a50-bd57-136bddabb33e,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-13d84c43-352e-4c6e-aa57-cee5fe6a5912,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004771940-172.17.0.12-1597123051693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-8e26b2dc-bd10-4431-8ac5-7ae1fb31a852,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-ee18e5b6-2ce4-4247-9071-dc949b8eb71d,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-3a89cebb-6a92-452b-88f7-03639987c5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-840ee96a-ff85-41e4-a050-1bcb0d9f5461,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-25f279a1-f74b-4a29-8520-f62c6bc5eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-c376d409-e951-4a48-b503-9c054112ce16,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-8e125afe-a224-4a50-bd57-136bddabb33e,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-13d84c43-352e-4c6e-aa57-cee5fe6a5912,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398295997-172.17.0.12-1597123240932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-990c22a4-f0ed-4e51-adbe-d5bc6cb3a059,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-5068097d-4fb7-4ab9-98bf-7542c1cb6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-58b33631-8666-4209-80fd-c9866689e195,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-d43bbc4e-4b59-44ff-8f4e-b62d3eee1b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-87a2f58b-a4a6-4acd-9a39-2afda54f6e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-ebcccfad-10fe-41b6-b572-cf1918479d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-5f500d82-06e8-47e6-9706-4e9aa4198385,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-c458674d-ff42-4d12-a21a-74d8c4fa4660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398295997-172.17.0.12-1597123240932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-990c22a4-f0ed-4e51-adbe-d5bc6cb3a059,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-5068097d-4fb7-4ab9-98bf-7542c1cb6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-58b33631-8666-4209-80fd-c9866689e195,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-d43bbc4e-4b59-44ff-8f4e-b62d3eee1b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-87a2f58b-a4a6-4acd-9a39-2afda54f6e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-ebcccfad-10fe-41b6-b572-cf1918479d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-5f500d82-06e8-47e6-9706-4e9aa4198385,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-c458674d-ff42-4d12-a21a-74d8c4fa4660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586830204-172.17.0.12-1597123420844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46379,DS-ebbc8373-3ec2-4cb9-9adb-330bbd10d9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-6ed118a7-dc6e-4e9a-9c78-cdf1c715c4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-934aae80-3c78-42aa-8850-df2bdce60882,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-c49ae0ac-9e86-4e1f-aba1-d278690bb965,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-e6a430f9-802c-4e95-a494-02c684b2557f,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-9b700dcf-b0cd-45b0-97f3-0856f24b9fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-943ba3f1-5fa0-4a26-9923-12a4dce9cb60,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-86b0fecc-c743-43bf-8584-c5102d388e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586830204-172.17.0.12-1597123420844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46379,DS-ebbc8373-3ec2-4cb9-9adb-330bbd10d9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-6ed118a7-dc6e-4e9a-9c78-cdf1c715c4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-934aae80-3c78-42aa-8850-df2bdce60882,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-c49ae0ac-9e86-4e1f-aba1-d278690bb965,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-e6a430f9-802c-4e95-a494-02c684b2557f,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-9b700dcf-b0cd-45b0-97f3-0856f24b9fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-943ba3f1-5fa0-4a26-9923-12a4dce9cb60,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-86b0fecc-c743-43bf-8584-c5102d388e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589151461-172.17.0.12-1597123485535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33503,DS-1b4a8bf8-6104-4df3-9da6-434e10bbb55c,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-e991b244-f464-4e83-9147-3ca9713977be,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-e75c0bae-10f6-45fc-b692-e83df2087839,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-8eea4b90-6b95-4ec4-acaa-940dbdb86702,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-bcd2d119-98ee-41d9-a122-2ac8200d061b,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-0e7c000a-248d-4fcf-a618-deb6685e579a,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-8d82cae4-b6a8-4e3f-b8dc-f879031f5243,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-ac37d61b-0727-463f-90de-1d51fd1fe1fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589151461-172.17.0.12-1597123485535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33503,DS-1b4a8bf8-6104-4df3-9da6-434e10bbb55c,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-e991b244-f464-4e83-9147-3ca9713977be,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-e75c0bae-10f6-45fc-b692-e83df2087839,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-8eea4b90-6b95-4ec4-acaa-940dbdb86702,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-bcd2d119-98ee-41d9-a122-2ac8200d061b,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-0e7c000a-248d-4fcf-a618-deb6685e579a,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-8d82cae4-b6a8-4e3f-b8dc-f879031f5243,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-ac37d61b-0727-463f-90de-1d51fd1fe1fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642608822-172.17.0.12-1597123631616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-bb39c144-a32e-44df-b477-aedbf1f6b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-1a49ce3c-707c-4f16-98f0-88cc0325cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-231eafd8-ce83-4f8f-905c-b66d41c778fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-baa490f0-a318-4705-9cb8-c509af352d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-1eeeb896-fa43-4e57-8176-18646bd9b132,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-4eb94526-e0d6-48ac-abf6-425f105df730,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-4ac71b3a-7558-409e-b4de-d3c9b01b169a,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-92baf6d0-fbaa-4efa-87e0-1b47e64c956d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642608822-172.17.0.12-1597123631616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-bb39c144-a32e-44df-b477-aedbf1f6b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-1a49ce3c-707c-4f16-98f0-88cc0325cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-231eafd8-ce83-4f8f-905c-b66d41c778fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-baa490f0-a318-4705-9cb8-c509af352d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-1eeeb896-fa43-4e57-8176-18646bd9b132,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-4eb94526-e0d6-48ac-abf6-425f105df730,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-4ac71b3a-7558-409e-b4de-d3c9b01b169a,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-92baf6d0-fbaa-4efa-87e0-1b47e64c956d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847522033-172.17.0.12-1597123690950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-25dad3bd-1a69-494d-8f7e-6c4686ae40c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-098095b1-e988-44a0-9e4f-64b613ceadab,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-8c4936e3-c45f-41fd-a434-3b794bf34d49,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-1b1683c8-2c42-40d4-bf15-33e23c8c8e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-f5013999-b359-4279-97a3-67202b8cd3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-1bb9882e-36af-4c39-bdce-53d2c0872d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-64f33086-b3ba-4609-816a-f8d0b2db166a,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-28e7b0dc-57af-40bb-be55-189cffa89eea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847522033-172.17.0.12-1597123690950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-25dad3bd-1a69-494d-8f7e-6c4686ae40c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-098095b1-e988-44a0-9e4f-64b613ceadab,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-8c4936e3-c45f-41fd-a434-3b794bf34d49,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-1b1683c8-2c42-40d4-bf15-33e23c8c8e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-f5013999-b359-4279-97a3-67202b8cd3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-1bb9882e-36af-4c39-bdce-53d2c0872d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-64f33086-b3ba-4609-816a-f8d0b2db166a,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-28e7b0dc-57af-40bb-be55-189cffa89eea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783414703-172.17.0.12-1597124081561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43345,DS-dd464d8c-462b-4312-b532-eb2e9d6f3d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-ceadc04f-a17d-4229-83f4-85098e9bce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-2c5edb6b-f1a1-4778-bc21-c9d9ece24251,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-0126d0ab-58e3-4f01-b702-8c24cf4510b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-25ccd888-def4-44f9-aee3-ca00afb26c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-1400e680-2721-4e46-9a62-d701c1f96ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-5863064c-11dc-4cf2-8c9d-3a432ea24432,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-d7c99505-980b-43b4-a232-79f6e32ac2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783414703-172.17.0.12-1597124081561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43345,DS-dd464d8c-462b-4312-b532-eb2e9d6f3d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-ceadc04f-a17d-4229-83f4-85098e9bce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-2c5edb6b-f1a1-4778-bc21-c9d9ece24251,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-0126d0ab-58e3-4f01-b702-8c24cf4510b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-25ccd888-def4-44f9-aee3-ca00afb26c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-1400e680-2721-4e46-9a62-d701c1f96ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-5863064c-11dc-4cf2-8c9d-3a432ea24432,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-d7c99505-980b-43b4-a232-79f6e32ac2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245111550-172.17.0.12-1597124155257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34755,DS-ef153bd4-e948-42ce-858f-06d4e25be8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-3915a4cc-be5f-4a1f-b50e-e5971f8ec4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-89d76fae-ec65-4d1a-a143-f1da4001d810,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-666d6d00-bdda-4620-982b-e71c61204a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-049ca741-8343-4f46-a8c3-c274507bf0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-aa5e82d9-58dc-47e9-a63a-ea1b5c135ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-8322d22f-588a-4900-8d13-cb767e2c05d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-01283314-add7-425a-af66-c175c567a980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245111550-172.17.0.12-1597124155257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34755,DS-ef153bd4-e948-42ce-858f-06d4e25be8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-3915a4cc-be5f-4a1f-b50e-e5971f8ec4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-89d76fae-ec65-4d1a-a143-f1da4001d810,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-666d6d00-bdda-4620-982b-e71c61204a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-049ca741-8343-4f46-a8c3-c274507bf0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-aa5e82d9-58dc-47e9-a63a-ea1b5c135ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-8322d22f-588a-4900-8d13-cb767e2c05d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-01283314-add7-425a-af66-c175c567a980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075772353-172.17.0.12-1597124610393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-7ad75818-868c-4d04-a324-c2c412a4d377,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-c829ba43-626a-4ea5-b87d-e38f512aeb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-342fb96f-7ffe-4b06-89b3-f8e2b2f2c8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-03b6d1f2-3b37-4d02-a9fa-1bed9d407117,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-d47ba568-a4b2-475b-83e0-37e9dd1b32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-c0907228-ef70-4c20-bcd0-3fe351e014bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-1759e53d-21cd-42bb-bad1-67ae5ab5a049,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-63d5f57f-fa1e-433c-a4f6-326a3995ecee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075772353-172.17.0.12-1597124610393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-7ad75818-868c-4d04-a324-c2c412a4d377,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-c829ba43-626a-4ea5-b87d-e38f512aeb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-342fb96f-7ffe-4b06-89b3-f8e2b2f2c8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-03b6d1f2-3b37-4d02-a9fa-1bed9d407117,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-d47ba568-a4b2-475b-83e0-37e9dd1b32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-c0907228-ef70-4c20-bcd0-3fe351e014bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-1759e53d-21cd-42bb-bad1-67ae5ab5a049,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-63d5f57f-fa1e-433c-a4f6-326a3995ecee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081749506-172.17.0.12-1597124642737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-8d02a280-f9d6-4581-aecb-957a555859a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-9ea54cc1-8ac6-49d3-bb5d-1a1b65af5430,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-f6397e9e-364b-4d8d-a7ea-07f18eca0b30,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-ce6da3a0-0ac5-4352-a0d0-7347590de6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-5a61548d-8b90-4ff3-aa87-626da821d2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-09d5f202-0ead-434b-9c96-acce65e708c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-6e082d47-aaba-476f-b1dd-8779c81692a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-db9a0d43-1a4c-4cc6-897f-31c7e01cf42b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081749506-172.17.0.12-1597124642737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-8d02a280-f9d6-4581-aecb-957a555859a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-9ea54cc1-8ac6-49d3-bb5d-1a1b65af5430,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-f6397e9e-364b-4d8d-a7ea-07f18eca0b30,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-ce6da3a0-0ac5-4352-a0d0-7347590de6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-5a61548d-8b90-4ff3-aa87-626da821d2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-09d5f202-0ead-434b-9c96-acce65e708c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-6e082d47-aaba-476f-b1dd-8779c81692a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-db9a0d43-1a4c-4cc6-897f-31c7e01cf42b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068898191-172.17.0.12-1597124773238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45047,DS-14fc159c-bb8c-4699-9167-7df643fe10d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-694f6103-1334-452a-8137-632aef526841,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-0bbfe724-d6fc-47fc-b0c6-e6d6c38e9f88,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-00418448-fc5e-4ed0-ab80-1d50b922c109,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-300e42ae-18f8-4f80-8b5f-a3a20900da89,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-9460386d-8ad0-427b-8f37-932bfc5529db,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-e40ec9df-e34b-4506-9e9f-594fe92a393c,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-10d43203-af55-48aa-9bb6-977d9907d67f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068898191-172.17.0.12-1597124773238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45047,DS-14fc159c-bb8c-4699-9167-7df643fe10d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-694f6103-1334-452a-8137-632aef526841,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-0bbfe724-d6fc-47fc-b0c6-e6d6c38e9f88,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-00418448-fc5e-4ed0-ab80-1d50b922c109,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-300e42ae-18f8-4f80-8b5f-a3a20900da89,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-9460386d-8ad0-427b-8f37-932bfc5529db,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-e40ec9df-e34b-4506-9e9f-594fe92a393c,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-10d43203-af55-48aa-9bb6-977d9907d67f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061127883-172.17.0.12-1597124937948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33335,DS-9cf4fc5c-9819-4a66-ba3d-bf178f23cff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-3d558c52-4c85-4b90-b898-e14e135b1bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-387b813b-8362-437b-8ad0-206170f9444f,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-f34442fe-b6bf-42bf-983e-ef8b0d63c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-fe2ec7e5-3246-4e2e-a837-4fc53b66e504,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-f9d2e2a7-56e1-4ec8-8a4a-80ea679e60eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-aa5f6bd7-05d4-455f-8afd-e2fd81f68058,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-0d3c9c66-7079-46a2-87bb-5bdfd56ddc5b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061127883-172.17.0.12-1597124937948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33335,DS-9cf4fc5c-9819-4a66-ba3d-bf178f23cff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-3d558c52-4c85-4b90-b898-e14e135b1bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-387b813b-8362-437b-8ad0-206170f9444f,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-f34442fe-b6bf-42bf-983e-ef8b0d63c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-fe2ec7e5-3246-4e2e-a837-4fc53b66e504,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-f9d2e2a7-56e1-4ec8-8a4a-80ea679e60eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-aa5f6bd7-05d4-455f-8afd-e2fd81f68058,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-0d3c9c66-7079-46a2-87bb-5bdfd56ddc5b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283135081-172.17.0.12-1597125104769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-e0bfe0f2-084a-4bf9-ad97-c94d9996cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-a778e57e-4372-40ca-89ba-8ce4f0e0f447,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-ceec8920-119f-43f5-a4cf-c609af0878a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-ad24cf7a-538f-4740-91c7-76efca94411c,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-1088988e-603a-449d-b416-37335f317eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-f8a9ba61-814e-4e82-ae6c-1041596f3d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-5e9b7d08-9e7d-48f8-a3b8-9ebbd0c96d67,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-39a416fe-3c3d-4836-beed-5af10e652043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283135081-172.17.0.12-1597125104769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-e0bfe0f2-084a-4bf9-ad97-c94d9996cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-a778e57e-4372-40ca-89ba-8ce4f0e0f447,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-ceec8920-119f-43f5-a4cf-c609af0878a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-ad24cf7a-538f-4740-91c7-76efca94411c,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-1088988e-603a-449d-b416-37335f317eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-f8a9ba61-814e-4e82-ae6c-1041596f3d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-5e9b7d08-9e7d-48f8-a3b8-9ebbd0c96d67,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-39a416fe-3c3d-4836-beed-5af10e652043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509854860-172.17.0.12-1597125314413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43887,DS-45e835d2-ed05-4454-b99b-2af6062d7835,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-338dac6e-7822-44f9-91e3-86675f7079cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-aa5a9cd6-de55-446c-af4e-f2e5e9f07ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-63b09c3e-f36c-4b32-9090-fb8d955b2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-61daa829-75f7-43c9-a570-083f9221c5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-c8a90aa7-672d-4626-b692-c1ebd870a382,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-1a1d7e6c-138a-458a-8d42-927e50708e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-990ff76f-b463-4412-bb35-b437a22adb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509854860-172.17.0.12-1597125314413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43887,DS-45e835d2-ed05-4454-b99b-2af6062d7835,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-338dac6e-7822-44f9-91e3-86675f7079cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-aa5a9cd6-de55-446c-af4e-f2e5e9f07ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-63b09c3e-f36c-4b32-9090-fb8d955b2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-61daa829-75f7-43c9-a570-083f9221c5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-c8a90aa7-672d-4626-b692-c1ebd870a382,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-1a1d7e6c-138a-458a-8d42-927e50708e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-990ff76f-b463-4412-bb35-b437a22adb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170312161-172.17.0.12-1597125391749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33118,DS-754fd3ff-1b32-428d-97c0-1a694108e9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-6714ff3f-320d-43a4-8640-85f74801659b,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-661df436-83d8-4ff1-b8ed-117e308472b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-a828eb24-70fc-4f0c-a568-2ac1b30f79ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-f27f81f3-dce8-4909-9550-ae9a5a2936d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-9082aa8d-1df0-4876-9ae0-ea50b0721028,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-7ac5a0c0-c847-4bd1-9609-e657eb664fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-f5a22ff8-4522-4cab-b0c0-e27a6f24a696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170312161-172.17.0.12-1597125391749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33118,DS-754fd3ff-1b32-428d-97c0-1a694108e9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-6714ff3f-320d-43a4-8640-85f74801659b,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-661df436-83d8-4ff1-b8ed-117e308472b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-a828eb24-70fc-4f0c-a568-2ac1b30f79ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-f27f81f3-dce8-4909-9550-ae9a5a2936d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-9082aa8d-1df0-4876-9ae0-ea50b0721028,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-7ac5a0c0-c847-4bd1-9609-e657eb664fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-f5a22ff8-4522-4cab-b0c0-e27a6f24a696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314569581-172.17.0.12-1597125536365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40443,DS-ec8bc2eb-aa9b-47c9-9a33-cac1c36275ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-8edd101b-d131-4898-b87f-44611e9cbfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-2d9346e6-7933-4b7e-b7d9-2d06a38e4f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-5c8fc89f-92e8-46cb-aee1-77187338d8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-016351fb-1ece-4978-a95f-d101e608cb35,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-0319d7ad-5086-4663-afe9-eb7b7b6860cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-00f68caf-83a1-4f38-b059-c6a6eb00144d,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-e36c8f53-01cd-474d-98cf-d0f461a1ac03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314569581-172.17.0.12-1597125536365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40443,DS-ec8bc2eb-aa9b-47c9-9a33-cac1c36275ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-8edd101b-d131-4898-b87f-44611e9cbfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-2d9346e6-7933-4b7e-b7d9-2d06a38e4f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-5c8fc89f-92e8-46cb-aee1-77187338d8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-016351fb-1ece-4978-a95f-d101e608cb35,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-0319d7ad-5086-4663-afe9-eb7b7b6860cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-00f68caf-83a1-4f38-b059-c6a6eb00144d,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-e36c8f53-01cd-474d-98cf-d0f461a1ac03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367775945-172.17.0.12-1597125678248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39093,DS-65eb4312-d914-443a-b1a3-1d3de4739f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-f564c884-3ee5-46b8-853c-be77335bcf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-44377611-7f61-45bd-8521-06dfece05474,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-9428551c-628a-4fad-ad65-3b0b145c3b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-d777873d-0dc5-43a7-b925-38386e0e9e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-8f3ec7c1-2506-4bd3-9b5a-b28a749f3d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-34a76c2f-3ceb-4e4b-8057-ebd337770aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-5bd965c2-865f-425c-9dda-2388424ca15c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367775945-172.17.0.12-1597125678248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39093,DS-65eb4312-d914-443a-b1a3-1d3de4739f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-f564c884-3ee5-46b8-853c-be77335bcf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-44377611-7f61-45bd-8521-06dfece05474,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-9428551c-628a-4fad-ad65-3b0b145c3b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-d777873d-0dc5-43a7-b925-38386e0e9e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-8f3ec7c1-2506-4bd3-9b5a-b28a749f3d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-34a76c2f-3ceb-4e4b-8057-ebd337770aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-5bd965c2-865f-425c-9dda-2388424ca15c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185858087-172.17.0.12-1597125751109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43493,DS-5002ac43-8575-4c97-8133-5e6616c5c017,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-20ac70b4-09a4-4463-91b9-8001638a952a,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-9bfff31d-f823-4180-be1b-900cd02c165c,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-5976e1aa-077b-4fcc-ad96-74b35bd5dab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-7b5ecdf8-6bf5-45c0-8cea-30bf7f709c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-56f9ca3d-ca7c-4cfc-a4e2-023653f2e495,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-f8a735e1-65b8-480b-91a5-b7a41ba09b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-f7611466-20ac-4889-851d-65bd3ce4efd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185858087-172.17.0.12-1597125751109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43493,DS-5002ac43-8575-4c97-8133-5e6616c5c017,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-20ac70b4-09a4-4463-91b9-8001638a952a,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-9bfff31d-f823-4180-be1b-900cd02c165c,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-5976e1aa-077b-4fcc-ad96-74b35bd5dab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-7b5ecdf8-6bf5-45c0-8cea-30bf7f709c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-56f9ca3d-ca7c-4cfc-a4e2-023653f2e495,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-f8a735e1-65b8-480b-91a5-b7a41ba09b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-f7611466-20ac-4889-851d-65bd3ce4efd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017571180-172.17.0.12-1597125858965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40088,DS-b8e0fca0-7e2d-423b-b317-ced287959ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-e3765de1-196f-451b-af0c-e01327168cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-3bafabc7-9cb6-44bc-a091-43ad838600da,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-629aed16-099e-40af-aa9f-70ba1446bcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-78709993-2194-44cf-a5fe-034b792e70b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-4301c673-9a91-4a83-a7e6-9152622ba7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-a2ebf9ab-4766-4a6a-b77d-48def95fcf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-fbf91415-1974-43c3-a3a0-987c5d7ec013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017571180-172.17.0.12-1597125858965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40088,DS-b8e0fca0-7e2d-423b-b317-ced287959ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-e3765de1-196f-451b-af0c-e01327168cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-3bafabc7-9cb6-44bc-a091-43ad838600da,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-629aed16-099e-40af-aa9f-70ba1446bcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-78709993-2194-44cf-a5fe-034b792e70b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-4301c673-9a91-4a83-a7e6-9152622ba7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-a2ebf9ab-4766-4a6a-b77d-48def95fcf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-fbf91415-1974-43c3-a3a0-987c5d7ec013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107813715-172.17.0.12-1597125930351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41615,DS-ac06b9e3-28ec-4e88-824c-0bf97041e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-107624aa-9802-4403-89bc-c338c95407cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-05baa756-e958-4bc4-b5aa-88f4365a8965,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-2f375e95-b61e-4021-bf9f-b14fbf0737c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-2722a6d2-d7ef-4670-bf7a-0e8b65399f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-be7ce613-ea8f-4f00-9772-99fe9424b9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-7561604f-3936-408e-86c5-65bd14389cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-f2211cd6-aa6b-432a-b729-5c49c6ee747d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107813715-172.17.0.12-1597125930351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41615,DS-ac06b9e3-28ec-4e88-824c-0bf97041e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-107624aa-9802-4403-89bc-c338c95407cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-05baa756-e958-4bc4-b5aa-88f4365a8965,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-2f375e95-b61e-4021-bf9f-b14fbf0737c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-2722a6d2-d7ef-4670-bf7a-0e8b65399f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-be7ce613-ea8f-4f00-9772-99fe9424b9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-7561604f-3936-408e-86c5-65bd14389cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-f2211cd6-aa6b-432a-b729-5c49c6ee747d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103316130-172.17.0.12-1597125965292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-d4b7ae69-8535-4b74-8ffe-10c08678da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-d764d7e2-bd37-4f63-93ac-508adbea33d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-5bde1ee1-1adb-46b3-84ef-22bef91ea008,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-1bc73e73-0c6c-44c3-8c86-6a6b0fc74bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-bf8916e9-ebfa-48ec-aff5-4c2162b51f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-023c143a-32b3-4860-ad97-6801bc08f146,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-d5563e9b-94c2-434f-8452-5624e5e90160,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-4adc8f89-f723-4164-9a09-317c70c641a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103316130-172.17.0.12-1597125965292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-d4b7ae69-8535-4b74-8ffe-10c08678da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-d764d7e2-bd37-4f63-93ac-508adbea33d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-5bde1ee1-1adb-46b3-84ef-22bef91ea008,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-1bc73e73-0c6c-44c3-8c86-6a6b0fc74bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-bf8916e9-ebfa-48ec-aff5-4c2162b51f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-023c143a-32b3-4860-ad97-6801bc08f146,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-d5563e9b-94c2-434f-8452-5624e5e90160,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-4adc8f89-f723-4164-9a09-317c70c641a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038166363-172.17.0.12-1597126119234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-e2d07f9c-f26b-4fed-bff4-ed6dbda53d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-dbfb5253-3c61-44bf-960f-2a3d263d4a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-dd452663-0948-4e70-a48f-0c931c2561d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-c1604178-49f0-4402-be65-fbf6fbfd4712,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-94e24920-7ef9-40ef-a951-0ae7b390b47c,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-f0549bfd-df33-4022-ba7e-89fdfa59b1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-2aaf289a-ab29-4281-a06f-4a2283263d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-296f6921-cd32-4032-90b4-27b6b3c4b814,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038166363-172.17.0.12-1597126119234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-e2d07f9c-f26b-4fed-bff4-ed6dbda53d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-dbfb5253-3c61-44bf-960f-2a3d263d4a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-dd452663-0948-4e70-a48f-0c931c2561d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-c1604178-49f0-4402-be65-fbf6fbfd4712,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-94e24920-7ef9-40ef-a951-0ae7b390b47c,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-f0549bfd-df33-4022-ba7e-89fdfa59b1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-2aaf289a-ab29-4281-a06f-4a2283263d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-296f6921-cd32-4032-90b4-27b6b3c4b814,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483918421-172.17.0.12-1597126195617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-de717cde-91b5-4ac4-9d95-7bba3f7ba9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-027e1127-af77-4d01-92f9-7c56c0452b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-52bb528c-74d3-4cbd-bc2e-f84c0ac81a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-609829bb-8aed-48e3-a699-079558fc6973,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-3e4bf51c-c377-4534-82ae-ab7bde61ad71,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-8022d1d0-a2f2-4c8a-acbc-93df7f23c162,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-9a96abd5-a8ad-463f-ad55-3cd9a1071017,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-86052522-da71-4db0-ac76-df593ad7b6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483918421-172.17.0.12-1597126195617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-de717cde-91b5-4ac4-9d95-7bba3f7ba9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-027e1127-af77-4d01-92f9-7c56c0452b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-52bb528c-74d3-4cbd-bc2e-f84c0ac81a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-609829bb-8aed-48e3-a699-079558fc6973,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-3e4bf51c-c377-4534-82ae-ab7bde61ad71,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-8022d1d0-a2f2-4c8a-acbc-93df7f23c162,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-9a96abd5-a8ad-463f-ad55-3cd9a1071017,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-86052522-da71-4db0-ac76-df593ad7b6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405842179-172.17.0.12-1597126409035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38649,DS-2a439760-8017-483e-aac7-be1fd356c41e,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-14c980cb-7e4b-4057-aa31-79c3a86b8e27,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-4ebcf20c-9e43-4120-95ce-e65bbafd98fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-01b4df6b-43a0-4377-b65a-9b9be1383861,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-8dd23dd2-a3e6-464c-addb-50039fc5051c,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-ec6a47eb-998b-4684-a3f6-4a72e8e612e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-79252500-337d-4364-adca-6c70d3b8f0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-838deaad-506c-4f82-b6c1-5e684b0c7d2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405842179-172.17.0.12-1597126409035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38649,DS-2a439760-8017-483e-aac7-be1fd356c41e,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-14c980cb-7e4b-4057-aa31-79c3a86b8e27,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-4ebcf20c-9e43-4120-95ce-e65bbafd98fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-01b4df6b-43a0-4377-b65a-9b9be1383861,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-8dd23dd2-a3e6-464c-addb-50039fc5051c,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-ec6a47eb-998b-4684-a3f6-4a72e8e612e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-79252500-337d-4364-adca-6c70d3b8f0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-838deaad-506c-4f82-b6c1-5e684b0c7d2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796293089-172.17.0.12-1597126444342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-68d53e6a-aec5-4cc1-969a-90854d6a93f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-926b8a2f-21de-4de3-81f1-84a9d6e8ac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-5040ceec-9cc4-4b15-a3a5-3fb11ea6f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-759e7e01-8518-4fdc-9509-9be9d50a3c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-24e642df-6713-4480-932a-dbb5af5ce6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-91a326f8-05b2-4402-b26b-aa14a6485091,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-9f4dc189-920b-46b9-b5e9-75b111597bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-83c768af-c5b4-454d-ab56-506dd2da4818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796293089-172.17.0.12-1597126444342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-68d53e6a-aec5-4cc1-969a-90854d6a93f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-926b8a2f-21de-4de3-81f1-84a9d6e8ac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-5040ceec-9cc4-4b15-a3a5-3fb11ea6f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-759e7e01-8518-4fdc-9509-9be9d50a3c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-24e642df-6713-4480-932a-dbb5af5ce6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-91a326f8-05b2-4402-b26b-aa14a6485091,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-9f4dc189-920b-46b9-b5e9-75b111597bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-83c768af-c5b4-454d-ab56-506dd2da4818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5153
