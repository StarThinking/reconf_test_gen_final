reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569654324-172.17.0.12-1597180433726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-5eefe16f-d76d-479c-9f5a-bea241d7151d,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-d214a8c3-8ee6-45a6-92ba-243a81fe80ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-62566eec-de9b-42d2-b449-9c9ebcb6eb57,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-728ae90e-f230-4a7b-9dd6-667814cce17c,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-521653bd-3493-4c58-92ab-9f3dc9f4e7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-307c871b-f09a-445f-8bf4-5c52bb70236c,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-8fef31c8-96ee-4b0c-83ad-a1aa4f0c7e62,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-971e7b0d-32b0-44c0-ad95-1d7269aef426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569654324-172.17.0.12-1597180433726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-5eefe16f-d76d-479c-9f5a-bea241d7151d,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-d214a8c3-8ee6-45a6-92ba-243a81fe80ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-62566eec-de9b-42d2-b449-9c9ebcb6eb57,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-728ae90e-f230-4a7b-9dd6-667814cce17c,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-521653bd-3493-4c58-92ab-9f3dc9f4e7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-307c871b-f09a-445f-8bf4-5c52bb70236c,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-8fef31c8-96ee-4b0c-83ad-a1aa4f0c7e62,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-971e7b0d-32b0-44c0-ad95-1d7269aef426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254851765-172.17.0.12-1597181195370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40555,DS-c75413be-11a0-4bc3-ae76-a379e259acdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-d48d99a8-f66c-4011-a6e2-a4f5d11536c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-21a13661-7f1a-4098-840b-5508aed5ce8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-ea5a9bec-f007-416f-a233-b60098cd3ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-ce4138d5-dc37-467e-8435-33166eed933a,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-dbde1fa1-4fba-4815-9b6d-2f6e98d22dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-be17ca8c-f411-4d1f-bb5f-69eb32677d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-acb85022-d684-4bcf-b34e-fbd07759f8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254851765-172.17.0.12-1597181195370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40555,DS-c75413be-11a0-4bc3-ae76-a379e259acdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-d48d99a8-f66c-4011-a6e2-a4f5d11536c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-21a13661-7f1a-4098-840b-5508aed5ce8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-ea5a9bec-f007-416f-a233-b60098cd3ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-ce4138d5-dc37-467e-8435-33166eed933a,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-dbde1fa1-4fba-4815-9b6d-2f6e98d22dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-be17ca8c-f411-4d1f-bb5f-69eb32677d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-acb85022-d684-4bcf-b34e-fbd07759f8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1959542181-172.17.0.12-1597181375130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43118,DS-38cd283e-d44f-45a1-8bf8-9e1919534312,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-b983713a-580c-4e55-aee4-7022e65b138d,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-855a63ca-dfe5-47a7-885d-020733be747f,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-a48e6a1e-b099-455e-935a-5793e9e9cef2,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-ecbfe3ea-03d2-4165-b26a-f1f77868a5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-b21fc938-0521-41eb-a4cf-388c155d6151,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-200aa18f-3aa3-4d6c-84e8-442971d5853b,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-b757489e-4e01-4103-bcca-2be3ae1430cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1959542181-172.17.0.12-1597181375130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43118,DS-38cd283e-d44f-45a1-8bf8-9e1919534312,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-b983713a-580c-4e55-aee4-7022e65b138d,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-855a63ca-dfe5-47a7-885d-020733be747f,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-a48e6a1e-b099-455e-935a-5793e9e9cef2,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-ecbfe3ea-03d2-4165-b26a-f1f77868a5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-b21fc938-0521-41eb-a4cf-388c155d6151,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-200aa18f-3aa3-4d6c-84e8-442971d5853b,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-b757489e-4e01-4103-bcca-2be3ae1430cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203462950-172.17.0.12-1597182011788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-eab83bc1-0e92-4793-8464-b959144776b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-ea460d27-42fd-4b35-9b1a-1b78a5e2897c,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-a38de4c7-4f00-4cc9-b069-e4df0221ad23,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-8c7ed10a-8883-46b5-b38c-f2e80a8f9589,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-2a94a16b-ff2b-4426-b85c-9b0c7a7918c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-1697ec6b-19dc-401f-b47e-4e7d6f6c55bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-84b2c741-4468-40cc-99ee-0499155827be,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-f1f2c70f-8cd6-4938-8db5-7f35ac59a568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203462950-172.17.0.12-1597182011788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-eab83bc1-0e92-4793-8464-b959144776b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-ea460d27-42fd-4b35-9b1a-1b78a5e2897c,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-a38de4c7-4f00-4cc9-b069-e4df0221ad23,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-8c7ed10a-8883-46b5-b38c-f2e80a8f9589,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-2a94a16b-ff2b-4426-b85c-9b0c7a7918c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-1697ec6b-19dc-401f-b47e-4e7d6f6c55bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-84b2c741-4468-40cc-99ee-0499155827be,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-f1f2c70f-8cd6-4938-8db5-7f35ac59a568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414938272-172.17.0.12-1597182040844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-abff9fee-3602-46ef-bba8-5ca13fd58c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-40a9b55b-9441-437e-b8b5-84967f3bbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-3b50ea4c-caba-4cfe-9302-3ab17e8eaa08,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-cab7f891-8448-48bb-89a3-72d1ac05cf49,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-26a3ead4-f494-4be1-afa4-9b8427c2e061,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-b87626ee-8a2b-4ae5-8865-64961cc8ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-469236a5-70e4-47da-a6f5-256c7f827113,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-d61a7103-38a2-4dba-8528-8c0b1851b09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414938272-172.17.0.12-1597182040844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-abff9fee-3602-46ef-bba8-5ca13fd58c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-40a9b55b-9441-437e-b8b5-84967f3bbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-3b50ea4c-caba-4cfe-9302-3ab17e8eaa08,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-cab7f891-8448-48bb-89a3-72d1ac05cf49,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-26a3ead4-f494-4be1-afa4-9b8427c2e061,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-b87626ee-8a2b-4ae5-8865-64961cc8ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-469236a5-70e4-47da-a6f5-256c7f827113,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-d61a7103-38a2-4dba-8528-8c0b1851b09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761296651-172.17.0.12-1597182290881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-c8e2a15a-3ff3-460e-9cdc-bb7c767b53f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-bed2caad-3775-41ad-972f-d9818091e386,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-ad6c69ae-2a63-4a09-8945-40316ce6ca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-0f3203c2-c398-4c3d-9c97-16b899660008,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-b460796a-a06a-4bfa-8923-c62596cf5537,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-3ddf643d-c174-464e-aeaf-52ee958729c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-c3651b2e-a430-4f0d-998c-be23d14cbe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-ae3be9a2-3d7b-420d-a9b3-2f45fee79aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761296651-172.17.0.12-1597182290881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-c8e2a15a-3ff3-460e-9cdc-bb7c767b53f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-bed2caad-3775-41ad-972f-d9818091e386,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-ad6c69ae-2a63-4a09-8945-40316ce6ca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-0f3203c2-c398-4c3d-9c97-16b899660008,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-b460796a-a06a-4bfa-8923-c62596cf5537,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-3ddf643d-c174-464e-aeaf-52ee958729c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-c3651b2e-a430-4f0d-998c-be23d14cbe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-ae3be9a2-3d7b-420d-a9b3-2f45fee79aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306891981-172.17.0.12-1597183000100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38919,DS-051c367e-d9bb-4dfa-888d-97bff48df870,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-a7a24871-c5ed-4aa7-8801-b5f577bb98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-17c63a27-746e-45f5-a601-7ecc119f838b,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-6892f324-9b3d-4fc9-91ce-b9e3a18f6ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-3de7a9f4-9705-4006-9a75-cfd5f4bb1bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-1523e3ad-fdb7-4bb8-9ebd-e87a5075006b,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-898489d0-4530-46d8-8ad9-e19d034af26b,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-98ffdad2-ffde-4f01-b20f-f6df6ef1242a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306891981-172.17.0.12-1597183000100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38919,DS-051c367e-d9bb-4dfa-888d-97bff48df870,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-a7a24871-c5ed-4aa7-8801-b5f577bb98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-17c63a27-746e-45f5-a601-7ecc119f838b,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-6892f324-9b3d-4fc9-91ce-b9e3a18f6ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-3de7a9f4-9705-4006-9a75-cfd5f4bb1bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-1523e3ad-fdb7-4bb8-9ebd-e87a5075006b,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-898489d0-4530-46d8-8ad9-e19d034af26b,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-98ffdad2-ffde-4f01-b20f-f6df6ef1242a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613432241-172.17.0.12-1597183468448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45721,DS-c3df2c44-968e-49ad-b2eb-f9248ed7e7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-d0f1e15b-5c2a-4b92-8c89-f027868a9326,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-b699c8b0-2a85-48e0-b59f-f81b9e252d38,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-1c38d14e-cbcb-427b-a3af-0f96e089b699,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f2c39f74-8de3-44a5-afb7-cc97f5ef0a15,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-8229a51d-62c7-4f74-a0fd-ffacd4c88d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-8db011db-c2be-4e5c-91e1-022bc21134be,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-f1edeb55-42ef-4291-877b-cfa4cc9c7430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613432241-172.17.0.12-1597183468448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45721,DS-c3df2c44-968e-49ad-b2eb-f9248ed7e7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-d0f1e15b-5c2a-4b92-8c89-f027868a9326,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-b699c8b0-2a85-48e0-b59f-f81b9e252d38,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-1c38d14e-cbcb-427b-a3af-0f96e089b699,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f2c39f74-8de3-44a5-afb7-cc97f5ef0a15,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-8229a51d-62c7-4f74-a0fd-ffacd4c88d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-8db011db-c2be-4e5c-91e1-022bc21134be,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-f1edeb55-42ef-4291-877b-cfa4cc9c7430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779732206-172.17.0.12-1597184073241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-0acae810-abd2-4e1a-ba27-5a33c5ffb26b,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-0cff950f-bb86-4900-b6d1-a544732a6a19,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-38f62d76-d978-43a9-8877-abce494c45f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-ac966d4a-e0e6-4ef7-8b22-cd7032d49c30,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-5270c373-091f-4549-90f8-700948478262,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-f5ee2d6c-d3b2-490f-86b4-d2be8edea2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-27e9e3fb-c9da-4287-9fb0-886d241b576a,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-bff6f2f6-5356-4d16-b236-736a0bd0c8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779732206-172.17.0.12-1597184073241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-0acae810-abd2-4e1a-ba27-5a33c5ffb26b,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-0cff950f-bb86-4900-b6d1-a544732a6a19,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-38f62d76-d978-43a9-8877-abce494c45f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-ac966d4a-e0e6-4ef7-8b22-cd7032d49c30,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-5270c373-091f-4549-90f8-700948478262,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-f5ee2d6c-d3b2-490f-86b4-d2be8edea2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-27e9e3fb-c9da-4287-9fb0-886d241b576a,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-bff6f2f6-5356-4d16-b236-736a0bd0c8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288622598-172.17.0.12-1597184886585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-60a6cc40-c4c3-49b2-90f2-bac30a782011,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-4cb0ba57-d753-43dd-b88f-1be6af1eef0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-f54896d4-93b4-4095-ba5a-372afdc434e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-6e253103-1278-4f85-b766-ad669836dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-d36b05a1-78a7-4eb9-b10e-eb402ea0e104,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-f4525088-0369-421e-a2b9-a8816442a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-249a9c17-368f-4662-9a06-f3b422528ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-3f82ee40-3eec-419f-ae28-03ed7df2fc58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288622598-172.17.0.12-1597184886585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-60a6cc40-c4c3-49b2-90f2-bac30a782011,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-4cb0ba57-d753-43dd-b88f-1be6af1eef0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-f54896d4-93b4-4095-ba5a-372afdc434e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-6e253103-1278-4f85-b766-ad669836dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-d36b05a1-78a7-4eb9-b10e-eb402ea0e104,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-f4525088-0369-421e-a2b9-a8816442a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-249a9c17-368f-4662-9a06-f3b422528ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-3f82ee40-3eec-419f-ae28-03ed7df2fc58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208240234-172.17.0.12-1597185250150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37549,DS-6599158f-bdb9-4ed0-8bee-fa019e31abf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-7821559b-86b7-475f-b74b-5d894be839ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-c5443b6b-ab80-4f19-b347-52ecd567dc81,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-745b73ec-7fc9-4890-b885-a9058340fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-b28ebdc6-e465-45a4-8ee2-955d0e493139,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-8e9dec2f-b7c8-4786-8329-b6f1cff6db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-362fda20-6e2d-4c7f-916c-bf76976aa1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-fd1097fe-755c-4fea-bc4a-949533957b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208240234-172.17.0.12-1597185250150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37549,DS-6599158f-bdb9-4ed0-8bee-fa019e31abf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-7821559b-86b7-475f-b74b-5d894be839ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-c5443b6b-ab80-4f19-b347-52ecd567dc81,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-745b73ec-7fc9-4890-b885-a9058340fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-b28ebdc6-e465-45a4-8ee2-955d0e493139,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-8e9dec2f-b7c8-4786-8329-b6f1cff6db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-362fda20-6e2d-4c7f-916c-bf76976aa1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-fd1097fe-755c-4fea-bc4a-949533957b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5202
