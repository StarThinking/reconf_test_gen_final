reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782433707-172.17.0.8-1597146182648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38418,DS-6f0ebc5f-dcfc-478a-bea4-bd4ed5435988,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-e7dc5b0a-9a27-48d3-a95e-47d6e569e9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-6980b042-c7b4-455f-b0ab-5753f0fd438d,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-e9684e65-217c-4d37-a6a0-51dd48782aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-23970150-f065-404e-956d-c70c39732c07,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-f184d10c-cccf-4bae-a5a2-52d22de8c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-30fa1edc-03d5-44a4-a8bc-b32eab9f7007,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-e8d6cf68-7d0c-47e1-a306-370dc340e97c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782433707-172.17.0.8-1597146182648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38418,DS-6f0ebc5f-dcfc-478a-bea4-bd4ed5435988,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-e7dc5b0a-9a27-48d3-a95e-47d6e569e9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-6980b042-c7b4-455f-b0ab-5753f0fd438d,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-e9684e65-217c-4d37-a6a0-51dd48782aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-23970150-f065-404e-956d-c70c39732c07,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-f184d10c-cccf-4bae-a5a2-52d22de8c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-30fa1edc-03d5-44a4-a8bc-b32eab9f7007,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-e8d6cf68-7d0c-47e1-a306-370dc340e97c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666205901-172.17.0.8-1597146502374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41589,DS-38d56b47-2834-4dfc-b44e-bc02ac91f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-6a2e108d-b363-44de-ade8-806e9828b01f,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-1fac2d60-91e6-4d0b-bdb8-1c7e73ee667b,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-21f46dde-d1ea-4bd9-ab0d-bba0ae87a2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-16a448c8-e5b3-4530-a13e-b4b2b1b2fca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-ad2bf71d-5d2e-4f53-9e7f-285e5c9fb5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-ff9b6d6a-519e-4abb-b6ec-09894cbf93fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-71c4101b-95fa-48a8-9400-499259e5eb7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666205901-172.17.0.8-1597146502374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41589,DS-38d56b47-2834-4dfc-b44e-bc02ac91f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-6a2e108d-b363-44de-ade8-806e9828b01f,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-1fac2d60-91e6-4d0b-bdb8-1c7e73ee667b,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-21f46dde-d1ea-4bd9-ab0d-bba0ae87a2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-16a448c8-e5b3-4530-a13e-b4b2b1b2fca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-ad2bf71d-5d2e-4f53-9e7f-285e5c9fb5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-ff9b6d6a-519e-4abb-b6ec-09894cbf93fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-71c4101b-95fa-48a8-9400-499259e5eb7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894054499-172.17.0.8-1597146682733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-58490b7e-a91a-44be-bb6a-7f9a39ff38e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-cb6d1cd3-19a3-4f58-944a-a197fe9d1aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-fe0eba52-131e-4a44-805c-0e84d6ffc5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-37ec8440-e1c0-4d7d-ac85-8cd12f29558b,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-f7404ae1-a93f-4c8f-803e-0eec1a22127c,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-89f42da6-9798-4377-821f-ba96d433a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-bef93e32-db9b-4f2c-9ef6-197689bd17db,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-d6eb5853-6bf4-4262-a1ff-dbe78c55291e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894054499-172.17.0.8-1597146682733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-58490b7e-a91a-44be-bb6a-7f9a39ff38e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-cb6d1cd3-19a3-4f58-944a-a197fe9d1aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-fe0eba52-131e-4a44-805c-0e84d6ffc5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-37ec8440-e1c0-4d7d-ac85-8cd12f29558b,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-f7404ae1-a93f-4c8f-803e-0eec1a22127c,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-89f42da6-9798-4377-821f-ba96d433a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-bef93e32-db9b-4f2c-9ef6-197689bd17db,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-d6eb5853-6bf4-4262-a1ff-dbe78c55291e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576747076-172.17.0.8-1597146752390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44342,DS-c34bfab9-cc75-4185-ba4e-eea46066c611,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-549e928a-c7dd-429a-b81f-5c58472694f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-146049b7-b007-438b-a611-0cb28fc9197d,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-108c33d3-2e19-4cb3-a239-f395d9d47e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-06aa412d-8d92-4bd9-971b-2284afd2b777,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-1ce4d26d-e289-4ee3-9144-4a00ddb03ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-87912b7d-2d9d-4079-af36-9d0c353b9347,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-a14c070d-7e3d-4008-8182-de49b30cdaa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576747076-172.17.0.8-1597146752390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44342,DS-c34bfab9-cc75-4185-ba4e-eea46066c611,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-549e928a-c7dd-429a-b81f-5c58472694f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-146049b7-b007-438b-a611-0cb28fc9197d,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-108c33d3-2e19-4cb3-a239-f395d9d47e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-06aa412d-8d92-4bd9-971b-2284afd2b777,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-1ce4d26d-e289-4ee3-9144-4a00ddb03ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-87912b7d-2d9d-4079-af36-9d0c353b9347,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-a14c070d-7e3d-4008-8182-de49b30cdaa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472721068-172.17.0.8-1597146898462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-bc61d996-a31a-4703-b4a1-7494ec74d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-4153c585-2943-4dc9-a22a-81f80c0a60e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-608c3d27-cc39-49b9-8a44-bc21acdab1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-7c2fe6ea-f50f-4e1a-80cc-bf5962b61480,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-c25b5fbd-76ad-40f0-8d02-25e619a37a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-9140eaa4-60b0-4156-a568-b2a946dfa285,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-f0595382-20f0-40b9-85ce-a02cb473b794,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-e4229730-d1ac-493d-9c4e-670bf43340c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472721068-172.17.0.8-1597146898462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-bc61d996-a31a-4703-b4a1-7494ec74d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-4153c585-2943-4dc9-a22a-81f80c0a60e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-608c3d27-cc39-49b9-8a44-bc21acdab1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-7c2fe6ea-f50f-4e1a-80cc-bf5962b61480,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-c25b5fbd-76ad-40f0-8d02-25e619a37a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-9140eaa4-60b0-4156-a568-b2a946dfa285,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-f0595382-20f0-40b9-85ce-a02cb473b794,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-e4229730-d1ac-493d-9c4e-670bf43340c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856837809-172.17.0.8-1597147003247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-5abc6890-1963-4ab1-9510-294b90943b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-2494a0b9-0706-4979-8009-ab78536342d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-cffa0214-c3e5-4c10-b1cf-646192bc32c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-77aeba4d-6ec4-4196-9b05-c720e8232903,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-a5d92835-3843-4158-9101-3f740dfe235f,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-a8c839ad-9332-433c-95d9-2c8aadbc80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-9f2d36a7-e20f-4b46-8465-2d8cadd70ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-e3fcdd89-44ec-4735-87cb-847be8179cd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856837809-172.17.0.8-1597147003247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-5abc6890-1963-4ab1-9510-294b90943b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-2494a0b9-0706-4979-8009-ab78536342d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-cffa0214-c3e5-4c10-b1cf-646192bc32c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-77aeba4d-6ec4-4196-9b05-c720e8232903,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-a5d92835-3843-4158-9101-3f740dfe235f,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-a8c839ad-9332-433c-95d9-2c8aadbc80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-9f2d36a7-e20f-4b46-8465-2d8cadd70ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-e3fcdd89-44ec-4735-87cb-847be8179cd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133629750-172.17.0.8-1597147073495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36885,DS-11dd05e3-3ad5-4be8-8aaa-a6f48992dd24,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-cca2a2df-8147-4a9a-be1f-43a099e4a7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-a50c491f-daa4-4f45-bdcf-dfa828c49073,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-159afff4-ad45-4d91-a2b4-1d2a59a18860,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-6fa94f4d-e56a-47d4-bd7e-eb4783962958,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-260307d2-c6c6-425d-ad14-d92953573bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-6a314e99-df27-4fae-8d61-553eaf7b5f14,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-3d5e8c55-4a98-4631-9ec8-aaabbb816f0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133629750-172.17.0.8-1597147073495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36885,DS-11dd05e3-3ad5-4be8-8aaa-a6f48992dd24,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-cca2a2df-8147-4a9a-be1f-43a099e4a7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-a50c491f-daa4-4f45-bdcf-dfa828c49073,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-159afff4-ad45-4d91-a2b4-1d2a59a18860,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-6fa94f4d-e56a-47d4-bd7e-eb4783962958,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-260307d2-c6c6-425d-ad14-d92953573bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-6a314e99-df27-4fae-8d61-553eaf7b5f14,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-3d5e8c55-4a98-4631-9ec8-aaabbb816f0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388556537-172.17.0.8-1597147475216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-9bfad1fc-c0e8-4c68-b174-e7b81915e775,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-c1a9c22f-1e6d-4372-9125-4146c9ab96e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-54ff1fe6-24c2-41d4-b20b-8e076e456931,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-0529476c-467a-4022-a6b7-1a661f6c3fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-32d10255-2b7e-42a8-bab2-ebc4d7c13c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-56b6d49d-4984-4c86-be87-3a105068c817,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-067ac8ed-5a48-43a7-b1d8-5ebbb86e7c55,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-44799538-7003-48c4-baef-a597a9dc8ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388556537-172.17.0.8-1597147475216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-9bfad1fc-c0e8-4c68-b174-e7b81915e775,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-c1a9c22f-1e6d-4372-9125-4146c9ab96e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-54ff1fe6-24c2-41d4-b20b-8e076e456931,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-0529476c-467a-4022-a6b7-1a661f6c3fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-32d10255-2b7e-42a8-bab2-ebc4d7c13c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-56b6d49d-4984-4c86-be87-3a105068c817,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-067ac8ed-5a48-43a7-b1d8-5ebbb86e7c55,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-44799538-7003-48c4-baef-a597a9dc8ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286648216-172.17.0.8-1597147514744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34064,DS-e389695b-32d1-44cb-9450-6de2d0cc7841,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-9cb72317-1906-4292-af9b-233ccadb7001,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-5713036a-3e14-4f38-a6ea-d7705cd5ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-78b2f94b-05fc-4813-9b44-ef910e9464ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-865d5eba-6404-43f9-bdeb-6fe0ad9c3845,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-e4afa157-5b93-4a25-9863-f9704e4bdd58,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-0450c5bc-a450-4c20-932e-a6cff4728db0,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-9b1b2296-e03f-46d4-9100-f848da492a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286648216-172.17.0.8-1597147514744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34064,DS-e389695b-32d1-44cb-9450-6de2d0cc7841,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-9cb72317-1906-4292-af9b-233ccadb7001,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-5713036a-3e14-4f38-a6ea-d7705cd5ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-78b2f94b-05fc-4813-9b44-ef910e9464ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-865d5eba-6404-43f9-bdeb-6fe0ad9c3845,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-e4afa157-5b93-4a25-9863-f9704e4bdd58,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-0450c5bc-a450-4c20-932e-a6cff4728db0,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-9b1b2296-e03f-46d4-9100-f848da492a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561525526-172.17.0.8-1597147877882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33604,DS-41547bbc-8598-4a0c-b10c-6319a052a5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-0088c610-47b6-4464-bc86-3381b1d1af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-d1165d6f-0ca7-4009-8d05-f4c8f1b37817,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-fedf7bdb-b558-4324-8ae2-999db6af8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-50ca800d-6007-4f44-97db-e70c4f289360,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-4fdc35c0-06e0-4e18-8438-b56de2f070a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-78f44e5f-6c34-4956-9ad2-0fa0c32ecdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-c14f4ad8-a652-45bb-9617-c6bb670464d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561525526-172.17.0.8-1597147877882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33604,DS-41547bbc-8598-4a0c-b10c-6319a052a5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-0088c610-47b6-4464-bc86-3381b1d1af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-d1165d6f-0ca7-4009-8d05-f4c8f1b37817,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-fedf7bdb-b558-4324-8ae2-999db6af8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-50ca800d-6007-4f44-97db-e70c4f289360,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-4fdc35c0-06e0-4e18-8438-b56de2f070a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-78f44e5f-6c34-4956-9ad2-0fa0c32ecdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-c14f4ad8-a652-45bb-9617-c6bb670464d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997408663-172.17.0.8-1597148293259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-cf6ca8b9-8715-4dd4-adc1-9b9f213f575c,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-beed8e63-a945-4129-bd7f-e4ac66281ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-48dd8722-f0bd-44a4-8541-ea0556423f61,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-8348297b-d3c7-4963-87b6-e277dd2ebe04,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-1a51b1d4-e3ab-4d64-9436-a399ad4b073c,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-f06dcb99-e40b-4716-8cc4-e1f5cee0aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-de5da813-a4b6-46fc-a13a-3d8134ac5b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-eddf62b7-c9a4-428d-b9d3-e32d7a15de51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997408663-172.17.0.8-1597148293259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-cf6ca8b9-8715-4dd4-adc1-9b9f213f575c,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-beed8e63-a945-4129-bd7f-e4ac66281ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-48dd8722-f0bd-44a4-8541-ea0556423f61,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-8348297b-d3c7-4963-87b6-e277dd2ebe04,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-1a51b1d4-e3ab-4d64-9436-a399ad4b073c,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-f06dcb99-e40b-4716-8cc4-e1f5cee0aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-de5da813-a4b6-46fc-a13a-3d8134ac5b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-eddf62b7-c9a4-428d-b9d3-e32d7a15de51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257356771-172.17.0.8-1597148440482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-ab1bc829-97dc-4d18-84d5-3707f7c48932,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-e7cf661b-1076-4952-8088-7014da0448fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-d764c2c3-34cf-4583-ac4f-e8a637a3ac23,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-0e5b5f2a-a7d0-481f-afc6-4988da62a5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-384ecee0-6d90-4197-81c0-abe5a15297d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-b3cd0242-eb25-4402-8c52-41d5816f8a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-502c698d-f0c6-4428-909d-11e5585369a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-470d5d08-2546-4786-beb7-8dde4263eff0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257356771-172.17.0.8-1597148440482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-ab1bc829-97dc-4d18-84d5-3707f7c48932,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-e7cf661b-1076-4952-8088-7014da0448fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-d764c2c3-34cf-4583-ac4f-e8a637a3ac23,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-0e5b5f2a-a7d0-481f-afc6-4988da62a5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-384ecee0-6d90-4197-81c0-abe5a15297d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-b3cd0242-eb25-4402-8c52-41d5816f8a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-502c698d-f0c6-4428-909d-11e5585369a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-470d5d08-2546-4786-beb7-8dde4263eff0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706214998-172.17.0.8-1597148544810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35375,DS-e2510aef-e2d7-4e61-a206-05f74879f1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-246349be-4ff5-4dfd-b910-9d94f7ef5cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-678e8135-4307-4279-9f9b-f07765448b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-1ccec402-4b52-4292-a62e-1a161c1ad68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-58cf2966-c2f5-421b-b10f-17a882b490ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-cbee516d-dc83-454d-bbe2-ead49eda0aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-91d4a8b6-abde-4d5a-8730-123297cf040c,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-6e189bfb-ee5d-45cc-a133-e17768beb878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706214998-172.17.0.8-1597148544810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35375,DS-e2510aef-e2d7-4e61-a206-05f74879f1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-246349be-4ff5-4dfd-b910-9d94f7ef5cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-678e8135-4307-4279-9f9b-f07765448b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-1ccec402-4b52-4292-a62e-1a161c1ad68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-58cf2966-c2f5-421b-b10f-17a882b490ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-cbee516d-dc83-454d-bbe2-ead49eda0aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-91d4a8b6-abde-4d5a-8730-123297cf040c,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-6e189bfb-ee5d-45cc-a133-e17768beb878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825921855-172.17.0.8-1597148624298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-0f694206-9b74-4926-b83f-38f23761ff85,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-b8e3f7fc-9555-4db1-a765-47d5b9532872,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-4b01a7ee-93d3-424e-988e-9ca644817d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-0d29df4f-94ac-45be-9f29-c3a1b3bd6a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-e66c7cb0-57d6-456f-9ba0-f1b307b27658,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-7d72dd2b-8f07-44fd-a94e-35c1a4fc76aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-c11ebb2f-9c77-491a-8d24-a4c481c1e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-6bc8431b-cd39-4046-88fb-cead18c9f841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825921855-172.17.0.8-1597148624298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-0f694206-9b74-4926-b83f-38f23761ff85,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-b8e3f7fc-9555-4db1-a765-47d5b9532872,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-4b01a7ee-93d3-424e-988e-9ca644817d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-0d29df4f-94ac-45be-9f29-c3a1b3bd6a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-e66c7cb0-57d6-456f-9ba0-f1b307b27658,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-7d72dd2b-8f07-44fd-a94e-35c1a4fc76aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-c11ebb2f-9c77-491a-8d24-a4c481c1e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-6bc8431b-cd39-4046-88fb-cead18c9f841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172627668-172.17.0.8-1597148688494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-35addd2b-83a6-43ee-8023-6fecc8adc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-3deec70f-664f-482f-8dd1-fdf6a773f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-5893ecea-41e5-4593-84f2-2b620b928c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-44212b69-923c-4f0b-bb57-6d489f6d63fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-af279aef-b10a-44d5-81bf-a5272b5cc71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-62ac6bae-7f94-4372-8aab-350146e78ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-1e9969aa-2c02-4566-b245-5bf770d27e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-5e954fbe-f8e4-42a0-9f21-f27f6a9d9dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172627668-172.17.0.8-1597148688494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-35addd2b-83a6-43ee-8023-6fecc8adc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-3deec70f-664f-482f-8dd1-fdf6a773f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-5893ecea-41e5-4593-84f2-2b620b928c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-44212b69-923c-4f0b-bb57-6d489f6d63fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-af279aef-b10a-44d5-81bf-a5272b5cc71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-62ac6bae-7f94-4372-8aab-350146e78ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-1e9969aa-2c02-4566-b245-5bf770d27e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-5e954fbe-f8e4-42a0-9f21-f27f6a9d9dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11703789-172.17.0.8-1597148727576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-09df7389-8027-4f77-b01c-a8341e9990e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-615bf238-6890-49de-94ea-a81e2d2ec7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-69c03a8d-e139-4330-b242-40a5f644fa17,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-dbc7217b-17b2-4c66-8664-46cdd6336dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-5af5851c-fb6d-48a8-97cd-af9368d9acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-c1dba76f-a453-4fa6-a8ec-1f52b680ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-66b87ffc-0055-452b-8926-e9cba01a18b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-e614e7b7-541f-4071-9877-bd4746e70774,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11703789-172.17.0.8-1597148727576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-09df7389-8027-4f77-b01c-a8341e9990e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-615bf238-6890-49de-94ea-a81e2d2ec7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-69c03a8d-e139-4330-b242-40a5f644fa17,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-dbc7217b-17b2-4c66-8664-46cdd6336dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-5af5851c-fb6d-48a8-97cd-af9368d9acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-c1dba76f-a453-4fa6-a8ec-1f52b680ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-66b87ffc-0055-452b-8926-e9cba01a18b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-e614e7b7-541f-4071-9877-bd4746e70774,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909800910-172.17.0.8-1597149174264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44715,DS-aaa3f474-051a-407b-9c53-9b646821ac02,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-211ab601-7c5f-4e19-9b8b-940e85484baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-3de49eb1-9052-46b4-a96c-43c23efc27e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-15d9b675-55f8-470a-a153-f79d5a202b75,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-e7d0511e-c6eb-49f2-88a3-47a1f6130d79,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-84c43602-66df-491b-aa6b-7adc3d43dfad,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-d5fffd62-2589-4afb-b2f5-96cdc75fe913,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-d68a29f4-a020-4069-907f-e4ab7d30d81a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909800910-172.17.0.8-1597149174264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44715,DS-aaa3f474-051a-407b-9c53-9b646821ac02,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-211ab601-7c5f-4e19-9b8b-940e85484baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-3de49eb1-9052-46b4-a96c-43c23efc27e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-15d9b675-55f8-470a-a153-f79d5a202b75,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-e7d0511e-c6eb-49f2-88a3-47a1f6130d79,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-84c43602-66df-491b-aa6b-7adc3d43dfad,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-d5fffd62-2589-4afb-b2f5-96cdc75fe913,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-d68a29f4-a020-4069-907f-e4ab7d30d81a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369364901-172.17.0.8-1597149677708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41027,DS-525c58dd-9624-48d1-b35c-0b85aced3c81,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-b08da76d-b5c4-4768-9b76-04f3ed0a0b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-05e78be2-788f-4481-be65-154be3e16d65,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-4c2ebdf5-6b2f-45f6-be95-ea01bcc6c947,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-f4d56d3e-ee6c-4452-9d4c-0a01da260578,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-14851254-8ed8-4d7e-8a64-3ed82e12c721,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-22cbb5c2-7bd6-40bb-8349-ee0fa74cb694,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-2906e514-539a-4509-bc62-5a67255b446b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369364901-172.17.0.8-1597149677708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41027,DS-525c58dd-9624-48d1-b35c-0b85aced3c81,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-b08da76d-b5c4-4768-9b76-04f3ed0a0b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-05e78be2-788f-4481-be65-154be3e16d65,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-4c2ebdf5-6b2f-45f6-be95-ea01bcc6c947,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-f4d56d3e-ee6c-4452-9d4c-0a01da260578,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-14851254-8ed8-4d7e-8a64-3ed82e12c721,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-22cbb5c2-7bd6-40bb-8349-ee0fa74cb694,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-2906e514-539a-4509-bc62-5a67255b446b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737629417-172.17.0.8-1597149908345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-8f442ae7-5c33-42aa-b2d9-9daa16ad62b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-1fcd193f-9cd4-4f8b-9bae-09a044e158d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-f4103324-0e9a-4a7e-9a0b-8479b760dccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-e059ffc2-aab0-4d0f-af33-83630aa6fe6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-fda5da93-7d44-467a-b2ce-01b4a2c7ca2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-5dc60746-e093-4c81-b1a7-db2158b7683d,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-211de432-8185-48e7-8dd7-e5e0de101f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-0076b0cd-fa23-4649-b425-e4017160f3fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737629417-172.17.0.8-1597149908345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-8f442ae7-5c33-42aa-b2d9-9daa16ad62b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-1fcd193f-9cd4-4f8b-9bae-09a044e158d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-f4103324-0e9a-4a7e-9a0b-8479b760dccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-e059ffc2-aab0-4d0f-af33-83630aa6fe6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-fda5da93-7d44-467a-b2ce-01b4a2c7ca2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-5dc60746-e093-4c81-b1a7-db2158b7683d,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-211de432-8185-48e7-8dd7-e5e0de101f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-0076b0cd-fa23-4649-b425-e4017160f3fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515138944-172.17.0.8-1597150060858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-a008b18c-caad-4189-9349-05e47c943e11,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-76a71ea6-969a-4f2b-8152-3f782fd107cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-7a71bac7-2151-4c8d-af3b-f1e9106e5560,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-c172ab35-5921-4500-a867-547a3f430985,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-48637f68-1d11-4501-b94c-56abc079e090,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-368ca35a-88ae-4530-ae8a-c2f66cc34ede,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-1b9fd176-20d1-42e5-ad55-f600369a8a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-10988077-9e6f-4ece-9276-d2cfdda7513c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515138944-172.17.0.8-1597150060858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-a008b18c-caad-4189-9349-05e47c943e11,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-76a71ea6-969a-4f2b-8152-3f782fd107cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-7a71bac7-2151-4c8d-af3b-f1e9106e5560,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-c172ab35-5921-4500-a867-547a3f430985,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-48637f68-1d11-4501-b94c-56abc079e090,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-368ca35a-88ae-4530-ae8a-c2f66cc34ede,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-1b9fd176-20d1-42e5-ad55-f600369a8a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-10988077-9e6f-4ece-9276-d2cfdda7513c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404381409-172.17.0.8-1597150495207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-91f45b3d-83d7-4f95-9759-c2ba1584da96,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-2245ee01-dcb4-43a9-b511-c8d835889b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-afbd8661-f721-4490-bc5a-9af6df3dcb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-f961325b-340b-43e6-a3ad-9fc81b10a9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-681107f3-4ff0-4776-a765-889ea77340e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-b185cc53-a6dd-4786-84cd-efe2497ff38d,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-1602c964-f8e4-4231-8c76-4a0ecc0f1d83,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-af267c71-9558-4d30-b05c-1a9685e5d9c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404381409-172.17.0.8-1597150495207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-91f45b3d-83d7-4f95-9759-c2ba1584da96,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-2245ee01-dcb4-43a9-b511-c8d835889b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-afbd8661-f721-4490-bc5a-9af6df3dcb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-f961325b-340b-43e6-a3ad-9fc81b10a9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-681107f3-4ff0-4776-a765-889ea77340e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-b185cc53-a6dd-4786-84cd-efe2497ff38d,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-1602c964-f8e4-4231-8c76-4a0ecc0f1d83,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-af267c71-9558-4d30-b05c-1a9685e5d9c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719631543-172.17.0.8-1597150561790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-95ffa276-c8d0-4176-afe4-81331c67562d,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-3ccdb7c6-42f7-4543-8e85-cd9d1e6db70f,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-d8273028-7030-4527-b5b2-6b54f5424655,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-fb8d27d6-cd52-4084-963c-d2cdedc87401,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-6a5d3cf8-ebd3-4b75-a69d-de6c9148529d,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-bfaa3a27-ae8a-4f1f-ad12-10e67a774085,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-3ee6680e-dbb1-4e16-8bfe-1ea4ddcd0dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-8da1a7a7-4322-43ea-8bd2-91670b207093,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719631543-172.17.0.8-1597150561790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-95ffa276-c8d0-4176-afe4-81331c67562d,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-3ccdb7c6-42f7-4543-8e85-cd9d1e6db70f,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-d8273028-7030-4527-b5b2-6b54f5424655,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-fb8d27d6-cd52-4084-963c-d2cdedc87401,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-6a5d3cf8-ebd3-4b75-a69d-de6c9148529d,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-bfaa3a27-ae8a-4f1f-ad12-10e67a774085,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-3ee6680e-dbb1-4e16-8bfe-1ea4ddcd0dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-8da1a7a7-4322-43ea-8bd2-91670b207093,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112986356-172.17.0.8-1597151312227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44015,DS-7a3ae3f6-455f-4837-8810-5f26c39dade9,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-4f22fb11-93c8-4779-af19-fdcf5c973eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-2352462a-30ad-4c5c-88f2-701d53d91d76,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-43e1840c-d8f5-4f51-a840-188557b82f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-36dba8c7-b0fa-40b5-ba70-7111ce12ca33,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-f1fab791-80ab-4df7-b64c-b00f8489b814,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-68a13036-c625-4eca-8fe5-5bc8f4a0c72c,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-31239d4a-7776-493c-abee-1c5c07f1a337,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112986356-172.17.0.8-1597151312227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44015,DS-7a3ae3f6-455f-4837-8810-5f26c39dade9,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-4f22fb11-93c8-4779-af19-fdcf5c973eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-2352462a-30ad-4c5c-88f2-701d53d91d76,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-43e1840c-d8f5-4f51-a840-188557b82f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-36dba8c7-b0fa-40b5-ba70-7111ce12ca33,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-f1fab791-80ab-4df7-b64c-b00f8489b814,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-68a13036-c625-4eca-8fe5-5bc8f4a0c72c,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-31239d4a-7776-493c-abee-1c5c07f1a337,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300924679-172.17.0.8-1597151348310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-f8ce43e9-bb76-4895-b9f4-3dee244dea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-65c41e6e-dcb0-4d92-9446-301196ac8a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-ab61cb35-d771-4b9f-a59c-5073665c5230,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-19d75f81-2ac5-4d5f-aa64-04e7f7614dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-342f5f4f-2cc4-4f0f-be5b-ed7f2b0e1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-c4cc498e-3c38-4e50-aa26-09c962662c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-dfb4a0bc-0766-495e-93e1-596ab11a9404,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-61fc7c18-4341-4c72-9a17-798b73fb8b23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300924679-172.17.0.8-1597151348310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-f8ce43e9-bb76-4895-b9f4-3dee244dea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-65c41e6e-dcb0-4d92-9446-301196ac8a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-ab61cb35-d771-4b9f-a59c-5073665c5230,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-19d75f81-2ac5-4d5f-aa64-04e7f7614dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-342f5f4f-2cc4-4f0f-be5b-ed7f2b0e1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-c4cc498e-3c38-4e50-aa26-09c962662c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-dfb4a0bc-0766-495e-93e1-596ab11a9404,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-61fc7c18-4341-4c72-9a17-798b73fb8b23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5381
