reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670575729-172.17.0.21-1597188681218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42874,DS-2dfb92d0-363a-4c84-bd1c-650fbcb344fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-67c72588-d0b5-41ad-9e41-128ad44b506b,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-9c4b334c-f373-43d0-b9b0-97cb2b4b2bca,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-77a8c199-6235-4656-bf52-81f0b7c20a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-3ed1a9f6-8c29-46f2-8a00-dbc8f96d89d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-f785128f-0509-4f45-b0e1-86539d932d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-e48a22c5-3f24-44e3-b8d0-2f3bfd0ac73e,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-71f06801-6e82-4779-9996-063ad5de6772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670575729-172.17.0.21-1597188681218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42874,DS-2dfb92d0-363a-4c84-bd1c-650fbcb344fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-67c72588-d0b5-41ad-9e41-128ad44b506b,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-9c4b334c-f373-43d0-b9b0-97cb2b4b2bca,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-77a8c199-6235-4656-bf52-81f0b7c20a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-3ed1a9f6-8c29-46f2-8a00-dbc8f96d89d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-f785128f-0509-4f45-b0e1-86539d932d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-e48a22c5-3f24-44e3-b8d0-2f3bfd0ac73e,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-71f06801-6e82-4779-9996-063ad5de6772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163485357-172.17.0.21-1597188968587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-2ba05b6d-f9b2-4afa-a907-1fc25e77fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-a8fd56dc-56f8-43c3-8eb7-9e193b541582,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-dfe148c8-24e3-470a-ba13-a6e0c4ad459e,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-6d4a4ef7-0a24-4e7c-980c-15ccfb4e072b,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-300f3f99-4daf-4c9d-a648-ce405dbd04c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-eb398778-30ff-4dda-b0d2-6c125bccceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2397484d-0b60-493e-a498-68b89c719e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-a8337b3c-6ff5-4c6b-bc3b-ec57eac43d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163485357-172.17.0.21-1597188968587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-2ba05b6d-f9b2-4afa-a907-1fc25e77fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-a8fd56dc-56f8-43c3-8eb7-9e193b541582,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-dfe148c8-24e3-470a-ba13-a6e0c4ad459e,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-6d4a4ef7-0a24-4e7c-980c-15ccfb4e072b,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-300f3f99-4daf-4c9d-a648-ce405dbd04c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-eb398778-30ff-4dda-b0d2-6c125bccceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2397484d-0b60-493e-a498-68b89c719e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-a8337b3c-6ff5-4c6b-bc3b-ec57eac43d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873644084-172.17.0.21-1597189332053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36350,DS-dad0d881-9b6c-409c-9a26-7d4c6a70f194,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-98578120-19f4-4516-83c8-7b94a1a12a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-51e980e2-a1f3-442a-b541-363e5a0ac98f,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-12681057-49a4-4773-a970-7525347d132b,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-e910d831-ac06-4eb0-b53c-99da64989474,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-6ed23b9d-3ba5-420b-8a73-9c84a2986482,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-db1505a3-8eba-49d9-a6e0-4e7d9135200e,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-224e7ad2-4da0-4805-a6d7-0e492a7b831c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873644084-172.17.0.21-1597189332053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36350,DS-dad0d881-9b6c-409c-9a26-7d4c6a70f194,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-98578120-19f4-4516-83c8-7b94a1a12a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-51e980e2-a1f3-442a-b541-363e5a0ac98f,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-12681057-49a4-4773-a970-7525347d132b,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-e910d831-ac06-4eb0-b53c-99da64989474,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-6ed23b9d-3ba5-420b-8a73-9c84a2986482,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-db1505a3-8eba-49d9-a6e0-4e7d9135200e,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-224e7ad2-4da0-4805-a6d7-0e492a7b831c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722047149-172.17.0.21-1597189722884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41833,DS-16bf5c87-dc47-43a3-a460-56be9c70055a,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-ad2b1a74-28db-4f16-aeb9-3fc93d7941ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-7c23ae4f-18e1-4b72-aa71-97a1130bf335,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-6a0bb694-ec0a-4830-8500-a57ed6374cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-83c93884-6e1f-4833-859b-12323c4a9d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-b4388251-7996-429e-99d5-dd7fc0e86750,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-42c70941-c3a7-4219-8acd-990c8d6e5433,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-ff8f958d-a3de-4c55-9593-e95aba32a86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722047149-172.17.0.21-1597189722884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41833,DS-16bf5c87-dc47-43a3-a460-56be9c70055a,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-ad2b1a74-28db-4f16-aeb9-3fc93d7941ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-7c23ae4f-18e1-4b72-aa71-97a1130bf335,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-6a0bb694-ec0a-4830-8500-a57ed6374cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-83c93884-6e1f-4833-859b-12323c4a9d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-b4388251-7996-429e-99d5-dd7fc0e86750,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-42c70941-c3a7-4219-8acd-990c8d6e5433,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-ff8f958d-a3de-4c55-9593-e95aba32a86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767352507-172.17.0.21-1597189861221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41812,DS-20e53346-d545-4f02-8fd8-5fe04f3a379f,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-dfb40e83-82b2-4368-b223-f2ae107b8ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-01e58c52-0d14-4d0a-9f3c-fa0098c21e18,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-df7faf61-fc86-4ad6-9ecc-72c9d9c4a0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-c2fc2da5-bd3c-4dfe-8e14-0717764ca257,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-334f97a6-b691-472a-9c7d-b9784c72e108,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-cca54e28-ec2b-4256-a550-e1cf2b160f53,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-6710b765-0a4c-4d26-82dc-b7d8f4b6cefb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767352507-172.17.0.21-1597189861221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41812,DS-20e53346-d545-4f02-8fd8-5fe04f3a379f,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-dfb40e83-82b2-4368-b223-f2ae107b8ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-01e58c52-0d14-4d0a-9f3c-fa0098c21e18,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-df7faf61-fc86-4ad6-9ecc-72c9d9c4a0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-c2fc2da5-bd3c-4dfe-8e14-0717764ca257,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-334f97a6-b691-472a-9c7d-b9784c72e108,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-cca54e28-ec2b-4256-a550-e1cf2b160f53,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-6710b765-0a4c-4d26-82dc-b7d8f4b6cefb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069358149-172.17.0.21-1597190553048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-f03cdeed-742e-4e26-a8cd-d9ebdde2391f,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-b8978df2-c202-41c1-83e7-3108fe46e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-a897c1da-a66d-4ef7-94a4-d85591293904,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-c15b666d-af91-4713-801a-f5c5a932ff00,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-29e243b6-815d-4d0b-9b54-1fcd3ada1398,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-832cb45b-24be-48e4-a4f6-8befe9041024,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-3814c3d0-34a2-45b4-befd-71c11e346810,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-346fc1fb-0214-463c-ad45-0d50e80f9aa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069358149-172.17.0.21-1597190553048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-f03cdeed-742e-4e26-a8cd-d9ebdde2391f,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-b8978df2-c202-41c1-83e7-3108fe46e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-a897c1da-a66d-4ef7-94a4-d85591293904,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-c15b666d-af91-4713-801a-f5c5a932ff00,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-29e243b6-815d-4d0b-9b54-1fcd3ada1398,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-832cb45b-24be-48e4-a4f6-8befe9041024,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-3814c3d0-34a2-45b4-befd-71c11e346810,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-346fc1fb-0214-463c-ad45-0d50e80f9aa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647269148-172.17.0.21-1597190873323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-05781b4d-e976-419c-a850-2c9f15bd694b,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-908a2855-a22d-457d-bc49-261fa7341270,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-e25ebc7d-8cf0-48e2-9b9d-c3d7071db387,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-df15bdec-afc3-4483-83f5-9196f9ace44a,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-bc091826-4556-4da2-b2c8-efb08aef54c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-48352e10-f3d0-42df-86c5-e21beddf64a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-984b2659-1a94-4b5f-a3bb-a707c115ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-37730da6-9fe2-4326-b235-71eaacee6c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647269148-172.17.0.21-1597190873323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-05781b4d-e976-419c-a850-2c9f15bd694b,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-908a2855-a22d-457d-bc49-261fa7341270,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-e25ebc7d-8cf0-48e2-9b9d-c3d7071db387,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-df15bdec-afc3-4483-83f5-9196f9ace44a,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-bc091826-4556-4da2-b2c8-efb08aef54c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-48352e10-f3d0-42df-86c5-e21beddf64a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-984b2659-1a94-4b5f-a3bb-a707c115ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-37730da6-9fe2-4326-b235-71eaacee6c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896694478-172.17.0.21-1597191100649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-d57a3e7d-59da-4248-ab09-80d31c8f453a,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-1d214147-f88e-4723-b597-6fc87a17c2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-4d335797-5784-4b49-b23f-565d0e1c2a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-648d6dfc-e730-4ad1-aec0-79880beddd03,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-15116379-5ffa-4482-88c9-eefde374a797,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-a9b857db-bf25-4007-bf72-21c3b92b9dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-24e547b0-28db-49ca-8508-14ef51522ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-a4ce41bc-090a-42be-ac98-2a1192692897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896694478-172.17.0.21-1597191100649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-d57a3e7d-59da-4248-ab09-80d31c8f453a,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-1d214147-f88e-4723-b597-6fc87a17c2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-4d335797-5784-4b49-b23f-565d0e1c2a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-648d6dfc-e730-4ad1-aec0-79880beddd03,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-15116379-5ffa-4482-88c9-eefde374a797,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-a9b857db-bf25-4007-bf72-21c3b92b9dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-24e547b0-28db-49ca-8508-14ef51522ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-a4ce41bc-090a-42be-ac98-2a1192692897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009213323-172.17.0.21-1597191134628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36348,DS-19f889a7-94ea-43cc-bf3c-96e683dca5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-81ddd38a-d7df-4396-b04b-5edf63ae29e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-4fe85fca-ef2f-441a-b4cc-b38e9e81a76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-e582f2c9-1f8f-47d4-a8ed-7fd43d5946b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-f015672c-6fa9-4bc8-9a3a-a75b9cda0d99,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-f353231f-6e18-42c9-bc8c-d8b7c537fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b57c7725-c6ed-4990-958d-db4b82ce4243,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-9c709543-357b-4dc9-a3e1-ba99fa84a4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009213323-172.17.0.21-1597191134628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36348,DS-19f889a7-94ea-43cc-bf3c-96e683dca5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-81ddd38a-d7df-4396-b04b-5edf63ae29e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-4fe85fca-ef2f-441a-b4cc-b38e9e81a76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-e582f2c9-1f8f-47d4-a8ed-7fd43d5946b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-f015672c-6fa9-4bc8-9a3a-a75b9cda0d99,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-f353231f-6e18-42c9-bc8c-d8b7c537fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b57c7725-c6ed-4990-958d-db4b82ce4243,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-9c709543-357b-4dc9-a3e1-ba99fa84a4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008053936-172.17.0.21-1597191202308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-92c9fe96-5dc0-47c6-a601-a72316d28f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-a989ca26-f31f-4700-8670-64280de485b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-04ba06a5-cbbb-4a26-bd5c-057b076f9a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-a96021a8-5225-4c6a-b475-fa66ebc79183,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-2d9cae1d-c5b5-4390-b8b9-c25ecadd20f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-87722b31-f430-45f8-a97a-21fc9c270a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-6551994e-db1a-4ad1-a61d-e39d9f1f2761,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-ed7b3230-ce75-447e-940e-1a5eb895efa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008053936-172.17.0.21-1597191202308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-92c9fe96-5dc0-47c6-a601-a72316d28f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-a989ca26-f31f-4700-8670-64280de485b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-04ba06a5-cbbb-4a26-bd5c-057b076f9a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-a96021a8-5225-4c6a-b475-fa66ebc79183,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-2d9cae1d-c5b5-4390-b8b9-c25ecadd20f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-87722b31-f430-45f8-a97a-21fc9c270a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-6551994e-db1a-4ad1-a61d-e39d9f1f2761,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-ed7b3230-ce75-447e-940e-1a5eb895efa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529644998-172.17.0.21-1597191429041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45214,DS-dc94c8ca-27b9-4701-a78e-62d4b5ab8994,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-4058e807-5028-44d9-8b3d-08959fc2066b,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-969c0f43-c654-4ec1-9e61-6e01243b60f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-36ca79f6-5b2b-49aa-9524-c3de9fa03b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-8219cbd7-30f9-43cf-9427-a62bda367151,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-6f4e3c61-b50e-47d6-a0f0-382daf555f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-8ed4cfb8-6253-46d0-b9e4-f200a5d900a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-5bbfc1f7-0aab-4477-b289-e18a0d68a56d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529644998-172.17.0.21-1597191429041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45214,DS-dc94c8ca-27b9-4701-a78e-62d4b5ab8994,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-4058e807-5028-44d9-8b3d-08959fc2066b,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-969c0f43-c654-4ec1-9e61-6e01243b60f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-36ca79f6-5b2b-49aa-9524-c3de9fa03b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-8219cbd7-30f9-43cf-9427-a62bda367151,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-6f4e3c61-b50e-47d6-a0f0-382daf555f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-8ed4cfb8-6253-46d0-b9e4-f200a5d900a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-5bbfc1f7-0aab-4477-b289-e18a0d68a56d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142410514-172.17.0.21-1597191750216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33217,DS-e3ce7c22-cd02-4f06-a5a8-8c136a751406,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-234dfc9c-e09c-4963-8134-18cf40ee2a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-877bfbfe-00ee-480a-bc9b-e7c3a8ac4628,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-316d0b82-0e48-4cc0-b038-ebf2cadaccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-b1daeeb0-351c-4ab7-ae44-2f2ff1182a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-c46ac579-008d-4a4b-95f1-cb1675dca032,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-eb11fe68-8cb1-48ea-8cf7-7612f9b958fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-5e80b3d1-37f9-47de-94ca-fbb51a9dc307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142410514-172.17.0.21-1597191750216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33217,DS-e3ce7c22-cd02-4f06-a5a8-8c136a751406,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-234dfc9c-e09c-4963-8134-18cf40ee2a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-877bfbfe-00ee-480a-bc9b-e7c3a8ac4628,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-316d0b82-0e48-4cc0-b038-ebf2cadaccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-b1daeeb0-351c-4ab7-ae44-2f2ff1182a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-c46ac579-008d-4a4b-95f1-cb1675dca032,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-eb11fe68-8cb1-48ea-8cf7-7612f9b958fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-5e80b3d1-37f9-47de-94ca-fbb51a9dc307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808906840-172.17.0.21-1597191820959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41692,DS-17c93d16-92be-4a41-a85c-5bb1848b495d,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-db7738e1-2354-4a3b-b1ef-5bdef4972f90,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-fdcc6c95-a35f-481c-927d-b92cba58e663,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-7e7f556f-11f8-46ef-ad9a-30c712a48498,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-f2ea18a7-e882-49c5-a247-926cce6f10cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-258f1e62-21ba-4107-b102-8e2c9f01dbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-63e41975-2e78-4ba6-adc6-5426f7bdc03c,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-39470a91-7d84-4ac7-bc6e-237839ceb8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808906840-172.17.0.21-1597191820959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41692,DS-17c93d16-92be-4a41-a85c-5bb1848b495d,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-db7738e1-2354-4a3b-b1ef-5bdef4972f90,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-fdcc6c95-a35f-481c-927d-b92cba58e663,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-7e7f556f-11f8-46ef-ad9a-30c712a48498,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-f2ea18a7-e882-49c5-a247-926cce6f10cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-258f1e62-21ba-4107-b102-8e2c9f01dbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-63e41975-2e78-4ba6-adc6-5426f7bdc03c,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-39470a91-7d84-4ac7-bc6e-237839ceb8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385633229-172.17.0.21-1597191956221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36214,DS-3b96b66d-a657-4c71-8543-103347175bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-785424f9-a275-4610-95ef-d3c56ba0ba37,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5d3a6418-1e65-43ac-b23d-7cb45d813734,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-ddb70be2-2fab-4f22-8622-684a42026c87,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-da52a291-3e39-42b2-b8bd-79bdc50ae87d,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-07b0bfeb-173c-4826-8130-ed3cc73c1879,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-a787d88e-df89-4255-8ec0-13e1ab8aa8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-143208fe-c0f9-4121-ac26-4db5413f61ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385633229-172.17.0.21-1597191956221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36214,DS-3b96b66d-a657-4c71-8543-103347175bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-785424f9-a275-4610-95ef-d3c56ba0ba37,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5d3a6418-1e65-43ac-b23d-7cb45d813734,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-ddb70be2-2fab-4f22-8622-684a42026c87,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-da52a291-3e39-42b2-b8bd-79bdc50ae87d,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-07b0bfeb-173c-4826-8130-ed3cc73c1879,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-a787d88e-df89-4255-8ec0-13e1ab8aa8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-143208fe-c0f9-4121-ac26-4db5413f61ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159623003-172.17.0.21-1597192338847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-468a64f1-d9ca-4f16-8ffc-8608135697c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-a0fa80b1-c759-4eea-a700-b54344ead7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-8573a84f-ccaa-49d7-9069-88ee8ce1ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-7d06a33f-a760-4f3d-acd4-624c57638ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-9aa07f45-7aee-4c40-96c9-b39c3c1117ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-4759c046-fc1e-46ae-bbef-0266288c8531,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-58fa5ecc-3e3d-4596-bd57-800b6f1bb569,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-226dde0f-caa5-4316-a551-19d603441806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159623003-172.17.0.21-1597192338847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-468a64f1-d9ca-4f16-8ffc-8608135697c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-a0fa80b1-c759-4eea-a700-b54344ead7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-8573a84f-ccaa-49d7-9069-88ee8ce1ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-7d06a33f-a760-4f3d-acd4-624c57638ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-9aa07f45-7aee-4c40-96c9-b39c3c1117ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-4759c046-fc1e-46ae-bbef-0266288c8531,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-58fa5ecc-3e3d-4596-bd57-800b6f1bb569,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-226dde0f-caa5-4316-a551-19d603441806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463494100-172.17.0.21-1597192411198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40020,DS-f4c10d5c-4593-4654-9211-74de2e94faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-b7795fc6-75a9-43a9-b570-33441647511d,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-93338fe6-e029-492c-a093-6cd5ebf6e475,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-e707c078-6f02-46c3-bcf0-4415e44e1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-a2c5bc11-0cab-4b4f-a6ee-f60b1a9d1d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-067ea1de-9579-4b62-9b1f-41a78a05b1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-b0b7f99b-f479-4fcf-af71-115c8bf78795,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-73b3e609-b3e9-487b-b132-75c2f3f981f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463494100-172.17.0.21-1597192411198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40020,DS-f4c10d5c-4593-4654-9211-74de2e94faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-b7795fc6-75a9-43a9-b570-33441647511d,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-93338fe6-e029-492c-a093-6cd5ebf6e475,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-e707c078-6f02-46c3-bcf0-4415e44e1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-a2c5bc11-0cab-4b4f-a6ee-f60b1a9d1d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-067ea1de-9579-4b62-9b1f-41a78a05b1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-b0b7f99b-f479-4fcf-af71-115c8bf78795,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-73b3e609-b3e9-487b-b132-75c2f3f981f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506863715-172.17.0.21-1597192441956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-58126501-d0e7-4712-86ac-5fe10c5fc7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-655b9111-d2c5-48f7-ae42-83a4958edbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-14c6e131-a27d-4854-bcb8-df0596835626,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-af1f42c0-a963-4fcc-93b1-765af5cf17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-298d1293-a225-4a87-8612-9f2d8e490ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-139e0bdf-60dc-4fd3-8deb-a7ce5cc88c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-0e409506-05b7-4b16-8a63-749d2a2aea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-fcf6b38a-d5e2-4c1c-b9b5-af8cf2f2d3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506863715-172.17.0.21-1597192441956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-58126501-d0e7-4712-86ac-5fe10c5fc7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-655b9111-d2c5-48f7-ae42-83a4958edbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-14c6e131-a27d-4854-bcb8-df0596835626,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-af1f42c0-a963-4fcc-93b1-765af5cf17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-298d1293-a225-4a87-8612-9f2d8e490ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-139e0bdf-60dc-4fd3-8deb-a7ce5cc88c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-0e409506-05b7-4b16-8a63-749d2a2aea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-fcf6b38a-d5e2-4c1c-b9b5-af8cf2f2d3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162563248-172.17.0.21-1597192555963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34705,DS-7cee3f03-d101-42e1-b540-715f89941b35,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-008c1254-9747-43cb-bff3-6482c84e448c,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-7aa29b56-acd4-4e41-b2e0-20cb0e9be7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-cec2d085-a73c-4cb5-9a5c-4bb1118481b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-ec9baaf1-5033-46c3-a02b-0c39a1193e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-428c10dc-87b5-4636-a28b-034755d3afaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-ccbd5778-3eaf-4737-b73d-224293ab6d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-f00bed02-4fcc-467c-b9db-89f33f9f55ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162563248-172.17.0.21-1597192555963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34705,DS-7cee3f03-d101-42e1-b540-715f89941b35,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-008c1254-9747-43cb-bff3-6482c84e448c,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-7aa29b56-acd4-4e41-b2e0-20cb0e9be7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-cec2d085-a73c-4cb5-9a5c-4bb1118481b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-ec9baaf1-5033-46c3-a02b-0c39a1193e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-428c10dc-87b5-4636-a28b-034755d3afaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-ccbd5778-3eaf-4737-b73d-224293ab6d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-f00bed02-4fcc-467c-b9db-89f33f9f55ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809286108-172.17.0.21-1597192591012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37574,DS-468f4e79-9c0a-4634-9d23-70b6427bf1db,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-729de75e-a1b2-4c33-b64a-e40201e05815,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-bb7b8dbd-3a1f-41ef-801d-96797e33c277,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-6bba212a-2923-447e-96f5-72e39bf6bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d944a283-208e-41f6-ab76-3dbabf132b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-7e7e054b-e3a9-4039-909c-b5f432cb2612,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-ca4f9586-be6d-4116-83c6-ec668249e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-6390a98c-e363-4d0e-b6e9-4f49daffb06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809286108-172.17.0.21-1597192591012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37574,DS-468f4e79-9c0a-4634-9d23-70b6427bf1db,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-729de75e-a1b2-4c33-b64a-e40201e05815,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-bb7b8dbd-3a1f-41ef-801d-96797e33c277,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-6bba212a-2923-447e-96f5-72e39bf6bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d944a283-208e-41f6-ab76-3dbabf132b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-7e7e054b-e3a9-4039-909c-b5f432cb2612,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-ca4f9586-be6d-4116-83c6-ec668249e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-6390a98c-e363-4d0e-b6e9-4f49daffb06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056682096-172.17.0.21-1597192833296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-ae214f9d-562b-4514-aad5-7014f90595d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-cc4d06d1-dcd9-4c59-aa0e-554f353b3c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-a959e71e-8067-4456-a513-fdb987309ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-6399bfc3-a4b8-49f7-8f93-45eb77d4a5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-d6257504-d791-49a2-93f4-fa8c9b1b404d,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-442aca84-9a14-43a8-8d09-d5779df51015,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-457ed8e8-e3aa-490d-919a-6c86e30e09c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-727c9b48-e1ed-42d6-b1ed-9154cc8379d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056682096-172.17.0.21-1597192833296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-ae214f9d-562b-4514-aad5-7014f90595d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-cc4d06d1-dcd9-4c59-aa0e-554f353b3c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-a959e71e-8067-4456-a513-fdb987309ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-6399bfc3-a4b8-49f7-8f93-45eb77d4a5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-d6257504-d791-49a2-93f4-fa8c9b1b404d,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-442aca84-9a14-43a8-8d09-d5779df51015,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-457ed8e8-e3aa-490d-919a-6c86e30e09c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-727c9b48-e1ed-42d6-b1ed-9154cc8379d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241298297-172.17.0.21-1597192969579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39294,DS-b395b2e8-6cc8-4863-a751-59adefb2e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-521a1087-6c39-498c-8d74-535baa4deefc,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-ab751284-5a9a-4030-9645-618853740ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-6b39688d-fa51-43f2-af43-8e74bbf9fbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-4be3544e-a3b8-4777-bce1-27c0d76ef0be,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-7be3fdea-75bf-4cbf-8a6e-078aea538c42,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-f268ae6a-7f73-494f-b74c-825cc8838ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-32e0bb48-f067-45c1-8b86-897bfa57f375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241298297-172.17.0.21-1597192969579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39294,DS-b395b2e8-6cc8-4863-a751-59adefb2e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-521a1087-6c39-498c-8d74-535baa4deefc,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-ab751284-5a9a-4030-9645-618853740ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-6b39688d-fa51-43f2-af43-8e74bbf9fbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-4be3544e-a3b8-4777-bce1-27c0d76ef0be,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-7be3fdea-75bf-4cbf-8a6e-078aea538c42,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-f268ae6a-7f73-494f-b74c-825cc8838ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-32e0bb48-f067-45c1-8b86-897bfa57f375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725781299-172.17.0.21-1597193370823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-690def51-7a78-4286-9377-1300d75d3b74,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-f50ca58f-02c2-4c5f-aa9d-562fefad93f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-2497de2c-7d59-4c8f-95a2-f3ac31e24dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-24933e19-8614-436d-a28a-4815311b17d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-5a6e6168-1f81-468b-b2a6-74ecce478917,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-395c8970-2cde-4009-a952-c8ed8200eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-0c83ad2c-de4b-4d63-862e-2b119a6924e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-9d8942dd-ab95-476b-bc56-571337768c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725781299-172.17.0.21-1597193370823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-690def51-7a78-4286-9377-1300d75d3b74,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-f50ca58f-02c2-4c5f-aa9d-562fefad93f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-2497de2c-7d59-4c8f-95a2-f3ac31e24dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-24933e19-8614-436d-a28a-4815311b17d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-5a6e6168-1f81-468b-b2a6-74ecce478917,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-395c8970-2cde-4009-a952-c8ed8200eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-0c83ad2c-de4b-4d63-862e-2b119a6924e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-9d8942dd-ab95-476b-bc56-571337768c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505541889-172.17.0.21-1597193656864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-9b6604c1-f491-4ccd-8a5f-a3da09f50aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-83db906b-30ef-4ed2-8058-53f336cd88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-570d3a74-1350-40c7-adaa-a03b9491847e,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-a7bfc3bd-bbe9-4ecd-aaf6-0575c5286c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-26deda6f-b800-455d-930c-3fe250721e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-94595281-4744-4a43-b7a8-7e3cbeef48f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-8658b214-612f-4c65-a5f1-618bc14856fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-bc076347-0968-4b97-b596-e7f484ebeb80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505541889-172.17.0.21-1597193656864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-9b6604c1-f491-4ccd-8a5f-a3da09f50aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-83db906b-30ef-4ed2-8058-53f336cd88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-570d3a74-1350-40c7-adaa-a03b9491847e,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-a7bfc3bd-bbe9-4ecd-aaf6-0575c5286c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-26deda6f-b800-455d-930c-3fe250721e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-94595281-4744-4a43-b7a8-7e3cbeef48f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-8658b214-612f-4c65-a5f1-618bc14856fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-bc076347-0968-4b97-b596-e7f484ebeb80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5254
