reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048602666-172.17.0.14-1597192522736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-3866f2d4-19a8-4f29-9bc1-d9aba1ff1893,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-875730bb-3ddf-413a-ac9a-8e53ec58ff22,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-ccb37ded-19a1-48db-bb7a-a7e8c76f4ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-52bfa7c0-c651-4ccb-aa76-3beef0aaab08,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-d04976ac-9640-486f-b723-015a95d48fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-ffe61bab-7153-4574-a9b1-c93394cc8c59,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-4fdb53c9-8b8d-4bd3-b25e-3fab8ce87cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-fce2ad59-18af-4aa1-8203-ed9f3d8a84d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048602666-172.17.0.14-1597192522736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-3866f2d4-19a8-4f29-9bc1-d9aba1ff1893,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-875730bb-3ddf-413a-ac9a-8e53ec58ff22,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-ccb37ded-19a1-48db-bb7a-a7e8c76f4ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-52bfa7c0-c651-4ccb-aa76-3beef0aaab08,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-d04976ac-9640-486f-b723-015a95d48fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-ffe61bab-7153-4574-a9b1-c93394cc8c59,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-4fdb53c9-8b8d-4bd3-b25e-3fab8ce87cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-fce2ad59-18af-4aa1-8203-ed9f3d8a84d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433059064-172.17.0.14-1597192731386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39095,DS-a0abdb30-4b41-4d93-af2c-f9b23033688a,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-59eb1af9-1fec-464b-8640-b3c22cdccb79,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-037dadbf-6a2f-4c92-97b6-78a675497fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-386f790f-09a6-45c0-97a6-1d6fe3ae656e,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-28d19cea-d10e-4031-b094-5e3204c6c763,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-f502dea5-1d65-4ec9-a60e-64ce129fe311,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-b24c1995-d039-441c-831c-c483d90602ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-25e57151-3b81-4d63-bc38-1582a6397e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433059064-172.17.0.14-1597192731386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39095,DS-a0abdb30-4b41-4d93-af2c-f9b23033688a,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-59eb1af9-1fec-464b-8640-b3c22cdccb79,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-037dadbf-6a2f-4c92-97b6-78a675497fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-386f790f-09a6-45c0-97a6-1d6fe3ae656e,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-28d19cea-d10e-4031-b094-5e3204c6c763,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-f502dea5-1d65-4ec9-a60e-64ce129fe311,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-b24c1995-d039-441c-831c-c483d90602ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-25e57151-3b81-4d63-bc38-1582a6397e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1820661154-172.17.0.14-1597193488125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40754,DS-374a786f-8113-4826-99c0-609ec9302629,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-cd7745ab-a083-451b-b3dd-54ba78ff6e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-56f4a923-5122-4adb-b669-ba3f970c2cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-474ccea1-eedd-4b21-b5d7-37b146f8f938,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-752a6521-edd1-4676-a6ca-0cea091639bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-85827226-8af1-47c9-b7ea-7c43433150d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-84d01a1b-01d1-4156-affb-8eb45601d3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-c1b8f699-2db6-4f19-bd2f-721e15d5acc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1820661154-172.17.0.14-1597193488125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40754,DS-374a786f-8113-4826-99c0-609ec9302629,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-cd7745ab-a083-451b-b3dd-54ba78ff6e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-56f4a923-5122-4adb-b669-ba3f970c2cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-474ccea1-eedd-4b21-b5d7-37b146f8f938,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-752a6521-edd1-4676-a6ca-0cea091639bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-85827226-8af1-47c9-b7ea-7c43433150d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-84d01a1b-01d1-4156-affb-8eb45601d3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-c1b8f699-2db6-4f19-bd2f-721e15d5acc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005678514-172.17.0.14-1597193889902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37048,DS-566afbd4-e21d-403c-b2f9-0d995f32ef53,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-40348d45-f024-4e57-baf7-c72abf1e1330,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-eb165c79-695e-457a-8eb0-bd3c07bb041c,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-369e6dba-2c25-410c-a692-22a1e1b9652f,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-420cda05-af81-4613-b627-bd93ac6c563c,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-eec68809-8932-4ee7-9f46-c5f410e128c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-c308ad48-13ee-4821-a292-68e1d2888e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-ac00c11a-4faa-4179-8256-beff77ea5d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005678514-172.17.0.14-1597193889902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37048,DS-566afbd4-e21d-403c-b2f9-0d995f32ef53,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-40348d45-f024-4e57-baf7-c72abf1e1330,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-eb165c79-695e-457a-8eb0-bd3c07bb041c,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-369e6dba-2c25-410c-a692-22a1e1b9652f,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-420cda05-af81-4613-b627-bd93ac6c563c,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-eec68809-8932-4ee7-9f46-c5f410e128c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-c308ad48-13ee-4821-a292-68e1d2888e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-ac00c11a-4faa-4179-8256-beff77ea5d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831962329-172.17.0.14-1597194218961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-9c974996-d0d2-431a-a268-efbc0bdc99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-4d214e36-228c-45e4-9434-9f4e906b1084,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-2163548b-ba7d-469f-8269-3e38982fffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-98ea48e5-b1e0-4d7c-87a0-4f43adf2987f,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-b8149a02-5b04-4e66-b564-e759208aad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-d632178a-9fe5-4955-a12e-6130da21ebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-28435b87-be4a-40b1-a82c-388257c60575,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-4b05afb6-0423-4524-9fa9-aad154867e0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831962329-172.17.0.14-1597194218961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-9c974996-d0d2-431a-a268-efbc0bdc99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-4d214e36-228c-45e4-9434-9f4e906b1084,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-2163548b-ba7d-469f-8269-3e38982fffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-98ea48e5-b1e0-4d7c-87a0-4f43adf2987f,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-b8149a02-5b04-4e66-b564-e759208aad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-d632178a-9fe5-4955-a12e-6130da21ebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-28435b87-be4a-40b1-a82c-388257c60575,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-4b05afb6-0423-4524-9fa9-aad154867e0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148841144-172.17.0.14-1597194532680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-145bfadf-fe67-4630-9048-41cf168b72d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-08f92d99-66de-4996-bff0-5c3dddf9cae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-51a05329-3269-487c-988a-8143067917df,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-da6035fe-399e-456f-896b-1f1e6dd5747a,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-d7c50ad9-c0e3-4ce0-a537-e45dd40cd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-71dbb93f-89ce-43bc-aa4d-8969db71c292,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-8e4e0ebf-8b24-4548-a940-4d9f7091684f,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-22395d5f-756d-4457-9b0e-3d0ca20705ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148841144-172.17.0.14-1597194532680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-145bfadf-fe67-4630-9048-41cf168b72d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-08f92d99-66de-4996-bff0-5c3dddf9cae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-51a05329-3269-487c-988a-8143067917df,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-da6035fe-399e-456f-896b-1f1e6dd5747a,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-d7c50ad9-c0e3-4ce0-a537-e45dd40cd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-71dbb93f-89ce-43bc-aa4d-8969db71c292,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-8e4e0ebf-8b24-4548-a940-4d9f7091684f,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-22395d5f-756d-4457-9b0e-3d0ca20705ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990866193-172.17.0.14-1597194604327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38729,DS-13923a58-1da8-4b0f-aaf5-5540755c8325,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-8b2fe083-5346-4fa7-a174-fd62ad7d4baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-49ce52e9-0439-4636-91d0-ea2a0e8da549,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-f01ac1e1-e447-4adf-95a5-dc1f6faa3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-c96a3c6e-0382-4343-b3fe-95abd9db5405,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-2f47a638-eefd-4e5f-bbf8-ff4d9e653c16,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-1240914b-5b09-4b53-8e09-9411444e26cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-993aeb94-5cb4-453b-8a04-97379a051d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990866193-172.17.0.14-1597194604327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38729,DS-13923a58-1da8-4b0f-aaf5-5540755c8325,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-8b2fe083-5346-4fa7-a174-fd62ad7d4baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-49ce52e9-0439-4636-91d0-ea2a0e8da549,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-f01ac1e1-e447-4adf-95a5-dc1f6faa3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-c96a3c6e-0382-4343-b3fe-95abd9db5405,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-2f47a638-eefd-4e5f-bbf8-ff4d9e653c16,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-1240914b-5b09-4b53-8e09-9411444e26cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-993aeb94-5cb4-453b-8a04-97379a051d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479958247-172.17.0.14-1597194915336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38237,DS-7579c889-287a-4e6a-8f16-9760a9c779f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-8905e847-f166-4e0e-9f80-7264849edc85,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-240c135b-f9af-4ded-bf2c-583ca350dbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-ab25ad8c-f072-48c4-83a2-79d7ed28c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-405b34c7-de7e-4f3c-ac65-a3c20ea5a3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-309fe9c6-5bf1-42d7-b00d-b931e0078d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-57f8eb11-8cc3-42df-86f0-57db0625512d,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-d57b12f3-c13c-42e5-acfb-fb0c14c92855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479958247-172.17.0.14-1597194915336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38237,DS-7579c889-287a-4e6a-8f16-9760a9c779f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-8905e847-f166-4e0e-9f80-7264849edc85,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-240c135b-f9af-4ded-bf2c-583ca350dbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-ab25ad8c-f072-48c4-83a2-79d7ed28c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-405b34c7-de7e-4f3c-ac65-a3c20ea5a3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-309fe9c6-5bf1-42d7-b00d-b931e0078d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-57f8eb11-8cc3-42df-86f0-57db0625512d,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-d57b12f3-c13c-42e5-acfb-fb0c14c92855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475062897-172.17.0.14-1597195010602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-68aca1cd-de76-43c4-bcba-301e2e10b55c,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-020f6b39-ce6e-4070-b6f1-549c8049bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-c266b64f-127b-4e0b-b61a-61ed7fbdbade,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-4943b2cc-1de6-4732-8090-f54fa5ed1299,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-75de2009-a844-4b91-b7ba-fd2370422492,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-2a015a29-e909-4f72-9e98-14df88f41e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-53ce842b-b7ee-4148-b5b1-13821ba02ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-9d02f860-651c-4eea-b0c2-13432eef72e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475062897-172.17.0.14-1597195010602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-68aca1cd-de76-43c4-bcba-301e2e10b55c,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-020f6b39-ce6e-4070-b6f1-549c8049bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-c266b64f-127b-4e0b-b61a-61ed7fbdbade,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-4943b2cc-1de6-4732-8090-f54fa5ed1299,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-75de2009-a844-4b91-b7ba-fd2370422492,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-2a015a29-e909-4f72-9e98-14df88f41e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-53ce842b-b7ee-4148-b5b1-13821ba02ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-9d02f860-651c-4eea-b0c2-13432eef72e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627441766-172.17.0.14-1597196322364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-93959329-33bf-4d4f-a945-e59097aaf800,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-338851cf-404c-4694-a3c6-e1e77eb9fc80,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-ba0d0777-ad2b-4834-a2c5-e2c4e4b811f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-8457045f-2877-4162-9564-811c6aec5dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-eb66301f-85e2-4c45-8f09-5edf01586c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-f569f2e9-8341-4935-812c-b255e60a7d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-33842d64-61b4-44a3-a392-103f011a6a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-4d33e28a-cfb2-4e88-85b3-23b2bcf49781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627441766-172.17.0.14-1597196322364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-93959329-33bf-4d4f-a945-e59097aaf800,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-338851cf-404c-4694-a3c6-e1e77eb9fc80,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-ba0d0777-ad2b-4834-a2c5-e2c4e4b811f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-8457045f-2877-4162-9564-811c6aec5dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-eb66301f-85e2-4c45-8f09-5edf01586c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-f569f2e9-8341-4935-812c-b255e60a7d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-33842d64-61b4-44a3-a392-103f011a6a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-4d33e28a-cfb2-4e88-85b3-23b2bcf49781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110588786-172.17.0.14-1597196739761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-81ec1f99-50d6-4eaa-99ed-de625b0cca03,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-96276c79-2535-43ed-9c6d-62c1dfef5c91,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-2993a936-1b06-4d0b-92e7-1597439074ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-43f141a8-7f23-4380-88dd-5e79f9e6dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-73b240dd-bf7e-41a7-97fb-288031d14331,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-24ccfcc5-cf38-4dc3-b138-6baeaae35179,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-922f13a5-7b4b-40cd-b986-3140b05180c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-e9da94ff-3cac-4696-9f12-915b93c7fa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110588786-172.17.0.14-1597196739761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-81ec1f99-50d6-4eaa-99ed-de625b0cca03,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-96276c79-2535-43ed-9c6d-62c1dfef5c91,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-2993a936-1b06-4d0b-92e7-1597439074ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-43f141a8-7f23-4380-88dd-5e79f9e6dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-73b240dd-bf7e-41a7-97fb-288031d14331,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-24ccfcc5-cf38-4dc3-b138-6baeaae35179,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-922f13a5-7b4b-40cd-b986-3140b05180c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-e9da94ff-3cac-4696-9f12-915b93c7fa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128456329-172.17.0.14-1597197068256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-3edde794-8bc4-4743-af4b-eced6d40a586,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-20312d36-30d5-483a-92e0-cb26151c9c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-966b2c66-a806-4315-9ffc-da02b6f4f4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-fad50998-532e-46d4-8dd5-5d439fc954dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-ca4cfbd1-47bf-4cfd-908b-ba5a0d509a68,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-4762a284-0048-465d-b613-4a5e68386168,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-89b9cb13-699a-4e6c-a432-ca51414f1806,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-82ecfc8b-37f2-4629-889a-04f1984ff487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128456329-172.17.0.14-1597197068256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-3edde794-8bc4-4743-af4b-eced6d40a586,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-20312d36-30d5-483a-92e0-cb26151c9c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-966b2c66-a806-4315-9ffc-da02b6f4f4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-fad50998-532e-46d4-8dd5-5d439fc954dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-ca4cfbd1-47bf-4cfd-908b-ba5a0d509a68,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-4762a284-0048-465d-b613-4a5e68386168,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-89b9cb13-699a-4e6c-a432-ca51414f1806,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-82ecfc8b-37f2-4629-889a-04f1984ff487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493717569-172.17.0.14-1597197397818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36767,DS-cd03a949-fedf-46c1-869d-8ea376a91fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-ef971a0f-4724-411c-82f9-1f24a3dc2347,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-036cfcc4-87ed-44f5-a2e4-6a02883d3daa,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-a68ba451-0a0e-4964-b917-70e3a45ecc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-ec51d498-dc4d-4e8e-9103-9830b0555863,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-5c1c6320-d7b0-4b37-bf75-be6a2a7d2de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-0489ef44-0268-4d8b-abb4-70c43ce012a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-4cbed0f8-0652-4b0e-98d7-61881d040612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493717569-172.17.0.14-1597197397818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36767,DS-cd03a949-fedf-46c1-869d-8ea376a91fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-ef971a0f-4724-411c-82f9-1f24a3dc2347,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-036cfcc4-87ed-44f5-a2e4-6a02883d3daa,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-a68ba451-0a0e-4964-b917-70e3a45ecc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-ec51d498-dc4d-4e8e-9103-9830b0555863,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-5c1c6320-d7b0-4b37-bf75-be6a2a7d2de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-0489ef44-0268-4d8b-abb4-70c43ce012a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-4cbed0f8-0652-4b0e-98d7-61881d040612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830484464-172.17.0.14-1597197823329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35300,DS-3601f40e-15d9-4cd7-bf7a-93df6feac53f,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-06f03e7b-2338-4f46-a0bb-ba7765b2bf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-0c1f0701-c650-4412-9e0e-50a19ac91ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-01c54d5c-82a7-4fc3-a690-4b70a09a6390,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-5e8b364e-3182-4c9c-9e17-43b2fc561b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-c4b6fe6d-4f21-4fd0-a7aa-e934fddbed30,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-fb0a1ff6-ac6a-4a09-a73e-988afe14022a,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-9705a7ab-6612-43df-8f6c-9d55800a3cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830484464-172.17.0.14-1597197823329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35300,DS-3601f40e-15d9-4cd7-bf7a-93df6feac53f,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-06f03e7b-2338-4f46-a0bb-ba7765b2bf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-0c1f0701-c650-4412-9e0e-50a19ac91ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-01c54d5c-82a7-4fc3-a690-4b70a09a6390,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-5e8b364e-3182-4c9c-9e17-43b2fc561b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-c4b6fe6d-4f21-4fd0-a7aa-e934fddbed30,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-fb0a1ff6-ac6a-4a09-a73e-988afe14022a,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-9705a7ab-6612-43df-8f6c-9d55800a3cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5400
