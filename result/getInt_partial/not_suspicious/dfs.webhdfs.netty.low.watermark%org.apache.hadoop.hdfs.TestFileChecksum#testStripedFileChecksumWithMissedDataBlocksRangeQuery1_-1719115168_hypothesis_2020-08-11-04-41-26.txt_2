reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968640011-172.17.0.12-1597120973460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-3f7be609-a586-43fa-a5e6-9e496282efbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-671cbdf9-768e-4d7c-baf1-2cd4c192cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-20efe143-844e-4182-9947-56f3e3492ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-6f8130f4-7b8c-4517-be72-7175f7711df5,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-cfbb0909-53bd-48de-8100-8cb98a5da77b,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-abaa83f1-9346-402e-b354-1a9a2b3bb5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-42c26e63-5d9f-4141-908d-aa05eb2af591,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-ea264bec-3002-451e-aab3-5b59c2779be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968640011-172.17.0.12-1597120973460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-3f7be609-a586-43fa-a5e6-9e496282efbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-671cbdf9-768e-4d7c-baf1-2cd4c192cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-20efe143-844e-4182-9947-56f3e3492ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-6f8130f4-7b8c-4517-be72-7175f7711df5,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-cfbb0909-53bd-48de-8100-8cb98a5da77b,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-abaa83f1-9346-402e-b354-1a9a2b3bb5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-42c26e63-5d9f-4141-908d-aa05eb2af591,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-ea264bec-3002-451e-aab3-5b59c2779be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491261186-172.17.0.12-1597121218001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41540,DS-1dfbeb82-1ccd-4f34-8636-9f90863fbb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-1584e525-9d65-48a4-b9fd-ce43736819fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-fc7a5830-e54a-42c8-9ee5-21d64678eb93,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-5fc099d9-6a32-40ec-b089-e8de7f6e9aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-0b54415d-75fe-4792-9669-b7c4be578b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-41232369-c1e4-419c-89ad-3ee0efb5f40c,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-4c903a1c-6db7-4128-85fd-c65b3f945008,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-02aee69b-4c15-4f0f-b97b-1a658b629855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491261186-172.17.0.12-1597121218001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41540,DS-1dfbeb82-1ccd-4f34-8636-9f90863fbb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-1584e525-9d65-48a4-b9fd-ce43736819fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-fc7a5830-e54a-42c8-9ee5-21d64678eb93,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-5fc099d9-6a32-40ec-b089-e8de7f6e9aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-0b54415d-75fe-4792-9669-b7c4be578b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-41232369-c1e4-419c-89ad-3ee0efb5f40c,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-4c903a1c-6db7-4128-85fd-c65b3f945008,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-02aee69b-4c15-4f0f-b97b-1a658b629855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521657767-172.17.0.12-1597121541089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37377,DS-70df7ab1-0e74-4dec-9d32-afae47ce9b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-16494228-15de-4b94-a80a-b71bdecf2ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-cee87df7-acd3-4365-9c3c-9baa0d012643,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-2a1c2bfa-1e9b-455c-863b-ef203952da6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-9a1be32e-84b1-4502-bbe3-8ee47ac6b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-0bb71d62-3796-46a9-ba2f-a866cc1077ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-efe630cf-fe4f-4847-bafa-c2bad1539ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-a80e97da-87b5-4580-a9e5-5249ddaa8382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521657767-172.17.0.12-1597121541089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37377,DS-70df7ab1-0e74-4dec-9d32-afae47ce9b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-16494228-15de-4b94-a80a-b71bdecf2ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-cee87df7-acd3-4365-9c3c-9baa0d012643,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-2a1c2bfa-1e9b-455c-863b-ef203952da6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-9a1be32e-84b1-4502-bbe3-8ee47ac6b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-0bb71d62-3796-46a9-ba2f-a866cc1077ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-efe630cf-fe4f-4847-bafa-c2bad1539ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-a80e97da-87b5-4580-a9e5-5249ddaa8382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154283938-172.17.0.12-1597121581289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-1137d9dd-17b5-4de2-ab55-3c9bbe3c00c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-66d837d5-2d8a-4113-81a5-9a8feaa96d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-e8450bc5-dc8e-479e-93c5-b2e9e72e9163,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-70cefe15-efbf-4a4a-b526-8febc1d1c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-0c452e3c-4ec5-40d5-819e-a885d2bb780d,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-9ccaba42-dee4-4b65-bb27-d1a5d5a9810d,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-aeceb386-57a3-4fd9-9b86-dfe2120ac1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-71df7b7d-262e-43f6-9f03-3ba8141fc99e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154283938-172.17.0.12-1597121581289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-1137d9dd-17b5-4de2-ab55-3c9bbe3c00c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-66d837d5-2d8a-4113-81a5-9a8feaa96d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-e8450bc5-dc8e-479e-93c5-b2e9e72e9163,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-70cefe15-efbf-4a4a-b526-8febc1d1c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-0c452e3c-4ec5-40d5-819e-a885d2bb780d,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-9ccaba42-dee4-4b65-bb27-d1a5d5a9810d,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-aeceb386-57a3-4fd9-9b86-dfe2120ac1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-71df7b7d-262e-43f6-9f03-3ba8141fc99e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791410512-172.17.0.12-1597122144297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-99d8f273-266c-4dac-a7fd-9a918de6329c,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-552110e4-7f19-452b-9798-8ad0485dcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-a432b0f3-92e0-43f8-a466-2cb9fc63e622,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-f3b6850a-f137-4491-a193-85899c996511,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-16829f5d-6064-4d6f-bfd2-76b24b790afd,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-cc343143-f9a8-428d-bcc3-75818bd49641,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-4d3f8e0d-89f0-44df-91e9-10b11b2426a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-af537dad-cd44-47fc-a408-a900a3b4b6fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791410512-172.17.0.12-1597122144297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-99d8f273-266c-4dac-a7fd-9a918de6329c,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-552110e4-7f19-452b-9798-8ad0485dcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-a432b0f3-92e0-43f8-a466-2cb9fc63e622,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-f3b6850a-f137-4491-a193-85899c996511,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-16829f5d-6064-4d6f-bfd2-76b24b790afd,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-cc343143-f9a8-428d-bcc3-75818bd49641,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-4d3f8e0d-89f0-44df-91e9-10b11b2426a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-af537dad-cd44-47fc-a408-a900a3b4b6fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069354216-172.17.0.12-1597122173226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-8578c1ed-2cc9-4983-9abc-03f037209630,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-e2e05dc1-418d-47c0-89b6-c47d79f6f879,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-f6a15e35-8e41-4b07-b07a-22674eb78da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-6cb65b4e-6e2a-4b08-b35a-016c75641378,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-4583f8c6-e714-4ea0-81ac-7a9ff79ebb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-88edf10a-8d33-4584-8116-fe0aeb9d8783,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-5abf7594-1130-43de-bf77-33b372a27157,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-9c5117a5-0a7f-44a4-a17d-c70141c64dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069354216-172.17.0.12-1597122173226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-8578c1ed-2cc9-4983-9abc-03f037209630,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-e2e05dc1-418d-47c0-89b6-c47d79f6f879,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-f6a15e35-8e41-4b07-b07a-22674eb78da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-6cb65b4e-6e2a-4b08-b35a-016c75641378,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-4583f8c6-e714-4ea0-81ac-7a9ff79ebb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-88edf10a-8d33-4584-8116-fe0aeb9d8783,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-5abf7594-1130-43de-bf77-33b372a27157,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-9c5117a5-0a7f-44a4-a17d-c70141c64dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729115235-172.17.0.12-1597122494401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45287,DS-888dd854-8673-49b2-a2c0-1cb1268772fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-28834074-9e82-4eea-989a-f7d5b5dfbdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-1cefa8aa-2fd4-4926-ab95-c4d18c9b1a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-16db9144-f0e1-4dbd-927f-3abb335cc891,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-66c66335-3ea0-4beb-9ec6-6c3557e97478,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-076ab4d7-140c-40be-b960-c0d55049b325,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-97d4f1e2-6f92-4b65-97ce-656634f43d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-a4268a8b-59ee-45ed-b41b-4981a736ce0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729115235-172.17.0.12-1597122494401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45287,DS-888dd854-8673-49b2-a2c0-1cb1268772fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-28834074-9e82-4eea-989a-f7d5b5dfbdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-1cefa8aa-2fd4-4926-ab95-c4d18c9b1a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-16db9144-f0e1-4dbd-927f-3abb335cc891,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-66c66335-3ea0-4beb-9ec6-6c3557e97478,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-076ab4d7-140c-40be-b960-c0d55049b325,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-97d4f1e2-6f92-4b65-97ce-656634f43d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-a4268a8b-59ee-45ed-b41b-4981a736ce0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103906569-172.17.0.12-1597123208852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46409,DS-66e89500-b2a9-4cf5-a92f-5914d1760f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-5bb5d177-985f-4ec9-89a2-3849ca9e807b,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-69a45af0-96b9-4471-a647-466fcb7e73cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-3cb0fc90-50d8-42ae-91c9-5a961ac1a9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-47cd8b35-7035-4a4e-8de0-94766e042fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-116d7409-59cb-479c-9fd4-2862604d0104,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-d19ca5b9-94b1-4af2-a3a2-079b34424317,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-d42d7580-fc74-44de-a84f-bab19990036b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103906569-172.17.0.12-1597123208852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46409,DS-66e89500-b2a9-4cf5-a92f-5914d1760f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-5bb5d177-985f-4ec9-89a2-3849ca9e807b,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-69a45af0-96b9-4471-a647-466fcb7e73cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-3cb0fc90-50d8-42ae-91c9-5a961ac1a9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-47cd8b35-7035-4a4e-8de0-94766e042fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-116d7409-59cb-479c-9fd4-2862604d0104,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-d19ca5b9-94b1-4af2-a3a2-079b34424317,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-d42d7580-fc74-44de-a84f-bab19990036b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132138083-172.17.0.12-1597123316110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39743,DS-8a6ade88-d672-486e-b5ae-b976ca12e38f,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-5af0f210-3b89-48f3-ac5b-67aa6f3ed029,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-8bf23586-cdaf-4de2-a16e-99f04710f2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-b4110cd8-dcee-4491-af27-8386588ee142,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-a9ab2449-83ad-4da8-9969-efc44b1c0d15,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-f1fb734d-afca-40d8-8a96-847fa63c96e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-ad8755f0-459e-4a25-8ab5-d7f83785bb93,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-bbd12360-a118-4ea1-b3c1-8f69c263b2ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132138083-172.17.0.12-1597123316110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39743,DS-8a6ade88-d672-486e-b5ae-b976ca12e38f,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-5af0f210-3b89-48f3-ac5b-67aa6f3ed029,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-8bf23586-cdaf-4de2-a16e-99f04710f2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-b4110cd8-dcee-4491-af27-8386588ee142,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-a9ab2449-83ad-4da8-9969-efc44b1c0d15,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-f1fb734d-afca-40d8-8a96-847fa63c96e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-ad8755f0-459e-4a25-8ab5-d7f83785bb93,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-bbd12360-a118-4ea1-b3c1-8f69c263b2ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826579381-172.17.0.12-1597124015617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-e4b57607-a3bc-409b-ad23-31ddf1256576,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-557342cf-bf38-408b-af7b-a5e5973abbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-657398ca-b071-4891-9d53-a6a69f29bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3874186d-2374-4646-8885-1d073a3eeb72,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-7cef48af-562f-489c-b5c1-e4e3772d6932,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-75149bfc-ea49-49e7-8f0c-6b32874210b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-a943c952-d206-447a-b670-61c8d8a93711,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-acf30677-2188-4818-ae5e-82cdec21f882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826579381-172.17.0.12-1597124015617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-e4b57607-a3bc-409b-ad23-31ddf1256576,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-557342cf-bf38-408b-af7b-a5e5973abbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-657398ca-b071-4891-9d53-a6a69f29bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3874186d-2374-4646-8885-1d073a3eeb72,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-7cef48af-562f-489c-b5c1-e4e3772d6932,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-75149bfc-ea49-49e7-8f0c-6b32874210b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-a943c952-d206-447a-b670-61c8d8a93711,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-acf30677-2188-4818-ae5e-82cdec21f882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917282347-172.17.0.12-1597124672920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42532,DS-70060071-bad0-4193-8709-38234988bc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-47f2651f-231a-4253-9736-dd3278ddb9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-47e8c75d-44d7-461a-8de0-fa5f839d1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-7a4ff496-164e-43b1-acb5-ee5992af27f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-f5a65572-edbb-41d7-8b69-74e40249c379,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-ce4d0436-1e9b-4377-9645-4ec8f23f0ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-eb765d40-242f-407a-a987-0f95e4e8f113,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-c6b64379-228e-4b68-96c1-7a217967d05f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917282347-172.17.0.12-1597124672920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42532,DS-70060071-bad0-4193-8709-38234988bc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-47f2651f-231a-4253-9736-dd3278ddb9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-47e8c75d-44d7-461a-8de0-fa5f839d1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-7a4ff496-164e-43b1-acb5-ee5992af27f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-f5a65572-edbb-41d7-8b69-74e40249c379,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-ce4d0436-1e9b-4377-9645-4ec8f23f0ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-eb765d40-242f-407a-a987-0f95e4e8f113,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-c6b64379-228e-4b68-96c1-7a217967d05f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92984777-172.17.0.12-1597124924338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-f90f4cb0-8dfd-47db-9b64-1667333462ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-3c43ebed-eb7f-4130-b027-119890db2dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-77ef3a84-615d-40ab-91b9-80ad0cf547f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-759aedfc-0dcb-48ff-9d99-53e872b5d040,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-5774aa4b-a778-4a6a-87c5-a4d91617df47,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-e37062a2-0aac-4593-a8e0-2e3c31d6fb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-671dfb6b-1524-46bc-af1e-f699c2140796,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-2076b0e3-832e-4131-aa82-2a97ae09b43a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92984777-172.17.0.12-1597124924338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-f90f4cb0-8dfd-47db-9b64-1667333462ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-3c43ebed-eb7f-4130-b027-119890db2dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-77ef3a84-615d-40ab-91b9-80ad0cf547f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-759aedfc-0dcb-48ff-9d99-53e872b5d040,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-5774aa4b-a778-4a6a-87c5-a4d91617df47,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-e37062a2-0aac-4593-a8e0-2e3c31d6fb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-671dfb6b-1524-46bc-af1e-f699c2140796,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-2076b0e3-832e-4131-aa82-2a97ae09b43a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795852049-172.17.0.12-1597125112983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37949,DS-59f4d931-32ff-4fd6-917c-c0b558fb027b,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-cdb0de5a-5df6-422e-b62d-3d04b076252e,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-feaf7d65-ae34-445c-a314-f314f8367592,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-ee10795c-6cc9-435f-8daf-c1a78163f5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-e26e9669-5542-41cc-95ae-72ffa962ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-b837d058-13f5-43fa-adbf-74e13fd64b28,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-646e0408-424a-42ee-a74e-8d8b585aa9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-db78ac9f-cf27-4a49-94b7-399377cf9c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795852049-172.17.0.12-1597125112983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37949,DS-59f4d931-32ff-4fd6-917c-c0b558fb027b,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-cdb0de5a-5df6-422e-b62d-3d04b076252e,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-feaf7d65-ae34-445c-a314-f314f8367592,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-ee10795c-6cc9-435f-8daf-c1a78163f5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-e26e9669-5542-41cc-95ae-72ffa962ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-b837d058-13f5-43fa-adbf-74e13fd64b28,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-646e0408-424a-42ee-a74e-8d8b585aa9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-db78ac9f-cf27-4a49-94b7-399377cf9c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32261243-172.17.0.12-1597125951882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-7535e009-26d8-44e4-9b9d-cc8e5cd57982,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-594ec0f4-4653-41f1-b10c-b67dc551228f,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-dc1bbeb1-b69c-410c-aee7-4bf09a6dd259,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-a6f58ce8-701a-4a8b-87fa-ffbb67a5e555,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-160d9b48-9127-4aac-8103-c22d77529dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-ccc67329-d1e4-4e8e-abaa-a09306c7110e,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-3c1accce-7963-421d-bb54-91a2b6fbc18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-3646cbbe-a48d-414d-9565-bd1cf120238b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32261243-172.17.0.12-1597125951882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-7535e009-26d8-44e4-9b9d-cc8e5cd57982,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-594ec0f4-4653-41f1-b10c-b67dc551228f,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-dc1bbeb1-b69c-410c-aee7-4bf09a6dd259,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-a6f58ce8-701a-4a8b-87fa-ffbb67a5e555,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-160d9b48-9127-4aac-8103-c22d77529dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-ccc67329-d1e4-4e8e-abaa-a09306c7110e,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-3c1accce-7963-421d-bb54-91a2b6fbc18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-3646cbbe-a48d-414d-9565-bd1cf120238b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5486
