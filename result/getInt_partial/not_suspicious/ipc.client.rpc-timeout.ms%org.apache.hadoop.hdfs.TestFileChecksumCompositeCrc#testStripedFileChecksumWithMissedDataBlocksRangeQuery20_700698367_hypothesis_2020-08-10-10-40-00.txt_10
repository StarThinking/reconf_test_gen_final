reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285538112-172.17.0.21-1597056044550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-0597abf0-5ce2-4a69-83a5-431ca0815e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-10296ddb-5a91-42f2-9b09-6102b5fe1e91,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-376c0e88-a5a0-4773-b57e-f6471b8a26ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-8e855256-8b12-40f1-9728-db79bb6d783a,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-e621f969-9395-4992-8c15-6104458b1a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-a2ba916c-6204-4a3d-b65d-4424bc9cf3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-1a3355d6-2b05-4694-80c5-bda5e97416dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-73c86876-fc3a-47bb-8227-84360b9fde30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285538112-172.17.0.21-1597056044550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-0597abf0-5ce2-4a69-83a5-431ca0815e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-10296ddb-5a91-42f2-9b09-6102b5fe1e91,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-376c0e88-a5a0-4773-b57e-f6471b8a26ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-8e855256-8b12-40f1-9728-db79bb6d783a,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-e621f969-9395-4992-8c15-6104458b1a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-a2ba916c-6204-4a3d-b65d-4424bc9cf3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-1a3355d6-2b05-4694-80c5-bda5e97416dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-73c86876-fc3a-47bb-8227-84360b9fde30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288940782-172.17.0.21-1597056124422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45406,DS-8c1b2fd0-597d-47e2-aa46-b1fcec007ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-bdf62693-7327-4502-a0a2-55daef26fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-e8242e12-b2f5-437b-a8d5-542030e55ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-638b230f-1530-4df0-a813-99db0cec3bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-11ec82b6-189b-4814-88d3-3f84cf8c993c,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-96bb10a0-ddb2-45f3-809d-1ecee6129d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-e1424f18-cb4b-483a-94d6-6ecde41cc32c,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-e58f600c-b263-4c1b-9b16-2244a8da9ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288940782-172.17.0.21-1597056124422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45406,DS-8c1b2fd0-597d-47e2-aa46-b1fcec007ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-bdf62693-7327-4502-a0a2-55daef26fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-e8242e12-b2f5-437b-a8d5-542030e55ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-638b230f-1530-4df0-a813-99db0cec3bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-11ec82b6-189b-4814-88d3-3f84cf8c993c,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-96bb10a0-ddb2-45f3-809d-1ecee6129d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-e1424f18-cb4b-483a-94d6-6ecde41cc32c,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-e58f600c-b263-4c1b-9b16-2244a8da9ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929481679-172.17.0.21-1597056195126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39029,DS-b9465891-71b2-4b4e-8408-b806eb7c1481,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-0dbaafdf-50e5-4279-a66c-6d6430a1e758,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-9e6ecf7c-2a41-40a4-bc07-7c19447207c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-9cab2ef9-3614-4d0d-8888-c6200080a768,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-40ee2dd1-6918-48d3-8c1b-e71c060e60db,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-12ea0184-5a98-43f9-bd07-3e52fe933c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-a2bf01d5-6dd6-47ee-b3ac-1f822ad08065,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-89d0ac5a-6f00-48f1-8474-e4f56830c476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929481679-172.17.0.21-1597056195126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39029,DS-b9465891-71b2-4b4e-8408-b806eb7c1481,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-0dbaafdf-50e5-4279-a66c-6d6430a1e758,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-9e6ecf7c-2a41-40a4-bc07-7c19447207c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-9cab2ef9-3614-4d0d-8888-c6200080a768,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-40ee2dd1-6918-48d3-8c1b-e71c060e60db,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-12ea0184-5a98-43f9-bd07-3e52fe933c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-a2bf01d5-6dd6-47ee-b3ac-1f822ad08065,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-89d0ac5a-6f00-48f1-8474-e4f56830c476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063034604-172.17.0.21-1597056308009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43500,DS-249097ba-fbdc-42cb-bcd2-6efdc7e3cd93,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-b5b34e00-fe30-46b8-8136-cbf0254b49a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-8cc59f28-0cdc-4adb-af31-79d6edbd94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-accc9efc-82fc-43b7-b675-16bf4b0138fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-58de18b0-d14d-4c4c-8dbc-71504fd3f037,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-25556476-0f5d-467e-8f01-2254bf039f71,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-4aa1db86-f231-405e-80c1-152517822999,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-2c52780a-6b97-42e2-8d99-6d09d3cd1e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063034604-172.17.0.21-1597056308009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43500,DS-249097ba-fbdc-42cb-bcd2-6efdc7e3cd93,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-b5b34e00-fe30-46b8-8136-cbf0254b49a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-8cc59f28-0cdc-4adb-af31-79d6edbd94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-accc9efc-82fc-43b7-b675-16bf4b0138fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-58de18b0-d14d-4c4c-8dbc-71504fd3f037,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-25556476-0f5d-467e-8f01-2254bf039f71,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-4aa1db86-f231-405e-80c1-152517822999,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-2c52780a-6b97-42e2-8d99-6d09d3cd1e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121658428-172.17.0.21-1597056521563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39624,DS-267e8854-5195-4ae8-b2e1-c621561c042a,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-676b0dc0-b48d-4563-a764-703b0227545d,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-65973673-391b-4de2-b9b5-000d13f01924,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-ba9031d4-feea-4e07-96e6-835489565b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-575628d5-3005-481a-b432-baf988960de0,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-835ca453-e648-4d61-a3a6-44acde33d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-569f30fb-164a-4634-b77d-39f8c17e0685,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-f9e42f1d-6c70-45fa-b6cb-def576dfe6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121658428-172.17.0.21-1597056521563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39624,DS-267e8854-5195-4ae8-b2e1-c621561c042a,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-676b0dc0-b48d-4563-a764-703b0227545d,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-65973673-391b-4de2-b9b5-000d13f01924,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-ba9031d4-feea-4e07-96e6-835489565b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-575628d5-3005-481a-b432-baf988960de0,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-835ca453-e648-4d61-a3a6-44acde33d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-569f30fb-164a-4634-b77d-39f8c17e0685,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-f9e42f1d-6c70-45fa-b6cb-def576dfe6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899146701-172.17.0.21-1597056948250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-24b765c7-9793-419e-ab4b-16196bee1c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-12155343-2ac0-4e82-b703-1c29caea7ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-f4235f79-5be7-4c04-a28f-7df1ecbaa960,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-7c5b4bb3-2c6f-4a6d-90a0-0de865b0bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-208d8421-b593-44ec-a55e-1b51084ba0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-8ce15029-1e15-4c91-801a-8ca767626a03,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-535269e8-d932-46a5-b219-d9c60fc6e839,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-f590cffe-cc80-4440-a905-b38d33e4db4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899146701-172.17.0.21-1597056948250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-24b765c7-9793-419e-ab4b-16196bee1c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-12155343-2ac0-4e82-b703-1c29caea7ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-f4235f79-5be7-4c04-a28f-7df1ecbaa960,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-7c5b4bb3-2c6f-4a6d-90a0-0de865b0bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-208d8421-b593-44ec-a55e-1b51084ba0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-8ce15029-1e15-4c91-801a-8ca767626a03,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-535269e8-d932-46a5-b219-d9c60fc6e839,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-f590cffe-cc80-4440-a905-b38d33e4db4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627420183-172.17.0.21-1597057079176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34248,DS-e688dae6-223f-4137-a7c9-1494e0c78812,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-57e2e4d9-61ad-4e1a-b555-c3b935b88630,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-76ced18c-9339-4669-9ade-fcbe69ae5b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-5ad492d9-7d2e-4b9e-9e2f-21b2e55cc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-215017e1-3023-486b-bfcc-f79f8c9bbeae,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-cd221097-aa9e-4c8c-be50-8094015a6769,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-27130a63-fa63-4b83-badf-0cbea2e68907,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-4673bb8d-bbab-4525-bc55-611448cd5928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627420183-172.17.0.21-1597057079176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34248,DS-e688dae6-223f-4137-a7c9-1494e0c78812,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-57e2e4d9-61ad-4e1a-b555-c3b935b88630,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-76ced18c-9339-4669-9ade-fcbe69ae5b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-5ad492d9-7d2e-4b9e-9e2f-21b2e55cc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-215017e1-3023-486b-bfcc-f79f8c9bbeae,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-cd221097-aa9e-4c8c-be50-8094015a6769,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-27130a63-fa63-4b83-badf-0cbea2e68907,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-4673bb8d-bbab-4525-bc55-611448cd5928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615056669-172.17.0.21-1597058337086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-b99077ac-8302-4610-b004-db0057fe58e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-dabcb9d5-e1d1-4c55-9f92-bfe156b4a865,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-102f1035-b853-491a-903c-f9ef0fdb325e,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-4d745824-8b6d-4a73-8337-7dd7616974eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-78c35d67-59f5-4834-9c14-5c29c338be4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-9589c977-f3b6-428b-b5aa-e5325f3c3bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-2234c191-5841-436d-bb33-fdafcf093d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-0c6b2df7-1ded-4bee-ad30-3145f5788bb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615056669-172.17.0.21-1597058337086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-b99077ac-8302-4610-b004-db0057fe58e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-dabcb9d5-e1d1-4c55-9f92-bfe156b4a865,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-102f1035-b853-491a-903c-f9ef0fdb325e,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-4d745824-8b6d-4a73-8337-7dd7616974eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-78c35d67-59f5-4834-9c14-5c29c338be4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-9589c977-f3b6-428b-b5aa-e5325f3c3bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-2234c191-5841-436d-bb33-fdafcf093d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-0c6b2df7-1ded-4bee-ad30-3145f5788bb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535578538-172.17.0.21-1597058400946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45550,DS-5f226007-2869-4ae8-846b-82f01a536286,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-ffcc95e3-0a5d-487a-9af2-d91516f0a7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-463713a7-d1b2-44c4-8a69-4b928ab33089,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-535c18aa-49de-4d9e-a754-b218b000a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-56a70742-ecb4-4d83-8bcd-d5b0e4b6f8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-250f884f-3b85-4b76-b09c-2f0d8ca0af6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-939ca2bd-e54e-4138-9d71-35eb8aada3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-a2952c61-1c0f-4c8f-9d8b-9414ef499abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535578538-172.17.0.21-1597058400946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45550,DS-5f226007-2869-4ae8-846b-82f01a536286,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-ffcc95e3-0a5d-487a-9af2-d91516f0a7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-463713a7-d1b2-44c4-8a69-4b928ab33089,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-535c18aa-49de-4d9e-a754-b218b000a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-56a70742-ecb4-4d83-8bcd-d5b0e4b6f8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-250f884f-3b85-4b76-b09c-2f0d8ca0af6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-939ca2bd-e54e-4138-9d71-35eb8aada3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-a2952c61-1c0f-4c8f-9d8b-9414ef499abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490332121-172.17.0.21-1597058556919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-a2b8a47d-4624-4726-bb5f-7bcb9319725c,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-4126278e-5996-4acf-bd10-818fdbb6e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-57135e5a-9d69-448c-8841-b7e41f0846f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-836d7a6f-22f8-4d17-ac00-f3f56d06de07,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-994b6923-8236-441e-b37b-69a9b9b33cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-90106fa6-850c-4ca0-bb58-87b3d5c3c485,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-d76bf8a3-ea53-4873-b066-b7dd73cd244e,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-41ddafd2-238c-47c2-a7f8-65f4cce4dd19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490332121-172.17.0.21-1597058556919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-a2b8a47d-4624-4726-bb5f-7bcb9319725c,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-4126278e-5996-4acf-bd10-818fdbb6e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-57135e5a-9d69-448c-8841-b7e41f0846f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-836d7a6f-22f8-4d17-ac00-f3f56d06de07,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-994b6923-8236-441e-b37b-69a9b9b33cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-90106fa6-850c-4ca0-bb58-87b3d5c3c485,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-d76bf8a3-ea53-4873-b066-b7dd73cd244e,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-41ddafd2-238c-47c2-a7f8-65f4cce4dd19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090771636-172.17.0.21-1597058755750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46544,DS-c9408b29-7531-4af4-9ea5-0908fb6b347a,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-ab80ff4d-88a5-407f-ba13-d3b7184d42a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-b018bcdc-a427-46e4-974e-32ee4eb796a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-140241f8-a337-49d3-bd60-9a85bb864da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-95282ef5-4db7-4257-8dc1-a074d827ab90,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-01ded7be-479f-4b8e-a21b-01db18963c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-285afc7d-5ad7-43d4-9bfa-eb92150a803e,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-c15d29ba-aa14-41cc-8c92-5553c07886c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090771636-172.17.0.21-1597058755750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46544,DS-c9408b29-7531-4af4-9ea5-0908fb6b347a,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-ab80ff4d-88a5-407f-ba13-d3b7184d42a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-b018bcdc-a427-46e4-974e-32ee4eb796a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-140241f8-a337-49d3-bd60-9a85bb864da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-95282ef5-4db7-4257-8dc1-a074d827ab90,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-01ded7be-479f-4b8e-a21b-01db18963c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-285afc7d-5ad7-43d4-9bfa-eb92150a803e,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-c15d29ba-aa14-41cc-8c92-5553c07886c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542758957-172.17.0.21-1597058793998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-36037dec-33f2-4298-94fd-f3b58e5ddcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-3d69262b-a402-40df-8b0a-14122e45caab,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-ab43ff7f-a421-49e3-8323-a891fbc3c86e,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-45dc7e54-e9f6-4e27-ada9-c2dd6450751a,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-bd76e4f7-610f-42fa-b908-143bc3984a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-b395f5ce-799d-4af6-a3a8-5bf737f906d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-0375bc8c-09de-4293-88a3-c84be0a24e27,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-4cf8d0a8-1ce8-4150-8414-1e08b052197a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542758957-172.17.0.21-1597058793998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-36037dec-33f2-4298-94fd-f3b58e5ddcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-3d69262b-a402-40df-8b0a-14122e45caab,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-ab43ff7f-a421-49e3-8323-a891fbc3c86e,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-45dc7e54-e9f6-4e27-ada9-c2dd6450751a,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-bd76e4f7-610f-42fa-b908-143bc3984a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-b395f5ce-799d-4af6-a3a8-5bf737f906d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-0375bc8c-09de-4293-88a3-c84be0a24e27,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-4cf8d0a8-1ce8-4150-8414-1e08b052197a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182131573-172.17.0.21-1597058925848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38867,DS-a5f69f34-ff70-415d-babd-e905e8d401f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-32654d32-f778-4611-81e0-d5d909b88f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-852cf532-b667-41ea-822e-ae5e09ea225f,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-25c6d3cd-e44f-4a60-9dc3-5e172e0b91b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-56a0bf9c-5038-40c2-880f-5962ccd8ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-35edc849-2bdc-49fb-953e-74780538c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-62b0c39f-6ed3-459a-accd-28e93348cff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-208c3ffc-5568-4faf-9706-742db324fa49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182131573-172.17.0.21-1597058925848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38867,DS-a5f69f34-ff70-415d-babd-e905e8d401f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-32654d32-f778-4611-81e0-d5d909b88f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-852cf532-b667-41ea-822e-ae5e09ea225f,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-25c6d3cd-e44f-4a60-9dc3-5e172e0b91b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-56a0bf9c-5038-40c2-880f-5962ccd8ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-35edc849-2bdc-49fb-953e-74780538c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-62b0c39f-6ed3-459a-accd-28e93348cff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-208c3ffc-5568-4faf-9706-742db324fa49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009697215-172.17.0.21-1597059033303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-aa4060ea-b80f-48de-b68a-52207f5b077a,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-de09b4f3-f7bf-432f-8876-41207ce1e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-6a892ea1-f978-4782-b721-8c3daa331148,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-36bbaf0d-4d6f-456d-8a24-014a8401b00f,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-6e9154b6-d3f4-49a2-9ae5-5005e8871f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-55fe8c26-2623-4b99-92f4-06950e51e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-166b3ebf-c363-4bf1-92d5-a51fc5ccc268,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-4a549131-d5c5-4f81-9a0d-920b7881c83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009697215-172.17.0.21-1597059033303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-aa4060ea-b80f-48de-b68a-52207f5b077a,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-de09b4f3-f7bf-432f-8876-41207ce1e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-6a892ea1-f978-4782-b721-8c3daa331148,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-36bbaf0d-4d6f-456d-8a24-014a8401b00f,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-6e9154b6-d3f4-49a2-9ae5-5005e8871f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-55fe8c26-2623-4b99-92f4-06950e51e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-166b3ebf-c363-4bf1-92d5-a51fc5ccc268,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-4a549131-d5c5-4f81-9a0d-920b7881c83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935232593-172.17.0.21-1597059074889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45249,DS-adfef6c8-ab1c-4bda-8927-9582777442bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-68c37768-0952-4450-9e07-372549dcffcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-33a64d06-02f2-43d1-8c16-89807a8b9cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-24a28477-e767-4722-9b41-e9ac60bb73a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-b1157c19-34d2-4e06-a4bb-224c281c819f,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-c0d6a9e9-4b9f-4634-acd7-bc9cb00a3025,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-9d826a7a-143d-4190-aa47-0f2db57b34d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-448ffb51-94b0-4443-8c3b-40215d993c20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935232593-172.17.0.21-1597059074889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45249,DS-adfef6c8-ab1c-4bda-8927-9582777442bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-68c37768-0952-4450-9e07-372549dcffcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-33a64d06-02f2-43d1-8c16-89807a8b9cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-24a28477-e767-4722-9b41-e9ac60bb73a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-b1157c19-34d2-4e06-a4bb-224c281c819f,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-c0d6a9e9-4b9f-4634-acd7-bc9cb00a3025,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-9d826a7a-143d-4190-aa47-0f2db57b34d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-448ffb51-94b0-4443-8c3b-40215d993c20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677924645-172.17.0.21-1597059445396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-b7774dcb-5136-4b6a-8e11-0c17d8799fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-036f2cdf-25da-4783-892e-d6fa8a152345,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-e8af67ba-67a7-432a-850a-2af8f6798c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-d7666996-e2bd-450f-9aca-b5037fb6db63,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-d11774a5-d0ae-48b8-bb6d-da4b45193ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-fb936fd2-bbeb-42ae-96b0-2167c1ee77f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-7481436c-e555-42d9-a529-3da620a05d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-509ee4c7-9ef5-4427-9851-ad4b5cb29e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677924645-172.17.0.21-1597059445396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-b7774dcb-5136-4b6a-8e11-0c17d8799fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-036f2cdf-25da-4783-892e-d6fa8a152345,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-e8af67ba-67a7-432a-850a-2af8f6798c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-d7666996-e2bd-450f-9aca-b5037fb6db63,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-d11774a5-d0ae-48b8-bb6d-da4b45193ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-fb936fd2-bbeb-42ae-96b0-2167c1ee77f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-7481436c-e555-42d9-a529-3da620a05d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-509ee4c7-9ef5-4427-9851-ad4b5cb29e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508099719-172.17.0.21-1597059656402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45957,DS-c40d2b87-a7c4-4657-813a-29f3dddf5a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-85eff75b-42f1-404c-aa5a-b108539a1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-863baa42-0d0e-4841-a5d2-909fb9918b49,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-22082f24-b1e3-4d09-aa63-49c088680136,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-93d94abd-7d17-44fa-ba57-2159ef0fa00d,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-34e4a1fd-e67e-4d15-87f6-a92d13937fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-a0782b40-503f-41ef-9805-b0cf5fd3637f,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-faecfd8c-46e8-4f18-aa88-718e1840180f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508099719-172.17.0.21-1597059656402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45957,DS-c40d2b87-a7c4-4657-813a-29f3dddf5a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-85eff75b-42f1-404c-aa5a-b108539a1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-863baa42-0d0e-4841-a5d2-909fb9918b49,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-22082f24-b1e3-4d09-aa63-49c088680136,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-93d94abd-7d17-44fa-ba57-2159ef0fa00d,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-34e4a1fd-e67e-4d15-87f6-a92d13937fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-a0782b40-503f-41ef-9805-b0cf5fd3637f,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-faecfd8c-46e8-4f18-aa88-718e1840180f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033168213-172.17.0.21-1597060315654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-937be2b6-c75c-4423-900e-9c66877eae9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-75c5303d-e5b8-4ba0-9120-86fa2f0e6107,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-ffa2672b-dcb7-422b-b8a0-d6439adb1867,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-e56f4aa9-2531-4594-be9b-42fc20b7f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-fc105d29-8e2f-43e6-8612-88163f99ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-0929ce00-91f7-4232-a97c-8e1ada5d5166,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-06094ebb-e65a-481a-a54d-027eef94318c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-c67a8f6d-f983-4c1b-aaf2-2aef2dac7265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033168213-172.17.0.21-1597060315654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-937be2b6-c75c-4423-900e-9c66877eae9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-75c5303d-e5b8-4ba0-9120-86fa2f0e6107,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-ffa2672b-dcb7-422b-b8a0-d6439adb1867,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-e56f4aa9-2531-4594-be9b-42fc20b7f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-fc105d29-8e2f-43e6-8612-88163f99ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-0929ce00-91f7-4232-a97c-8e1ada5d5166,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-06094ebb-e65a-481a-a54d-027eef94318c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-c67a8f6d-f983-4c1b-aaf2-2aef2dac7265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024561985-172.17.0.21-1597060610418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-fae70f65-9ad0-4b36-b534-2120cb907565,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-e56b514a-d456-4382-be65-40b29c04ad81,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-a25ef15f-23e1-4200-984f-20a659ec54f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-f2acaea2-e9fd-4b8b-9a2d-b52bbf1a0093,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-be37da40-4a7a-403e-998a-3b2b73793fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-0644a47b-e9a7-4e34-b64d-a637439d70d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-6a580ae4-7ec3-462e-b8cc-d66219d78b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-bc7a81e2-4905-46e3-99c0-f63db557078e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024561985-172.17.0.21-1597060610418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-fae70f65-9ad0-4b36-b534-2120cb907565,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-e56b514a-d456-4382-be65-40b29c04ad81,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-a25ef15f-23e1-4200-984f-20a659ec54f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-f2acaea2-e9fd-4b8b-9a2d-b52bbf1a0093,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-be37da40-4a7a-403e-998a-3b2b73793fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-0644a47b-e9a7-4e34-b64d-a637439d70d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-6a580ae4-7ec3-462e-b8cc-d66219d78b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-bc7a81e2-4905-46e3-99c0-f63db557078e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729048077-172.17.0.21-1597060802473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42445,DS-889eff9e-7f1c-49b9-80cd-24884295ebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-1fcc1200-13ef-47c3-92b1-d60e1b49ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-b48e9846-1d89-4e0d-995d-1b3439cc713a,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-8a32c680-8c99-45e6-bf37-f11a7aacb251,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-626ef121-d0db-4777-94b3-b22acc0e92f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-0f04e082-03c0-4587-a6ea-8af8ae95d4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-4f1df329-2e7c-4b1f-a8eb-908222587b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-b5f829ef-0311-4bd1-8c47-f9036fc5fe8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729048077-172.17.0.21-1597060802473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42445,DS-889eff9e-7f1c-49b9-80cd-24884295ebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-1fcc1200-13ef-47c3-92b1-d60e1b49ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-b48e9846-1d89-4e0d-995d-1b3439cc713a,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-8a32c680-8c99-45e6-bf37-f11a7aacb251,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-626ef121-d0db-4777-94b3-b22acc0e92f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-0f04e082-03c0-4587-a6ea-8af8ae95d4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-4f1df329-2e7c-4b1f-a8eb-908222587b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-b5f829ef-0311-4bd1-8c47-f9036fc5fe8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5287
