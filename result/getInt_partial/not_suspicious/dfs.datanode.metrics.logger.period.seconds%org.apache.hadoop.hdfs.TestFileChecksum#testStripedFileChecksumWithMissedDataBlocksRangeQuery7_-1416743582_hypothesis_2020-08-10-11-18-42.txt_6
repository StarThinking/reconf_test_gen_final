reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474791909-172.17.0.11-1597058376710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-f9371074-6962-4c64-86ae-b2e1557ab0de,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-a0787789-4678-4f26-8a9c-b50e7eb05a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-cc0ecb24-ba62-40a7-9134-3438f8d32fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-95b3ebb0-9ce3-4ea1-9aa6-4d15c75c7235,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-7a107008-b4de-4e15-ae2d-dd2278ae5fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-3ee4c9c8-29ae-4ff5-a1d9-9285197e8c12,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-7d2f20dc-8435-4e4e-8230-4cf04347912f,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-f27e6025-83f3-4aa5-a96c-31e6fb6b232f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474791909-172.17.0.11-1597058376710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-f9371074-6962-4c64-86ae-b2e1557ab0de,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-a0787789-4678-4f26-8a9c-b50e7eb05a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-cc0ecb24-ba62-40a7-9134-3438f8d32fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-95b3ebb0-9ce3-4ea1-9aa6-4d15c75c7235,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-7a107008-b4de-4e15-ae2d-dd2278ae5fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-3ee4c9c8-29ae-4ff5-a1d9-9285197e8c12,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-7d2f20dc-8435-4e4e-8230-4cf04347912f,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-f27e6025-83f3-4aa5-a96c-31e6fb6b232f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507874338-172.17.0.11-1597058668287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36262,DS-394f34c4-aa6c-459f-8c71-1db8601643cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-c017792b-0e2e-43be-bcfe-57a3b98629fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-33b51440-efc3-48fb-a535-c61f21cee398,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-cacefb2d-8d51-4c5b-91fb-bcd91fe328b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-a028a193-29fa-45cd-9620-3443a7330da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-25fb4f34-f2df-4c68-a225-8c07f0d2ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-cc2acdff-305e-413d-b8e5-8d82b635d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-83e002af-d3d6-4be4-bce0-1b4a3e4fe06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507874338-172.17.0.11-1597058668287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36262,DS-394f34c4-aa6c-459f-8c71-1db8601643cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-c017792b-0e2e-43be-bcfe-57a3b98629fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-33b51440-efc3-48fb-a535-c61f21cee398,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-cacefb2d-8d51-4c5b-91fb-bcd91fe328b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-a028a193-29fa-45cd-9620-3443a7330da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-25fb4f34-f2df-4c68-a225-8c07f0d2ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-cc2acdff-305e-413d-b8e5-8d82b635d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-83e002af-d3d6-4be4-bce0-1b4a3e4fe06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961384069-172.17.0.11-1597058959569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-91249d5a-0cf5-46bf-8df5-3d272fa43584,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-2b0102b3-47b1-4c5f-85da-df1bf58b3288,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-412e27eb-d864-4fba-b352-cc7ad4eaf9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-ec45ccee-ad11-4fd7-a778-85324925d8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-c2f4fe64-d2a8-4002-ba20-ed78fd1b3b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-7f3a9648-cd14-4761-bb25-29092a2c37c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-5cfa32ad-44e7-4b73-9e92-98e5bd6026d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-b60ef3d3-1271-45b7-a9d6-cde31175c51a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961384069-172.17.0.11-1597058959569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-91249d5a-0cf5-46bf-8df5-3d272fa43584,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-2b0102b3-47b1-4c5f-85da-df1bf58b3288,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-412e27eb-d864-4fba-b352-cc7ad4eaf9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-ec45ccee-ad11-4fd7-a778-85324925d8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-c2f4fe64-d2a8-4002-ba20-ed78fd1b3b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-7f3a9648-cd14-4761-bb25-29092a2c37c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-5cfa32ad-44e7-4b73-9e92-98e5bd6026d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-b60ef3d3-1271-45b7-a9d6-cde31175c51a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332218884-172.17.0.11-1597059073219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38448,DS-b6899c69-7f2c-470a-aa4b-2412c8ea26c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-bc724711-4119-4955-b651-403ec4471e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-c977b820-d653-43c6-857f-966d430c47ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-3b85029f-24fc-4fc3-96b8-687fca139f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-6c2e4a91-2155-4166-b631-94d554f992de,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-33ec1b16-917a-427c-85c4-c1e47aca142f,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-7ed88f9d-baf8-4b4d-8bba-549a50319845,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-a927a52b-e27d-4c95-874b-5c40355b6f8f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332218884-172.17.0.11-1597059073219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38448,DS-b6899c69-7f2c-470a-aa4b-2412c8ea26c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-bc724711-4119-4955-b651-403ec4471e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-c977b820-d653-43c6-857f-966d430c47ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-3b85029f-24fc-4fc3-96b8-687fca139f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-6c2e4a91-2155-4166-b631-94d554f992de,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-33ec1b16-917a-427c-85c4-c1e47aca142f,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-7ed88f9d-baf8-4b4d-8bba-549a50319845,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-a927a52b-e27d-4c95-874b-5c40355b6f8f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100448647-172.17.0.11-1597059142962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-933439a5-d7bf-4e98-acad-18038d26f713,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-5f8b3faf-f096-4578-8589-d5ada9abefa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-5cbf5aee-a660-4050-8930-1d1a7fc25a84,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-e3f7a9c7-bd61-4737-b4c7-b1682881fa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-695b5511-b875-458c-8834-6767fec8d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-3f005571-4a1b-4b3f-a554-0a67f3e69a57,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-f9c3b32c-ce35-46a7-8cdf-cea520a105b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-c36f8cec-b19a-47f7-a78f-eded101da924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100448647-172.17.0.11-1597059142962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-933439a5-d7bf-4e98-acad-18038d26f713,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-5f8b3faf-f096-4578-8589-d5ada9abefa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-5cbf5aee-a660-4050-8930-1d1a7fc25a84,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-e3f7a9c7-bd61-4737-b4c7-b1682881fa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-695b5511-b875-458c-8834-6767fec8d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-3f005571-4a1b-4b3f-a554-0a67f3e69a57,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-f9c3b32c-ce35-46a7-8cdf-cea520a105b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-c36f8cec-b19a-47f7-a78f-eded101da924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821349658-172.17.0.11-1597059549676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44786,DS-d3aaf511-3c96-4310-bade-1dac811ed0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-54002ad1-1e9d-469d-8018-111ff2942b61,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-91d6fb0a-84bc-4517-8810-f6a67859f3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-0785d03e-41d3-4993-9c4a-51ff37ee7831,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-aee64473-49bb-4f00-aeb8-a5b18f93f7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-b4062364-d78b-4bd0-8804-630fb7367626,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-bf74d30a-ced3-4d2e-ae2e-db35b21df49a,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-e250fac7-48ac-45ab-8f01-756a8dafe2a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821349658-172.17.0.11-1597059549676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44786,DS-d3aaf511-3c96-4310-bade-1dac811ed0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-54002ad1-1e9d-469d-8018-111ff2942b61,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-91d6fb0a-84bc-4517-8810-f6a67859f3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-0785d03e-41d3-4993-9c4a-51ff37ee7831,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-aee64473-49bb-4f00-aeb8-a5b18f93f7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-b4062364-d78b-4bd0-8804-630fb7367626,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-bf74d30a-ced3-4d2e-ae2e-db35b21df49a,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-e250fac7-48ac-45ab-8f01-756a8dafe2a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034436167-172.17.0.11-1597059824587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-ccafccbe-5beb-4d68-81b4-6758e04c5712,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-f44c1d90-449d-4f53-98b6-74a85a4f022a,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-7d8b09f2-b7bd-47ce-a5cf-4d2566b520f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-dae8ff5d-6f7e-47e2-9240-499e2d798e19,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-0efaac16-9ef7-4357-bafd-5503488b58d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-c5c810e2-9ea6-4229-afe8-bd50fd6d8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-58725d14-d6f3-49e1-86f1-46d3a4cfcc70,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-ca486e89-d40d-413e-a423-206725575fad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034436167-172.17.0.11-1597059824587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-ccafccbe-5beb-4d68-81b4-6758e04c5712,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-f44c1d90-449d-4f53-98b6-74a85a4f022a,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-7d8b09f2-b7bd-47ce-a5cf-4d2566b520f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-dae8ff5d-6f7e-47e2-9240-499e2d798e19,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-0efaac16-9ef7-4357-bafd-5503488b58d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-c5c810e2-9ea6-4229-afe8-bd50fd6d8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-58725d14-d6f3-49e1-86f1-46d3a4cfcc70,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-ca486e89-d40d-413e-a423-206725575fad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632558904-172.17.0.11-1597060117387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-79173ed1-53e9-4fde-964e-44eef60030bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-d3aa8e2a-bdbf-4091-bf8b-19c4f3795f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-a87569b1-df7c-4656-9ced-9cbff3d086d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-be88adae-b153-44e4-bd76-2a1b5290b897,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-b32845a0-8795-4e21-9dc8-8a0a2890d785,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-23f3ee52-d80a-47c6-b31a-daf0617f1216,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-21004a26-4656-492f-b03c-ff1008fe106b,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-ec168dfe-fefd-43cc-9a24-5c4d9e9a4c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632558904-172.17.0.11-1597060117387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-79173ed1-53e9-4fde-964e-44eef60030bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-d3aa8e2a-bdbf-4091-bf8b-19c4f3795f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-a87569b1-df7c-4656-9ced-9cbff3d086d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-be88adae-b153-44e4-bd76-2a1b5290b897,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-b32845a0-8795-4e21-9dc8-8a0a2890d785,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-23f3ee52-d80a-47c6-b31a-daf0617f1216,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-21004a26-4656-492f-b03c-ff1008fe106b,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-ec168dfe-fefd-43cc-9a24-5c4d9e9a4c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619353866-172.17.0.11-1597060183797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33090,DS-164c60b1-5f51-4169-8a9b-d24f51a65d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-4705fef9-3cbf-447f-bce4-6552c1d22e34,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-5e6b5881-3812-40b8-8554-7567f73f83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-00a3f0a6-15e2-4d07-8bbb-a40240f9485e,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-8098e2ed-e393-4b55-ba8f-e473309f230f,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-1729b75a-34c7-4d43-8ff5-407c0f596008,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-0d4ef9b2-f896-458d-b905-1212eed5d6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-83b90606-c490-427b-83af-ef28a3955ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619353866-172.17.0.11-1597060183797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33090,DS-164c60b1-5f51-4169-8a9b-d24f51a65d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-4705fef9-3cbf-447f-bce4-6552c1d22e34,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-5e6b5881-3812-40b8-8554-7567f73f83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-00a3f0a6-15e2-4d07-8bbb-a40240f9485e,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-8098e2ed-e393-4b55-ba8f-e473309f230f,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-1729b75a-34c7-4d43-8ff5-407c0f596008,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-0d4ef9b2-f896-458d-b905-1212eed5d6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-83b90606-c490-427b-83af-ef28a3955ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705246678-172.17.0.11-1597060223989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-6320261f-8104-4689-887b-9c8c6d6e1d18,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-a0582f83-99c2-4952-bbdb-211b8e2e087f,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-e2a39c80-121d-4e64-99ff-58c38cf44560,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-70bf9cd9-6aff-4053-a8ba-0da4b20ff78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-b1f27b54-3891-4582-bf1e-36cee78d99f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-1d561f4a-59cf-41c1-b42d-da6a72291e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-8b9687f9-29e4-402b-9c06-c6ff5a5047db,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-6e914ae6-5522-44cc-ba3b-f6c528c78612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705246678-172.17.0.11-1597060223989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-6320261f-8104-4689-887b-9c8c6d6e1d18,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-a0582f83-99c2-4952-bbdb-211b8e2e087f,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-e2a39c80-121d-4e64-99ff-58c38cf44560,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-70bf9cd9-6aff-4053-a8ba-0da4b20ff78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-b1f27b54-3891-4582-bf1e-36cee78d99f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-1d561f4a-59cf-41c1-b42d-da6a72291e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-8b9687f9-29e4-402b-9c06-c6ff5a5047db,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-6e914ae6-5522-44cc-ba3b-f6c528c78612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855958628-172.17.0.11-1597060450967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38345,DS-7bdfc799-3e4a-4283-b94d-ae844fbc4e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-ee9151bb-1cc9-4b26-ac4b-c9d8157dd0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-2a593ce4-d726-4c0b-8242-426db9e0e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-3b3ef532-449a-43cd-9532-ce314bf1b2db,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-edf6d84d-bf11-46a5-89bb-ffab6b17fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-979758d4-2a9c-467e-a6e6-ca031e959f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-65ba7d5e-f2c7-465b-9740-d8f6f25407d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-3ebdeb5a-e6ba-4677-b799-2ca3f9567d2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855958628-172.17.0.11-1597060450967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38345,DS-7bdfc799-3e4a-4283-b94d-ae844fbc4e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-ee9151bb-1cc9-4b26-ac4b-c9d8157dd0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-2a593ce4-d726-4c0b-8242-426db9e0e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-3b3ef532-449a-43cd-9532-ce314bf1b2db,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-edf6d84d-bf11-46a5-89bb-ffab6b17fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-979758d4-2a9c-467e-a6e6-ca031e959f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-65ba7d5e-f2c7-465b-9740-d8f6f25407d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-3ebdeb5a-e6ba-4677-b799-2ca3f9567d2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432030861-172.17.0.11-1597060488843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35248,DS-387a1b9d-2a79-49ad-8551-5eff8873e490,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-0791b17a-5391-4e1a-ab48-023f5a727aed,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-7116301e-ea92-4587-b58c-da0e186ba32a,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-332c1a9b-4d94-4642-bc8b-e6b93a2ac6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-5ca55fef-107a-4ed8-a02f-e33d41770a42,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-8ed123a1-b5fd-4269-923b-47a30cc46f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-43d9bbd3-f7e5-4925-bee8-7af1e07f0a87,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-2851fe8f-c7c0-48e7-88c5-09fdef04ce11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432030861-172.17.0.11-1597060488843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35248,DS-387a1b9d-2a79-49ad-8551-5eff8873e490,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-0791b17a-5391-4e1a-ab48-023f5a727aed,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-7116301e-ea92-4587-b58c-da0e186ba32a,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-332c1a9b-4d94-4642-bc8b-e6b93a2ac6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-5ca55fef-107a-4ed8-a02f-e33d41770a42,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-8ed123a1-b5fd-4269-923b-47a30cc46f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-43d9bbd3-f7e5-4925-bee8-7af1e07f0a87,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-2851fe8f-c7c0-48e7-88c5-09fdef04ce11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477579346-172.17.0.11-1597060639415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41787,DS-dcb5328a-6f18-41bd-af98-d75f464e4d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-d9cd4928-9928-4852-a517-7f4bba96baf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-d85ae92f-8646-494d-8347-a3194f49e1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-abd696a2-d72c-45d4-8eb9-743934e339cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-85fab0d7-09c7-480f-8dac-aa53fee0fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-3cb7480a-6db4-4af2-af21-46efa7717c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-44f897f3-4c17-4b11-98ae-506f567d497a,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-50923177-d1aa-4533-a95c-f92f8dfd0a79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477579346-172.17.0.11-1597060639415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41787,DS-dcb5328a-6f18-41bd-af98-d75f464e4d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-d9cd4928-9928-4852-a517-7f4bba96baf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-d85ae92f-8646-494d-8347-a3194f49e1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-abd696a2-d72c-45d4-8eb9-743934e339cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-85fab0d7-09c7-480f-8dac-aa53fee0fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-3cb7480a-6db4-4af2-af21-46efa7717c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-44f897f3-4c17-4b11-98ae-506f567d497a,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-50923177-d1aa-4533-a95c-f92f8dfd0a79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636577034-172.17.0.11-1597060722128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40096,DS-3003f73c-d621-4dbd-95c9-08b8c3e69953,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-9a386bd8-4a7e-4748-bd77-9e438f48df35,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-f27effe0-032b-4341-bdac-caa47a716482,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-8707bdb6-d465-42ae-8d56-0be21d7ceb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-74633c36-7312-4668-bfd8-9258e929d0af,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-271e3c74-643d-4350-a019-af4b0ccec495,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-823420b3-e8d9-4d7b-943b-441056501d64,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-d6ab4ad9-80ff-476c-8546-a7539ce40d4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636577034-172.17.0.11-1597060722128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40096,DS-3003f73c-d621-4dbd-95c9-08b8c3e69953,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-9a386bd8-4a7e-4748-bd77-9e438f48df35,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-f27effe0-032b-4341-bdac-caa47a716482,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-8707bdb6-d465-42ae-8d56-0be21d7ceb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-74633c36-7312-4668-bfd8-9258e929d0af,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-271e3c74-643d-4350-a019-af4b0ccec495,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-823420b3-e8d9-4d7b-943b-441056501d64,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-d6ab4ad9-80ff-476c-8546-a7539ce40d4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914792360-172.17.0.11-1597060846474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34673,DS-b6099265-8d3b-4bde-8e4d-532d9f302d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-8334d7f3-10ee-4cc1-8832-4271d4968dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-0aaffff8-de1e-4aeb-b9dc-403042563669,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-50b3f0c0-ff4e-4ebb-b9e3-0cdca7a20d92,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-d7fef280-274b-418a-9a13-9825e3f7a154,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-19fbb198-0e63-4637-9412-9613a5ca6bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-e3e583fa-3754-413b-8524-e425f9d68fae,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-a9b32fac-2df5-4308-9bd9-09f06a276783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914792360-172.17.0.11-1597060846474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34673,DS-b6099265-8d3b-4bde-8e4d-532d9f302d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-8334d7f3-10ee-4cc1-8832-4271d4968dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-0aaffff8-de1e-4aeb-b9dc-403042563669,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-50b3f0c0-ff4e-4ebb-b9e3-0cdca7a20d92,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-d7fef280-274b-418a-9a13-9825e3f7a154,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-19fbb198-0e63-4637-9412-9613a5ca6bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-e3e583fa-3754-413b-8524-e425f9d68fae,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-a9b32fac-2df5-4308-9bd9-09f06a276783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251728014-172.17.0.11-1597060920908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43082,DS-88b74c9b-d4a6-487d-b375-5c943b3ff028,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-e678f8e1-5d04-495c-8a8a-e44cc615c4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-badac453-768c-49e7-a1a7-2aa73c1b12a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-daac6ffe-5c62-4a46-8d3f-430432581bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-60f7d4e5-1667-4a2f-92f5-e05fe6d43a16,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-2c33dca7-e99f-448c-a991-59d96ba3ec46,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-f2c81afd-3f56-4124-ad9e-cd1ff6256ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-8375d385-4569-4c5b-84d5-8270720938df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251728014-172.17.0.11-1597060920908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43082,DS-88b74c9b-d4a6-487d-b375-5c943b3ff028,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-e678f8e1-5d04-495c-8a8a-e44cc615c4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-badac453-768c-49e7-a1a7-2aa73c1b12a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-daac6ffe-5c62-4a46-8d3f-430432581bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-60f7d4e5-1667-4a2f-92f5-e05fe6d43a16,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-2c33dca7-e99f-448c-a991-59d96ba3ec46,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-f2c81afd-3f56-4124-ad9e-cd1ff6256ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-8375d385-4569-4c5b-84d5-8270720938df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340301755-172.17.0.11-1597061274893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37815,DS-5bd49780-50ea-4faf-a0d8-c1b15462ce24,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-73ff6635-39f2-4ff7-b07b-8599f59492c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-fff8ea62-d7be-46e1-ac81-076f6a274501,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-cf04f319-0aeb-4248-9953-830faac2d643,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-e31178a4-6aa0-4f4e-811b-f97f6eabe1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-24cff1d2-e509-4f04-b900-66efed6e34ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-8ed5f86f-510b-4b23-95f5-d8789bebb1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-27fba55d-cfb1-4212-bb2e-0480b181411d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340301755-172.17.0.11-1597061274893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37815,DS-5bd49780-50ea-4faf-a0d8-c1b15462ce24,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-73ff6635-39f2-4ff7-b07b-8599f59492c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-fff8ea62-d7be-46e1-ac81-076f6a274501,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-cf04f319-0aeb-4248-9953-830faac2d643,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-e31178a4-6aa0-4f4e-811b-f97f6eabe1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-24cff1d2-e509-4f04-b900-66efed6e34ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-8ed5f86f-510b-4b23-95f5-d8789bebb1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-27fba55d-cfb1-4212-bb2e-0480b181411d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801859381-172.17.0.11-1597061348373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-db639a68-636f-42a8-97b2-0f2314f081f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-6066e92c-1906-4874-9f8a-38505b57605a,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-6acbd9e4-6a1b-4c94-a453-805006d4d79b,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-2e30b844-6a51-4a32-950e-7c3d5b42a81a,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-fa83d735-4ec0-42ff-b591-6db6515db071,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-b1b82288-803b-46ad-82d5-6cd1d4f53687,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-36e95942-7341-40ba-a339-ee715f202c60,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-0a3fa1dc-7edd-4e05-a684-aea6c81b0a64,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801859381-172.17.0.11-1597061348373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-db639a68-636f-42a8-97b2-0f2314f081f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-6066e92c-1906-4874-9f8a-38505b57605a,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-6acbd9e4-6a1b-4c94-a453-805006d4d79b,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-2e30b844-6a51-4a32-950e-7c3d5b42a81a,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-fa83d735-4ec0-42ff-b591-6db6515db071,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-b1b82288-803b-46ad-82d5-6cd1d4f53687,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-36e95942-7341-40ba-a339-ee715f202c60,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-0a3fa1dc-7edd-4e05-a684-aea6c81b0a64,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976825205-172.17.0.11-1597061586567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46796,DS-2e037dec-dbac-4fa7-bd13-9716517e389f,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-866283c1-70d4-4066-9012-53aa9d15902b,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-fd5ac8ba-4dcc-4ed2-9f1e-ea128dcccb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-320a994e-7800-4e79-9dae-42b4f64295a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-63c5c6bb-ad87-47dc-9876-8b564afb8aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-6eb2d7b0-dd73-459a-84a8-d7c45ae3cca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-33354321-6a17-44b4-b15d-2474b67d0b77,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-4df27562-b90d-4816-ac55-7cc59c479a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976825205-172.17.0.11-1597061586567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46796,DS-2e037dec-dbac-4fa7-bd13-9716517e389f,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-866283c1-70d4-4066-9012-53aa9d15902b,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-fd5ac8ba-4dcc-4ed2-9f1e-ea128dcccb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-320a994e-7800-4e79-9dae-42b4f64295a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-63c5c6bb-ad87-47dc-9876-8b564afb8aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-6eb2d7b0-dd73-459a-84a8-d7c45ae3cca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-33354321-6a17-44b4-b15d-2474b67d0b77,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-4df27562-b90d-4816-ac55-7cc59c479a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896529807-172.17.0.11-1597061665328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-d1db9c48-0156-4acf-86ec-c34c1b612302,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-9b29bf54-5fbc-44a7-8334-49b6962a2885,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-5ad5fd2e-e27a-4a44-b2ba-61baef0756d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-9395cf73-10eb-4bf9-8e65-800bff4db89a,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-2e3fe503-3967-4bfa-a2ff-184105a80087,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-589ced41-8948-4825-b1f0-f2ce13c37224,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-85e0476a-1730-484d-874b-76bf1c43a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-14851508-ff75-4b65-af12-b79898e9f01f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896529807-172.17.0.11-1597061665328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-d1db9c48-0156-4acf-86ec-c34c1b612302,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-9b29bf54-5fbc-44a7-8334-49b6962a2885,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-5ad5fd2e-e27a-4a44-b2ba-61baef0756d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-9395cf73-10eb-4bf9-8e65-800bff4db89a,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-2e3fe503-3967-4bfa-a2ff-184105a80087,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-589ced41-8948-4825-b1f0-f2ce13c37224,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-85e0476a-1730-484d-874b-76bf1c43a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-14851508-ff75-4b65-af12-b79898e9f01f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920371670-172.17.0.11-1597061748998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-bd23b1aa-fc64-4778-8384-50a3b31f50b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-06d67423-38e3-466d-bae5-7b4ee9ffd1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-b675b368-2c50-4338-bcd2-61ae073e9796,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-6f79411d-0b6c-4179-bd8a-6559db86d49f,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-b1947d6e-051e-43b8-a1c0-9732542c32da,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-d87e398f-5e59-4cb0-834d-f6690f984ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-0480edbf-29b6-4c48-bb3a-9c4edc9b2c09,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-2cb6f115-f8e2-4bee-b75d-eadb51120783,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920371670-172.17.0.11-1597061748998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-bd23b1aa-fc64-4778-8384-50a3b31f50b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-06d67423-38e3-466d-bae5-7b4ee9ffd1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-b675b368-2c50-4338-bcd2-61ae073e9796,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-6f79411d-0b6c-4179-bd8a-6559db86d49f,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-b1947d6e-051e-43b8-a1c0-9732542c32da,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-d87e398f-5e59-4cb0-834d-f6690f984ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-0480edbf-29b6-4c48-bb3a-9c4edc9b2c09,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-2cb6f115-f8e2-4bee-b75d-eadb51120783,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962741113-172.17.0.11-1597061790734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-312d5850-b713-4b93-acfe-db161aec3e09,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-34d0f572-9b86-4d38-bb0d-6d7d3a76c426,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-a071bb5b-299b-4f82-9ce6-361236881083,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-2b19ccb2-2297-4f3c-badd-624f2c11b988,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-e6396e7f-3062-4667-aa01-b355e2eaab05,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-fde08a28-fdca-408f-80e2-3f25082e6591,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-f460cf09-4156-4a8b-af4f-3ef00a23f9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-ee2e0392-1c36-4a65-948a-dedf2be8c755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962741113-172.17.0.11-1597061790734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-312d5850-b713-4b93-acfe-db161aec3e09,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-34d0f572-9b86-4d38-bb0d-6d7d3a76c426,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-a071bb5b-299b-4f82-9ce6-361236881083,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-2b19ccb2-2297-4f3c-badd-624f2c11b988,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-e6396e7f-3062-4667-aa01-b355e2eaab05,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-fde08a28-fdca-408f-80e2-3f25082e6591,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-f460cf09-4156-4a8b-af4f-3ef00a23f9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-ee2e0392-1c36-4a65-948a-dedf2be8c755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575233113-172.17.0.11-1597062273773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35540,DS-1f925f3f-75a0-4fbd-91bd-b4b193466b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-b41a249e-4d21-466c-af1a-56823bc0529b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-03fd7219-b5a6-488f-b36a-a2b3f8103aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-30bf8ce0-e51e-471d-8789-72ba0c7d6143,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-0192a312-3720-45dc-b8bf-98f10d2207e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-a67dbf86-6924-4b39-bdf7-b8ab808a0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-6dcccea6-e507-4666-b977-8e8fa93dbbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-5f5c3861-96b0-448d-b36a-2ac2b9692ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575233113-172.17.0.11-1597062273773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35540,DS-1f925f3f-75a0-4fbd-91bd-b4b193466b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-b41a249e-4d21-466c-af1a-56823bc0529b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-03fd7219-b5a6-488f-b36a-a2b3f8103aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-30bf8ce0-e51e-471d-8789-72ba0c7d6143,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-0192a312-3720-45dc-b8bf-98f10d2207e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-a67dbf86-6924-4b39-bdf7-b8ab808a0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-6dcccea6-e507-4666-b977-8e8fa93dbbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-5f5c3861-96b0-448d-b36a-2ac2b9692ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881612553-172.17.0.11-1597062308854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-69344967-cec3-4091-91ac-de185ece51fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-cd89302b-4cf1-455f-9bf2-bac91c9b314d,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-42815609-3fc1-4a32-9196-0ddf43894cca,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-1514a4f7-4f74-49f9-b6c5-60480fa634a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-459bd88f-6063-4cd7-adcb-b9f0e66d8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-965dcf94-99c6-48c4-b88e-de244dd0d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-3b829049-302f-48ce-9adf-9087569ecae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-bc306e46-e577-4c66-ad8a-e26dcf72461f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881612553-172.17.0.11-1597062308854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-69344967-cec3-4091-91ac-de185ece51fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-cd89302b-4cf1-455f-9bf2-bac91c9b314d,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-42815609-3fc1-4a32-9196-0ddf43894cca,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-1514a4f7-4f74-49f9-b6c5-60480fa634a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-459bd88f-6063-4cd7-adcb-b9f0e66d8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-965dcf94-99c6-48c4-b88e-de244dd0d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-3b829049-302f-48ce-9adf-9087569ecae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-bc306e46-e577-4c66-ad8a-e26dcf72461f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135328951-172.17.0.11-1597062421528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46460,DS-b51253de-6cc2-44cb-a779-24ec7a937d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-55c6091e-e894-49d3-917e-08665a64d221,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-bd9d5e96-ce09-496f-b4e9-7c4e23e3d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-2db01683-1bbe-49d4-a064-5266bb36c172,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-c66b32eb-beba-4cc7-9793-cd5e7c6d4ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-f012c23c-c2f7-46ac-b807-8ba0347a396f,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-57264716-9aee-46ca-ab70-5bab1868d573,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-5e8f1320-d0ce-4723-8715-4f6aa18072b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135328951-172.17.0.11-1597062421528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46460,DS-b51253de-6cc2-44cb-a779-24ec7a937d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-55c6091e-e894-49d3-917e-08665a64d221,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-bd9d5e96-ce09-496f-b4e9-7c4e23e3d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-2db01683-1bbe-49d4-a064-5266bb36c172,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-c66b32eb-beba-4cc7-9793-cd5e7c6d4ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-f012c23c-c2f7-46ac-b807-8ba0347a396f,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-57264716-9aee-46ca-ab70-5bab1868d573,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-5e8f1320-d0ce-4723-8715-4f6aa18072b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127265775-172.17.0.11-1597062460629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-51fae38d-5ece-4247-90bd-11614112145c,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-7f33ec22-f1fc-466d-b4c2-d855a63c945d,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-bea3cafe-9be6-4075-9459-0ca0c2831248,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-85f10989-2059-4463-a4e4-30b09aebd0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-75fc1bde-5782-4544-bf46-bd3f6deb1b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-c7040ee5-acd6-4e35-b26c-298f2fe1ebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-af656f56-e628-4df6-b960-61ce6ad230a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-cbf62c18-6478-434f-85f0-e49bc10c6cec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127265775-172.17.0.11-1597062460629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-51fae38d-5ece-4247-90bd-11614112145c,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-7f33ec22-f1fc-466d-b4c2-d855a63c945d,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-bea3cafe-9be6-4075-9459-0ca0c2831248,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-85f10989-2059-4463-a4e4-30b09aebd0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-75fc1bde-5782-4544-bf46-bd3f6deb1b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-c7040ee5-acd6-4e35-b26c-298f2fe1ebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-af656f56-e628-4df6-b960-61ce6ad230a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-cbf62c18-6478-434f-85f0-e49bc10c6cec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795984600-172.17.0.11-1597062599802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-221feccf-eb78-4672-b234-730ff58ccda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-e2123c6f-027e-46da-9ace-09b402fd618a,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-9e01d48c-d73c-4c4f-bece-49284736125f,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-36f5c954-abba-44f5-89ec-4d3aa68b8bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-9785cfc4-76bb-43d2-abfa-a76d45af0144,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-1d7fd3fd-23ae-4036-9eb2-bc86a8f240b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-0f9b52db-24f7-482b-9a8d-67ed4560f3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-7306eec8-0c95-428c-80c4-b73b40327e02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795984600-172.17.0.11-1597062599802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-221feccf-eb78-4672-b234-730ff58ccda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-e2123c6f-027e-46da-9ace-09b402fd618a,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-9e01d48c-d73c-4c4f-bece-49284736125f,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-36f5c954-abba-44f5-89ec-4d3aa68b8bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-9785cfc4-76bb-43d2-abfa-a76d45af0144,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-1d7fd3fd-23ae-4036-9eb2-bc86a8f240b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-0f9b52db-24f7-482b-9a8d-67ed4560f3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-7306eec8-0c95-428c-80c4-b73b40327e02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428959023-172.17.0.11-1597062776691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39033,DS-183f93f6-3268-4cd5-a2db-dde961c885d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-2e7e5262-a5b0-4465-9b2b-fe7776e2394d,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-9a9aaa62-630e-4674-8aff-1e8e1cf5e2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-06f86f63-7688-43b7-a9aa-e5870bd9c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-f60615ad-bae6-4531-8933-3349dc1bbf73,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-7304125f-f6f7-4fec-a5b5-8cf8cf569df1,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-d695ed57-1d97-41cc-9411-9995eb89b510,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-f7493446-dfd9-4d4b-8241-2a42e70d2632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428959023-172.17.0.11-1597062776691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39033,DS-183f93f6-3268-4cd5-a2db-dde961c885d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-2e7e5262-a5b0-4465-9b2b-fe7776e2394d,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-9a9aaa62-630e-4674-8aff-1e8e1cf5e2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-06f86f63-7688-43b7-a9aa-e5870bd9c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-f60615ad-bae6-4531-8933-3349dc1bbf73,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-7304125f-f6f7-4fec-a5b5-8cf8cf569df1,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-d695ed57-1d97-41cc-9411-9995eb89b510,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-f7493446-dfd9-4d4b-8241-2a42e70d2632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576733492-172.17.0.11-1597062947192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39089,DS-cb3f69ce-4eae-4e15-a489-dab7f5bbad21,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-795637e9-5899-4192-ae4a-f27d35269305,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-0bfbdb12-33fd-4585-b2da-ca987fb2e385,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-818ecaa4-f5bb-4244-b860-71c550f1bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-4ed192a7-54cf-4bca-83a8-9d7d231f4ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-56341dc9-be8d-42be-a1b4-6ee9885750ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-98b31ecc-8bc7-4c5e-9dc1-b38f5dfb8e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-aeaadcb2-f801-48da-a7c7-f556a7a3878f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576733492-172.17.0.11-1597062947192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39089,DS-cb3f69ce-4eae-4e15-a489-dab7f5bbad21,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-795637e9-5899-4192-ae4a-f27d35269305,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-0bfbdb12-33fd-4585-b2da-ca987fb2e385,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-818ecaa4-f5bb-4244-b860-71c550f1bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-4ed192a7-54cf-4bca-83a8-9d7d231f4ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-56341dc9-be8d-42be-a1b4-6ee9885750ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-98b31ecc-8bc7-4c5e-9dc1-b38f5dfb8e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-aeaadcb2-f801-48da-a7c7-f556a7a3878f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440752949-172.17.0.11-1597063157964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-4cc9d67a-dd63-481d-8ab2-b7de0a0bf15c,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-3eab7853-6893-4a75-93eb-719c12046e76,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-5f6e8f7b-f677-4031-a018-ebf425495aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-c10c0da3-0548-4bcc-8935-25aa184665e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-6f13d3d7-90ff-4bb4-898c-9ce505f2e19e,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-1e2ecc8a-16b6-41f8-9cfa-8938b39c924b,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-d33f49ff-487f-4f86-9e88-7f7a6be69081,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-5d64fa62-8e8a-47ec-919b-30375502434d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440752949-172.17.0.11-1597063157964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-4cc9d67a-dd63-481d-8ab2-b7de0a0bf15c,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-3eab7853-6893-4a75-93eb-719c12046e76,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-5f6e8f7b-f677-4031-a018-ebf425495aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-c10c0da3-0548-4bcc-8935-25aa184665e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-6f13d3d7-90ff-4bb4-898c-9ce505f2e19e,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-1e2ecc8a-16b6-41f8-9cfa-8938b39c924b,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-d33f49ff-487f-4f86-9e88-7f7a6be69081,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-5d64fa62-8e8a-47ec-919b-30375502434d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294775271-172.17.0.11-1597063192876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44782,DS-55f3fa95-1bf9-4cf0-ab32-a862d5704c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-be1ec0aa-5896-4b5b-9d02-478268a8d941,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-840ab3d4-875c-4217-9d8f-4d4f1cbe075b,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-ce5626c9-5731-4c49-8075-e99286460492,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-fe20d4a1-4460-4a7b-bd11-73de83cdd6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-b62a69ca-3a1f-499d-b130-4ef405cf3262,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-7d927fc0-9fbf-47cc-bbee-fd00041e98b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-0e538b29-8703-4f32-9e9d-7d274fa0a1c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294775271-172.17.0.11-1597063192876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44782,DS-55f3fa95-1bf9-4cf0-ab32-a862d5704c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-be1ec0aa-5896-4b5b-9d02-478268a8d941,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-840ab3d4-875c-4217-9d8f-4d4f1cbe075b,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-ce5626c9-5731-4c49-8075-e99286460492,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-fe20d4a1-4460-4a7b-bd11-73de83cdd6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-b62a69ca-3a1f-499d-b130-4ef405cf3262,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-7d927fc0-9fbf-47cc-bbee-fd00041e98b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-0e538b29-8703-4f32-9e9d-7d274fa0a1c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5628
