reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978352818-172.17.0.7-1597175351777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-1b560be0-6878-423b-9064-681fdc3f779d,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-349c0a5f-d7ec-488f-a600-554141376c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-9afbb7f4-61c2-42da-baab-6890e14357e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-0048d175-50cb-4fbd-96cd-7f805e0b63ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-1f102775-5ee3-4b8b-8968-644d78bdaed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-673a6b58-bd0b-454c-b338-b9e907ba2f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-4bc5147a-b732-4f6c-88c8-1bb5475c8fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-9012e69b-6d0a-4c85-9f29-ce9bca16f55a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978352818-172.17.0.7-1597175351777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-1b560be0-6878-423b-9064-681fdc3f779d,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-349c0a5f-d7ec-488f-a600-554141376c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-9afbb7f4-61c2-42da-baab-6890e14357e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-0048d175-50cb-4fbd-96cd-7f805e0b63ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-1f102775-5ee3-4b8b-8968-644d78bdaed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-673a6b58-bd0b-454c-b338-b9e907ba2f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-4bc5147a-b732-4f6c-88c8-1bb5475c8fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-9012e69b-6d0a-4c85-9f29-ce9bca16f55a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697515841-172.17.0.7-1597175775784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46044,DS-dda92ee8-8c95-4865-aa78-94e7f6e893e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-9866ece4-c4c9-4cd3-afca-bcab5f6c67b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-586a7ee7-8110-4807-b977-3f9c7b191800,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-711cfdcb-2054-441d-8dd3-cc6ff4eebf81,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-7b79060e-d645-47ac-9e69-3f7576ed959b,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-db17c267-9b3a-4a6f-9de7-f3eb019d308a,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-c7a2d2fe-777c-4080-aac7-18e0fab36a17,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-a5ed142a-f7b3-480f-98bc-8211f74346ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697515841-172.17.0.7-1597175775784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46044,DS-dda92ee8-8c95-4865-aa78-94e7f6e893e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-9866ece4-c4c9-4cd3-afca-bcab5f6c67b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-586a7ee7-8110-4807-b977-3f9c7b191800,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-711cfdcb-2054-441d-8dd3-cc6ff4eebf81,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-7b79060e-d645-47ac-9e69-3f7576ed959b,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-db17c267-9b3a-4a6f-9de7-f3eb019d308a,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-c7a2d2fe-777c-4080-aac7-18e0fab36a17,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-a5ed142a-f7b3-480f-98bc-8211f74346ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442310332-172.17.0.7-1597176024613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43283,DS-dfa908ae-c098-4d2f-8c4f-0ecdda90e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-3550a14b-b9d2-441e-bd35-6892791a66a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-2efa8154-8874-4f65-8465-14722f0767ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-8569a35d-e842-477b-a75f-a2f97695b241,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-b9506b72-996e-4a62-8052-0b8caaef0e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-dc9b66a0-8d6e-4e7b-9a84-e0c3142b9cec,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-f3f652ec-5533-43fa-b287-60a5c643cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-550c9bd0-944d-4ecb-952a-227509501d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442310332-172.17.0.7-1597176024613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43283,DS-dfa908ae-c098-4d2f-8c4f-0ecdda90e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-3550a14b-b9d2-441e-bd35-6892791a66a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-2efa8154-8874-4f65-8465-14722f0767ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-8569a35d-e842-477b-a75f-a2f97695b241,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-b9506b72-996e-4a62-8052-0b8caaef0e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-dc9b66a0-8d6e-4e7b-9a84-e0c3142b9cec,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-f3f652ec-5533-43fa-b287-60a5c643cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-550c9bd0-944d-4ecb-952a-227509501d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292291758-172.17.0.7-1597176466158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41112,DS-436d0341-35fe-4bf3-ae14-413ccf72e63c,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-ace61a0e-0b9c-43bb-a057-6843762e22fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-0fcfb627-9899-46dc-90ba-c4bb969d0b60,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-1663783d-9d34-4a71-a02b-761e1d5c2637,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-99f22f9f-ac6f-4dbc-adc2-cfa224df446e,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-dcb27ebd-0f8f-4fb9-8e71-c71580a82498,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-d68e119e-cf61-4dfd-b0b2-7b9cedeac349,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-f60d636c-be66-4f47-a2cd-6f138aa4d8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292291758-172.17.0.7-1597176466158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41112,DS-436d0341-35fe-4bf3-ae14-413ccf72e63c,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-ace61a0e-0b9c-43bb-a057-6843762e22fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-0fcfb627-9899-46dc-90ba-c4bb969d0b60,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-1663783d-9d34-4a71-a02b-761e1d5c2637,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-99f22f9f-ac6f-4dbc-adc2-cfa224df446e,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-dcb27ebd-0f8f-4fb9-8e71-c71580a82498,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-d68e119e-cf61-4dfd-b0b2-7b9cedeac349,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-f60d636c-be66-4f47-a2cd-6f138aa4d8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141804932-172.17.0.7-1597176505975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35773,DS-43a88e48-0309-4e81-b4fb-204a57c2f50d,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-a50db621-ea51-4c3a-b780-5f09066d84e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c3d1fcf8-e30b-4c8f-9ed4-6dffceece8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-ed7f9171-9890-4084-b733-02044368b756,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-c4edbcd6-7de1-47c8-b04a-aba0a2454981,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-91cb53b4-8107-4137-84e0-34609bf9813f,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-3a879cb9-b15a-4331-9f97-b10f1506876c,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-0e391823-eb69-49a3-8606-3790eb798571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141804932-172.17.0.7-1597176505975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35773,DS-43a88e48-0309-4e81-b4fb-204a57c2f50d,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-a50db621-ea51-4c3a-b780-5f09066d84e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c3d1fcf8-e30b-4c8f-9ed4-6dffceece8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-ed7f9171-9890-4084-b733-02044368b756,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-c4edbcd6-7de1-47c8-b04a-aba0a2454981,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-91cb53b4-8107-4137-84e0-34609bf9813f,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-3a879cb9-b15a-4331-9f97-b10f1506876c,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-0e391823-eb69-49a3-8606-3790eb798571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678859250-172.17.0.7-1597176840845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43329,DS-50adaf33-0e4c-481b-b617-8f05379912a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-6c642b25-50ec-4a96-a7aa-01d967aea6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-19d47464-a6b8-45a6-a1bd-9991f6a0054c,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-74cfbdda-f4ee-41ca-a068-1b1765d33e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-5efd0ebf-adc9-4656-b4ff-54b6392a6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-a3ee93c1-d5ba-4d91-b757-04c2d244e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-f82a448c-921c-42d2-999f-3bda1fdfffb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-9f51834e-76e4-41c4-b60d-07095122b544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678859250-172.17.0.7-1597176840845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43329,DS-50adaf33-0e4c-481b-b617-8f05379912a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-6c642b25-50ec-4a96-a7aa-01d967aea6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-19d47464-a6b8-45a6-a1bd-9991f6a0054c,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-74cfbdda-f4ee-41ca-a068-1b1765d33e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-5efd0ebf-adc9-4656-b4ff-54b6392a6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-a3ee93c1-d5ba-4d91-b757-04c2d244e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-f82a448c-921c-42d2-999f-3bda1fdfffb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-9f51834e-76e4-41c4-b60d-07095122b544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876392137-172.17.0.7-1597176879629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35831,DS-9d67426b-17b5-4ad9-9da2-b9bf4f2778d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-b1780947-6f97-4645-871a-c1d9f1bc383a,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-b5795cab-e2d1-467d-88c3-2b13ff65a9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-1a46d8b7-47bc-4888-9d23-64a5e6542525,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-42585fad-182b-4bf7-bd41-f816411a51ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-3d0b2ae3-c376-4784-a0eb-49f068c8f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-5e265c5b-1ca3-435e-ba4f-cfd3abd1903a,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-1fc0c93d-f806-4353-b6fa-b9a885544fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876392137-172.17.0.7-1597176879629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35831,DS-9d67426b-17b5-4ad9-9da2-b9bf4f2778d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-b1780947-6f97-4645-871a-c1d9f1bc383a,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-b5795cab-e2d1-467d-88c3-2b13ff65a9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-1a46d8b7-47bc-4888-9d23-64a5e6542525,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-42585fad-182b-4bf7-bd41-f816411a51ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-3d0b2ae3-c376-4784-a0eb-49f068c8f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-5e265c5b-1ca3-435e-ba4f-cfd3abd1903a,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-1fc0c93d-f806-4353-b6fa-b9a885544fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640774929-172.17.0.7-1597177787586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38317,DS-8afd1db8-42b9-4992-83d0-fc94de59efa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-3a24382a-d4b1-4c0b-bbb1-e19e59080baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-37878fc8-fd74-4638-9bde-47e99027b30d,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-b1863d90-be5f-4d4a-9412-04cd09132695,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-ff696e41-6416-4578-b690-6e3fdb2b5098,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-54c30f14-ff8e-4f1c-9df0-1d3902dd851f,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-ca399537-19fa-4aab-969c-9a872d94b933,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-179f3534-6f83-461a-a9b4-30144e5bcf41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640774929-172.17.0.7-1597177787586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38317,DS-8afd1db8-42b9-4992-83d0-fc94de59efa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-3a24382a-d4b1-4c0b-bbb1-e19e59080baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-37878fc8-fd74-4638-9bde-47e99027b30d,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-b1863d90-be5f-4d4a-9412-04cd09132695,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-ff696e41-6416-4578-b690-6e3fdb2b5098,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-54c30f14-ff8e-4f1c-9df0-1d3902dd851f,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-ca399537-19fa-4aab-969c-9a872d94b933,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-179f3534-6f83-461a-a9b4-30144e5bcf41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277428126-172.17.0.7-1597177892990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38893,DS-35c5a27d-b5b3-4edd-b132-07adbdab9360,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-088bb22c-87d2-492c-b389-c27cec05ac89,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-5fb0c5e1-1a8d-432c-a7ff-1c1da93f8230,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-679223f2-34e8-4312-8c12-7befc3aeaaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-79a9ff32-994a-4afc-b731-d39d58fb31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-47a542d7-3a7a-470c-bced-eab47dab71dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-97e67f27-ab04-4f06-bb39-fce0eee455c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-2d1417fd-f134-48ff-be37-1496ad1e6791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277428126-172.17.0.7-1597177892990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38893,DS-35c5a27d-b5b3-4edd-b132-07adbdab9360,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-088bb22c-87d2-492c-b389-c27cec05ac89,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-5fb0c5e1-1a8d-432c-a7ff-1c1da93f8230,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-679223f2-34e8-4312-8c12-7befc3aeaaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-79a9ff32-994a-4afc-b731-d39d58fb31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-47a542d7-3a7a-470c-bced-eab47dab71dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-97e67f27-ab04-4f06-bb39-fce0eee455c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-2d1417fd-f134-48ff-be37-1496ad1e6791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1796035112-172.17.0.7-1597178076301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40530,DS-b5b6a049-38f3-4f69-9e16-87e3b1c378f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-655604d3-af3e-45f3-8175-1cc4f1488c10,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-98be879e-17d6-43f2-b74e-bdb930d7ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-39d376c5-1681-4c66-b7c2-cb9b52bd9034,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-2c2ae08b-9cb4-497a-8112-8446ca7f546d,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-f1e2a7fa-2989-4034-9ea3-84b05424f914,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-757c1133-7836-4916-993e-75f48ed201c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-7e8d3870-b75d-49e3-ac52-996563d77dd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1796035112-172.17.0.7-1597178076301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40530,DS-b5b6a049-38f3-4f69-9e16-87e3b1c378f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-655604d3-af3e-45f3-8175-1cc4f1488c10,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-98be879e-17d6-43f2-b74e-bdb930d7ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-39d376c5-1681-4c66-b7c2-cb9b52bd9034,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-2c2ae08b-9cb4-497a-8112-8446ca7f546d,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-f1e2a7fa-2989-4034-9ea3-84b05424f914,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-757c1133-7836-4916-993e-75f48ed201c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-7e8d3870-b75d-49e3-ac52-996563d77dd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615022225-172.17.0.7-1597178179848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33130,DS-6f15b3b2-b0c2-4cdc-ba3f-d7bbb1cff35b,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-354e25e6-3f29-465c-87b0-8f94efbbe58a,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-3063b7d1-6d1d-4499-9151-e5fc0514d1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-b927fa11-508e-43c3-944a-3ac4402a5813,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-c462fb2b-d82e-4d0c-abd0-248fe11563f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-55c36274-5cf7-4b41-aea8-1b478308a086,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-e63b4d25-cab4-4a31-8457-34eb3af35a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-faa10d8d-c895-4a63-9dec-15519130b325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615022225-172.17.0.7-1597178179848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33130,DS-6f15b3b2-b0c2-4cdc-ba3f-d7bbb1cff35b,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-354e25e6-3f29-465c-87b0-8f94efbbe58a,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-3063b7d1-6d1d-4499-9151-e5fc0514d1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-b927fa11-508e-43c3-944a-3ac4402a5813,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-c462fb2b-d82e-4d0c-abd0-248fe11563f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-55c36274-5cf7-4b41-aea8-1b478308a086,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-e63b4d25-cab4-4a31-8457-34eb3af35a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-faa10d8d-c895-4a63-9dec-15519130b325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867471080-172.17.0.7-1597178287087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33777,DS-e20df5e0-ce41-4365-932e-8c7c56c12e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-46d39031-6136-4209-a934-bbc4e14d0324,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-e26869b2-f699-4f4f-ae7f-9863db7a159a,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-4d7833be-a947-405c-9e46-c3ee4cacb7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-8f862412-5798-442a-bcce-044513322104,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-7d9c0ced-49d4-4f56-b1cf-0f0947b4dce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-88412513-8207-41ed-89b2-d383d04af955,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-81a12404-c0d2-4055-b6d8-588bb4c97b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867471080-172.17.0.7-1597178287087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33777,DS-e20df5e0-ce41-4365-932e-8c7c56c12e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-46d39031-6136-4209-a934-bbc4e14d0324,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-e26869b2-f699-4f4f-ae7f-9863db7a159a,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-4d7833be-a947-405c-9e46-c3ee4cacb7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-8f862412-5798-442a-bcce-044513322104,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-7d9c0ced-49d4-4f56-b1cf-0f0947b4dce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-88412513-8207-41ed-89b2-d383d04af955,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-81a12404-c0d2-4055-b6d8-588bb4c97b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164591140-172.17.0.7-1597178579591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-395ef63a-e61f-416b-a63f-f5bd080f81cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-74eb4094-e414-4253-8e73-af5807a7d718,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-858ec124-b108-4803-8e8a-3a7b8638e328,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-07bbe85f-483e-4589-ae8f-a247b036fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-87d16de2-90c8-4da3-af9a-e736eacc250c,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-16510f87-bf13-41de-ab5a-423845c0a5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-875f1cf4-4898-4c8e-a105-4bc270eb172e,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-9eb6dda9-3aab-417c-b8d4-db904b996507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164591140-172.17.0.7-1597178579591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-395ef63a-e61f-416b-a63f-f5bd080f81cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-74eb4094-e414-4253-8e73-af5807a7d718,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-858ec124-b108-4803-8e8a-3a7b8638e328,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-07bbe85f-483e-4589-ae8f-a247b036fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-87d16de2-90c8-4da3-af9a-e736eacc250c,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-16510f87-bf13-41de-ab5a-423845c0a5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-875f1cf4-4898-4c8e-a105-4bc270eb172e,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-9eb6dda9-3aab-417c-b8d4-db904b996507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285056144-172.17.0.7-1597178680791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-62fd8c73-39bb-428a-a294-067829bc2850,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-516967ba-6876-457f-bc3e-7526c3b0a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-f775e21e-60db-4fc9-8367-04ded6ca5cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-a5cc9120-bb30-4a78-ad1c-5628cf7ff8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-c44759bc-89c5-4009-9d4d-cf8b48b1ee92,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-7299d027-6667-437f-986e-eaae777f2d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-3ecafc8f-aeec-4097-831b-c17e96756d79,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-926c7eb0-5d43-4495-a413-50f6819d8766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285056144-172.17.0.7-1597178680791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-62fd8c73-39bb-428a-a294-067829bc2850,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-516967ba-6876-457f-bc3e-7526c3b0a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-f775e21e-60db-4fc9-8367-04ded6ca5cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-a5cc9120-bb30-4a78-ad1c-5628cf7ff8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-c44759bc-89c5-4009-9d4d-cf8b48b1ee92,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-7299d027-6667-437f-986e-eaae777f2d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-3ecafc8f-aeec-4097-831b-c17e96756d79,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-926c7eb0-5d43-4495-a413-50f6819d8766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176595422-172.17.0.7-1597179152866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-0deaa71b-3690-4083-8426-d3e28e24ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-7e3f5801-bcdf-4951-8927-2495e078ae9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-1b1e92f1-e9a4-4452-a742-0e22e597097f,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-be8fd112-8f8f-4911-bd80-cab6cff97636,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-fdb2456d-cb52-4809-aaf1-b1998a46e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-7336fb83-c9ce-4613-889c-24405eab35c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-6a517f15-cf36-48c2-bf26-ebf96f2998f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-8a18d4cf-d1a5-48ca-9bbd-87d8d9778c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176595422-172.17.0.7-1597179152866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-0deaa71b-3690-4083-8426-d3e28e24ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-7e3f5801-bcdf-4951-8927-2495e078ae9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-1b1e92f1-e9a4-4452-a742-0e22e597097f,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-be8fd112-8f8f-4911-bd80-cab6cff97636,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-fdb2456d-cb52-4809-aaf1-b1998a46e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-7336fb83-c9ce-4613-889c-24405eab35c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-6a517f15-cf36-48c2-bf26-ebf96f2998f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-8a18d4cf-d1a5-48ca-9bbd-87d8d9778c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701055883-172.17.0.7-1597179306984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34636,DS-fa1f65bb-403e-4432-9da2-696ba2b44f45,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-52068425-c7b8-4bdb-b878-f97b80cc4004,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-4dea64cd-af00-4ab7-b0aa-80cae3153470,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-88cf0b18-001f-4b83-81b7-09c737a39ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-a7dcd32d-2ae5-4179-a1b9-fe49403b4774,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-c17ab76d-61f2-45d7-b6e7-2c4034f585a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-a3785bab-e3ba-4113-bb3a-8937a40fcaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-e2a3b605-b537-4b18-8360-b44c562ce191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701055883-172.17.0.7-1597179306984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34636,DS-fa1f65bb-403e-4432-9da2-696ba2b44f45,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-52068425-c7b8-4bdb-b878-f97b80cc4004,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-4dea64cd-af00-4ab7-b0aa-80cae3153470,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-88cf0b18-001f-4b83-81b7-09c737a39ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-a7dcd32d-2ae5-4179-a1b9-fe49403b4774,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-c17ab76d-61f2-45d7-b6e7-2c4034f585a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-a3785bab-e3ba-4113-bb3a-8937a40fcaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-e2a3b605-b537-4b18-8360-b44c562ce191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5445
