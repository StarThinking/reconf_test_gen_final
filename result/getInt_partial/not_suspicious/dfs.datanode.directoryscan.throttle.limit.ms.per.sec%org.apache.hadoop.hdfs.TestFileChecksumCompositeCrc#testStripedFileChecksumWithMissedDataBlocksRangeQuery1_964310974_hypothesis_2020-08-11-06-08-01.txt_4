reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528080541-172.17.0.9-1597126094650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-18558309-270a-49a5-9dee-c78829a2b330,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-fef49bdc-848a-4196-bbbb-16c827637aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-423dfad9-a712-458c-b852-e55c39bb1216,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-420248e5-7d71-4b50-b16b-cad94c8af2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-56af62d2-733b-4ec7-bb2d-1ddea71efccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-2bb9f54e-2171-4284-b065-e5c5ec5c364c,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-571f44ea-c0a2-457b-ab09-e8a1f00c73c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-c2e9610a-438c-4e2c-8726-aafbf8a6ec14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528080541-172.17.0.9-1597126094650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-18558309-270a-49a5-9dee-c78829a2b330,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-fef49bdc-848a-4196-bbbb-16c827637aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-423dfad9-a712-458c-b852-e55c39bb1216,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-420248e5-7d71-4b50-b16b-cad94c8af2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-56af62d2-733b-4ec7-bb2d-1ddea71efccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-2bb9f54e-2171-4284-b065-e5c5ec5c364c,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-571f44ea-c0a2-457b-ab09-e8a1f00c73c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-c2e9610a-438c-4e2c-8726-aafbf8a6ec14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722314815-172.17.0.9-1597126424604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-24f2692a-6d4c-4450-82ae-a7ee637fd4db,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-fef7d815-2115-48b3-b2f4-45305f4b5375,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-392d04f8-f889-416f-9c00-464254805695,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-0f8b78f3-c963-47f0-b035-2781bf2cba40,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-80cc4a1f-8c06-4514-b730-e652f05cf5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-6c7cb2bf-fce3-4816-a9ee-5ae3f32b02a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-655fc507-905c-4aa1-997f-99a321f6ed26,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-348c44e6-2401-45ba-811a-a9e5ebcad039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722314815-172.17.0.9-1597126424604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-24f2692a-6d4c-4450-82ae-a7ee637fd4db,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-fef7d815-2115-48b3-b2f4-45305f4b5375,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-392d04f8-f889-416f-9c00-464254805695,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-0f8b78f3-c963-47f0-b035-2781bf2cba40,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-80cc4a1f-8c06-4514-b730-e652f05cf5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-6c7cb2bf-fce3-4816-a9ee-5ae3f32b02a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-655fc507-905c-4aa1-997f-99a321f6ed26,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-348c44e6-2401-45ba-811a-a9e5ebcad039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793173804-172.17.0.9-1597126831960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42233,DS-6d7f1279-fc31-4b35-8535-72289b617b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-bccf4c52-2276-40da-af74-291a4c4aba01,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-a984d572-6a74-4f56-a26f-8e14de1bc18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-f69b0db9-f122-4a20-b918-e8f0ebee4270,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-0a6d1549-1acb-464c-b7f5-81e6232e2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-5e3fd564-48ee-41f2-9ade-216d774c6678,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-f7379c7b-2e6b-409c-be61-25afd92d55bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-d75ddc05-25b4-4529-8bd9-203371e192e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793173804-172.17.0.9-1597126831960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42233,DS-6d7f1279-fc31-4b35-8535-72289b617b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-bccf4c52-2276-40da-af74-291a4c4aba01,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-a984d572-6a74-4f56-a26f-8e14de1bc18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-f69b0db9-f122-4a20-b918-e8f0ebee4270,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-0a6d1549-1acb-464c-b7f5-81e6232e2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-5e3fd564-48ee-41f2-9ade-216d774c6678,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-f7379c7b-2e6b-409c-be61-25afd92d55bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-d75ddc05-25b4-4529-8bd9-203371e192e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799705742-172.17.0.9-1597127440802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45861,DS-a6cb131a-13e0-4366-9b3b-71bbd5cad4db,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-f2b16cf2-2f7f-49ef-88ac-bfdc82286b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-b092ce21-37e5-4e50-8cca-da74cc04ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-1d90b4ea-95e1-46bf-b331-cffa879c1823,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-a8cbd87b-cbb8-48a7-b868-f4223ce57bff,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-71ba10df-4051-48b3-92fb-bdc098d89a65,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-28921359-5ea7-4a14-bd51-30c2ed0989f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-07e2a260-6921-411b-9726-a5af5d07c5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799705742-172.17.0.9-1597127440802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45861,DS-a6cb131a-13e0-4366-9b3b-71bbd5cad4db,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-f2b16cf2-2f7f-49ef-88ac-bfdc82286b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-b092ce21-37e5-4e50-8cca-da74cc04ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-1d90b4ea-95e1-46bf-b331-cffa879c1823,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-a8cbd87b-cbb8-48a7-b868-f4223ce57bff,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-71ba10df-4051-48b3-92fb-bdc098d89a65,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-28921359-5ea7-4a14-bd51-30c2ed0989f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-07e2a260-6921-411b-9726-a5af5d07c5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512857041-172.17.0.9-1597127682056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34506,DS-491006b3-83a4-4ab7-b4e9-f7cac7c255df,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-1817527c-f652-486e-b892-a88db7575a81,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-88fe6353-6b67-4e60-98c5-57974e37cb62,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-ca03cb51-fdd1-44b0-b18d-b34c1ebaa81a,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-16c04fbd-e706-45bf-8341-312f48695154,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-7aff5739-ba11-4d3a-a41e-c287a829b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-f09ea172-6385-4eff-b313-e6ab0962d6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-c1d94465-3d8a-41bb-a023-2588119af310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512857041-172.17.0.9-1597127682056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34506,DS-491006b3-83a4-4ab7-b4e9-f7cac7c255df,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-1817527c-f652-486e-b892-a88db7575a81,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-88fe6353-6b67-4e60-98c5-57974e37cb62,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-ca03cb51-fdd1-44b0-b18d-b34c1ebaa81a,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-16c04fbd-e706-45bf-8341-312f48695154,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-7aff5739-ba11-4d3a-a41e-c287a829b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-f09ea172-6385-4eff-b313-e6ab0962d6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-c1d94465-3d8a-41bb-a023-2588119af310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668914033-172.17.0.9-1597128228889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-0731aa6d-1d52-49d9-88f7-d278895d8ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-4c8da043-27af-4bdc-b852-d4b54945834e,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-6a243b32-382c-4a4d-82f7-0d9df6debee1,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-610af563-4012-46f7-9014-c28a49c6575a,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-8639d609-33f4-4491-8c4b-79785c34a486,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-31194e82-61ea-4ce1-a832-8338f3fc3a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-6ce3f9ff-42eb-46b5-bea0-3208b322e1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-c70a3cc3-b607-4cc2-bda3-8a0f3732aa4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668914033-172.17.0.9-1597128228889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-0731aa6d-1d52-49d9-88f7-d278895d8ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-4c8da043-27af-4bdc-b852-d4b54945834e,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-6a243b32-382c-4a4d-82f7-0d9df6debee1,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-610af563-4012-46f7-9014-c28a49c6575a,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-8639d609-33f4-4491-8c4b-79785c34a486,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-31194e82-61ea-4ce1-a832-8338f3fc3a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-6ce3f9ff-42eb-46b5-bea0-3208b322e1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-c70a3cc3-b607-4cc2-bda3-8a0f3732aa4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805879094-172.17.0.9-1597128484478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33885,DS-dffaecb1-7e94-4c72-9f0c-e1f53431942e,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e89801a6-131f-4717-926c-30eb3a4982c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-4a3c38ba-c045-485e-9aff-fe0d3e99f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-a148dc6a-5490-4e6a-971d-3d7438fc1f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-9f9403be-d014-4f9a-84bd-dc4191988dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-14732efe-ded6-4247-94d2-3342a60d9750,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-9ed9cb17-46d0-4b0d-8c85-1b7b3b2688c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-ea73a84e-d137-4868-bb67-65a1f1ad012e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805879094-172.17.0.9-1597128484478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33885,DS-dffaecb1-7e94-4c72-9f0c-e1f53431942e,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e89801a6-131f-4717-926c-30eb3a4982c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-4a3c38ba-c045-485e-9aff-fe0d3e99f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-a148dc6a-5490-4e6a-971d-3d7438fc1f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-9f9403be-d014-4f9a-84bd-dc4191988dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-14732efe-ded6-4247-94d2-3342a60d9750,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-9ed9cb17-46d0-4b0d-8c85-1b7b3b2688c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-ea73a84e-d137-4868-bb67-65a1f1ad012e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943712468-172.17.0.9-1597128523762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34595,DS-3c6a2264-b52b-4724-ba09-88e9ec7bf5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-6898b7f1-1580-4973-8009-743429f6ba21,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-1730a8bd-47d6-495f-bd3d-e9d6b77085b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-e29a90ee-d364-4607-a506-e2caa8e0a683,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-1d8db9fc-3a3c-4d23-bc91-42a72bd2ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-ca2c28bd-d564-47c4-9f09-b0b92d225441,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-66d3bfd3-7608-4a50-afd5-98bd167c2c93,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-782474d5-b271-46de-a0f1-5a2858912364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943712468-172.17.0.9-1597128523762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34595,DS-3c6a2264-b52b-4724-ba09-88e9ec7bf5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-6898b7f1-1580-4973-8009-743429f6ba21,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-1730a8bd-47d6-495f-bd3d-e9d6b77085b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-e29a90ee-d364-4607-a506-e2caa8e0a683,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-1d8db9fc-3a3c-4d23-bc91-42a72bd2ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-ca2c28bd-d564-47c4-9f09-b0b92d225441,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-66d3bfd3-7608-4a50-afd5-98bd167c2c93,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-782474d5-b271-46de-a0f1-5a2858912364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209988568-172.17.0.9-1597128626717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40905,DS-edef8791-a65e-4862-a44b-fd13273fb06e,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-a79a0f71-edd4-44fa-8f87-6b1828cdf428,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-e46c22ba-6dbe-4153-a0e9-695145274135,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-65201743-0299-4925-bf51-faadbd4f65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-45afb454-d6da-4270-b53c-0ada2274a733,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-2663a91e-6548-4f2b-875f-9f3f39ca631f,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-1fa80c85-6e02-4b6a-9557-aae6d4b283cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-3d120722-b591-496f-b2c0-4d310532530c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209988568-172.17.0.9-1597128626717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40905,DS-edef8791-a65e-4862-a44b-fd13273fb06e,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-a79a0f71-edd4-44fa-8f87-6b1828cdf428,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-e46c22ba-6dbe-4153-a0e9-695145274135,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-65201743-0299-4925-bf51-faadbd4f65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-45afb454-d6da-4270-b53c-0ada2274a733,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-2663a91e-6548-4f2b-875f-9f3f39ca631f,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-1fa80c85-6e02-4b6a-9557-aae6d4b283cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-3d120722-b591-496f-b2c0-4d310532530c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089598297-172.17.0.9-1597128660554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41426,DS-0ab410d4-17a3-4356-ad05-75426478c071,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-ae070157-e36a-46a4-9efc-ac52be050c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-ba3d6a15-4327-418d-885e-4720253a780f,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-f2bbfd71-77d8-44ce-bf11-26180ddd2788,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-91ec57b9-2b54-4c15-946e-c99931506b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-d0d1d3b7-2093-4f8d-9078-a234cf86e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-a76c5a73-019d-4637-bd83-3b2d968559a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-67de2a3a-9110-488b-b155-22a63d9ebf97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089598297-172.17.0.9-1597128660554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41426,DS-0ab410d4-17a3-4356-ad05-75426478c071,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-ae070157-e36a-46a4-9efc-ac52be050c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-ba3d6a15-4327-418d-885e-4720253a780f,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-f2bbfd71-77d8-44ce-bf11-26180ddd2788,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-91ec57b9-2b54-4c15-946e-c99931506b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-d0d1d3b7-2093-4f8d-9078-a234cf86e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-a76c5a73-019d-4637-bd83-3b2d968559a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-67de2a3a-9110-488b-b155-22a63d9ebf97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667152947-172.17.0.9-1597128915620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34119,DS-0e96a3b4-783f-4bba-a855-f9ea00d1dabe,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-fd1b4b20-31a8-4983-aad2-b8369468f80d,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-ba051090-fbfd-4e5d-9b36-8d6cefc1ad6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-b77b639b-9d54-4b59-8b3c-5424aee80fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-66d2d645-2cff-4c35-a822-37c1428a3640,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-8f4e911f-1d04-455a-b8f7-7f765ef78952,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-d3b2fa65-002d-442a-b5a9-7ca24a36b42f,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-a68eb936-db67-4b14-81c1-27e80622c31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667152947-172.17.0.9-1597128915620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34119,DS-0e96a3b4-783f-4bba-a855-f9ea00d1dabe,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-fd1b4b20-31a8-4983-aad2-b8369468f80d,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-ba051090-fbfd-4e5d-9b36-8d6cefc1ad6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-b77b639b-9d54-4b59-8b3c-5424aee80fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-66d2d645-2cff-4c35-a822-37c1428a3640,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-8f4e911f-1d04-455a-b8f7-7f765ef78952,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-d3b2fa65-002d-442a-b5a9-7ca24a36b42f,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-a68eb936-db67-4b14-81c1-27e80622c31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282845379-172.17.0.9-1597129456387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-db4ca010-793d-4d08-83fe-5bddaecad529,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-3f2477a0-bca4-4cf0-a0b8-015622e24cda,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-b6ad2e4f-909c-449b-a273-2910db6a142b,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-46dcc58d-3417-4d15-9434-91aa816146ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-0caaeea9-9924-49c8-b3c4-30802b29b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-bd353c1d-affd-4160-9104-bd897df4c833,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-e47d1557-3096-4078-a856-d2be056fdb61,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-c54ad1e0-4df1-4528-a15b-fb3c65bfe83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282845379-172.17.0.9-1597129456387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-db4ca010-793d-4d08-83fe-5bddaecad529,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-3f2477a0-bca4-4cf0-a0b8-015622e24cda,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-b6ad2e4f-909c-449b-a273-2910db6a142b,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-46dcc58d-3417-4d15-9434-91aa816146ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-0caaeea9-9924-49c8-b3c4-30802b29b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-bd353c1d-affd-4160-9104-bd897df4c833,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-e47d1557-3096-4078-a856-d2be056fdb61,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-c54ad1e0-4df1-4528-a15b-fb3c65bfe83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798083819-172.17.0.9-1597129528002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43798,DS-54ffa3c9-16a8-4ef1-9e61-e20548ce5850,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-e62b1b2f-ee9c-4274-acf6-7e50f47a64b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-372e9335-8e3c-4c97-8745-8531a6f1dd38,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-2a461f73-c04e-45db-9b05-2e6305b87dec,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-9c20851b-3f90-4ce9-8479-e1c51ee6d644,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-b90442b9-fd0a-468b-811b-25b398b112a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-5db405b2-bab8-4ef7-a9a2-9f178117bfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-968c8e80-1ab7-4893-a83d-80946127fa5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798083819-172.17.0.9-1597129528002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43798,DS-54ffa3c9-16a8-4ef1-9e61-e20548ce5850,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-e62b1b2f-ee9c-4274-acf6-7e50f47a64b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-372e9335-8e3c-4c97-8745-8531a6f1dd38,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-2a461f73-c04e-45db-9b05-2e6305b87dec,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-9c20851b-3f90-4ce9-8479-e1c51ee6d644,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-b90442b9-fd0a-468b-811b-25b398b112a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-5db405b2-bab8-4ef7-a9a2-9f178117bfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-968c8e80-1ab7-4893-a83d-80946127fa5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123436686-172.17.0.9-1597129562394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38378,DS-32987ecb-3d74-443a-a593-c75394625881,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-f2718ef2-bb5d-4388-9ebd-54e00e62d6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-843e5121-44e5-43b6-b6b6-9b50a818ae5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-830303b2-d63a-4fe0-a4b3-3a62050939a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-961d805c-f23b-4fd3-b521-59405603c869,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-3c8b1ddb-d051-4342-8970-6dc4af7bcf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-ce66e62e-0545-44ab-8c1d-dc37873a57fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-286c0abf-142c-4edf-a7bc-15aa82b85ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123436686-172.17.0.9-1597129562394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38378,DS-32987ecb-3d74-443a-a593-c75394625881,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-f2718ef2-bb5d-4388-9ebd-54e00e62d6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-843e5121-44e5-43b6-b6b6-9b50a818ae5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-830303b2-d63a-4fe0-a4b3-3a62050939a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-961d805c-f23b-4fd3-b521-59405603c869,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-3c8b1ddb-d051-4342-8970-6dc4af7bcf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-ce66e62e-0545-44ab-8c1d-dc37873a57fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-286c0abf-142c-4edf-a7bc-15aa82b85ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884835770-172.17.0.9-1597129598385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-9e89bc4c-e5e8-40c9-8f3a-7e1125053238,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-b42a6348-1c08-4593-960a-091edf06dad4,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-6fe55364-a1c6-4138-a53b-e8f7c2970bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-06fb29ba-557b-43ec-81d3-7deba29d8ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-87b697d7-b64e-49fe-a386-f7fbbd5e3822,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-9ead8163-395e-4d50-8d56-adf323a42e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-e91a3c58-2a0a-4823-b847-f76d232e2c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-92518cc0-fe53-4979-8e3a-b2951d5c3071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884835770-172.17.0.9-1597129598385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-9e89bc4c-e5e8-40c9-8f3a-7e1125053238,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-b42a6348-1c08-4593-960a-091edf06dad4,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-6fe55364-a1c6-4138-a53b-e8f7c2970bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-06fb29ba-557b-43ec-81d3-7deba29d8ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-87b697d7-b64e-49fe-a386-f7fbbd5e3822,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-9ead8163-395e-4d50-8d56-adf323a42e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-e91a3c58-2a0a-4823-b847-f76d232e2c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-92518cc0-fe53-4979-8e3a-b2951d5c3071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739578748-172.17.0.9-1597130093182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-e0bf92c7-cd44-4953-9054-1476cca06419,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-cb5c42e6-910f-4350-be62-0a9f9233f32d,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-ee86b884-c6ff-4eb1-9314-8553467f5c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-7cbe5f38-0bb3-41cc-b407-b4e36cdcbd73,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-5f362e4f-742e-4f71-8184-7615001ec8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-0fbd7d71-85df-49d0-add7-d936c5c4626e,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-3653273d-0aaf-4550-9165-725454daeab5,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-20789bbe-8ae6-4961-9bf3-84a935eecd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739578748-172.17.0.9-1597130093182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-e0bf92c7-cd44-4953-9054-1476cca06419,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-cb5c42e6-910f-4350-be62-0a9f9233f32d,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-ee86b884-c6ff-4eb1-9314-8553467f5c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-7cbe5f38-0bb3-41cc-b407-b4e36cdcbd73,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-5f362e4f-742e-4f71-8184-7615001ec8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-0fbd7d71-85df-49d0-add7-d936c5c4626e,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-3653273d-0aaf-4550-9165-725454daeab5,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-20789bbe-8ae6-4961-9bf3-84a935eecd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510970295-172.17.0.9-1597130427449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-1ec9270b-ddef-48e1-8f3f-de8dc23000b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-02b893e3-4b66-4061-8816-5baee69e7642,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-2b350202-b67b-4355-83fb-c7c7499eec41,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-bf9a48e6-53d8-4d42-815b-b95ca95a5124,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-a871211b-a065-440c-9001-249ef64c2f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-8997b235-812a-4978-9967-1a6c6ca87423,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-9ddd6be1-2754-46ad-ae9f-6a7723c3e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-d1a2fdf6-ea4e-4427-a127-1e84182bc9e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510970295-172.17.0.9-1597130427449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-1ec9270b-ddef-48e1-8f3f-de8dc23000b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-02b893e3-4b66-4061-8816-5baee69e7642,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-2b350202-b67b-4355-83fb-c7c7499eec41,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-bf9a48e6-53d8-4d42-815b-b95ca95a5124,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-a871211b-a065-440c-9001-249ef64c2f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-8997b235-812a-4978-9967-1a6c6ca87423,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-9ddd6be1-2754-46ad-ae9f-6a7723c3e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-d1a2fdf6-ea4e-4427-a127-1e84182bc9e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383687493-172.17.0.9-1597130679041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-0e61253a-81db-4e92-8cfb-26fac98e748a,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-e1646d34-e229-4475-b32d-a3cdd795d4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-50af8198-3b8e-44cd-b5bf-5c3dd8a9eb80,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-d708f3b3-1e51-4569-90c5-2ffda18599ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-5ae562d5-636d-48db-a19e-792a2ce9b209,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-8b33826b-a076-4e9e-92e4-c56bb47f4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-6b77d33b-a17d-41a6-aa35-52b9ca386d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-e8feb95d-73e7-4896-ae65-9df323849c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383687493-172.17.0.9-1597130679041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-0e61253a-81db-4e92-8cfb-26fac98e748a,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-e1646d34-e229-4475-b32d-a3cdd795d4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-50af8198-3b8e-44cd-b5bf-5c3dd8a9eb80,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-d708f3b3-1e51-4569-90c5-2ffda18599ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-5ae562d5-636d-48db-a19e-792a2ce9b209,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-8b33826b-a076-4e9e-92e4-c56bb47f4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-6b77d33b-a17d-41a6-aa35-52b9ca386d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-e8feb95d-73e7-4896-ae65-9df323849c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280642833-172.17.0.9-1597130796907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40109,DS-86a6b045-08d0-4b5b-a92f-9d6394ccf46c,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-5c937862-dcc8-44e5-ba17-47784fc8481c,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-484af44a-4ad4-4042-a3fb-b2e41de6ea48,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-747a15cb-de58-4484-85f9-c57a320eba60,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-393a6e6d-fa00-41fd-8164-d656d64420cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-5bf68853-32a0-44f4-8274-98003f3e7162,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-d926ce37-ccc0-4ab1-9d7f-d279c6576eda,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-da5b9ef1-16b7-4daf-b7fd-2a1e9afce447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280642833-172.17.0.9-1597130796907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40109,DS-86a6b045-08d0-4b5b-a92f-9d6394ccf46c,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-5c937862-dcc8-44e5-ba17-47784fc8481c,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-484af44a-4ad4-4042-a3fb-b2e41de6ea48,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-747a15cb-de58-4484-85f9-c57a320eba60,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-393a6e6d-fa00-41fd-8164-d656d64420cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-5bf68853-32a0-44f4-8274-98003f3e7162,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-d926ce37-ccc0-4ab1-9d7f-d279c6576eda,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-da5b9ef1-16b7-4daf-b7fd-2a1e9afce447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849603480-172.17.0.9-1597131042731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36437,DS-b923c259-485f-43f1-8100-8dcbc4da13cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-49d87fac-a091-4515-b1bb-86a8df025072,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-c0ed2b0f-02a2-4c1f-8209-a4b0bdd83ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-00f8c7bd-0a7b-42ff-a558-c70d74d9e328,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-5c4ebf68-9397-4850-9f69-24f7fc7eead0,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-ff7037f4-c7c5-4e69-859b-973f3523e145,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-49aa2f08-4e7f-4d25-9103-992c9732dddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-752d8a6c-64a3-4650-82a3-8bc143fd4306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849603480-172.17.0.9-1597131042731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36437,DS-b923c259-485f-43f1-8100-8dcbc4da13cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-49d87fac-a091-4515-b1bb-86a8df025072,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-c0ed2b0f-02a2-4c1f-8209-a4b0bdd83ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-00f8c7bd-0a7b-42ff-a558-c70d74d9e328,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-5c4ebf68-9397-4850-9f69-24f7fc7eead0,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-ff7037f4-c7c5-4e69-859b-973f3523e145,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-49aa2f08-4e7f-4d25-9103-992c9732dddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-752d8a6c-64a3-4650-82a3-8bc143fd4306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800998205-172.17.0.9-1597131078449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-c55a166d-e3c4-4f7a-ac34-859bad159098,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-814ec283-efbd-4bcc-bb34-c2e346bf56ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-ffc6cbf9-6f4a-4f0c-b085-f401f49a1b64,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-3358061e-cc27-4153-9f6b-8ce689d18502,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-36c394d7-3ce7-4178-a9bc-f6dcb23e4db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-b645b8c2-1f21-4cb9-be34-ef41dd1c765a,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-652b5368-3816-4606-be86-5995118c57e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-7dbe7138-aa9a-4199-a554-6b3a5ac63c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800998205-172.17.0.9-1597131078449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-c55a166d-e3c4-4f7a-ac34-859bad159098,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-814ec283-efbd-4bcc-bb34-c2e346bf56ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-ffc6cbf9-6f4a-4f0c-b085-f401f49a1b64,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-3358061e-cc27-4153-9f6b-8ce689d18502,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-36c394d7-3ce7-4178-a9bc-f6dcb23e4db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-b645b8c2-1f21-4cb9-be34-ef41dd1c765a,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-652b5368-3816-4606-be86-5995118c57e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-7dbe7138-aa9a-4199-a554-6b3a5ac63c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936064959-172.17.0.9-1597131181317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40396,DS-f232f37d-8d1a-41e1-8d0f-00feb303f58d,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-b95b888f-b799-4602-9a84-7d6601138013,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-c757f39d-9601-4614-825a-f45c5a374bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-2def8fe9-e629-463d-9600-bd53aa1ed325,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-f33abc0f-0a45-47b2-b5f0-f729e9ccfde0,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-b2929cda-dad2-467d-8076-91a5e45cad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-0c1c33e9-61a4-4030-b229-d0f7986f22f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-278480da-99f2-4a48-a9e1-7dcc5bbc7d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936064959-172.17.0.9-1597131181317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40396,DS-f232f37d-8d1a-41e1-8d0f-00feb303f58d,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-b95b888f-b799-4602-9a84-7d6601138013,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-c757f39d-9601-4614-825a-f45c5a374bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-2def8fe9-e629-463d-9600-bd53aa1ed325,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-f33abc0f-0a45-47b2-b5f0-f729e9ccfde0,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-b2929cda-dad2-467d-8076-91a5e45cad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-0c1c33e9-61a4-4030-b229-d0f7986f22f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-278480da-99f2-4a48-a9e1-7dcc5bbc7d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5454
