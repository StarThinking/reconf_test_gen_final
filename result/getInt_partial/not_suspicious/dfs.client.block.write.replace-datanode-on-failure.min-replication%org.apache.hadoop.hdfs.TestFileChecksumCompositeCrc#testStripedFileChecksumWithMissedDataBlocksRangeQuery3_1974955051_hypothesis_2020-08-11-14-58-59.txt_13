reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350692445-172.17.0.15-1597158559385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37072,DS-963ee00b-70a7-46ad-8b7f-be760fdcc84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-133cf528-a7aa-43bd-980c-cb4d16fb068e,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-4044d294-c398-4e44-9e8a-3c73b8bf707a,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-5e4f7384-2bc1-42ee-b7c2-5c97b7ff03d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-b73b8c11-db30-4593-a439-c3b3043befba,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-4ea187ca-894c-4fcf-bb00-e3e36b5e6a26,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-99be9f1b-1973-4d13-a4a8-b5910ccba283,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b0ba8ff1-3358-4cac-9110-60d1c680850d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350692445-172.17.0.15-1597158559385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37072,DS-963ee00b-70a7-46ad-8b7f-be760fdcc84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-133cf528-a7aa-43bd-980c-cb4d16fb068e,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-4044d294-c398-4e44-9e8a-3c73b8bf707a,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-5e4f7384-2bc1-42ee-b7c2-5c97b7ff03d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-b73b8c11-db30-4593-a439-c3b3043befba,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-4ea187ca-894c-4fcf-bb00-e3e36b5e6a26,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-99be9f1b-1973-4d13-a4a8-b5910ccba283,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b0ba8ff1-3358-4cac-9110-60d1c680850d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305873608-172.17.0.15-1597158645441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38741,DS-68b7b8ce-e578-46df-9aa8-d16c841a9182,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-5a76ba33-ac28-4c84-ae06-a6520d336fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-a6a7ed93-d0b2-431f-a2cb-c8f017442c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-40619a86-3915-448c-85a7-dc0520e44c50,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-919a58aa-08e4-4e7b-b3b5-c826dfa752b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-494efef5-191d-46cb-acd2-0229a5890d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-80d0fccb-ee3d-4738-9fea-852e4ca2a612,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-bb99fa9d-29bd-4d98-a36c-7bdb19a58ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305873608-172.17.0.15-1597158645441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38741,DS-68b7b8ce-e578-46df-9aa8-d16c841a9182,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-5a76ba33-ac28-4c84-ae06-a6520d336fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-a6a7ed93-d0b2-431f-a2cb-c8f017442c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-40619a86-3915-448c-85a7-dc0520e44c50,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-919a58aa-08e4-4e7b-b3b5-c826dfa752b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-494efef5-191d-46cb-acd2-0229a5890d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-80d0fccb-ee3d-4738-9fea-852e4ca2a612,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-bb99fa9d-29bd-4d98-a36c-7bdb19a58ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437352843-172.17.0.15-1597159064651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40648,DS-bc285553-7de3-43d7-b7e7-1609c54b522f,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-2d8e9cfc-502c-4884-9793-d590c4cfa86d,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-d086db95-29fc-459b-86e1-abe4f78fe26b,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-1d5423a3-55a9-45f2-937e-d2558f739eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-f23b91b6-dd78-406f-8c86-e31ed9e6c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-b9ec3570-19db-49f2-a6bb-e66b52b3ab2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-4f2cf0b6-7147-41d6-9f5d-f63f7f6cd4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-cbf5d6d1-6b32-4f84-a0a9-99930d28ecc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437352843-172.17.0.15-1597159064651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40648,DS-bc285553-7de3-43d7-b7e7-1609c54b522f,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-2d8e9cfc-502c-4884-9793-d590c4cfa86d,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-d086db95-29fc-459b-86e1-abe4f78fe26b,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-1d5423a3-55a9-45f2-937e-d2558f739eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-f23b91b6-dd78-406f-8c86-e31ed9e6c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-b9ec3570-19db-49f2-a6bb-e66b52b3ab2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-4f2cf0b6-7147-41d6-9f5d-f63f7f6cd4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-cbf5d6d1-6b32-4f84-a0a9-99930d28ecc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799137820-172.17.0.15-1597159229204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-1820220a-db71-4c2a-8c3c-49d11ee44e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-8aee5e2a-bfcc-49c2-9553-78a0604931fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-f5a9c5de-4ea8-49ba-8ba2-6cbf996e8497,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-ee2337b9-4e41-42c3-9314-b26bb796da8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-e13da461-c355-463e-89c5-e6b6335e47ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-4afa57ce-66d0-4bd6-a2e3-9fe5888a43e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-bb8dc8e9-b1aa-4d80-b4fa-2e77efdf0077,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-8de9c9af-b94e-4895-8c88-9a6cbcd12888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799137820-172.17.0.15-1597159229204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-1820220a-db71-4c2a-8c3c-49d11ee44e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-8aee5e2a-bfcc-49c2-9553-78a0604931fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-f5a9c5de-4ea8-49ba-8ba2-6cbf996e8497,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-ee2337b9-4e41-42c3-9314-b26bb796da8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-e13da461-c355-463e-89c5-e6b6335e47ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-4afa57ce-66d0-4bd6-a2e3-9fe5888a43e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-bb8dc8e9-b1aa-4d80-b4fa-2e77efdf0077,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-8de9c9af-b94e-4895-8c88-9a6cbcd12888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63284768-172.17.0.15-1597159523248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43806,DS-149ab4d7-3836-4e1d-ae66-f774b6751b80,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-c0e6c56a-d091-4c98-81b1-aaecea8aab92,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-491306bb-f6c3-4fb4-a471-f3807a929449,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-d7c86b29-e7a5-403d-b722-15a70c80d570,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-e74b2af5-6663-4ca6-b8be-c7228529a76e,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-c253ed40-57a9-4e8b-9019-fa23dac67185,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-ddc91938-27c1-4976-ae53-7a5cbd4da6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-23582a6e-3be7-41da-818e-5f8fb3e40939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63284768-172.17.0.15-1597159523248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43806,DS-149ab4d7-3836-4e1d-ae66-f774b6751b80,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-c0e6c56a-d091-4c98-81b1-aaecea8aab92,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-491306bb-f6c3-4fb4-a471-f3807a929449,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-d7c86b29-e7a5-403d-b722-15a70c80d570,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-e74b2af5-6663-4ca6-b8be-c7228529a76e,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-c253ed40-57a9-4e8b-9019-fa23dac67185,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-ddc91938-27c1-4976-ae53-7a5cbd4da6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-23582a6e-3be7-41da-818e-5f8fb3e40939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038673484-172.17.0.15-1597159645926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36889,DS-6382015d-e137-4e03-800d-6ff1960f62d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-92ccf22b-24dd-46b3-9eb0-daf44f33058e,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-53beca6c-8a9e-4a0a-ac42-bbd1d626eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-4883fe35-218e-430c-a053-6d7ca261ca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b40f9de7-b993-408c-be28-00c2e1313946,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-08cce5b7-4630-459f-980f-d712af2bea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-05211e44-4516-45e3-b932-12b2fb31aa56,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-f8aa13ef-1cfe-42a3-8a21-b02204aa70d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038673484-172.17.0.15-1597159645926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36889,DS-6382015d-e137-4e03-800d-6ff1960f62d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-92ccf22b-24dd-46b3-9eb0-daf44f33058e,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-53beca6c-8a9e-4a0a-ac42-bbd1d626eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-4883fe35-218e-430c-a053-6d7ca261ca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b40f9de7-b993-408c-be28-00c2e1313946,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-08cce5b7-4630-459f-980f-d712af2bea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-05211e44-4516-45e3-b932-12b2fb31aa56,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-f8aa13ef-1cfe-42a3-8a21-b02204aa70d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859672599-172.17.0.15-1597160392561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40945,DS-8d496b9a-6e25-4d46-84a6-d0a8badcd374,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-4b287300-5a13-461b-8e07-83819062c768,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-85f2a914-a6b9-431e-90c2-4af02a399cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-b2ee0925-1de6-4b14-b66d-b41627c492cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-c8d42232-d05f-449f-81c7-bfd43cdd7d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4fcb639f-6c68-4231-a9a8-ecc70dbb3c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-37769db7-7ec5-4811-9b05-20a723c1570d,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-58642594-c823-47c2-a617-09535b65200d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859672599-172.17.0.15-1597160392561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40945,DS-8d496b9a-6e25-4d46-84a6-d0a8badcd374,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-4b287300-5a13-461b-8e07-83819062c768,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-85f2a914-a6b9-431e-90c2-4af02a399cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-b2ee0925-1de6-4b14-b66d-b41627c492cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-c8d42232-d05f-449f-81c7-bfd43cdd7d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4fcb639f-6c68-4231-a9a8-ecc70dbb3c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-37769db7-7ec5-4811-9b05-20a723c1570d,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-58642594-c823-47c2-a617-09535b65200d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069429904-172.17.0.15-1597160696418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41983,DS-fc6034dc-39c1-43ca-843b-c4849b552ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-2a8163bb-c565-46dd-a9ef-da05fcedb608,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-85b1a56b-3451-44ec-a642-7c18d198b2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-452ac924-70ba-401c-8eb5-e0067552e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-5b08e3fd-42cd-4ddb-b797-b70ab5c5a915,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-43609365-441d-47e7-b9ea-f29ad0c0372a,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-2ca5bca3-fd67-4214-9905-f29ce4a137f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-45581ef2-bd5b-4677-87f2-6264a6c11b3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069429904-172.17.0.15-1597160696418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41983,DS-fc6034dc-39c1-43ca-843b-c4849b552ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-2a8163bb-c565-46dd-a9ef-da05fcedb608,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-85b1a56b-3451-44ec-a642-7c18d198b2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-452ac924-70ba-401c-8eb5-e0067552e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-5b08e3fd-42cd-4ddb-b797-b70ab5c5a915,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-43609365-441d-47e7-b9ea-f29ad0c0372a,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-2ca5bca3-fd67-4214-9905-f29ce4a137f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-45581ef2-bd5b-4677-87f2-6264a6c11b3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250867758-172.17.0.15-1597160731276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-f6527bb9-094a-4075-b515-185f78c204f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-8250f4ef-df75-45ee-bb31-db77947e4fed,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-201c2785-a6a1-499f-90e1-4b4521a1ea68,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-58c1dae5-9928-4441-8fac-3c041decb03c,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-25b52356-d54a-4ab9-af6c-0671ed8fe7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-fd3ae0ca-0fbc-42db-bc7b-36f0564b8d06,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-ecc5a917-b75a-4784-ad6c-1c1fa27c83d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-8fa7e0d0-d4e5-44ed-8a6a-bbccff5c935f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250867758-172.17.0.15-1597160731276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-f6527bb9-094a-4075-b515-185f78c204f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-8250f4ef-df75-45ee-bb31-db77947e4fed,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-201c2785-a6a1-499f-90e1-4b4521a1ea68,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-58c1dae5-9928-4441-8fac-3c041decb03c,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-25b52356-d54a-4ab9-af6c-0671ed8fe7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-fd3ae0ca-0fbc-42db-bc7b-36f0564b8d06,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-ecc5a917-b75a-4784-ad6c-1c1fa27c83d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-8fa7e0d0-d4e5-44ed-8a6a-bbccff5c935f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052842310-172.17.0.15-1597161409562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35173,DS-ab5656c2-777f-42bc-89b5-191d62afdccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-7f6d276e-2800-43c4-bcf5-416cca72a88a,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-f58e2d40-ebc7-42f4-8239-5f2186571b69,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-87dcbf87-07f9-40f4-a335-02da7fc68da2,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-216386c4-3173-4c01-96ad-b18933ba3670,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-d64043a7-0289-4049-bc1c-18f20549914e,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-49791992-c34e-45b0-8981-176d4f4eddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-13f810f9-039f-45ad-ae8f-e50ae98d7ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052842310-172.17.0.15-1597161409562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35173,DS-ab5656c2-777f-42bc-89b5-191d62afdccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-7f6d276e-2800-43c4-bcf5-416cca72a88a,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-f58e2d40-ebc7-42f4-8239-5f2186571b69,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-87dcbf87-07f9-40f4-a335-02da7fc68da2,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-216386c4-3173-4c01-96ad-b18933ba3670,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-d64043a7-0289-4049-bc1c-18f20549914e,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-49791992-c34e-45b0-8981-176d4f4eddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-13f810f9-039f-45ad-ae8f-e50ae98d7ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978322692-172.17.0.15-1597162679934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38251,DS-3b0d6b88-66ec-4821-8805-e6dbe2bc4aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-7eb720d3-8011-45c2-bda7-49634b14ccd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-d170a01e-b645-4481-920f-b46ca153f914,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-1857ad99-087f-49d6-9a49-ff443c15ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-8f3a16e2-2e27-47eb-9561-0366b74ae07e,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-df96f7a6-7460-4ef5-a2f9-c82ee235911c,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-57d95568-dffd-43af-ba95-db8eb6d1b6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-daabafdd-591d-48e2-9325-6f42b3373416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978322692-172.17.0.15-1597162679934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38251,DS-3b0d6b88-66ec-4821-8805-e6dbe2bc4aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-7eb720d3-8011-45c2-bda7-49634b14ccd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-d170a01e-b645-4481-920f-b46ca153f914,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-1857ad99-087f-49d6-9a49-ff443c15ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-8f3a16e2-2e27-47eb-9561-0366b74ae07e,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-df96f7a6-7460-4ef5-a2f9-c82ee235911c,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-57d95568-dffd-43af-ba95-db8eb6d1b6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-daabafdd-591d-48e2-9325-6f42b3373416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642561709-172.17.0.15-1597163238888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-4a761483-eaf7-4280-a630-e73e405f0b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-879b35dc-9dde-4320-be39-6fe4ce57206e,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-772a881a-af72-4d66-953c-b88335f8778e,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d2b64ec3-76c7-425e-926d-ae4fda71c13f,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-954ac55a-c2a2-4973-98b7-f041a361211a,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-6eca7d8b-05ff-468e-b39f-1c0ed261db54,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-db47b186-0884-4591-bd6c-7845a8de98d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-2c389346-1b56-4e45-ac00-500d96fa8013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642561709-172.17.0.15-1597163238888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-4a761483-eaf7-4280-a630-e73e405f0b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-879b35dc-9dde-4320-be39-6fe4ce57206e,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-772a881a-af72-4d66-953c-b88335f8778e,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d2b64ec3-76c7-425e-926d-ae4fda71c13f,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-954ac55a-c2a2-4973-98b7-f041a361211a,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-6eca7d8b-05ff-468e-b39f-1c0ed261db54,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-db47b186-0884-4591-bd6c-7845a8de98d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-2c389346-1b56-4e45-ac00-500d96fa8013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805153822-172.17.0.15-1597163568155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-03ca1e0e-cf1c-437b-82c4-4292fd4cf6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-5997fe40-1aa1-41f8-97e9-7ab08e075afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-715e232b-045a-4d7b-b383-a4e2c6285da7,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-5bb79ede-3a5f-4644-bd90-6c8b5ee1751a,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-5e0ba470-89a0-45fe-a307-bf0c1d4e243c,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-7c4e1891-0cfd-4524-839c-5a0fd4354645,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-15d6b04f-5187-4773-9d57-6f41ee19a9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-b38373df-564f-4ee3-a361-def4aef3ed81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805153822-172.17.0.15-1597163568155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-03ca1e0e-cf1c-437b-82c4-4292fd4cf6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-5997fe40-1aa1-41f8-97e9-7ab08e075afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-715e232b-045a-4d7b-b383-a4e2c6285da7,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-5bb79ede-3a5f-4644-bd90-6c8b5ee1751a,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-5e0ba470-89a0-45fe-a307-bf0c1d4e243c,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-7c4e1891-0cfd-4524-839c-5a0fd4354645,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-15d6b04f-5187-4773-9d57-6f41ee19a9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-b38373df-564f-4ee3-a361-def4aef3ed81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6516
