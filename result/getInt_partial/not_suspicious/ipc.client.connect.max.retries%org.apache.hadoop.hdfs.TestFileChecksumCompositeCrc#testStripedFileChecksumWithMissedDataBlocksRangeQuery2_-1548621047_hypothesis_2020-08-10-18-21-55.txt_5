reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879174327-172.17.0.12-1597084443779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-d5f9fe24-491f-4255-8497-faea20f7e4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-f5bb547a-300e-470f-815f-a2dd4b0b2598,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-9951c538-7852-4337-a103-33d86fba7a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-9573ca1d-32f8-4a17-ae45-1f51f621bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-6546abbb-a31e-4006-ac10-20a6b765571c,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-147d8b59-44d0-4826-8abb-a5688f8dce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-f6df2869-43f2-458b-8600-e3f54db44ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-e3d54b4c-719f-44d3-9bb3-a1663d8d17d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879174327-172.17.0.12-1597084443779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-d5f9fe24-491f-4255-8497-faea20f7e4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-f5bb547a-300e-470f-815f-a2dd4b0b2598,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-9951c538-7852-4337-a103-33d86fba7a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-9573ca1d-32f8-4a17-ae45-1f51f621bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-6546abbb-a31e-4006-ac10-20a6b765571c,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-147d8b59-44d0-4826-8abb-a5688f8dce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-f6df2869-43f2-458b-8600-e3f54db44ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-e3d54b4c-719f-44d3-9bb3-a1663d8d17d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039535522-172.17.0.12-1597085302720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-eceaf88a-f5dd-4cde-aa92-37dcec08af3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-1c164499-5d16-43d8-af5d-f1e04d1a82a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-64c4f81c-65c4-41f0-ab03-b10fc1b22b46,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-9f84eaea-0a68-4391-9532-86c45373a483,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-5a03cf1c-26f9-4f4e-aba4-2e551d6cbda3,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-2d466b7a-b83f-4cb8-a1d8-f2f2fcfa873f,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-fec53ed3-160c-46ef-809b-a29819abc17c,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-2a3b35db-b333-47af-81ef-823c6094f361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039535522-172.17.0.12-1597085302720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-eceaf88a-f5dd-4cde-aa92-37dcec08af3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-1c164499-5d16-43d8-af5d-f1e04d1a82a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-64c4f81c-65c4-41f0-ab03-b10fc1b22b46,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-9f84eaea-0a68-4391-9532-86c45373a483,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-5a03cf1c-26f9-4f4e-aba4-2e551d6cbda3,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-2d466b7a-b83f-4cb8-a1d8-f2f2fcfa873f,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-fec53ed3-160c-46ef-809b-a29819abc17c,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-2a3b35db-b333-47af-81ef-823c6094f361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218969685-172.17.0.12-1597085495136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-dfde00b7-efd5-42c2-ac4e-bbd9fc8dcfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-10e308ed-6d9b-478b-86e3-a92f3a790bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-b5d04540-4508-4bb8-9466-02ee4171f53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-c78c7f67-bb89-407c-b40f-c1e92602d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-fb9c8470-6a8b-4f15-ba0f-7e3bee47fc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-7d99e4b9-4403-4d44-8494-30db4eabfca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-b35c5648-bff8-49a2-a561-ea9bb96d1aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-54bf78d8-78da-4826-bb6d-e3bc5f32f0d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218969685-172.17.0.12-1597085495136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-dfde00b7-efd5-42c2-ac4e-bbd9fc8dcfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-10e308ed-6d9b-478b-86e3-a92f3a790bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-b5d04540-4508-4bb8-9466-02ee4171f53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-c78c7f67-bb89-407c-b40f-c1e92602d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-fb9c8470-6a8b-4f15-ba0f-7e3bee47fc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-7d99e4b9-4403-4d44-8494-30db4eabfca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-b35c5648-bff8-49a2-a561-ea9bb96d1aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-54bf78d8-78da-4826-bb6d-e3bc5f32f0d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956990373-172.17.0.12-1597085636565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-a0cc5821-15aa-416c-bdd3-c67e454f99b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-d06e39e7-a160-4e12-ade8-37f2247552bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-6af4e60f-8b54-4c6f-a35d-b8ad58250597,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-509311ed-80a7-40fe-b3cb-e4f3cd86546a,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-51784ca3-713c-40cb-8076-4dc0a9e5c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-434a5145-ce55-4d63-b477-6d0dbca984fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-335aab8c-4dcb-4e7c-9960-c85c1de4be5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-ec3299b7-08e5-4cc2-a198-cafe00fb6740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956990373-172.17.0.12-1597085636565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-a0cc5821-15aa-416c-bdd3-c67e454f99b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-d06e39e7-a160-4e12-ade8-37f2247552bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-6af4e60f-8b54-4c6f-a35d-b8ad58250597,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-509311ed-80a7-40fe-b3cb-e4f3cd86546a,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-51784ca3-713c-40cb-8076-4dc0a9e5c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-434a5145-ce55-4d63-b477-6d0dbca984fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-335aab8c-4dcb-4e7c-9960-c85c1de4be5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-ec3299b7-08e5-4cc2-a198-cafe00fb6740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256535636-172.17.0.12-1597086622844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42011,DS-af41b274-f581-4094-962e-2659f6e15899,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-3fe812ed-e9b7-43d5-b2d4-771be50dec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-ed456d02-37a7-41ec-9882-31a8741f9129,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-d6daf0b4-cd1b-4bfb-ab5b-21c5ee25891b,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-6a268303-042d-429b-9ec3-3df94a0fa565,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-56190fc9-4d7a-4986-8136-6845d10a4ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-e23d7336-3182-40d2-b5a5-9833179dc97d,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-5f34c0f6-f47f-45b3-9142-f370c61d60ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256535636-172.17.0.12-1597086622844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42011,DS-af41b274-f581-4094-962e-2659f6e15899,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-3fe812ed-e9b7-43d5-b2d4-771be50dec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-ed456d02-37a7-41ec-9882-31a8741f9129,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-d6daf0b4-cd1b-4bfb-ab5b-21c5ee25891b,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-6a268303-042d-429b-9ec3-3df94a0fa565,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-56190fc9-4d7a-4986-8136-6845d10a4ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-e23d7336-3182-40d2-b5a5-9833179dc97d,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-5f34c0f6-f47f-45b3-9142-f370c61d60ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377795385-172.17.0.12-1597086720933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-0f081cb0-cb32-425a-9a93-30090c3799f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-776b98f0-1568-4e22-bb96-a3d82658aa67,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-010fb696-5284-4fe8-894c-aafb9cd5a4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-820edff2-92d0-4f19-b074-69ac1fa6c17e,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-438dfe18-5e7d-400c-b829-e90df999286d,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-583bb036-13b1-4f85-81c7-6c0cfa3602d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-bd523966-2da8-44fd-bb50-20402517299b,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-112d3d17-547f-4458-b981-bd247df695c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377795385-172.17.0.12-1597086720933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-0f081cb0-cb32-425a-9a93-30090c3799f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-776b98f0-1568-4e22-bb96-a3d82658aa67,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-010fb696-5284-4fe8-894c-aafb9cd5a4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-820edff2-92d0-4f19-b074-69ac1fa6c17e,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-438dfe18-5e7d-400c-b829-e90df999286d,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-583bb036-13b1-4f85-81c7-6c0cfa3602d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-bd523966-2da8-44fd-bb50-20402517299b,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-112d3d17-547f-4458-b981-bd247df695c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868856439-172.17.0.12-1597086954892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38822,DS-2c40173f-ac51-4fb8-be1a-7a2dfc9da5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-85a413fc-7a06-4210-bc65-e83777bedb03,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-c8240b14-7137-4eff-a60d-d75f51a393df,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-fbbd214b-df43-4aac-9cd5-efbda87f93e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-0842b61f-e58f-4525-9d37-c8f2213198d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-95bc4b92-e9dd-4477-abdf-abed94253ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-ab96da91-4a24-4079-a00d-dabe95eb9d66,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-140fe9b0-0160-4d7c-982d-34d4a1c55f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868856439-172.17.0.12-1597086954892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38822,DS-2c40173f-ac51-4fb8-be1a-7a2dfc9da5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-85a413fc-7a06-4210-bc65-e83777bedb03,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-c8240b14-7137-4eff-a60d-d75f51a393df,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-fbbd214b-df43-4aac-9cd5-efbda87f93e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-0842b61f-e58f-4525-9d37-c8f2213198d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-95bc4b92-e9dd-4477-abdf-abed94253ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-ab96da91-4a24-4079-a00d-dabe95eb9d66,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-140fe9b0-0160-4d7c-982d-34d4a1c55f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404391152-172.17.0.12-1597087377027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35622,DS-04fcb107-4fc3-4fcf-b24b-10460ba04f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7f1f6402-c6ae-4bb5-a96c-bbfaf1e4232e,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-7faf2df9-cbb8-4417-8fab-2a2bdb6b0161,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-abfe35d1-2c29-445d-b277-8aa1c1d90f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-79c87a9b-1765-4ea6-8486-0c5abec756e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-aac3526e-b4a2-45e6-8c10-09e4f884572d,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-20a482aa-3598-4992-bd56-89157dac3614,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-8c6d0760-3382-4562-ba2f-d417c10114a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404391152-172.17.0.12-1597087377027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35622,DS-04fcb107-4fc3-4fcf-b24b-10460ba04f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7f1f6402-c6ae-4bb5-a96c-bbfaf1e4232e,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-7faf2df9-cbb8-4417-8fab-2a2bdb6b0161,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-abfe35d1-2c29-445d-b277-8aa1c1d90f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-79c87a9b-1765-4ea6-8486-0c5abec756e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-aac3526e-b4a2-45e6-8c10-09e4f884572d,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-20a482aa-3598-4992-bd56-89157dac3614,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-8c6d0760-3382-4562-ba2f-d417c10114a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58637364-172.17.0.12-1597087960683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42919,DS-f3aea87b-c3b5-41dc-82da-f5cd0c369cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-6da5094b-3202-45f1-83e4-a85d286afc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-2bc3aeea-746f-4cec-8ba8-24b945894b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-21b44b8e-2751-4c26-ac11-e3e08a9af9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-f45acbdc-356b-43cf-bf4f-e5b23f88bbea,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-6bd00725-d8b1-4849-a5a2-1a4e0eecd3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-3275aa06-1542-48a2-92c3-3801f0cebcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-85ff3e50-b47e-47c7-adea-643302f33999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58637364-172.17.0.12-1597087960683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42919,DS-f3aea87b-c3b5-41dc-82da-f5cd0c369cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-6da5094b-3202-45f1-83e4-a85d286afc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-2bc3aeea-746f-4cec-8ba8-24b945894b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-21b44b8e-2751-4c26-ac11-e3e08a9af9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-f45acbdc-356b-43cf-bf4f-e5b23f88bbea,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-6bd00725-d8b1-4849-a5a2-1a4e0eecd3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-3275aa06-1542-48a2-92c3-3801f0cebcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-85ff3e50-b47e-47c7-adea-643302f33999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511220935-172.17.0.12-1597088297267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-2086ffad-1de9-4506-8438-1301cdfd7d66,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-4b261dd0-59fd-4d19-ba25-e1f8ce99994f,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-bacf95dd-b196-4992-9daf-37cf280249b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-f5bd1893-3012-4d9d-bfeb-d0e567f829cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-d0fa5f0c-978a-4760-8c79-d3b5996d7ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-4037c0ef-0414-4b14-be18-25abbae68fad,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-5f5cea54-2a55-4d3a-9eb1-d141326ada55,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-97de679d-ce50-41cc-b093-0fb15464c578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511220935-172.17.0.12-1597088297267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-2086ffad-1de9-4506-8438-1301cdfd7d66,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-4b261dd0-59fd-4d19-ba25-e1f8ce99994f,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-bacf95dd-b196-4992-9daf-37cf280249b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-f5bd1893-3012-4d9d-bfeb-d0e567f829cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-d0fa5f0c-978a-4760-8c79-d3b5996d7ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-4037c0ef-0414-4b14-be18-25abbae68fad,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-5f5cea54-2a55-4d3a-9eb1-d141326ada55,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-97de679d-ce50-41cc-b093-0fb15464c578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653439223-172.17.0.12-1597089477196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43645,DS-888b5382-2937-49e4-a794-7c1589b6ccad,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-fdbe686a-5624-4616-9ac7-66629d5bd56f,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-ab0eba23-cda0-46cb-96ab-702f4b64b72e,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-251e4cdd-97ac-4550-a7b6-2bbf421c6ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-9c93af25-6146-4c42-ae29-05f54285aa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-d2b4eec1-2db8-4add-8cdc-4cc988052772,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-3927923c-8332-4c55-bdb1-5209c29495bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-74c695b3-079f-4e54-a12c-fb4587b6a13c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653439223-172.17.0.12-1597089477196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43645,DS-888b5382-2937-49e4-a794-7c1589b6ccad,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-fdbe686a-5624-4616-9ac7-66629d5bd56f,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-ab0eba23-cda0-46cb-96ab-702f4b64b72e,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-251e4cdd-97ac-4550-a7b6-2bbf421c6ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-9c93af25-6146-4c42-ae29-05f54285aa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-d2b4eec1-2db8-4add-8cdc-4cc988052772,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-3927923c-8332-4c55-bdb1-5209c29495bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-74c695b3-079f-4e54-a12c-fb4587b6a13c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307927465-172.17.0.12-1597089660580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38324,DS-fd3824ae-c777-47ce-af2d-9c49284b5cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-5804dfd3-7fd3-4ded-b0de-3ae312801737,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-05abf525-dffa-44ee-83a0-4b4d6e006ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-311018cc-5729-4705-87b8-2c72fff64f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-095db5c8-b299-4917-a9a8-fd60a963c931,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-76be1354-e2a8-466e-9150-d57a7428aa64,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-8a72aaeb-932d-463a-bd05-a55b4c94e51a,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-3bec21b6-4830-4caf-b03d-acd45dd837d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307927465-172.17.0.12-1597089660580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38324,DS-fd3824ae-c777-47ce-af2d-9c49284b5cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-5804dfd3-7fd3-4ded-b0de-3ae312801737,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-05abf525-dffa-44ee-83a0-4b4d6e006ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-311018cc-5729-4705-87b8-2c72fff64f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-095db5c8-b299-4917-a9a8-fd60a963c931,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-76be1354-e2a8-466e-9150-d57a7428aa64,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-8a72aaeb-932d-463a-bd05-a55b4c94e51a,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-3bec21b6-4830-4caf-b03d-acd45dd837d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145954316-172.17.0.12-1597089993516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34257,DS-02dc4e04-1754-4f39-801b-7abf9c26c413,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-18e7971d-3f48-41cc-b49b-ccd3613e05fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-3f614ce1-ded4-4b43-adab-72b36a101c47,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-bd053368-3369-47b1-b75e-1deac069fa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-d080ddbc-2031-4a13-9a42-4c0f54573b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-839c5053-f2b0-483f-8ab5-4f7178fb93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-c7ece98b-c317-4b2a-86dc-d5e97cc22680,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-46dfd4e8-c55e-4de2-a2a8-675385b39258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145954316-172.17.0.12-1597089993516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34257,DS-02dc4e04-1754-4f39-801b-7abf9c26c413,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-18e7971d-3f48-41cc-b49b-ccd3613e05fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-3f614ce1-ded4-4b43-adab-72b36a101c47,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-bd053368-3369-47b1-b75e-1deac069fa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-d080ddbc-2031-4a13-9a42-4c0f54573b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-839c5053-f2b0-483f-8ab5-4f7178fb93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-c7ece98b-c317-4b2a-86dc-d5e97cc22680,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-46dfd4e8-c55e-4de2-a2a8-675385b39258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089050024-172.17.0.12-1597090266629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-ed2a562e-ef70-4b1b-87b8-26e64d1a9c37,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-24b43244-81fa-4d12-bfe8-bf0f650b1de9,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-05ef4e50-ae9a-4816-b925-7eadb098f958,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-39253ed8-5f4b-4c24-bfad-833e784c7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-b7498b19-2909-4b26-9584-dca2606b5532,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-912671f7-5a36-49b9-ba99-427c53ff98ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-30db04eb-e33e-4a1a-9cf6-d1ff16b311ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-0e1f04c9-9165-47eb-b623-a97601ace310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089050024-172.17.0.12-1597090266629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-ed2a562e-ef70-4b1b-87b8-26e64d1a9c37,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-24b43244-81fa-4d12-bfe8-bf0f650b1de9,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-05ef4e50-ae9a-4816-b925-7eadb098f958,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-39253ed8-5f4b-4c24-bfad-833e784c7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-b7498b19-2909-4b26-9584-dca2606b5532,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-912671f7-5a36-49b9-ba99-427c53ff98ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-30db04eb-e33e-4a1a-9cf6-d1ff16b311ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-0e1f04c9-9165-47eb-b623-a97601ace310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603039291-172.17.0.12-1597090588579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-dd7ead38-f24d-4000-80d6-d8d15bcf6ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-fa08502e-0c52-4749-bfad-2add60d89a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-c2021a4c-7c4b-478c-9488-d14a11304368,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-fb2fbe05-9438-42bb-a242-92ffedf55889,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-3e477594-b279-4c42-8346-8f6a0b4366dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-9c6e9c66-526a-4a3a-b767-58ea1f4f47a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-9f3b3a2a-0560-4e2f-afb6-c88d1f45f537,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-1c7144d7-1f7d-4c7b-b94c-ecfc6f8f3f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603039291-172.17.0.12-1597090588579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-dd7ead38-f24d-4000-80d6-d8d15bcf6ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-fa08502e-0c52-4749-bfad-2add60d89a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-c2021a4c-7c4b-478c-9488-d14a11304368,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-fb2fbe05-9438-42bb-a242-92ffedf55889,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-3e477594-b279-4c42-8346-8f6a0b4366dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-9c6e9c66-526a-4a3a-b767-58ea1f4f47a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-9f3b3a2a-0560-4e2f-afb6-c88d1f45f537,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-1c7144d7-1f7d-4c7b-b94c-ecfc6f8f3f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6985
