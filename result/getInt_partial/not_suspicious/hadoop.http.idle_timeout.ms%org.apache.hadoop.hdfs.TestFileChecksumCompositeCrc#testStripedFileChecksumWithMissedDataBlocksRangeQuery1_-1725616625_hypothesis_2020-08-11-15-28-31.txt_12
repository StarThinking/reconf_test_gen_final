reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224954771-172.17.0.16-1597160076087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35227,DS-3c30f6b9-12ff-4779-9e1d-f0a7581bf3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-75cb7515-ff99-4708-acc3-dd0d9e32c0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-68a4e8e4-5f3a-428c-a53c-51327f822857,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-ce7ed8c7-23f5-4908-995d-513405104b10,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-b82123af-2a4b-4fe7-9b42-d03993950ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-88b5f55e-4b85-48ff-8017-04d7ef10f51e,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-80f31586-16ac-4426-9972-48dd5ca16e70,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-080ea170-980b-4794-839e-e39d1a688ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224954771-172.17.0.16-1597160076087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35227,DS-3c30f6b9-12ff-4779-9e1d-f0a7581bf3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-75cb7515-ff99-4708-acc3-dd0d9e32c0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-68a4e8e4-5f3a-428c-a53c-51327f822857,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-ce7ed8c7-23f5-4908-995d-513405104b10,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-b82123af-2a4b-4fe7-9b42-d03993950ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-88b5f55e-4b85-48ff-8017-04d7ef10f51e,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-80f31586-16ac-4426-9972-48dd5ca16e70,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-080ea170-980b-4794-839e-e39d1a688ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083223775-172.17.0.16-1597160187658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-01f0b7fd-ad4c-4ea3-9d29-b1214b6f6389,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-2c3a2f4d-f0b3-44c6-bd74-299e1ea9b676,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-9367e421-a0d6-4c02-809e-e62eaf10a524,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-023d7578-a0f2-49ca-82e8-36707f9c5898,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-2efa59e2-66f9-4bd3-9684-5f592313e131,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-1597061f-d1c9-4673-97f1-34907474d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-ab9cc01c-e6ee-4c39-9340-f22fcbca4134,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-77adc3b3-ae7e-4d19-881c-b2e886edc30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083223775-172.17.0.16-1597160187658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-01f0b7fd-ad4c-4ea3-9d29-b1214b6f6389,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-2c3a2f4d-f0b3-44c6-bd74-299e1ea9b676,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-9367e421-a0d6-4c02-809e-e62eaf10a524,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-023d7578-a0f2-49ca-82e8-36707f9c5898,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-2efa59e2-66f9-4bd3-9684-5f592313e131,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-1597061f-d1c9-4673-97f1-34907474d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-ab9cc01c-e6ee-4c39-9340-f22fcbca4134,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-77adc3b3-ae7e-4d19-881c-b2e886edc30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528376087-172.17.0.16-1597160407135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43926,DS-51a6a8ee-8d35-45ad-bfbf-5ff65bf73913,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-95dd402d-601d-4d5f-916a-9dc85c114007,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-9e6eabff-d10d-4499-8c35-f24d9058bcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-870afdec-6c52-4f92-8047-57984cc04a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-36c77673-6102-40b1-847d-7c374e60c3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-ece678b9-82e0-40e3-ac10-a4ec3f071e56,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-cb0b29f2-0cdf-43ae-8959-6065f6e401d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-5150c518-d453-45d8-bddb-883809d83e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528376087-172.17.0.16-1597160407135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43926,DS-51a6a8ee-8d35-45ad-bfbf-5ff65bf73913,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-95dd402d-601d-4d5f-916a-9dc85c114007,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-9e6eabff-d10d-4499-8c35-f24d9058bcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-870afdec-6c52-4f92-8047-57984cc04a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-36c77673-6102-40b1-847d-7c374e60c3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-ece678b9-82e0-40e3-ac10-a4ec3f071e56,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-cb0b29f2-0cdf-43ae-8959-6065f6e401d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-5150c518-d453-45d8-bddb-883809d83e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393894133-172.17.0.16-1597160513504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39099,DS-758fce01-e688-46a9-947c-bc8ffab1a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-0d93e2a9-350c-4be7-8167-6f75b0321b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-ad02024b-2a46-4e03-99cd-098455a76c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-768dad76-8f78-4784-bbe4-aa8d4a4a7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-6d9784ce-988d-4195-b554-6918ff1efdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-e613462a-4154-4b89-b3a8-48f75ed687f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-6fb6adcd-ec99-44c9-a76e-8f515c63236e,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-fb1aabea-da82-4ab5-bbf6-f5b7565a8e56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393894133-172.17.0.16-1597160513504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39099,DS-758fce01-e688-46a9-947c-bc8ffab1a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-0d93e2a9-350c-4be7-8167-6f75b0321b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-ad02024b-2a46-4e03-99cd-098455a76c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-768dad76-8f78-4784-bbe4-aa8d4a4a7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-6d9784ce-988d-4195-b554-6918ff1efdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-e613462a-4154-4b89-b3a8-48f75ed687f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-6fb6adcd-ec99-44c9-a76e-8f515c63236e,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-fb1aabea-da82-4ab5-bbf6-f5b7565a8e56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738967602-172.17.0.16-1597160807803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42508,DS-48ad98f3-b44b-434a-8267-be4cd0424212,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-5c53cda3-6b50-4565-92c7-b4e5e366ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-0647a33a-4421-42e0-9b8a-5096dc4fa748,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-07566ad1-a933-44ba-a8d9-592c78090364,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-f8701236-9c84-41b8-932f-ba46727ff7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-39909650-6b90-4a77-ac25-e4b5054cc335,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-c0bccd07-48f4-483f-b497-8e7b3749f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-f8cf795d-2bdb-4a7d-b558-3b8bcac4fec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738967602-172.17.0.16-1597160807803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42508,DS-48ad98f3-b44b-434a-8267-be4cd0424212,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-5c53cda3-6b50-4565-92c7-b4e5e366ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-0647a33a-4421-42e0-9b8a-5096dc4fa748,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-07566ad1-a933-44ba-a8d9-592c78090364,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-f8701236-9c84-41b8-932f-ba46727ff7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-39909650-6b90-4a77-ac25-e4b5054cc335,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-c0bccd07-48f4-483f-b497-8e7b3749f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-f8cf795d-2bdb-4a7d-b558-3b8bcac4fec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307500505-172.17.0.16-1597160963486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33775,DS-5df9a7b6-1163-4d2c-a85a-8c9c5e80e297,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-28b6490b-36be-43a9-9c76-0493fd31b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-aca74689-7583-48b0-b62d-e9949c71f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-d1541e77-8528-4a8a-85d3-7995baf19265,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-f623e5e0-37c3-4b2d-a7d7-008dc70112fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-ab89f7d3-9dcb-48f8-9e3e-9b5a215434b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-2573a160-7f3d-42e0-a93d-fa17478ecab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-ebefa028-0b3f-4ffd-9a32-6cde3d8dcac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307500505-172.17.0.16-1597160963486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33775,DS-5df9a7b6-1163-4d2c-a85a-8c9c5e80e297,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-28b6490b-36be-43a9-9c76-0493fd31b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-aca74689-7583-48b0-b62d-e9949c71f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-d1541e77-8528-4a8a-85d3-7995baf19265,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-f623e5e0-37c3-4b2d-a7d7-008dc70112fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-ab89f7d3-9dcb-48f8-9e3e-9b5a215434b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-2573a160-7f3d-42e0-a93d-fa17478ecab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-ebefa028-0b3f-4ffd-9a32-6cde3d8dcac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812108331-172.17.0.16-1597161007486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44336,DS-585f8db1-ae85-4920-a41b-e52b4d27d17e,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-0f6d3333-08bc-4cd3-80a5-36fef3554a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-e72c7edc-6ac6-4c28-b827-948acb3b3520,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-62bfffe4-cbe5-4a7b-8ef0-4cad7f2c7173,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-a263dbe1-c917-470a-9aa4-9de3f1afa86b,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-679eb33b-54df-4ad8-9a5f-d3d132e93588,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-d71d1b64-c643-42e3-80d3-b9b701d34a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-ff49e8e6-11a7-4f0f-8528-6ed953786b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812108331-172.17.0.16-1597161007486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44336,DS-585f8db1-ae85-4920-a41b-e52b4d27d17e,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-0f6d3333-08bc-4cd3-80a5-36fef3554a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-e72c7edc-6ac6-4c28-b827-948acb3b3520,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-62bfffe4-cbe5-4a7b-8ef0-4cad7f2c7173,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-a263dbe1-c917-470a-9aa4-9de3f1afa86b,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-679eb33b-54df-4ad8-9a5f-d3d132e93588,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-d71d1b64-c643-42e3-80d3-b9b701d34a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-ff49e8e6-11a7-4f0f-8528-6ed953786b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020634007-172.17.0.16-1597161729692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-7993932c-bd75-49f6-bfec-a1e84a6e0e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-5e86c349-0eae-432a-a3ca-f34bc844ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-ad0f3f77-0da8-4059-8528-d796a18060f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-7ac28888-f297-4b13-9e44-1976e3747773,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-cefea623-522c-4d48-9996-267643873bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-1c12db2b-fb56-41e7-8332-7863f53330ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-9b6e6e1e-16dc-4c07-98bf-0eefe1299cba,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-da90a5f1-c473-4887-8720-40cda94a0dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020634007-172.17.0.16-1597161729692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-7993932c-bd75-49f6-bfec-a1e84a6e0e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-5e86c349-0eae-432a-a3ca-f34bc844ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-ad0f3f77-0da8-4059-8528-d796a18060f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-7ac28888-f297-4b13-9e44-1976e3747773,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-cefea623-522c-4d48-9996-267643873bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-1c12db2b-fb56-41e7-8332-7863f53330ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-9b6e6e1e-16dc-4c07-98bf-0eefe1299cba,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-da90a5f1-c473-4887-8720-40cda94a0dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133958619-172.17.0.16-1597161991205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40361,DS-df346396-07ee-4266-8d2d-4d0bec267ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-70af08b3-9071-4b77-b028-aad0865821d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-c8f38954-3fc9-4046-bc06-f97785f2c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-3e894cb4-a5a6-4ed4-8634-bdf2c122dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-da5b3145-e05b-4306-8def-ca03048db16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-25f4691f-cfaa-49c2-8177-3da3c1289f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-0e7bb4ec-c0b4-45a2-a77f-c4489cb02bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-83d10119-a46a-43bf-b63e-fa6ebce7c210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133958619-172.17.0.16-1597161991205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40361,DS-df346396-07ee-4266-8d2d-4d0bec267ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-70af08b3-9071-4b77-b028-aad0865821d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-c8f38954-3fc9-4046-bc06-f97785f2c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-3e894cb4-a5a6-4ed4-8634-bdf2c122dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-da5b3145-e05b-4306-8def-ca03048db16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-25f4691f-cfaa-49c2-8177-3da3c1289f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-0e7bb4ec-c0b4-45a2-a77f-c4489cb02bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-83d10119-a46a-43bf-b63e-fa6ebce7c210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687938213-172.17.0.16-1597162139446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-6ab78d64-a318-4f94-89e2-9fdca4aa7177,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-49ef2559-85ba-4e02-b77c-d475afecdcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-48fbfc8f-842d-4f71-b3d3-ff8476358770,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-3093e3df-4bba-4f7f-b918-46865871d713,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-9c51cfc1-e4cf-4558-b6c7-673154d052e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-1b43433a-8ed6-4650-8f54-f0fd61fee9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-6b7a0a81-fde9-455c-9d1b-52101e0e5bde,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-5cc41f1e-4079-4031-86c7-14938b41426c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687938213-172.17.0.16-1597162139446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-6ab78d64-a318-4f94-89e2-9fdca4aa7177,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-49ef2559-85ba-4e02-b77c-d475afecdcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-48fbfc8f-842d-4f71-b3d3-ff8476358770,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-3093e3df-4bba-4f7f-b918-46865871d713,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-9c51cfc1-e4cf-4558-b6c7-673154d052e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-1b43433a-8ed6-4650-8f54-f0fd61fee9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-6b7a0a81-fde9-455c-9d1b-52101e0e5bde,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-5cc41f1e-4079-4031-86c7-14938b41426c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62931529-172.17.0.16-1597162480296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-5bda83e9-0bfa-40dd-a613-47f8e8e243d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-690c2ddf-b05a-407e-88d5-3528813bb0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-e1b8eaa0-99dd-48e7-8b03-96a11a99fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-866200d1-69fa-4e50-b58a-4d9f513fa853,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-b71b3379-4027-46fa-95b1-a067df6b6c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-58f79aa0-c173-4bf2-9ad2-6aaace9f68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-fe80f94f-8096-461a-a8dd-bfc42e189cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-e1f75193-5e04-44fe-8b61-f1dbba39a167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62931529-172.17.0.16-1597162480296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-5bda83e9-0bfa-40dd-a613-47f8e8e243d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-690c2ddf-b05a-407e-88d5-3528813bb0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-e1b8eaa0-99dd-48e7-8b03-96a11a99fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-866200d1-69fa-4e50-b58a-4d9f513fa853,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-b71b3379-4027-46fa-95b1-a067df6b6c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-58f79aa0-c173-4bf2-9ad2-6aaace9f68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-fe80f94f-8096-461a-a8dd-bfc42e189cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-e1f75193-5e04-44fe-8b61-f1dbba39a167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515211876-172.17.0.16-1597163104088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46539,DS-f4150f61-c304-4996-b454-d27edc05801a,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-21793a9a-4989-4727-9337-6bf22736e810,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-1956bfe5-979d-47de-b345-f4661b224640,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-7dcdb10e-1f27-4def-b4d4-ecead6e3ce30,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-acc2ffba-6ce5-467a-9aea-c18a9b256a57,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-3581df15-f6f5-45c0-a982-8b20f4870d67,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-61fd742b-01ad-4ea7-9aa2-8432f9a50fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-a858c52c-82dd-4f1e-be78-d8d508b199e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515211876-172.17.0.16-1597163104088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46539,DS-f4150f61-c304-4996-b454-d27edc05801a,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-21793a9a-4989-4727-9337-6bf22736e810,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-1956bfe5-979d-47de-b345-f4661b224640,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-7dcdb10e-1f27-4def-b4d4-ecead6e3ce30,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-acc2ffba-6ce5-467a-9aea-c18a9b256a57,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-3581df15-f6f5-45c0-a982-8b20f4870d67,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-61fd742b-01ad-4ea7-9aa2-8432f9a50fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-a858c52c-82dd-4f1e-be78-d8d508b199e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369157571-172.17.0.16-1597163363156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45465,DS-afe5f599-b753-42c1-aa59-3c28ff0e2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-7e7651b5-4147-4c24-b6c4-cc7a971539c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-f3eebcd6-3b9a-4825-be48-f5f18d376158,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-699bd19d-a576-4164-8ae1-b414eb6af5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-f62fdeba-50a8-4051-ba42-f878e276bb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-2a61f51c-fb57-4128-960b-c9ba9d339833,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-9e20dea5-b8a8-4092-936c-04f14f5a0555,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-137cf7bf-6066-48d3-8fce-110c1bf262c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369157571-172.17.0.16-1597163363156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45465,DS-afe5f599-b753-42c1-aa59-3c28ff0e2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-7e7651b5-4147-4c24-b6c4-cc7a971539c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-f3eebcd6-3b9a-4825-be48-f5f18d376158,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-699bd19d-a576-4164-8ae1-b414eb6af5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-f62fdeba-50a8-4051-ba42-f878e276bb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-2a61f51c-fb57-4128-960b-c9ba9d339833,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-9e20dea5-b8a8-4092-936c-04f14f5a0555,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-137cf7bf-6066-48d3-8fce-110c1bf262c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045895274-172.17.0.16-1597163496030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-0a16c6e9-8de5-4301-90e4-169a6df3efa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-db6d9831-4043-4b5f-8ebe-ca6c40c9af20,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-6b1f621f-8a9f-44aa-be1d-9690ca4823f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-a299c425-1bc5-4cc3-8b28-468e7cc26031,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-5a9182d1-7ecf-458c-83e2-025de76459e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-df78e1b3-b8e2-4a54-900b-d3d84ba9f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-c8156d88-b394-4b54-b764-b06aeeb184e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-e8c5a360-b713-4325-8e89-3510011a547f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045895274-172.17.0.16-1597163496030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-0a16c6e9-8de5-4301-90e4-169a6df3efa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-db6d9831-4043-4b5f-8ebe-ca6c40c9af20,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-6b1f621f-8a9f-44aa-be1d-9690ca4823f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-a299c425-1bc5-4cc3-8b28-468e7cc26031,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-5a9182d1-7ecf-458c-83e2-025de76459e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-df78e1b3-b8e2-4a54-900b-d3d84ba9f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-c8156d88-b394-4b54-b764-b06aeeb184e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-e8c5a360-b713-4325-8e89-3510011a547f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247734524-172.17.0.16-1597163631585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41286,DS-73d1ea62-2798-4758-93ce-c18bbf871030,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-d7b413a2-b174-46a2-a719-ed2955d9af01,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-cc685213-1428-4dba-aac0-b69b742bdc76,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-25a862aa-4a4e-40ea-ba9a-66cae3637848,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-9d0adc9f-de3d-4b56-950a-c3eb78f2fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-aabd7fdb-28a4-48e9-9a4b-97666be8570b,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-5282fe56-47f5-463c-8745-ffc71a0ffbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-ee2cf1a4-befa-462d-9c12-df595b178d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247734524-172.17.0.16-1597163631585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41286,DS-73d1ea62-2798-4758-93ce-c18bbf871030,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-d7b413a2-b174-46a2-a719-ed2955d9af01,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-cc685213-1428-4dba-aac0-b69b742bdc76,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-25a862aa-4a4e-40ea-ba9a-66cae3637848,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-9d0adc9f-de3d-4b56-950a-c3eb78f2fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-aabd7fdb-28a4-48e9-9a4b-97666be8570b,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-5282fe56-47f5-463c-8745-ffc71a0ffbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-ee2cf1a4-befa-462d-9c12-df595b178d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161890543-172.17.0.16-1597163820289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-887f251b-6530-4f9b-89e6-4575d26e45f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-6b49e3a6-6ec6-4fd2-a0ac-0daad7cb1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-b6c4f9a7-52db-4b5c-96ca-45b8964c10b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-5f298e64-4202-4fd8-bfbd-d1c0ed554cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-6d3c0f08-defb-4e0d-9311-e2932547723f,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-0af852e9-0ea8-45b5-a8cb-30e35120f742,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-e928e383-4551-45be-b897-bed7ce2fd575,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-4595bcaf-40bf-4a3c-8cea-0463bc1d6fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161890543-172.17.0.16-1597163820289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-887f251b-6530-4f9b-89e6-4575d26e45f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-6b49e3a6-6ec6-4fd2-a0ac-0daad7cb1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-b6c4f9a7-52db-4b5c-96ca-45b8964c10b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-5f298e64-4202-4fd8-bfbd-d1c0ed554cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-6d3c0f08-defb-4e0d-9311-e2932547723f,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-0af852e9-0ea8-45b5-a8cb-30e35120f742,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-e928e383-4551-45be-b897-bed7ce2fd575,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-4595bcaf-40bf-4a3c-8cea-0463bc1d6fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167354550-172.17.0.16-1597163921218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-3efbbd8c-dade-4de4-a473-20b30f9d5d16,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-2148918d-2669-49d9-8b51-aa189b98d799,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-731b0cfa-6bb3-4a84-80fa-c5126cf34973,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-b6c01564-3966-4615-b7ad-2e2921a67b03,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-196db884-a7ed-4b33-ac2e-9d530d693410,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-15e9f3ba-d779-46c5-a5bc-8a72ae170159,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-eac2514e-cdd1-4870-8e05-c0328da822b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-45eacfd6-6b53-4181-b928-31bceed3cfbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167354550-172.17.0.16-1597163921218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-3efbbd8c-dade-4de4-a473-20b30f9d5d16,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-2148918d-2669-49d9-8b51-aa189b98d799,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-731b0cfa-6bb3-4a84-80fa-c5126cf34973,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-b6c01564-3966-4615-b7ad-2e2921a67b03,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-196db884-a7ed-4b33-ac2e-9d530d693410,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-15e9f3ba-d779-46c5-a5bc-8a72ae170159,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-eac2514e-cdd1-4870-8e05-c0328da822b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-45eacfd6-6b53-4181-b928-31bceed3cfbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593150863-172.17.0.16-1597164124953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-99a4de96-0f10-47de-8266-53044a8fda39,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-39661bf5-fe61-411d-a5cf-de7ebf342ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-1f4838fe-7659-4326-8b94-3e17311f919b,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-acf4f35b-7d3d-4100-9cdc-baa0b7158173,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-5e2d91be-7e9f-4953-bfb1-be061c07719c,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-c104f744-e224-4f91-bb45-e36b329a71bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-9a2618c1-bdba-4751-a13e-b406e4b45c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-d355f835-1173-4d7e-b01c-f7db82ff35e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593150863-172.17.0.16-1597164124953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-99a4de96-0f10-47de-8266-53044a8fda39,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-39661bf5-fe61-411d-a5cf-de7ebf342ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-1f4838fe-7659-4326-8b94-3e17311f919b,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-acf4f35b-7d3d-4100-9cdc-baa0b7158173,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-5e2d91be-7e9f-4953-bfb1-be061c07719c,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-c104f744-e224-4f91-bb45-e36b329a71bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-9a2618c1-bdba-4751-a13e-b406e4b45c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-d355f835-1173-4d7e-b01c-f7db82ff35e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994119710-172.17.0.16-1597164418453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-f8234577-579e-45df-85af-1a0704699771,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-0b4ad1d7-7e42-4183-9cb0-e2327abab905,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-4b974cfa-8791-45aa-8745-595a459b90e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-8d2e0398-eee1-4f6f-8365-08a2b9327805,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-0df8ff1a-5b35-429a-8bdd-c727cc3c12eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-e83cc941-80bd-4292-93f7-407c3ed56852,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-6042c9e6-c6b4-4c3c-970f-7aad65bf25c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-79bbea24-78ee-4641-a5fe-1672e3aa2635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994119710-172.17.0.16-1597164418453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-f8234577-579e-45df-85af-1a0704699771,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-0b4ad1d7-7e42-4183-9cb0-e2327abab905,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-4b974cfa-8791-45aa-8745-595a459b90e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-8d2e0398-eee1-4f6f-8365-08a2b9327805,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-0df8ff1a-5b35-429a-8bdd-c727cc3c12eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-e83cc941-80bd-4292-93f7-407c3ed56852,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-6042c9e6-c6b4-4c3c-970f-7aad65bf25c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-79bbea24-78ee-4641-a5fe-1672e3aa2635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258013016-172.17.0.16-1597164825553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-e3538c86-cc45-401c-9757-469e29707e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-cdedb211-68b3-4311-a949-6faf8dde2d79,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-66bddcc4-57e6-409e-af2f-8944455af72c,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-a9b45de5-86a4-4b84-acbe-b4781de62710,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-1933d8a0-efee-4a03-bb18-b9b254d2c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-58fd7c80-891b-49d7-9d6d-056ea1fe6d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-0f3b23cb-e499-4ad9-9c26-84aadd235dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-8fa1329c-f4ce-4760-b46f-2eb29ba6fbf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258013016-172.17.0.16-1597164825553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-e3538c86-cc45-401c-9757-469e29707e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-cdedb211-68b3-4311-a949-6faf8dde2d79,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-66bddcc4-57e6-409e-af2f-8944455af72c,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-a9b45de5-86a4-4b84-acbe-b4781de62710,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-1933d8a0-efee-4a03-bb18-b9b254d2c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-58fd7c80-891b-49d7-9d6d-056ea1fe6d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-0f3b23cb-e499-4ad9-9c26-84aadd235dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-8fa1329c-f4ce-4760-b46f-2eb29ba6fbf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5264
