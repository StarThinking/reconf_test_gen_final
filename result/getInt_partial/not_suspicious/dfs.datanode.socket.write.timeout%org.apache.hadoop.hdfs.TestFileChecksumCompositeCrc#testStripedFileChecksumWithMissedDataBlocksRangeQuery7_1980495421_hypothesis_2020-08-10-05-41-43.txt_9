reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123726088-172.17.0.11-1597038296623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-00ffc38c-7f46-4dd5-a710-a3a6ad5f6406,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-77dd32e5-1b6c-4b2c-a6f6-76af2f374d71,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-56177e71-d03a-4d5d-bb62-d0490960a75c,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-cb6934cf-a8b7-45b9-8fce-c9df7bb6bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-4ae68a51-87fe-45c0-947b-4e8c6fdaf186,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-14308d0d-611d-4298-a1f0-719e4ae48ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-b5503cfa-10b8-49e0-9e14-39e7ca45ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-0d60477e-695a-436b-9494-48291969e71c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123726088-172.17.0.11-1597038296623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-00ffc38c-7f46-4dd5-a710-a3a6ad5f6406,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-77dd32e5-1b6c-4b2c-a6f6-76af2f374d71,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-56177e71-d03a-4d5d-bb62-d0490960a75c,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-cb6934cf-a8b7-45b9-8fce-c9df7bb6bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-4ae68a51-87fe-45c0-947b-4e8c6fdaf186,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-14308d0d-611d-4298-a1f0-719e4ae48ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-b5503cfa-10b8-49e0-9e14-39e7ca45ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-0d60477e-695a-436b-9494-48291969e71c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182942424-172.17.0.11-1597038443905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-b8883561-a044-4e0a-9cd4-c221d4cb1a38,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-48447330-3b90-4c13-850b-b0bb6841d340,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-0ea2783e-4d44-4c50-a923-bec3057d22b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-765e38d0-804c-46fb-9975-c3fdbd693316,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-f1cc2bf5-d8cb-42ac-a22c-b8c8acfe08e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-4b7a6bbb-5d62-470d-a32d-5a2f9971bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-769eeef8-5ca3-4a76-95b7-9347339e267e,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-b35b1518-6524-4b8c-ac0c-4d68f0d6b467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182942424-172.17.0.11-1597038443905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-b8883561-a044-4e0a-9cd4-c221d4cb1a38,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-48447330-3b90-4c13-850b-b0bb6841d340,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-0ea2783e-4d44-4c50-a923-bec3057d22b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-765e38d0-804c-46fb-9975-c3fdbd693316,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-f1cc2bf5-d8cb-42ac-a22c-b8c8acfe08e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-4b7a6bbb-5d62-470d-a32d-5a2f9971bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-769eeef8-5ca3-4a76-95b7-9347339e267e,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-b35b1518-6524-4b8c-ac0c-4d68f0d6b467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047348964-172.17.0.11-1597038475047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-7b05ab41-3db6-438b-bea3-e516b6a07198,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-d49cead4-5ca8-4bc7-a125-8dd8ca419b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-277ebd59-feb0-4dfd-8e00-460b3e3f40c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-df58bfba-ff6b-4250-b970-ce5a42edf72d,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-da1e0c0d-d9e7-423c-b8ca-5f200643a533,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-334c2f33-1831-42e6-9df9-50520d48a162,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-0dbbe074-42ee-49f7-a5d5-45fb39954476,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-482f4062-b7c5-4ffc-b088-b523bf794dd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047348964-172.17.0.11-1597038475047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-7b05ab41-3db6-438b-bea3-e516b6a07198,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-d49cead4-5ca8-4bc7-a125-8dd8ca419b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-277ebd59-feb0-4dfd-8e00-460b3e3f40c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-df58bfba-ff6b-4250-b970-ce5a42edf72d,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-da1e0c0d-d9e7-423c-b8ca-5f200643a533,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-334c2f33-1831-42e6-9df9-50520d48a162,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-0dbbe074-42ee-49f7-a5d5-45fb39954476,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-482f4062-b7c5-4ffc-b088-b523bf794dd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890181480-172.17.0.11-1597038512311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36874,DS-95bed5cf-4a17-4f40-962a-174e2599ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-a96ba65f-44bf-4b0c-b6c8-092c6b6c7b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-0c75351d-7b1c-42c6-ad9e-829753e29f33,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-900f1754-2520-43f1-ae39-d01a89022237,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-d44ba3a3-e4cb-4f5d-a5eb-09e992840f25,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-351976c7-7778-4424-b51a-fe85c17feeec,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-65c7072c-8607-4b6c-be59-b5897f9a9577,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-2e7c8e40-846c-4f18-af93-e51cb43b9c0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890181480-172.17.0.11-1597038512311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36874,DS-95bed5cf-4a17-4f40-962a-174e2599ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-a96ba65f-44bf-4b0c-b6c8-092c6b6c7b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-0c75351d-7b1c-42c6-ad9e-829753e29f33,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-900f1754-2520-43f1-ae39-d01a89022237,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-d44ba3a3-e4cb-4f5d-a5eb-09e992840f25,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-351976c7-7778-4424-b51a-fe85c17feeec,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-65c7072c-8607-4b6c-be59-b5897f9a9577,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-2e7c8e40-846c-4f18-af93-e51cb43b9c0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258181079-172.17.0.11-1597038936543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-0dc74258-5c92-40f5-ac7e-ae9abf477ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-160cce49-919b-4ba0-a6a7-f452f1e5680f,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-766a2bf0-ccd9-420e-b479-4af2069ffa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-ab3ee6c3-23ee-4cbc-be7b-5cb21ec07779,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-afcff87f-7300-4d77-86ad-5d440bbe11ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-d25d69e4-f402-475d-95b9-5f02950b5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-d90cd4fd-78d0-4eaf-a037-c735a310959a,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-e92445e5-d695-4dc3-9398-bf13589a0b4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258181079-172.17.0.11-1597038936543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-0dc74258-5c92-40f5-ac7e-ae9abf477ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-160cce49-919b-4ba0-a6a7-f452f1e5680f,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-766a2bf0-ccd9-420e-b479-4af2069ffa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-ab3ee6c3-23ee-4cbc-be7b-5cb21ec07779,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-afcff87f-7300-4d77-86ad-5d440bbe11ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-d25d69e4-f402-475d-95b9-5f02950b5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-d90cd4fd-78d0-4eaf-a037-c735a310959a,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-e92445e5-d695-4dc3-9398-bf13589a0b4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117220070-172.17.0.11-1597039326967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41942,DS-43b6c125-1de4-4155-a46f-a59f23abf8af,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-99554ba2-bb1f-4fcf-b8e1-750847ca51e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-ce7e4c5e-0b83-446d-a683-27f05a272288,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-47a27e8a-4362-4a51-8d58-7e395a30f446,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-d3d72f4e-087f-4195-8bc9-eb46d926a7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-c434a832-697e-4be2-a88b-9b1a107cbcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-38b9fca3-f363-4991-836f-6c6a337df446,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-0c9ed2f9-6904-4bea-8c19-db054e65b4fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117220070-172.17.0.11-1597039326967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41942,DS-43b6c125-1de4-4155-a46f-a59f23abf8af,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-99554ba2-bb1f-4fcf-b8e1-750847ca51e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-ce7e4c5e-0b83-446d-a683-27f05a272288,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-47a27e8a-4362-4a51-8d58-7e395a30f446,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-d3d72f4e-087f-4195-8bc9-eb46d926a7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-c434a832-697e-4be2-a88b-9b1a107cbcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-38b9fca3-f363-4991-836f-6c6a337df446,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-0c9ed2f9-6904-4bea-8c19-db054e65b4fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568295549-172.17.0.11-1597039428691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-de235cb4-a822-4ed4-ab5f-54b673683977,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-c91c695d-e032-4819-92c9-139ac7c6bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-a9d85ced-c81d-47d1-96e7-76d81af21ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-9ae378ea-d60e-45fa-a797-17a3890ce708,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-e516c69f-ff9f-49f8-bf80-f72cb20016f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-4e312e96-7765-44f0-b4b7-4ceb0b627441,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-f1b399d8-087c-4236-9cc6-fb984856ecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-dd29fe82-fcc6-48c6-9c24-5d7251fb0ca0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568295549-172.17.0.11-1597039428691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-de235cb4-a822-4ed4-ab5f-54b673683977,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-c91c695d-e032-4819-92c9-139ac7c6bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-a9d85ced-c81d-47d1-96e7-76d81af21ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-9ae378ea-d60e-45fa-a797-17a3890ce708,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-e516c69f-ff9f-49f8-bf80-f72cb20016f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-4e312e96-7765-44f0-b4b7-4ceb0b627441,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-f1b399d8-087c-4236-9cc6-fb984856ecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-dd29fe82-fcc6-48c6-9c24-5d7251fb0ca0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187622725-172.17.0.11-1597039465308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-a2e72cce-336b-415c-969c-e0e20e497886,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-2a5e4952-6084-43d2-9215-b644544762ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-82239952-dd77-402e-9ba8-2f95a369be12,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-0c342cc4-98d9-46b9-aa86-7a573173b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f0e3d8f9-79a6-4105-b4d5-dd9d2a702230,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-2e5ed501-edc2-4901-978a-511afa5f3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-3e2df319-a104-4f0a-a948-3fd157f088fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-0742a3f6-9a4b-4686-aa55-1bff00ed38a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187622725-172.17.0.11-1597039465308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-a2e72cce-336b-415c-969c-e0e20e497886,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-2a5e4952-6084-43d2-9215-b644544762ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-82239952-dd77-402e-9ba8-2f95a369be12,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-0c342cc4-98d9-46b9-aa86-7a573173b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f0e3d8f9-79a6-4105-b4d5-dd9d2a702230,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-2e5ed501-edc2-4901-978a-511afa5f3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-3e2df319-a104-4f0a-a948-3fd157f088fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-0742a3f6-9a4b-4686-aa55-1bff00ed38a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65604694-172.17.0.11-1597039564139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46070,DS-d907941e-c5f2-498a-8a41-4756cf69640a,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-b0d2cc87-b735-484d-8e06-c7f599cb429e,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-d47a8efd-0b73-4881-80b3-8330d8831a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-da3300c2-8a05-4bec-b43c-df07028ad206,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-af08c161-3348-48a4-94b2-0584856db80a,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1dc538fe-16d0-4252-8e96-c51e1c3a7a77,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-c33c139c-6220-4149-943f-ebc488f801c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-b7239bf5-fd33-4134-95ff-06a41d4f9062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65604694-172.17.0.11-1597039564139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46070,DS-d907941e-c5f2-498a-8a41-4756cf69640a,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-b0d2cc87-b735-484d-8e06-c7f599cb429e,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-d47a8efd-0b73-4881-80b3-8330d8831a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-da3300c2-8a05-4bec-b43c-df07028ad206,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-af08c161-3348-48a4-94b2-0584856db80a,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1dc538fe-16d0-4252-8e96-c51e1c3a7a77,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-c33c139c-6220-4149-943f-ebc488f801c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-b7239bf5-fd33-4134-95ff-06a41d4f9062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5993638-172.17.0.11-1597039692676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38099,DS-a58c8eec-02f5-4233-89f9-22389f5cf496,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-5b251c0b-a8c2-4eaa-97d9-f45710a74f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-6b75a5b5-4233-4854-9324-5bc106dfd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-51f940a1-a453-4390-9897-963872f3863a,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-64f10268-cb98-4e57-bd6c-3b61fcd8f572,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-0dff6e8f-86da-4d02-8659-1336524b800e,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-31befb13-f750-41b9-9cde-0acbb380350d,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-06cad1fb-cda3-4cc3-809d-e7ca0192179d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5993638-172.17.0.11-1597039692676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38099,DS-a58c8eec-02f5-4233-89f9-22389f5cf496,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-5b251c0b-a8c2-4eaa-97d9-f45710a74f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-6b75a5b5-4233-4854-9324-5bc106dfd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-51f940a1-a453-4390-9897-963872f3863a,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-64f10268-cb98-4e57-bd6c-3b61fcd8f572,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-0dff6e8f-86da-4d02-8659-1336524b800e,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-31befb13-f750-41b9-9cde-0acbb380350d,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-06cad1fb-cda3-4cc3-809d-e7ca0192179d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69628632-172.17.0.11-1597039771789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-ae10d912-3b29-4bf6-a0bd-93abe404f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-425d12bc-c1c9-4194-838c-857023b6fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-c9f544e7-fb83-48ba-aeb3-1d07d1f9d65e,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-e26d0ca0-604b-4227-b489-8399d0ad6a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-f85825eb-2121-4075-8f50-d543bd1cc62e,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-9662de70-f355-470c-b962-ae3c696d1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-e116f6a0-482b-43a7-92c3-f5fcf1a603ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-932e6c83-5993-44f7-b388-4294c4f1977a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69628632-172.17.0.11-1597039771789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-ae10d912-3b29-4bf6-a0bd-93abe404f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-425d12bc-c1c9-4194-838c-857023b6fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-c9f544e7-fb83-48ba-aeb3-1d07d1f9d65e,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-e26d0ca0-604b-4227-b489-8399d0ad6a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-f85825eb-2121-4075-8f50-d543bd1cc62e,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-9662de70-f355-470c-b962-ae3c696d1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-e116f6a0-482b-43a7-92c3-f5fcf1a603ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-932e6c83-5993-44f7-b388-4294c4f1977a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40548505-172.17.0.11-1597040226494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37193,DS-b657ef8f-4f87-49e2-aaa8-f50653ae4385,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-5ced39d9-4094-414f-830a-354bf79581a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-3874120e-b083-4f96-a223-755b58f492e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-68240108-41d1-4418-9b68-ae42a97d2874,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-85920b97-5ae0-4d5e-b2bb-a22c10e5192b,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-7262d2b9-66fa-4cd9-8f8d-616d64b458b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-67b3569e-1616-494f-9f6b-acd0588698e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-fa616c47-30c8-4a52-a02e-55800b50c268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40548505-172.17.0.11-1597040226494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37193,DS-b657ef8f-4f87-49e2-aaa8-f50653ae4385,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-5ced39d9-4094-414f-830a-354bf79581a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-3874120e-b083-4f96-a223-755b58f492e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-68240108-41d1-4418-9b68-ae42a97d2874,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-85920b97-5ae0-4d5e-b2bb-a22c10e5192b,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-7262d2b9-66fa-4cd9-8f8d-616d64b458b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-67b3569e-1616-494f-9f6b-acd0588698e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-fa616c47-30c8-4a52-a02e-55800b50c268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552093636-172.17.0.11-1597040359141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-c39ec07e-f1c9-4f06-92a7-6101086e0b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-b24fb144-3066-45ac-ada3-50492743b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-b9e0b995-0be7-424e-87fa-9fd689d6df66,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-6fbf3ce3-d390-4afc-8f20-8c7a85f32523,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-c6bdebb9-c649-42c5-9bac-8582bafaa349,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-f133e67a-7a6f-448e-91d5-5ef16f6974b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-62debe04-81a0-4e7f-ae70-c6d6cacb30ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-46b63b74-ae57-4c43-b9cd-e863817b47f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552093636-172.17.0.11-1597040359141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-c39ec07e-f1c9-4f06-92a7-6101086e0b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-b24fb144-3066-45ac-ada3-50492743b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-b9e0b995-0be7-424e-87fa-9fd689d6df66,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-6fbf3ce3-d390-4afc-8f20-8c7a85f32523,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-c6bdebb9-c649-42c5-9bac-8582bafaa349,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-f133e67a-7a6f-448e-91d5-5ef16f6974b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-62debe04-81a0-4e7f-ae70-c6d6cacb30ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-46b63b74-ae57-4c43-b9cd-e863817b47f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551755567-172.17.0.11-1597040450240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43589,DS-601c2779-be2c-4ec4-9e26-2fc9aa6c0578,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-d0d14bf3-1a17-41ca-bcad-f3b20f7edc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-c537b7ac-577d-408c-a155-48d5682a26b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-9855bfb3-df86-405d-81c6-0bb620a38018,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-1b113068-3fba-4ebd-a315-0fd9f6bad6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-64cbfaaf-1b42-4645-9f95-21719a82ccb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-da9c2b56-09f1-464b-ab97-934ca2543ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-5865b209-5981-4ad3-9da5-a7e9683a5c92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551755567-172.17.0.11-1597040450240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43589,DS-601c2779-be2c-4ec4-9e26-2fc9aa6c0578,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-d0d14bf3-1a17-41ca-bcad-f3b20f7edc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-c537b7ac-577d-408c-a155-48d5682a26b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-9855bfb3-df86-405d-81c6-0bb620a38018,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-1b113068-3fba-4ebd-a315-0fd9f6bad6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-64cbfaaf-1b42-4645-9f95-21719a82ccb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-da9c2b56-09f1-464b-ab97-934ca2543ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-5865b209-5981-4ad3-9da5-a7e9683a5c92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314596401-172.17.0.11-1597040482619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-69afdf55-42a7-45e0-af83-740187f0578a,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-ce0affff-9f13-4cc5-92a3-3f0f998d0292,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-676f6428-03bf-4d82-b7e5-dd08c7c6752a,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-181e6252-75a1-49fa-8b90-d6dcfa3a1384,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-df9e793d-8605-4fc1-a04c-d055cfb5219c,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-6f172ba2-b9c0-4513-b4e2-dcaafab71e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-0f93963f-7115-41c5-af8e-c25989d5cd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-0ea7135a-fcce-44ea-9d11-ebd1a6fdec6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314596401-172.17.0.11-1597040482619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-69afdf55-42a7-45e0-af83-740187f0578a,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-ce0affff-9f13-4cc5-92a3-3f0f998d0292,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-676f6428-03bf-4d82-b7e5-dd08c7c6752a,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-181e6252-75a1-49fa-8b90-d6dcfa3a1384,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-df9e793d-8605-4fc1-a04c-d055cfb5219c,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-6f172ba2-b9c0-4513-b4e2-dcaafab71e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-0f93963f-7115-41c5-af8e-c25989d5cd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-0ea7135a-fcce-44ea-9d11-ebd1a6fdec6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139480202-172.17.0.11-1597040545796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43060,DS-8339080c-3293-44c2-beaa-273544aaca69,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-8cb36378-3fdb-4532-9dd6-90da9b3c073c,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-446fc53f-947b-4853-a1bb-efc819f27561,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-280c2f5e-aaab-4c71-b195-207617524547,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-86651391-e8f9-42ca-aca9-305812017d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-8e3fff45-849e-433b-97c6-7539a00d3924,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-d8bfc4e2-4b16-4385-bf70-e56c7b35e944,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-4cc28270-c393-4d7c-b91a-5c8242cfb968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139480202-172.17.0.11-1597040545796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43060,DS-8339080c-3293-44c2-beaa-273544aaca69,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-8cb36378-3fdb-4532-9dd6-90da9b3c073c,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-446fc53f-947b-4853-a1bb-efc819f27561,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-280c2f5e-aaab-4c71-b195-207617524547,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-86651391-e8f9-42ca-aca9-305812017d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-8e3fff45-849e-433b-97c6-7539a00d3924,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-d8bfc4e2-4b16-4385-bf70-e56c7b35e944,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-4cc28270-c393-4d7c-b91a-5c8242cfb968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141055943-172.17.0.11-1597040607912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45044,DS-7be5908c-ac4a-45d1-b321-14717d4e4309,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-d3d12ac4-7331-4540-9f2f-855270d105c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-d8178ebd-7126-4140-af2b-acc228832610,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-097604ec-cf4d-4ce0-ac40-f0903f7daaee,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-5d865837-b8ce-4e8f-af7d-16ae55aeea63,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-2a6ff2db-3586-463b-9136-89fa31dca100,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-92c0844a-2c41-4a13-8690-3a0b62f6dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-f3340f1b-7755-4edc-8639-1b9452ce3517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141055943-172.17.0.11-1597040607912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45044,DS-7be5908c-ac4a-45d1-b321-14717d4e4309,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-d3d12ac4-7331-4540-9f2f-855270d105c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-d8178ebd-7126-4140-af2b-acc228832610,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-097604ec-cf4d-4ce0-ac40-f0903f7daaee,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-5d865837-b8ce-4e8f-af7d-16ae55aeea63,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-2a6ff2db-3586-463b-9136-89fa31dca100,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-92c0844a-2c41-4a13-8690-3a0b62f6dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-f3340f1b-7755-4edc-8639-1b9452ce3517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853365351-172.17.0.11-1597040861261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-41e5e790-e454-42a5-8cdf-bc16510fa540,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-0ae81c77-981e-44d9-9fbd-c9548a1558eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-9301ac3e-e8c0-4e0c-9197-74a8cfc242d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-f194153f-0e61-44fa-b7f0-c62b4c147549,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-3dd4ed5e-043a-46cf-9749-3e32569cff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-ee445bb5-df4a-4878-a4f5-f9d0606800de,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-30d99a35-415c-431b-8a02-efcf01a7ceed,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-cb038de5-4d92-4279-b891-fef92cc60b68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853365351-172.17.0.11-1597040861261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-41e5e790-e454-42a5-8cdf-bc16510fa540,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-0ae81c77-981e-44d9-9fbd-c9548a1558eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-9301ac3e-e8c0-4e0c-9197-74a8cfc242d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-f194153f-0e61-44fa-b7f0-c62b4c147549,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-3dd4ed5e-043a-46cf-9749-3e32569cff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-ee445bb5-df4a-4878-a4f5-f9d0606800de,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-30d99a35-415c-431b-8a02-efcf01a7ceed,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-cb038de5-4d92-4279-b891-fef92cc60b68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516783179-172.17.0.11-1597041260550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46372,DS-12ee7814-d37f-4ef3-8264-22add4645728,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-cb598eae-1cf4-4e40-b3ad-0106c06cd42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-7bc5e5a5-2681-4a80-98f3-18fa4e139acc,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-59a83ae2-3c71-407f-87bd-57980042bb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-a4c21ddb-2f13-4e78-a395-99b78db0ee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-da5c5596-c8e1-4155-a34e-c4493cd520f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-da2e52d8-5a4a-4630-a394-840d576ee920,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-7f62a894-190b-401b-a2fa-66359591328d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516783179-172.17.0.11-1597041260550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46372,DS-12ee7814-d37f-4ef3-8264-22add4645728,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-cb598eae-1cf4-4e40-b3ad-0106c06cd42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-7bc5e5a5-2681-4a80-98f3-18fa4e139acc,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-59a83ae2-3c71-407f-87bd-57980042bb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-a4c21ddb-2f13-4e78-a395-99b78db0ee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-da5c5596-c8e1-4155-a34e-c4493cd520f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-da2e52d8-5a4a-4630-a394-840d576ee920,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-7f62a894-190b-401b-a2fa-66359591328d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915538252-172.17.0.11-1597041485766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45523,DS-91c0b573-190e-4e2e-a958-9bd0be0eae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-472a1ca5-df83-4c82-9d67-29c832851640,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-7936ea2d-ffd6-4f8b-9ef0-50a634c2d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-36736d40-e212-4c9c-a759-3fb375201371,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-b9808811-20e2-4148-9437-79e795608120,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-a3e95373-0caa-4345-9d9b-4fc45e05c355,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-798b5516-b4e2-4bf8-b92c-073b4766769c,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-33da033f-56dc-4183-b51d-ce428996c0c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915538252-172.17.0.11-1597041485766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45523,DS-91c0b573-190e-4e2e-a958-9bd0be0eae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-472a1ca5-df83-4c82-9d67-29c832851640,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-7936ea2d-ffd6-4f8b-9ef0-50a634c2d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-36736d40-e212-4c9c-a759-3fb375201371,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-b9808811-20e2-4148-9437-79e795608120,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-a3e95373-0caa-4345-9d9b-4fc45e05c355,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-798b5516-b4e2-4bf8-b92c-073b4766769c,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-33da033f-56dc-4183-b51d-ce428996c0c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135988476-172.17.0.11-1597042070920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-2e37d8bf-1713-47b9-b2ba-8b5aad8541c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-eb9bdf8d-6a8b-4923-bedb-d3a941aebbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-45d07fff-f043-4fe1-9058-2b842ff8aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-c819cb47-1b34-4b8e-9c34-faf7bf45dcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-06c99cbb-d509-4d71-8b75-6b68e4f7db90,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-f4474622-c6e6-4ce4-a7fd-dec1f104832e,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-317220fa-fd11-42ab-92f2-ab30c413565f,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-8800d425-555b-40cc-bd1d-e99d7a462252,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135988476-172.17.0.11-1597042070920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-2e37d8bf-1713-47b9-b2ba-8b5aad8541c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-eb9bdf8d-6a8b-4923-bedb-d3a941aebbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-45d07fff-f043-4fe1-9058-2b842ff8aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-c819cb47-1b34-4b8e-9c34-faf7bf45dcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-06c99cbb-d509-4d71-8b75-6b68e4f7db90,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-f4474622-c6e6-4ce4-a7fd-dec1f104832e,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-317220fa-fd11-42ab-92f2-ab30c413565f,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-8800d425-555b-40cc-bd1d-e99d7a462252,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284095564-172.17.0.11-1597042185802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35854,DS-bfbdaf49-ef66-4ac5-bdde-213c47ba4141,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-a5250891-f1a4-47a3-880e-83b96eaeb9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-31d9f06c-b414-44d2-b468-bf89d991bbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-010299f3-ce8f-43cc-9f73-eaf515d5e6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-38d3c155-a20b-4a9e-a9f9-35b4d2634f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-0bec09e3-c780-4763-976f-a80cb082d225,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-bee86ce9-c66b-4261-b4b2-3bec7c5a03c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-531227ee-6983-4331-a491-134845e45d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284095564-172.17.0.11-1597042185802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35854,DS-bfbdaf49-ef66-4ac5-bdde-213c47ba4141,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-a5250891-f1a4-47a3-880e-83b96eaeb9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-31d9f06c-b414-44d2-b468-bf89d991bbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-010299f3-ce8f-43cc-9f73-eaf515d5e6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-38d3c155-a20b-4a9e-a9f9-35b4d2634f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-0bec09e3-c780-4763-976f-a80cb082d225,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-bee86ce9-c66b-4261-b4b2-3bec7c5a03c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-531227ee-6983-4331-a491-134845e45d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213936086-172.17.0.11-1597042569846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40613,DS-b50a1be1-d57f-4b15-8ad3-ea6c809a0027,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-b0bd333c-c5a1-4a8e-b113-2f9dd4fa1b36,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-877f7d17-b75a-45af-9a24-14176c395a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-08b23bf5-44e1-46c7-a3f5-4d48f21606d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-9605ce2c-aa16-442e-a9a3-6588be3621f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-333c9c0d-075c-46a8-a3b2-5852dd3defe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-9dcd1cbe-c1f9-4188-bd5b-10733995318b,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-7b61afe8-0c06-462d-94e3-104fae714d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213936086-172.17.0.11-1597042569846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40613,DS-b50a1be1-d57f-4b15-8ad3-ea6c809a0027,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-b0bd333c-c5a1-4a8e-b113-2f9dd4fa1b36,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-877f7d17-b75a-45af-9a24-14176c395a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-08b23bf5-44e1-46c7-a3f5-4d48f21606d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-9605ce2c-aa16-442e-a9a3-6588be3621f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-333c9c0d-075c-46a8-a3b2-5852dd3defe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-9dcd1cbe-c1f9-4188-bd5b-10733995318b,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-7b61afe8-0c06-462d-94e3-104fae714d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713625237-172.17.0.11-1597042753168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-bfbd2a03-5ba9-4102-96b3-b0371e1a2475,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-49488285-b4f8-47f1-93b8-c3d8a751fc20,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-27501ef9-adae-4cc8-823b-8ee56835a4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-e288dbae-eb15-4978-aa5c-7645f85caa89,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-b154467a-1146-41fa-b828-73bfaa1c0d18,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-21e0fa3b-c1cd-486c-913e-f9a9d8182fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-ba07cd68-4ace-4ed2-87cb-fb7bc2de74ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-524e3ebb-97b7-460c-8be2-02e5659af335,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713625237-172.17.0.11-1597042753168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-bfbd2a03-5ba9-4102-96b3-b0371e1a2475,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-49488285-b4f8-47f1-93b8-c3d8a751fc20,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-27501ef9-adae-4cc8-823b-8ee56835a4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-e288dbae-eb15-4978-aa5c-7645f85caa89,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-b154467a-1146-41fa-b828-73bfaa1c0d18,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-21e0fa3b-c1cd-486c-913e-f9a9d8182fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-ba07cd68-4ace-4ed2-87cb-fb7bc2de74ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-524e3ebb-97b7-460c-8be2-02e5659af335,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466807256-172.17.0.11-1597042963152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39112,DS-51c4070b-56cf-461c-888e-41b74b262d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-7fe4b095-23cf-447e-bf90-7ea7dead1bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-01a6297b-fe8a-4f9b-b4f3-6bbc82a385df,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-fdad141a-adad-4e3c-9cd5-19c7d22f749f,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-f4f8e95f-fc8e-4238-8634-5a2e7aadc798,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-56b95022-8a4d-4a86-9e88-ae8eafa6aa7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-48b5c175-ecdb-4b12-a1fe-02e0abdecf45,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-f5f3a957-5913-46c6-8ca9-b9d912cb21e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466807256-172.17.0.11-1597042963152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39112,DS-51c4070b-56cf-461c-888e-41b74b262d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-7fe4b095-23cf-447e-bf90-7ea7dead1bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-01a6297b-fe8a-4f9b-b4f3-6bbc82a385df,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-fdad141a-adad-4e3c-9cd5-19c7d22f749f,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-f4f8e95f-fc8e-4238-8634-5a2e7aadc798,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-56b95022-8a4d-4a86-9e88-ae8eafa6aa7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-48b5c175-ecdb-4b12-a1fe-02e0abdecf45,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-f5f3a957-5913-46c6-8ca9-b9d912cb21e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017265531-172.17.0.11-1597043098323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37146,DS-7a3a5049-f35a-4920-8e97-c611e51737d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-62aa01eb-21c2-4f54-9ce3-262b96675106,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-db216021-1cc9-43f3-a709-6738a0890376,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-cd4eb015-8c18-4a9c-bab2-54ba31d8b083,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-5a5593fe-960c-4f02-bd24-d8e6355236e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-85a2be5a-fb16-4592-aff2-b0becf7f783a,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-c38b3e1b-da8a-4045-8086-b64f32e3e0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-958e83fb-bc04-4189-85ce-554d5d992828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017265531-172.17.0.11-1597043098323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37146,DS-7a3a5049-f35a-4920-8e97-c611e51737d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-62aa01eb-21c2-4f54-9ce3-262b96675106,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-db216021-1cc9-43f3-a709-6738a0890376,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-cd4eb015-8c18-4a9c-bab2-54ba31d8b083,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-5a5593fe-960c-4f02-bd24-d8e6355236e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-85a2be5a-fb16-4592-aff2-b0becf7f783a,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-c38b3e1b-da8a-4045-8086-b64f32e3e0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-958e83fb-bc04-4189-85ce-554d5d992828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016540587-172.17.0.11-1597043407394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34793,DS-3334105e-8c17-46ac-b08b-d5ade46bfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-8d7c2fbf-ed84-48b5-b58d-c226bc56c46e,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-49f45109-fe18-4aa6-a07d-054b5e334fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-771652d8-c73d-45f4-9249-0860bd81cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-4ca64100-e6d1-44fb-9c82-f3b2d7500201,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-dc53f639-0eb3-46c8-9008-d606a71f64dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-28d41bfc-eacd-4b0e-b117-d766abe8f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-f0cbe38c-93cf-42bb-81ba-394f782a981b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016540587-172.17.0.11-1597043407394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34793,DS-3334105e-8c17-46ac-b08b-d5ade46bfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-8d7c2fbf-ed84-48b5-b58d-c226bc56c46e,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-49f45109-fe18-4aa6-a07d-054b5e334fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-771652d8-c73d-45f4-9249-0860bd81cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-4ca64100-e6d1-44fb-9c82-f3b2d7500201,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-dc53f639-0eb3-46c8-9008-d606a71f64dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-28d41bfc-eacd-4b0e-b117-d766abe8f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-f0cbe38c-93cf-42bb-81ba-394f782a981b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5352
