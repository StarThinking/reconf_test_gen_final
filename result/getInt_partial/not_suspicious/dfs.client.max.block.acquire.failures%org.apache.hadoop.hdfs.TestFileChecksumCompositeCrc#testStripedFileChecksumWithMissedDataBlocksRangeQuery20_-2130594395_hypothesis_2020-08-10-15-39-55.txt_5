reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550000028-172.17.0.11-1597074113392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-98fc7493-58f0-46fb-9408-98b56aa28a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-559a0e4d-9f51-4454-842c-b32d814f8d96,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-60f0be0e-43c8-4d94-adee-afeb989397d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-4710d48d-a336-4248-8a05-5163f021e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-a73940aa-c28a-4cd4-9be4-3e0d20142fba,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-5f6b9a7e-f991-42b0-b3a5-0513f16cd9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-ae57f894-a25d-424e-a023-feff17d2c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-d106aa62-527f-46a5-aa4b-d486ed9add70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550000028-172.17.0.11-1597074113392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-98fc7493-58f0-46fb-9408-98b56aa28a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-559a0e4d-9f51-4454-842c-b32d814f8d96,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-60f0be0e-43c8-4d94-adee-afeb989397d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-4710d48d-a336-4248-8a05-5163f021e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-a73940aa-c28a-4cd4-9be4-3e0d20142fba,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-5f6b9a7e-f991-42b0-b3a5-0513f16cd9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-ae57f894-a25d-424e-a023-feff17d2c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-d106aa62-527f-46a5-aa4b-d486ed9add70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125903240-172.17.0.11-1597074519856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34775,DS-48bdba76-e03c-413e-a3cf-5c73b06fa58e,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-75f232e8-19f3-450e-b84b-41d52c8e9681,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-5e364348-646e-4d4c-9fd8-3edf266bf441,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-d9271a3e-f051-492b-872c-03edc51990e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-0535e5d2-bd54-475f-96b1-4579d9e6eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-6aaf6223-598a-4a48-b26e-780bb18ebf90,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-35256728-05da-4a79-a6fe-7df6e355fb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-1f30e1ab-458f-415e-9d6a-730ee07eb95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125903240-172.17.0.11-1597074519856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34775,DS-48bdba76-e03c-413e-a3cf-5c73b06fa58e,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-75f232e8-19f3-450e-b84b-41d52c8e9681,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-5e364348-646e-4d4c-9fd8-3edf266bf441,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-d9271a3e-f051-492b-872c-03edc51990e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-0535e5d2-bd54-475f-96b1-4579d9e6eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-6aaf6223-598a-4a48-b26e-780bb18ebf90,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-35256728-05da-4a79-a6fe-7df6e355fb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-1f30e1ab-458f-415e-9d6a-730ee07eb95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332466837-172.17.0.11-1597074932778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-dedda2e7-0b1a-4e93-970c-4c8d674a7b00,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-0d8928cc-02bf-439c-96fd-bb61e5b61735,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-8b401577-012a-4b4d-9155-f0db6fed3dae,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-25ac6ba7-45cb-420a-ada3-0fdf1889cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-c5653313-d03f-46eb-ba43-cf3da7f10be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-fd907e14-8818-4ba3-a28d-c10152004d68,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-1cb689ed-3169-4451-b267-0c22110e1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-e971de45-7a1c-490c-a5c8-740294f07475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332466837-172.17.0.11-1597074932778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-dedda2e7-0b1a-4e93-970c-4c8d674a7b00,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-0d8928cc-02bf-439c-96fd-bb61e5b61735,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-8b401577-012a-4b4d-9155-f0db6fed3dae,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-25ac6ba7-45cb-420a-ada3-0fdf1889cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-c5653313-d03f-46eb-ba43-cf3da7f10be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-fd907e14-8818-4ba3-a28d-c10152004d68,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-1cb689ed-3169-4451-b267-0c22110e1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-e971de45-7a1c-490c-a5c8-740294f07475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880629898-172.17.0.11-1597075254548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33486,DS-eba9182d-63e7-4820-8cd4-129d87434acd,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-53fc5c74-96d6-4d4e-9600-323ad337acf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-2bf95ef5-37db-41b3-907f-d0d6844cbc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-34dd2744-1197-46a0-a639-598ebf98e896,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-308844c1-158a-47a3-aa46-5ff857b11831,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-00380f09-67a7-4d5f-825c-725e1dd47911,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-8c615d34-c167-4bbc-a4f5-2f33294f25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-17a686ac-5675-4e6a-b42b-4256bf3b191a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880629898-172.17.0.11-1597075254548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33486,DS-eba9182d-63e7-4820-8cd4-129d87434acd,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-53fc5c74-96d6-4d4e-9600-323ad337acf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-2bf95ef5-37db-41b3-907f-d0d6844cbc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-34dd2744-1197-46a0-a639-598ebf98e896,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-308844c1-158a-47a3-aa46-5ff857b11831,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-00380f09-67a7-4d5f-825c-725e1dd47911,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-8c615d34-c167-4bbc-a4f5-2f33294f25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-17a686ac-5675-4e6a-b42b-4256bf3b191a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600088955-172.17.0.11-1597077228188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-5f8b8fd2-5c1b-4f2f-ab2e-2feb5e921ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-ab6c5ddf-7091-4eac-9c87-9c7c082a0dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-93b12194-8ae5-4803-aba1-5b36eb3a877c,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-6910b61c-29fb-4caf-a12a-780cbb73bf08,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-3a4f96a8-5e1c-45b7-86b9-5bacf094c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-15f00991-ac53-43fa-9f12-8095d2330353,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-27102979-6df1-40fc-ba27-60cbdcdb5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-43d6ced4-3d2d-4441-8810-27e924cb757c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600088955-172.17.0.11-1597077228188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-5f8b8fd2-5c1b-4f2f-ab2e-2feb5e921ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-ab6c5ddf-7091-4eac-9c87-9c7c082a0dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-93b12194-8ae5-4803-aba1-5b36eb3a877c,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-6910b61c-29fb-4caf-a12a-780cbb73bf08,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-3a4f96a8-5e1c-45b7-86b9-5bacf094c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-15f00991-ac53-43fa-9f12-8095d2330353,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-27102979-6df1-40fc-ba27-60cbdcdb5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-43d6ced4-3d2d-4441-8810-27e924cb757c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152499011-172.17.0.11-1597077414761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43968,DS-348bcb85-251b-47af-b53c-8ab1d7a7caf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-db886934-d0b7-488a-9dbb-1bca509ae1af,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-8f43d3e6-c605-44b8-8ada-dc2e572ad3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-c45e314d-6ebc-4960-b38e-12132b0f81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-8fba668c-82c9-4797-b909-da95d7496206,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-212b4192-d3a8-4bbb-8a6a-29cfb2dc5301,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-4532151e-ae3c-42bf-a973-1336f6d529c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-6785668f-73d6-4cc1-8b20-866e339251d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152499011-172.17.0.11-1597077414761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43968,DS-348bcb85-251b-47af-b53c-8ab1d7a7caf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-db886934-d0b7-488a-9dbb-1bca509ae1af,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-8f43d3e6-c605-44b8-8ada-dc2e572ad3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-c45e314d-6ebc-4960-b38e-12132b0f81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-8fba668c-82c9-4797-b909-da95d7496206,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-212b4192-d3a8-4bbb-8a6a-29cfb2dc5301,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-4532151e-ae3c-42bf-a973-1336f6d529c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-6785668f-73d6-4cc1-8b20-866e339251d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-481614098-172.17.0.11-1597077603551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45100,DS-8024f8c3-7c4b-4f12-9862-694f5bdf634d,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-0f2c77f9-6975-404e-9771-259979382fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-e6fa0053-8373-40b4-b07c-19dc1f3b130c,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-c9358a40-375d-4cf8-8a50-44eafc2215b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-13067685-7de8-4b54-bcec-de18dcb44989,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-bfa1e9b1-af1c-4d07-b272-431d9dd9463d,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-e7b1b258-939e-47ae-a58c-3cbfa1d4c478,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-6a5ee74e-c2a9-4a9f-80b5-69fa3a49662a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-481614098-172.17.0.11-1597077603551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45100,DS-8024f8c3-7c4b-4f12-9862-694f5bdf634d,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-0f2c77f9-6975-404e-9771-259979382fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-e6fa0053-8373-40b4-b07c-19dc1f3b130c,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-c9358a40-375d-4cf8-8a50-44eafc2215b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-13067685-7de8-4b54-bcec-de18dcb44989,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-bfa1e9b1-af1c-4d07-b272-431d9dd9463d,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-e7b1b258-939e-47ae-a58c-3cbfa1d4c478,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-6a5ee74e-c2a9-4a9f-80b5-69fa3a49662a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704293735-172.17.0.11-1597077963177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-b77c8521-8ea5-4cc2-951a-257eed1e2094,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-57e31e40-0d69-4bd0-80d7-93ff925480cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-03d6167a-0ad4-4bc3-a3c1-9400f4af92a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-7cecc6b1-3aaa-4fb9-b233-51e86091698a,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-5ec8e952-05e5-46d1-8d4e-d6eba6c94bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-0ace6f42-b2de-4c98-8423-fe79f6e4efac,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-b8080063-e4df-48ce-b84a-43f441c630ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-48ee86b8-17bc-4b6f-a124-507786334f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704293735-172.17.0.11-1597077963177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-b77c8521-8ea5-4cc2-951a-257eed1e2094,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-57e31e40-0d69-4bd0-80d7-93ff925480cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-03d6167a-0ad4-4bc3-a3c1-9400f4af92a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-7cecc6b1-3aaa-4fb9-b233-51e86091698a,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-5ec8e952-05e5-46d1-8d4e-d6eba6c94bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-0ace6f42-b2de-4c98-8423-fe79f6e4efac,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-b8080063-e4df-48ce-b84a-43f441c630ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-48ee86b8-17bc-4b6f-a124-507786334f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757414056-172.17.0.11-1597078471708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40148,DS-9bd013fd-0f7a-459f-b795-ca14f3c53bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-03a90f98-3092-4a16-845e-d2eb3bfbe837,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-29cda750-8357-4b22-b56b-b5107c147948,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-41026e69-fcfe-4c5e-adbc-b2a897300dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-5161dc16-e795-44f4-b127-7229b9079c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-25f266ee-e91a-437b-a197-f00047d28477,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-44a8ab72-4225-44bf-b99a-c65a889c7d82,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-12d44e0d-4e01-4233-8c79-1aad143695cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757414056-172.17.0.11-1597078471708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40148,DS-9bd013fd-0f7a-459f-b795-ca14f3c53bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-03a90f98-3092-4a16-845e-d2eb3bfbe837,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-29cda750-8357-4b22-b56b-b5107c147948,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-41026e69-fcfe-4c5e-adbc-b2a897300dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-5161dc16-e795-44f4-b127-7229b9079c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-25f266ee-e91a-437b-a197-f00047d28477,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-44a8ab72-4225-44bf-b99a-c65a889c7d82,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-12d44e0d-4e01-4233-8c79-1aad143695cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214580370-172.17.0.11-1597078525422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-fba0dcdc-e338-4849-ada2-50e26b83ca85,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-5381ceef-4d6d-4bf4-9f4b-f69538c241e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-e37cedd1-163c-4d5a-9cc6-aae1ee6d0714,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-d399be05-6655-4f40-befc-ed3f066ce0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-cc768e8f-5ebb-4a57-8acd-fd48379c4db2,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-e4000718-159c-4c98-b576-be15cf31b160,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-a2c5277c-9860-4511-b56b-539cd4c939e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-6eeff02f-f93a-44f1-8c7a-e3f49a8fc6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214580370-172.17.0.11-1597078525422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-fba0dcdc-e338-4849-ada2-50e26b83ca85,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-5381ceef-4d6d-4bf4-9f4b-f69538c241e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-e37cedd1-163c-4d5a-9cc6-aae1ee6d0714,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-d399be05-6655-4f40-befc-ed3f066ce0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-cc768e8f-5ebb-4a57-8acd-fd48379c4db2,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-e4000718-159c-4c98-b576-be15cf31b160,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-a2c5277c-9860-4511-b56b-539cd4c939e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-6eeff02f-f93a-44f1-8c7a-e3f49a8fc6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960686391-172.17.0.11-1597079505839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-736e0940-cc69-4bd2-b387-7faa3feee283,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-6454d3fe-d95c-413b-87ae-e56d8a0b93d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-3086aee5-759c-41fb-95f9-b5cd4448cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-aafc59d5-b8f6-43fa-b409-ff37bbf77d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-19f882dd-8a70-4231-9648-af2f15825629,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-7f39bb43-4491-4229-823b-ec9a54b5344e,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-d321fd62-bd46-406e-aedc-617f106396a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d7db4bfc-9150-434d-91d5-baddf63726f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960686391-172.17.0.11-1597079505839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-736e0940-cc69-4bd2-b387-7faa3feee283,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-6454d3fe-d95c-413b-87ae-e56d8a0b93d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-3086aee5-759c-41fb-95f9-b5cd4448cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-aafc59d5-b8f6-43fa-b409-ff37bbf77d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-19f882dd-8a70-4231-9648-af2f15825629,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-7f39bb43-4491-4229-823b-ec9a54b5344e,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-d321fd62-bd46-406e-aedc-617f106396a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d7db4bfc-9150-434d-91d5-baddf63726f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-407945564-172.17.0.11-1597080181659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-2578bde0-e802-45e4-ba9e-b4b955ad5054,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-3c5d224e-bf99-4de3-8423-cd0130493641,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-9d4a9ab9-dfd6-43aa-86a7-fa503b55cb27,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-00ab84c0-dfc4-42d4-a748-1d52a6c47652,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-746d37b9-9bd6-42a7-a8d6-435586e1ceea,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-a984b522-c66f-4d22-8e4f-e513ff0701af,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-ad579d3d-cdf9-4200-8917-44a49dcf3cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-5768c188-d75b-414d-8223-5aedebe35a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-407945564-172.17.0.11-1597080181659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-2578bde0-e802-45e4-ba9e-b4b955ad5054,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-3c5d224e-bf99-4de3-8423-cd0130493641,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-9d4a9ab9-dfd6-43aa-86a7-fa503b55cb27,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-00ab84c0-dfc4-42d4-a748-1d52a6c47652,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-746d37b9-9bd6-42a7-a8d6-435586e1ceea,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-a984b522-c66f-4d22-8e4f-e513ff0701af,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-ad579d3d-cdf9-4200-8917-44a49dcf3cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-5768c188-d75b-414d-8223-5aedebe35a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563893855-172.17.0.11-1597080647365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-a8aaf028-510c-4ee3-8e0a-62f78d7e8877,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-2795cca1-6df8-4e75-8b4c-1ad356ddd592,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-de1b2b04-5aae-437f-a402-4314bd896c11,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-90fa717b-6892-47d4-b5b0-643f9234ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-22044818-817f-44e2-a91f-58dae1bbe63d,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-bf74aba1-d910-4369-9c7b-f4e398c5f2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-16bce63c-5ff3-4939-bc98-d640de0fb9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-bb131a3a-4731-4525-b6cc-fce7d34a57b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563893855-172.17.0.11-1597080647365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-a8aaf028-510c-4ee3-8e0a-62f78d7e8877,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-2795cca1-6df8-4e75-8b4c-1ad356ddd592,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-de1b2b04-5aae-437f-a402-4314bd896c11,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-90fa717b-6892-47d4-b5b0-643f9234ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-22044818-817f-44e2-a91f-58dae1bbe63d,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-bf74aba1-d910-4369-9c7b-f4e398c5f2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-16bce63c-5ff3-4939-bc98-d640de0fb9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-bb131a3a-4731-4525-b6cc-fce7d34a57b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864896544-172.17.0.11-1597080734430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45702,DS-43e37774-af6b-4d5a-8a29-fbc2a259db3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-dde947ff-128b-4e37-a91c-f7c55f463bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-2e6b70c0-1364-41a3-a5fb-779addc0a13c,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-b80eceb1-975e-4c68-b3e6-34cf597c83c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-34683c2d-a61e-41c2-9041-8303c59c1991,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-6a9feeab-e19d-49d4-849a-53d5a56ee782,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-ea33d889-c886-4aac-95cc-780550493f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-d3b76158-7f6c-4a53-84f6-744250d21c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864896544-172.17.0.11-1597080734430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45702,DS-43e37774-af6b-4d5a-8a29-fbc2a259db3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-dde947ff-128b-4e37-a91c-f7c55f463bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-2e6b70c0-1364-41a3-a5fb-779addc0a13c,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-b80eceb1-975e-4c68-b3e6-34cf597c83c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-34683c2d-a61e-41c2-9041-8303c59c1991,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-6a9feeab-e19d-49d4-849a-53d5a56ee782,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-ea33d889-c886-4aac-95cc-780550493f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-d3b76158-7f6c-4a53-84f6-744250d21c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470553262-172.17.0.11-1597080874480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-c4d9241a-222f-49c7-b332-bb085c93e167,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-8ae62bc3-31ed-41ae-969e-0469807b0f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-8935b5d6-27bf-4e83-8a85-7fce8070cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-2f11edeb-c4cd-4421-9064-4a31cbde65ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-1ed3fb39-0998-4e55-8781-b2255a6ece43,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-84a32ceb-7231-4583-af68-19994b2200c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-4dc9ec54-855e-4df1-9051-9a96bf2833dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-f1f7049a-2e09-40d3-8542-a350aa12752c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470553262-172.17.0.11-1597080874480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-c4d9241a-222f-49c7-b332-bb085c93e167,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-8ae62bc3-31ed-41ae-969e-0469807b0f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-8935b5d6-27bf-4e83-8a85-7fce8070cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-2f11edeb-c4cd-4421-9064-4a31cbde65ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-1ed3fb39-0998-4e55-8781-b2255a6ece43,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-84a32ceb-7231-4583-af68-19994b2200c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-4dc9ec54-855e-4df1-9051-9a96bf2833dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-f1f7049a-2e09-40d3-8542-a350aa12752c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7034
