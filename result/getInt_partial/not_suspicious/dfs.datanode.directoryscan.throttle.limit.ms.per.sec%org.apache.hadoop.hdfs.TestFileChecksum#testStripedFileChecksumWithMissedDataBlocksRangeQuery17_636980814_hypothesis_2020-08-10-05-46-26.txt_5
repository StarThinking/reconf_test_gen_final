reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603016451-172.17.0.11-1597038474038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-120cd814-404d-49a9-b747-e6c818afdfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-2ae3c282-5307-45e7-a517-a99fc4e8f249,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-c2d86db6-efdd-4d47-9c9f-0e4227176dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-24774b86-76f4-4dea-b768-f6f258eb517b,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-25d7f37b-4a52-42d8-9f1c-5a4d671af9af,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-1ff1bb6a-aa4e-40ef-b2db-f188a22bd63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-bca9ba78-d782-4290-aee6-22d6dc609ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-543d7825-3df0-4620-a68e-c5b7c0260a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603016451-172.17.0.11-1597038474038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-120cd814-404d-49a9-b747-e6c818afdfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-2ae3c282-5307-45e7-a517-a99fc4e8f249,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-c2d86db6-efdd-4d47-9c9f-0e4227176dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-24774b86-76f4-4dea-b768-f6f258eb517b,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-25d7f37b-4a52-42d8-9f1c-5a4d671af9af,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-1ff1bb6a-aa4e-40ef-b2db-f188a22bd63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-bca9ba78-d782-4290-aee6-22d6dc609ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-543d7825-3df0-4620-a68e-c5b7c0260a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167053048-172.17.0.11-1597038811634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-a4a6d6c5-84f1-4a21-8775-abcb6fb9c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-e4e5331a-36cb-4037-b38e-247cba0fe100,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-1de873ca-110e-497d-ac7d-c6043ac168a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-1526995f-59dd-4fd7-a177-4789f9d55ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-5bbb8ce8-cfa1-4d07-8712-62908c82c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-fdeaa518-fae2-4c7a-b2c1-e6014268c196,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-b62c1892-4b92-49c0-9d49-3ae285bd3d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-eb7bf6aa-f938-483c-b801-3d8f0887684f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167053048-172.17.0.11-1597038811634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-a4a6d6c5-84f1-4a21-8775-abcb6fb9c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-e4e5331a-36cb-4037-b38e-247cba0fe100,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-1de873ca-110e-497d-ac7d-c6043ac168a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-1526995f-59dd-4fd7-a177-4789f9d55ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-5bbb8ce8-cfa1-4d07-8712-62908c82c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-fdeaa518-fae2-4c7a-b2c1-e6014268c196,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-b62c1892-4b92-49c0-9d49-3ae285bd3d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-eb7bf6aa-f938-483c-b801-3d8f0887684f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544152922-172.17.0.11-1597039000843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43109,DS-b8714d83-9dc3-4309-89b3-ecee54ea2516,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-45843f27-4e97-4027-88ba-3d04e1a8943e,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-88181130-630f-4720-acb0-b0181f4aa230,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-24e8d943-4d59-472e-b70f-09d597da3b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-995c493b-69e2-4501-88af-186dd60d27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-527e8a7c-81ef-48c0-8e3c-d55dcd28596b,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-f097917f-177e-4383-b926-d08b840f39cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-233bbf4b-5e57-432a-8ab9-e274173dae92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544152922-172.17.0.11-1597039000843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43109,DS-b8714d83-9dc3-4309-89b3-ecee54ea2516,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-45843f27-4e97-4027-88ba-3d04e1a8943e,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-88181130-630f-4720-acb0-b0181f4aa230,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-24e8d943-4d59-472e-b70f-09d597da3b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-995c493b-69e2-4501-88af-186dd60d27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-527e8a7c-81ef-48c0-8e3c-d55dcd28596b,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-f097917f-177e-4383-b926-d08b840f39cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-233bbf4b-5e57-432a-8ab9-e274173dae92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577235333-172.17.0.11-1597039360853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44808,DS-c168a96f-c5f5-4cf9-8b3b-0e429de63821,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-4db6dfb9-67b5-408f-aaad-f3f1e8de8434,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-217266cf-ac3f-4e70-b9b5-5c7c069047d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-45665d6d-ad49-4b81-a461-159b95933dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-271b03a0-82b4-4b2d-bd2b-1479062d2bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-f82909de-741b-4402-ae85-61964ad89755,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-0c2bb4d6-8b33-49b0-9ac1-d71691c83f41,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-8c971ad8-fb5a-4401-8508-20f08adec056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577235333-172.17.0.11-1597039360853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44808,DS-c168a96f-c5f5-4cf9-8b3b-0e429de63821,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-4db6dfb9-67b5-408f-aaad-f3f1e8de8434,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-217266cf-ac3f-4e70-b9b5-5c7c069047d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-45665d6d-ad49-4b81-a461-159b95933dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-271b03a0-82b4-4b2d-bd2b-1479062d2bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-f82909de-741b-4402-ae85-61964ad89755,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-0c2bb4d6-8b33-49b0-9ac1-d71691c83f41,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-8c971ad8-fb5a-4401-8508-20f08adec056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716444247-172.17.0.11-1597039540475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-fc5e030c-a58e-4134-9d1c-7f4c2a9d0e75,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-1bb4b446-5893-41fc-9906-350937c7df43,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-37bd4ca1-404a-4ceb-932d-9c7ae443ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-fcaa0553-200b-412c-b2f1-426bb2a15639,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-14e25a99-ea3f-4192-a7fe-4b3553195454,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-7758322e-5b85-43f9-820d-ba4e906a9c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-ed12c220-e640-41bc-98d3-6f5d5fb65e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-abc70e02-8742-4189-98fd-2d9e054ac9c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716444247-172.17.0.11-1597039540475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-fc5e030c-a58e-4134-9d1c-7f4c2a9d0e75,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-1bb4b446-5893-41fc-9906-350937c7df43,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-37bd4ca1-404a-4ceb-932d-9c7ae443ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-fcaa0553-200b-412c-b2f1-426bb2a15639,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-14e25a99-ea3f-4192-a7fe-4b3553195454,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-7758322e-5b85-43f9-820d-ba4e906a9c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-ed12c220-e640-41bc-98d3-6f5d5fb65e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-abc70e02-8742-4189-98fd-2d9e054ac9c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368670441-172.17.0.11-1597039745583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-66a4332c-0414-4d9b-8eaa-e2574f7c3255,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-30932da3-1c6d-41ae-90a8-999742602ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-64b286b8-020e-4743-b1f5-96c60bb99d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-deef5548-04fd-463b-99aa-1d905d04d366,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-6d00f9b2-51f8-4b76-bc72-187556d403eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-4db4e9cd-62ab-48b0-9099-5a191e611287,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-a3db4552-3da5-4887-8f83-56b934ebc91d,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-2d67e47b-7f2a-4012-a0be-8f7e3cc324b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368670441-172.17.0.11-1597039745583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-66a4332c-0414-4d9b-8eaa-e2574f7c3255,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-30932da3-1c6d-41ae-90a8-999742602ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-64b286b8-020e-4743-b1f5-96c60bb99d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-deef5548-04fd-463b-99aa-1d905d04d366,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-6d00f9b2-51f8-4b76-bc72-187556d403eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-4db4e9cd-62ab-48b0-9099-5a191e611287,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-a3db4552-3da5-4887-8f83-56b934ebc91d,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-2d67e47b-7f2a-4012-a0be-8f7e3cc324b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567131960-172.17.0.11-1597040916742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33789,DS-572d40d2-b20e-4e65-808a-fd120d9abec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-e8cb33d1-90da-41ba-8d04-dd666affcb93,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-48dfb608-3d84-4e2a-9208-b7e6803c4842,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-615c3fd3-e777-456a-a8a8-d2cb62d35fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-40f9adc3-068b-4e59-943e-7d30bd1525b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-6d6a8bcf-4e1e-47cc-9966-32ec2f0c85ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-e709ff72-27fd-49b9-ba4f-ee6b769fd955,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-242c379e-c126-4406-b6c7-ea08b1155c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567131960-172.17.0.11-1597040916742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33789,DS-572d40d2-b20e-4e65-808a-fd120d9abec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-e8cb33d1-90da-41ba-8d04-dd666affcb93,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-48dfb608-3d84-4e2a-9208-b7e6803c4842,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-615c3fd3-e777-456a-a8a8-d2cb62d35fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-40f9adc3-068b-4e59-943e-7d30bd1525b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-6d6a8bcf-4e1e-47cc-9966-32ec2f0c85ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-e709ff72-27fd-49b9-ba4f-ee6b769fd955,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-242c379e-c126-4406-b6c7-ea08b1155c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161255282-172.17.0.11-1597041428810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-81615a7b-60aa-4ca3-9b9d-5ec69e7b2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-b37adc71-d515-4079-8f6e-3f0443ad5d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-af5c7e09-24a6-4891-96d1-84424ba31d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-732df04e-9a69-402c-9c03-8bde29f6e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-d0fe86b6-31c8-4b2c-b83c-0b880248a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-3e38302d-2783-4417-b569-021c2f4ace7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-d0bc4efc-7b40-48d7-b13b-59b0a4eac716,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-a2b567a4-380c-4739-b043-b6f3721bd536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161255282-172.17.0.11-1597041428810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-81615a7b-60aa-4ca3-9b9d-5ec69e7b2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-b37adc71-d515-4079-8f6e-3f0443ad5d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-af5c7e09-24a6-4891-96d1-84424ba31d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-732df04e-9a69-402c-9c03-8bde29f6e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-d0fe86b6-31c8-4b2c-b83c-0b880248a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-3e38302d-2783-4417-b569-021c2f4ace7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-d0bc4efc-7b40-48d7-b13b-59b0a4eac716,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-a2b567a4-380c-4739-b043-b6f3721bd536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618080292-172.17.0.11-1597041663265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44200,DS-53336d2e-ad32-459c-bafd-b7fba839935d,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-daa31b57-9b4f-440b-a76c-260e0d08c1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-3a366f13-d99d-482d-86d9-c6d822f0f00f,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-ffc9489c-5b19-4916-9058-1d178aa8ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-517fea83-cfaf-40f3-b1a0-2e3234f42552,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-74f78aa0-c6c0-436b-b532-a46c457b3cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-e34860e0-9440-4cf0-aa51-c93d345d64d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-d99cbd82-dfc1-461f-9967-494de6904dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618080292-172.17.0.11-1597041663265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44200,DS-53336d2e-ad32-459c-bafd-b7fba839935d,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-daa31b57-9b4f-440b-a76c-260e0d08c1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-3a366f13-d99d-482d-86d9-c6d822f0f00f,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-ffc9489c-5b19-4916-9058-1d178aa8ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-517fea83-cfaf-40f3-b1a0-2e3234f42552,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-74f78aa0-c6c0-436b-b532-a46c457b3cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-e34860e0-9440-4cf0-aa51-c93d345d64d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-d99cbd82-dfc1-461f-9967-494de6904dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196746888-172.17.0.11-1597041985651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37188,DS-3f8d980d-9ad0-44f3-8202-8ace140ffd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-cf561b72-cbcf-44b0-95a5-67ce8a1e2695,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-bfdc73bc-14b4-4b3d-8042-1793aeeceb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-6caeee77-f390-4ad5-ba91-02589a4c4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-3434dee3-6a96-47fd-a837-a6c736e49e55,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-711ffcec-441e-46d4-ae31-26d03f56960c,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-f64e40fa-bbf1-4336-8bb6-9525cb12995a,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-be8f5a86-c1b9-4a6b-b199-94fee73eb56d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196746888-172.17.0.11-1597041985651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37188,DS-3f8d980d-9ad0-44f3-8202-8ace140ffd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-cf561b72-cbcf-44b0-95a5-67ce8a1e2695,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-bfdc73bc-14b4-4b3d-8042-1793aeeceb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-6caeee77-f390-4ad5-ba91-02589a4c4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-3434dee3-6a96-47fd-a837-a6c736e49e55,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-711ffcec-441e-46d4-ae31-26d03f56960c,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-f64e40fa-bbf1-4336-8bb6-9525cb12995a,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-be8f5a86-c1b9-4a6b-b199-94fee73eb56d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637628799-172.17.0.11-1597042362462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-42aa1755-b9f1-485e-92ab-f69eda44d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-24b4ab4b-d105-4f9b-9b89-061b4762e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-9cbddf97-518c-418f-8080-95bf13299a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-3750586c-6ee0-47e6-80c1-08ba66623dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-b47ea983-a25d-43fc-8075-343ce90b8a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-7294a44a-3a85-40bc-87da-9a999e0435bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-64488df3-cc9d-4e30-8408-369453f33a17,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-9ca8dc86-a72f-4676-9534-015fd48c8e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637628799-172.17.0.11-1597042362462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-42aa1755-b9f1-485e-92ab-f69eda44d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-24b4ab4b-d105-4f9b-9b89-061b4762e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-9cbddf97-518c-418f-8080-95bf13299a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-3750586c-6ee0-47e6-80c1-08ba66623dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-b47ea983-a25d-43fc-8075-343ce90b8a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-7294a44a-3a85-40bc-87da-9a999e0435bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-64488df3-cc9d-4e30-8408-369453f33a17,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-9ca8dc86-a72f-4676-9534-015fd48c8e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359031239-172.17.0.11-1597042555549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-636bb9f4-834e-4567-9868-d705481bcd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-6c320139-dbce-48a1-953b-e51623908add,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-90728d65-8761-4d9d-99e8-35f3be617689,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-db831a14-bbc6-4f41-a8e9-dbfc47f6f176,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-41c7ccd1-5761-4af6-933f-f8324b5ca13b,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-48fa587f-3801-4ffc-b9c1-79dcb1839274,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-a9cd8cea-a090-4da6-8cda-32ff700bc286,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-c0e4afe2-efc7-4175-95f6-d2e891370579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359031239-172.17.0.11-1597042555549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-636bb9f4-834e-4567-9868-d705481bcd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-6c320139-dbce-48a1-953b-e51623908add,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-90728d65-8761-4d9d-99e8-35f3be617689,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-db831a14-bbc6-4f41-a8e9-dbfc47f6f176,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-41c7ccd1-5761-4af6-933f-f8324b5ca13b,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-48fa587f-3801-4ffc-b9c1-79dcb1839274,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-a9cd8cea-a090-4da6-8cda-32ff700bc286,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-c0e4afe2-efc7-4175-95f6-d2e891370579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24297533-172.17.0.11-1597042718150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-266c2eea-f56e-45b7-a2dc-250a21d0f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-972139eb-2cda-4d7d-8bb3-1ccd3715f056,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-43cc7c80-00ac-4568-a8da-f29cfc7a73d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-2d09899d-824c-42e4-9bfe-b3cf7f786b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-aa505e16-9297-4113-bfc2-f5553591ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-4c28a10c-3d53-448c-8016-a4795eb85ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-f1863438-7d4d-4877-b098-7721dbb233a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-ddde1714-1821-4823-8e3f-5c02a3ef2c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24297533-172.17.0.11-1597042718150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-266c2eea-f56e-45b7-a2dc-250a21d0f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-972139eb-2cda-4d7d-8bb3-1ccd3715f056,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-43cc7c80-00ac-4568-a8da-f29cfc7a73d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-2d09899d-824c-42e4-9bfe-b3cf7f786b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-aa505e16-9297-4113-bfc2-f5553591ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-4c28a10c-3d53-448c-8016-a4795eb85ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-f1863438-7d4d-4877-b098-7721dbb233a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-ddde1714-1821-4823-8e3f-5c02a3ef2c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426384422-172.17.0.11-1597042827859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-40879361-578a-4b70-9b7a-dd39938a0cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-200d7087-45b3-4035-a9ef-73b74e605e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-4586f930-0312-432f-9cdd-8768ba6fb7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-1bac7b14-b657-4529-8302-2d31b3157815,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-ddbb2e4f-59bf-46ac-9abb-877f706f8e08,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-a71274f5-2e1f-49e9-b411-98b63cab93b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-7f3d8df4-e090-46eb-ab5a-67fdc87c1ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-f1b3471d-a1c1-4264-9c84-d212312b2c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426384422-172.17.0.11-1597042827859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-40879361-578a-4b70-9b7a-dd39938a0cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-200d7087-45b3-4035-a9ef-73b74e605e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-4586f930-0312-432f-9cdd-8768ba6fb7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-1bac7b14-b657-4529-8302-2d31b3157815,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-ddbb2e4f-59bf-46ac-9abb-877f706f8e08,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-a71274f5-2e1f-49e9-b411-98b63cab93b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-7f3d8df4-e090-46eb-ab5a-67fdc87c1ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-f1b3471d-a1c1-4264-9c84-d212312b2c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593683731-172.17.0.11-1597043014475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38188,DS-dcfa3f1a-4c1a-4a0a-a05f-261a232f1cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-a8e3af65-669e-4c0e-a0bc-7d54b70b2cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-04567c12-91a5-47dc-a0be-07ef816bc61d,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-f43cb098-178e-4dae-b230-28553122dd21,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-9cf12dea-e7ec-4d9f-a0c6-849e6e550728,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-2fe28adf-c41f-464d-a3ae-dbe2dabfde4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-f17e4bda-15ef-4d57-8acc-2ff35a401c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-9da9ed5d-6d9e-4e57-bf15-263d3ba9cdd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593683731-172.17.0.11-1597043014475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38188,DS-dcfa3f1a-4c1a-4a0a-a05f-261a232f1cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-a8e3af65-669e-4c0e-a0bc-7d54b70b2cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-04567c12-91a5-47dc-a0be-07ef816bc61d,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-f43cb098-178e-4dae-b230-28553122dd21,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-9cf12dea-e7ec-4d9f-a0c6-849e6e550728,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-2fe28adf-c41f-464d-a3ae-dbe2dabfde4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-f17e4bda-15ef-4d57-8acc-2ff35a401c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-9da9ed5d-6d9e-4e57-bf15-263d3ba9cdd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226980399-172.17.0.11-1597043554909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33949,DS-9b22b780-a1b0-4075-8ecf-4bdddfe317f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-12a8ce2c-9c06-48f5-b6f6-a94edc5005e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2b7b1642-9f59-4f12-a619-205dce5db0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-817472a0-a71d-44e6-80e4-b4e93bb56280,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-1c191f93-2b7e-46e1-9df3-efc3c27f96f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-d00f2ebd-6bb4-4ced-bc3a-8b6c3194d829,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-83004b40-2b4c-4a2f-836c-8837f3dc0e35,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-c5d23053-e56e-43b9-837c-ebe23763eca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226980399-172.17.0.11-1597043554909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33949,DS-9b22b780-a1b0-4075-8ecf-4bdddfe317f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-12a8ce2c-9c06-48f5-b6f6-a94edc5005e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2b7b1642-9f59-4f12-a619-205dce5db0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-817472a0-a71d-44e6-80e4-b4e93bb56280,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-1c191f93-2b7e-46e1-9df3-efc3c27f96f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-d00f2ebd-6bb4-4ced-bc3a-8b6c3194d829,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-83004b40-2b4c-4a2f-836c-8837f3dc0e35,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-c5d23053-e56e-43b9-837c-ebe23763eca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5296
