reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598132046-172.17.0.2-1597077212587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-35978bac-bbab-4af5-a283-31887228a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-ca9a4b38-65d0-46ae-994e-1ba4fe245e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-2c031ae4-fca6-4e6b-81aa-45251ae429ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-4d99aa07-6911-486f-9ead-bfa4f314a740,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-257dd5c2-f630-4554-96db-e17069f9b6de,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-6af14b48-adeb-40bc-b9d3-44569a735874,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-e4765239-87d1-4422-a953-eecc73177343,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-86885299-d75c-4ad1-b9d9-252a9e9ad892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598132046-172.17.0.2-1597077212587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-35978bac-bbab-4af5-a283-31887228a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-ca9a4b38-65d0-46ae-994e-1ba4fe245e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-2c031ae4-fca6-4e6b-81aa-45251ae429ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-4d99aa07-6911-486f-9ead-bfa4f314a740,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-257dd5c2-f630-4554-96db-e17069f9b6de,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-6af14b48-adeb-40bc-b9d3-44569a735874,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-e4765239-87d1-4422-a953-eecc73177343,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-86885299-d75c-4ad1-b9d9-252a9e9ad892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780955731-172.17.0.2-1597077672336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-7fa907d8-9e53-48cb-9649-0b755ea68ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-6e3cc68c-9e88-42a7-8dc2-3a42ff0fea03,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-28efbff9-53e8-4677-bf12-c542cb8914c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-6bbd7885-1f88-451d-a627-682912aff1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-fdfd3ea4-c557-449d-b93c-2132c2f7479c,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-47171c91-57c5-46a3-b452-c8230ab3cf66,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-6f120763-9822-4edb-8096-84f993b4b4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-938d6a9f-ca72-41a1-beaf-34eded419694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780955731-172.17.0.2-1597077672336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-7fa907d8-9e53-48cb-9649-0b755ea68ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-6e3cc68c-9e88-42a7-8dc2-3a42ff0fea03,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-28efbff9-53e8-4677-bf12-c542cb8914c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-6bbd7885-1f88-451d-a627-682912aff1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-fdfd3ea4-c557-449d-b93c-2132c2f7479c,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-47171c91-57c5-46a3-b452-c8230ab3cf66,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-6f120763-9822-4edb-8096-84f993b4b4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-938d6a9f-ca72-41a1-beaf-34eded419694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351399314-172.17.0.2-1597078026093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43114,DS-e8a2eed4-23e5-49cf-8dd3-3045f5b5b2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-cd244fd7-3f3b-4711-9d13-3d2353d5512f,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-c3c1d92b-01f3-476b-8b71-393b940a7922,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-f7af9a89-7e47-4123-bae8-b6e0bec6e279,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-b0d9211f-2b9c-46f2-81b0-573a6e17d435,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-d4d8fb55-f1da-4e34-9b82-fab79a5f6f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-fc238c03-6047-4994-b3a9-76f4a6ae1f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-c8cf6bb5-290f-4792-833c-bc95ca15882e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351399314-172.17.0.2-1597078026093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43114,DS-e8a2eed4-23e5-49cf-8dd3-3045f5b5b2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-cd244fd7-3f3b-4711-9d13-3d2353d5512f,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-c3c1d92b-01f3-476b-8b71-393b940a7922,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-f7af9a89-7e47-4123-bae8-b6e0bec6e279,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-b0d9211f-2b9c-46f2-81b0-573a6e17d435,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-d4d8fb55-f1da-4e34-9b82-fab79a5f6f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-fc238c03-6047-4994-b3a9-76f4a6ae1f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-c8cf6bb5-290f-4792-833c-bc95ca15882e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181464066-172.17.0.2-1597078461229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34540,DS-bd911c41-95b3-4970-89cd-634170089ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-87fea11f-f246-4db1-8499-996321288ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-70a2552f-e077-4b5c-9f4f-c2680b8a5532,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-b53710dd-6331-44d7-9d95-e0780ea7c5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-31be8497-0ad5-4b02-9489-7eb683cc9a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-4623d798-8036-41bb-a12d-b1a27575509a,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-f2a592ba-6c6f-479e-a779-1db573a0645b,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-21cd8bd7-80e9-4eb6-a174-e49d3e89772d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181464066-172.17.0.2-1597078461229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34540,DS-bd911c41-95b3-4970-89cd-634170089ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-87fea11f-f246-4db1-8499-996321288ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-70a2552f-e077-4b5c-9f4f-c2680b8a5532,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-b53710dd-6331-44d7-9d95-e0780ea7c5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-31be8497-0ad5-4b02-9489-7eb683cc9a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-4623d798-8036-41bb-a12d-b1a27575509a,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-f2a592ba-6c6f-479e-a779-1db573a0645b,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-21cd8bd7-80e9-4eb6-a174-e49d3e89772d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114418950-172.17.0.2-1597079577538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-5daf5f4f-c849-4fcd-b3fe-529092d9818e,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-ec106235-d7ee-408e-812c-7fa45d390c31,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-2ae6fc00-d93f-40cc-801c-c6a0b02130c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-478d27f3-bdda-4e01-ac27-bf2df1b514e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-5eb36b34-5ae6-4e19-870e-16141d3d649b,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-c77f54e9-4ac2-4cf2-83e1-aa31474e04df,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-dc985c5d-b666-4df9-8ff1-1a06e2a3aedf,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-85adde5a-1cf6-4aa8-8000-0c10bde64823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114418950-172.17.0.2-1597079577538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-5daf5f4f-c849-4fcd-b3fe-529092d9818e,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-ec106235-d7ee-408e-812c-7fa45d390c31,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-2ae6fc00-d93f-40cc-801c-c6a0b02130c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-478d27f3-bdda-4e01-ac27-bf2df1b514e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-5eb36b34-5ae6-4e19-870e-16141d3d649b,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-c77f54e9-4ac2-4cf2-83e1-aa31474e04df,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-dc985c5d-b666-4df9-8ff1-1a06e2a3aedf,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-85adde5a-1cf6-4aa8-8000-0c10bde64823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224219583-172.17.0.2-1597079912567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-3ecfbf7c-fef6-4f55-affb-16fe9bef6c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-fb9199aa-66ed-4a70-aebf-4e2e0e6f9c32,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-79a16bab-735c-473e-b998-4f338d75bdea,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-ddaf26ac-88b5-4940-ac9b-a9e40307d810,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-f8cde1b4-ddfa-4671-979c-7f81ed22669c,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-61a7ce49-74a3-40dd-9d05-025b68edc87d,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-bf4cabf7-1e7b-483b-ad6b-2095b4453169,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-64361057-e8b8-4a5b-a4e0-24fd172dffdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224219583-172.17.0.2-1597079912567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-3ecfbf7c-fef6-4f55-affb-16fe9bef6c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-fb9199aa-66ed-4a70-aebf-4e2e0e6f9c32,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-79a16bab-735c-473e-b998-4f338d75bdea,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-ddaf26ac-88b5-4940-ac9b-a9e40307d810,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-f8cde1b4-ddfa-4671-979c-7f81ed22669c,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-61a7ce49-74a3-40dd-9d05-025b68edc87d,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-bf4cabf7-1e7b-483b-ad6b-2095b4453169,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-64361057-e8b8-4a5b-a4e0-24fd172dffdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156988309-172.17.0.2-1597080263215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-009eace0-fcc4-4da7-80d4-cd30fac1f7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-a98f15db-e25a-4dfa-a00c-b2ce7ecb5f73,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-794b27f2-17de-47cc-bcbd-a804cf6cef64,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-1cb307a3-a6e1-403b-8435-9d016d33eb06,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-e06254ed-53b2-4aff-b87a-136a6568df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-e5afda0b-8c73-4ec1-af29-1f4e2dabe1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-085dc938-c773-41ab-9294-887e073a672d,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-6afdc0d7-e4ae-4ca8-b7ff-e62b4e0ab935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156988309-172.17.0.2-1597080263215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-009eace0-fcc4-4da7-80d4-cd30fac1f7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-a98f15db-e25a-4dfa-a00c-b2ce7ecb5f73,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-794b27f2-17de-47cc-bcbd-a804cf6cef64,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-1cb307a3-a6e1-403b-8435-9d016d33eb06,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-e06254ed-53b2-4aff-b87a-136a6568df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-e5afda0b-8c73-4ec1-af29-1f4e2dabe1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-085dc938-c773-41ab-9294-887e073a672d,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-6afdc0d7-e4ae-4ca8-b7ff-e62b4e0ab935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779139511-172.17.0.2-1597080361744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32876,DS-35f9063c-b5e3-44e6-b421-e180b42158bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-c0a983ca-070b-4dba-afa2-1169bd7a82d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-8512c963-6155-4143-9aaf-27aeace9f79e,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-d4002354-ce0d-4fbf-b620-915e3863e048,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-e9abd2ab-8408-49bc-bfaa-586d1460ee50,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-ca7398ed-1d83-4879-9cf1-4b006c1b722e,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-83d98c27-b9ea-4e6d-9e3c-3eaf348dceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-649296fb-f623-4448-b423-69289381cbf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779139511-172.17.0.2-1597080361744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32876,DS-35f9063c-b5e3-44e6-b421-e180b42158bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-c0a983ca-070b-4dba-afa2-1169bd7a82d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-8512c963-6155-4143-9aaf-27aeace9f79e,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-d4002354-ce0d-4fbf-b620-915e3863e048,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-e9abd2ab-8408-49bc-bfaa-586d1460ee50,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-ca7398ed-1d83-4879-9cf1-4b006c1b722e,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-83d98c27-b9ea-4e6d-9e3c-3eaf348dceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-649296fb-f623-4448-b423-69289381cbf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745126984-172.17.0.2-1597080422766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-1bba284c-a16f-4e8a-bd16-8ecde814fb57,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-19898cd5-cefa-4355-8f51-b6ccbdeb3e99,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-53b2180c-bdb2-4c7d-9b4a-01785584c7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-dc3ec316-bbff-4067-89d3-95aaa7d6a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-56024a7a-ae05-464e-8f55-e2df4a1d710c,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-3875770c-2ad6-4c5a-a9c6-3f0ef6601fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-40a48977-244b-4b70-a4bc-560da7b43c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-7e6ba5ec-130b-4ff9-958f-48a98c0d3218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745126984-172.17.0.2-1597080422766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-1bba284c-a16f-4e8a-bd16-8ecde814fb57,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-19898cd5-cefa-4355-8f51-b6ccbdeb3e99,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-53b2180c-bdb2-4c7d-9b4a-01785584c7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-dc3ec316-bbff-4067-89d3-95aaa7d6a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-56024a7a-ae05-464e-8f55-e2df4a1d710c,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-3875770c-2ad6-4c5a-a9c6-3f0ef6601fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-40a48977-244b-4b70-a4bc-560da7b43c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-7e6ba5ec-130b-4ff9-958f-48a98c0d3218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067393507-172.17.0.2-1597080754785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39572,DS-3a648ca7-6244-4bf1-be65-b5f2fa018dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-47617083-a2b1-44af-bb8f-e954232f85c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-fbd00b5e-2c67-4c7c-bbf3-45569699a9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-bbf72715-772e-4879-88cc-4383e5aa3554,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-dd720ca3-f90a-49ec-bbfd-f6a586f8ef53,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-adb0f1a4-602f-4650-ba46-e71fe12664ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-a8ada5d2-1332-47a6-92aa-24c249e0e416,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-de1e0009-f83d-43fa-b81a-df9c3e7a4d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067393507-172.17.0.2-1597080754785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39572,DS-3a648ca7-6244-4bf1-be65-b5f2fa018dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-47617083-a2b1-44af-bb8f-e954232f85c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-fbd00b5e-2c67-4c7c-bbf3-45569699a9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-bbf72715-772e-4879-88cc-4383e5aa3554,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-dd720ca3-f90a-49ec-bbfd-f6a586f8ef53,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-adb0f1a4-602f-4650-ba46-e71fe12664ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-a8ada5d2-1332-47a6-92aa-24c249e0e416,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-de1e0009-f83d-43fa-b81a-df9c3e7a4d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197715428-172.17.0.2-1597080888924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-b74408c9-aa9f-4ef3-b96f-409e7f6eb489,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-b60dca88-4da7-44fc-be7c-d949e946f203,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-78e5f050-bf1b-4898-b307-80669c698f65,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-37ce0e99-e96d-41a4-a7c6-b908aaecd44f,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-32cb5321-6dc2-4e30-9edc-208fe2aeb3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-aa05d682-b5c3-4e80-b1c8-e034c8d17c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-164286e7-b0b2-40f7-ae29-a2cf06e7b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-c3eed6ef-6d7c-40b3-8db1-3a2c24c45143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197715428-172.17.0.2-1597080888924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-b74408c9-aa9f-4ef3-b96f-409e7f6eb489,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-b60dca88-4da7-44fc-be7c-d949e946f203,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-78e5f050-bf1b-4898-b307-80669c698f65,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-37ce0e99-e96d-41a4-a7c6-b908aaecd44f,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-32cb5321-6dc2-4e30-9edc-208fe2aeb3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-aa05d682-b5c3-4e80-b1c8-e034c8d17c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-164286e7-b0b2-40f7-ae29-a2cf06e7b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-c3eed6ef-6d7c-40b3-8db1-3a2c24c45143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623205870-172.17.0.2-1597081450156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-34e453d3-3382-4182-bdb5-5f2562cabd71,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6b2d43ee-57f9-463c-a540-485e832d74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-8a6ef65d-840a-4570-9681-cc73538ae814,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-3a6ee44a-7be6-4528-b984-ff0fc92466d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-9dde6a3b-81a5-4b16-b088-daff299018e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-74989a56-d9ed-415f-8f84-2aaaaadbbc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-e74ab8c6-cb4c-430f-8a2b-50080d51c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-51bf75ac-7e8d-4526-b0e1-531655de5424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623205870-172.17.0.2-1597081450156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-34e453d3-3382-4182-bdb5-5f2562cabd71,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6b2d43ee-57f9-463c-a540-485e832d74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-8a6ef65d-840a-4570-9681-cc73538ae814,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-3a6ee44a-7be6-4528-b984-ff0fc92466d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-9dde6a3b-81a5-4b16-b088-daff299018e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-74989a56-d9ed-415f-8f84-2aaaaadbbc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-e74ab8c6-cb4c-430f-8a2b-50080d51c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-51bf75ac-7e8d-4526-b0e1-531655de5424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419890014-172.17.0.2-1597081924172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38025,DS-42ce962e-8a10-4c25-90fa-0aae1a45a423,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-cfbf1d8f-06cb-4960-b009-a5973ba126c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-53788a31-53da-4869-b9f2-04328b3d6ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-8d9c0306-f55b-488d-bfde-4e73baf3ce33,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-b320c5a0-561d-4210-b6aa-c88bd2d66b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-8e44d183-452b-4aa9-adcd-d2de3803ad35,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-f1740735-f40f-4333-9a9d-8ad2d276bb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-67871482-4dec-4351-b0f2-a2f4367c0457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419890014-172.17.0.2-1597081924172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38025,DS-42ce962e-8a10-4c25-90fa-0aae1a45a423,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-cfbf1d8f-06cb-4960-b009-a5973ba126c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-53788a31-53da-4869-b9f2-04328b3d6ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-8d9c0306-f55b-488d-bfde-4e73baf3ce33,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-b320c5a0-561d-4210-b6aa-c88bd2d66b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-8e44d183-452b-4aa9-adcd-d2de3803ad35,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-f1740735-f40f-4333-9a9d-8ad2d276bb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-67871482-4dec-4351-b0f2-a2f4367c0457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5229
