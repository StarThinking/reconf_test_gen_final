reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971730397-172.17.0.13-1597070580265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-da724c0d-22c2-46f3-8138-2c1ce225274b,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-84aae9b0-a555-42e0-9f4c-a0b19aab58eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-059f7d32-621a-4308-b59d-85d52c8ccad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-94e25f95-2b1d-40ec-bfa0-e112f43893f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-fea7ce85-3d53-4a87-9ade-88b3a63b0170,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-56e0366e-4f17-4fab-84c3-66f9391fb81b,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-bf378755-5559-4cd4-8163-69fdb6ee8f11,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-e7c8bc25-7947-492d-8d70-58a608886ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971730397-172.17.0.13-1597070580265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-da724c0d-22c2-46f3-8138-2c1ce225274b,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-84aae9b0-a555-42e0-9f4c-a0b19aab58eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-059f7d32-621a-4308-b59d-85d52c8ccad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-94e25f95-2b1d-40ec-bfa0-e112f43893f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-fea7ce85-3d53-4a87-9ade-88b3a63b0170,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-56e0366e-4f17-4fab-84c3-66f9391fb81b,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-bf378755-5559-4cd4-8163-69fdb6ee8f11,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-e7c8bc25-7947-492d-8d70-58a608886ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105569083-172.17.0.13-1597070821371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34716,DS-71033bbe-a5a3-487b-9f99-96fc73980090,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-a309591f-f140-4afc-bb9e-bfe660e122fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-de4987b9-6475-4609-8013-33072282a44e,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-cf0e808d-1480-479f-8cf8-80dc3cc08278,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-654f75a4-eb7b-468f-9e3d-f667b6c706e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-dbe0a624-12de-450b-8d34-35778bf15945,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-f6c74fa1-af24-4149-ab26-dced01fb5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-2cadcab5-cdb2-4c9e-bfea-e802c9765302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105569083-172.17.0.13-1597070821371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34716,DS-71033bbe-a5a3-487b-9f99-96fc73980090,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-a309591f-f140-4afc-bb9e-bfe660e122fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-de4987b9-6475-4609-8013-33072282a44e,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-cf0e808d-1480-479f-8cf8-80dc3cc08278,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-654f75a4-eb7b-468f-9e3d-f667b6c706e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-dbe0a624-12de-450b-8d34-35778bf15945,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-f6c74fa1-af24-4149-ab26-dced01fb5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-2cadcab5-cdb2-4c9e-bfea-e802c9765302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650953649-172.17.0.13-1597070923341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-2e8ac4c2-4e6f-4d74-a29a-95d858505ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-ec1b6a4c-5f0d-47df-a008-070d9f9aac72,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-5fa69514-ab1c-4129-96fd-ccc742736e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-e3387b06-dfc5-4292-b5c4-778c5019f43c,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-dac46407-2870-4d83-806a-b0fea090a964,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-f5be05ce-831e-4f4f-84e3-eb77c6b3269a,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-de3177b9-123c-45a4-b134-1ad9f1058250,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-0ab7b859-5a56-4310-938e-7834c0792db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650953649-172.17.0.13-1597070923341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-2e8ac4c2-4e6f-4d74-a29a-95d858505ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-ec1b6a4c-5f0d-47df-a008-070d9f9aac72,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-5fa69514-ab1c-4129-96fd-ccc742736e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-e3387b06-dfc5-4292-b5c4-778c5019f43c,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-dac46407-2870-4d83-806a-b0fea090a964,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-f5be05ce-831e-4f4f-84e3-eb77c6b3269a,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-de3177b9-123c-45a4-b134-1ad9f1058250,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-0ab7b859-5a56-4310-938e-7834c0792db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298047290-172.17.0.13-1597071050029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-2a17341f-ce18-41d7-897d-83b1b963bd21,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-92a46a9c-8aee-45c8-93f3-e2f04d113080,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-6f339d1d-dda4-465d-a070-ecdedf6fd1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-62c11dff-3a81-4b36-834f-71b4e2ea3ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-b0f38c56-45f9-47d3-8b5c-96aa8eff1493,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-d362e252-e7f7-44fd-a129-848dc6dbd504,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-5237b54d-08d8-490e-b8f7-7671a654e902,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-198032d2-e0fb-4c12-9bf5-719decdf16a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298047290-172.17.0.13-1597071050029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-2a17341f-ce18-41d7-897d-83b1b963bd21,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-92a46a9c-8aee-45c8-93f3-e2f04d113080,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-6f339d1d-dda4-465d-a070-ecdedf6fd1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-62c11dff-3a81-4b36-834f-71b4e2ea3ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-b0f38c56-45f9-47d3-8b5c-96aa8eff1493,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-d362e252-e7f7-44fd-a129-848dc6dbd504,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-5237b54d-08d8-490e-b8f7-7671a654e902,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-198032d2-e0fb-4c12-9bf5-719decdf16a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739529490-172.17.0.13-1597071352498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42978,DS-ae5411ff-c664-4816-bb3a-aeb1d54a273e,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-e1a1434c-2d08-4f90-9b4d-6310c4177a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-2ef803e4-e5f9-401e-b93b-b5ba36ffc85b,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-6fe6ae90-aaec-484a-87b2-702bcb34068e,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-57bf563d-4846-4004-ac96-77b6457de86b,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-2245890f-8971-43f4-ad18-b9ccef4c51a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-b32c383b-0df4-43fe-b0c2-fb5d8c197e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-bb263e9f-c37d-4428-94ed-88bb20c6547a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739529490-172.17.0.13-1597071352498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42978,DS-ae5411ff-c664-4816-bb3a-aeb1d54a273e,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-e1a1434c-2d08-4f90-9b4d-6310c4177a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-2ef803e4-e5f9-401e-b93b-b5ba36ffc85b,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-6fe6ae90-aaec-484a-87b2-702bcb34068e,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-57bf563d-4846-4004-ac96-77b6457de86b,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-2245890f-8971-43f4-ad18-b9ccef4c51a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-b32c383b-0df4-43fe-b0c2-fb5d8c197e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-bb263e9f-c37d-4428-94ed-88bb20c6547a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824589755-172.17.0.13-1597071805273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37367,DS-5975f131-135a-4a24-b367-07d63fa79a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-13b057fc-6038-4486-bfec-6fdfcc9b56a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-a0cb1087-5f9b-4ad3-b639-d7571fd0f0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-4799726b-161d-421c-b668-a6a2d2c08d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-4741a21d-3133-483f-ac0f-c2fbe1359865,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-1644a6a4-946e-4e13-af70-63f361cf2530,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-f7fc73e0-c237-49d9-9e70-4f7900276654,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-56cfa717-2c25-427e-95b3-3cd7db920cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824589755-172.17.0.13-1597071805273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37367,DS-5975f131-135a-4a24-b367-07d63fa79a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-13b057fc-6038-4486-bfec-6fdfcc9b56a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-a0cb1087-5f9b-4ad3-b639-d7571fd0f0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-4799726b-161d-421c-b668-a6a2d2c08d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-4741a21d-3133-483f-ac0f-c2fbe1359865,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-1644a6a4-946e-4e13-af70-63f361cf2530,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-f7fc73e0-c237-49d9-9e70-4f7900276654,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-56cfa717-2c25-427e-95b3-3cd7db920cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788083306-172.17.0.13-1597071895042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46269,DS-675d3538-c2d7-4476-8eff-bad2e783eb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-afd97701-4c1c-4741-82a8-0440ccdf0043,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-e62f1f08-c6d5-405c-9c7e-1b87d75fb8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-48cb5e44-55f3-419d-b97e-e4c4327c9e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-66ba6582-187c-461f-a8f9-679d62de7d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-691272d8-a41d-446d-aeb3-d994687299c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-a15345a2-c69e-4d5d-9d73-5e0c8c789c68,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-cef396d5-6224-4d4f-b6fb-252e9e224999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788083306-172.17.0.13-1597071895042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46269,DS-675d3538-c2d7-4476-8eff-bad2e783eb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-afd97701-4c1c-4741-82a8-0440ccdf0043,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-e62f1f08-c6d5-405c-9c7e-1b87d75fb8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-48cb5e44-55f3-419d-b97e-e4c4327c9e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-66ba6582-187c-461f-a8f9-679d62de7d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-691272d8-a41d-446d-aeb3-d994687299c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-a15345a2-c69e-4d5d-9d73-5e0c8c789c68,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-cef396d5-6224-4d4f-b6fb-252e9e224999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061026597-172.17.0.13-1597071954114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-1400b0df-872e-4495-8d37-1180c4edfcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-a27efc64-afa9-4ca9-874f-293cd2f0baba,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-1318128d-6019-441d-a7c5-23c572ba9034,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-f3642ac0-0701-4c15-b60d-636a1efcf58b,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-fb7962bf-0d00-4364-a4d4-082603ae73ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-86e8faa6-2710-4fd2-b664-3bbb7c018e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-9d9d798b-6dfe-49f0-88e4-2bc57c641376,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-2ec5e4bd-ca48-4d72-a870-d2dc16f53f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061026597-172.17.0.13-1597071954114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-1400b0df-872e-4495-8d37-1180c4edfcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-a27efc64-afa9-4ca9-874f-293cd2f0baba,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-1318128d-6019-441d-a7c5-23c572ba9034,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-f3642ac0-0701-4c15-b60d-636a1efcf58b,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-fb7962bf-0d00-4364-a4d4-082603ae73ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-86e8faa6-2710-4fd2-b664-3bbb7c018e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-9d9d798b-6dfe-49f0-88e4-2bc57c641376,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-2ec5e4bd-ca48-4d72-a870-d2dc16f53f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555849123-172.17.0.13-1597071992074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35401,DS-a571d1f9-814a-4ea8-ac38-544ff38f98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-e8023911-7be9-457a-b200-8b9a5912bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-cea032fa-7665-41ab-ae91-271d04c8badf,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-1c8d40d9-f72f-4d26-8d8a-494a27714789,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-6a99502e-cb3a-47f2-b0b6-126decec309d,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-53bd866d-1a67-41d8-bc70-15930d3508d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-ad618ac4-c296-42f9-b1c3-582434972ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-06f27a4d-856a-4185-b0e0-48689be6c509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555849123-172.17.0.13-1597071992074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35401,DS-a571d1f9-814a-4ea8-ac38-544ff38f98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-e8023911-7be9-457a-b200-8b9a5912bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-cea032fa-7665-41ab-ae91-271d04c8badf,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-1c8d40d9-f72f-4d26-8d8a-494a27714789,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-6a99502e-cb3a-47f2-b0b6-126decec309d,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-53bd866d-1a67-41d8-bc70-15930d3508d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-ad618ac4-c296-42f9-b1c3-582434972ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-06f27a4d-856a-4185-b0e0-48689be6c509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686062635-172.17.0.13-1597072677685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38422,DS-52073a77-acb2-4188-97cc-546209b74768,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-eb0de0ac-24b3-4e11-8bfa-bbc7a7f402de,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-188fae6d-2ce7-4bdb-b9cf-0e08ca4133ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-1bc63d91-23dc-4d89-a744-dbfaceb03cae,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-52233102-30a8-4242-b7fd-4d31c87a0319,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-a6e8074b-85c6-492c-a97f-e3432a85414f,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-3adf1765-f1fe-4650-9612-40b1acb0fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-65020588-53f5-46dd-b610-4855d7c7bcdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686062635-172.17.0.13-1597072677685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38422,DS-52073a77-acb2-4188-97cc-546209b74768,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-eb0de0ac-24b3-4e11-8bfa-bbc7a7f402de,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-188fae6d-2ce7-4bdb-b9cf-0e08ca4133ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-1bc63d91-23dc-4d89-a744-dbfaceb03cae,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-52233102-30a8-4242-b7fd-4d31c87a0319,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-a6e8074b-85c6-492c-a97f-e3432a85414f,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-3adf1765-f1fe-4650-9612-40b1acb0fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-65020588-53f5-46dd-b610-4855d7c7bcdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85931395-172.17.0.13-1597072729313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-af5452de-a77e-42c3-85d7-ff4685014ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-8a7cf51f-fce7-4913-b28c-aa2686bc5821,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-1df2e876-b425-42cf-afe4-9a85fa820486,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-145a38ca-dcbd-415c-ac85-765b7a764cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-ef0d8022-1bee-4b55-8b70-4075fdc803e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-ec33403a-2e32-4e03-8931-1b6fcb65b3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-5355f2b6-8007-44a2-aee1-c5723c8e3806,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-8d68cac0-b454-463d-8a78-c693c7f8a65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85931395-172.17.0.13-1597072729313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-af5452de-a77e-42c3-85d7-ff4685014ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-8a7cf51f-fce7-4913-b28c-aa2686bc5821,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-1df2e876-b425-42cf-afe4-9a85fa820486,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-145a38ca-dcbd-415c-ac85-765b7a764cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-ef0d8022-1bee-4b55-8b70-4075fdc803e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-ec33403a-2e32-4e03-8931-1b6fcb65b3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-5355f2b6-8007-44a2-aee1-c5723c8e3806,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-8d68cac0-b454-463d-8a78-c693c7f8a65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90417-172.17.0.13-1597072996946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-c24878b1-4440-4950-a108-29806607809f,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-304670c7-ca4a-4a7d-a797-8aa53730183a,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-0480f395-7b89-4ac8-aca3-fe7b899016b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-9e094639-1ba0-4cf8-976e-f1a5cdeca12a,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-72b56b18-d9f4-472c-86bd-a4d1bca97727,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-ff7af570-c284-4256-a665-db7d15870673,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-11fd31ed-d83a-409f-a1f8-89df6989e44c,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-37f5bd05-ed4c-42cc-bc43-f92607b65564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90417-172.17.0.13-1597072996946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-c24878b1-4440-4950-a108-29806607809f,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-304670c7-ca4a-4a7d-a797-8aa53730183a,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-0480f395-7b89-4ac8-aca3-fe7b899016b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-9e094639-1ba0-4cf8-976e-f1a5cdeca12a,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-72b56b18-d9f4-472c-86bd-a4d1bca97727,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-ff7af570-c284-4256-a665-db7d15870673,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-11fd31ed-d83a-409f-a1f8-89df6989e44c,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-37f5bd05-ed4c-42cc-bc43-f92607b65564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987345030-172.17.0.13-1597075766101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46669,DS-d2afac58-66e3-4037-b9ed-891b1b3cac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-67ea37b1-a0c0-4ab8-aab8-a576a01b8606,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-f999e315-2411-4dae-a768-5aadb95bbe68,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-044d251b-98c3-46f8-ba29-ac4a88a5e26a,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-d9a35050-555d-4694-ab7b-d66b2f6af228,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-af87ca72-4b82-465f-8ddd-cc496363cafc,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-403e441d-5e22-490d-95b3-b7a186b7d46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-1b01df80-2073-4a42-baa8-e2f9ef3cf86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987345030-172.17.0.13-1597075766101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46669,DS-d2afac58-66e3-4037-b9ed-891b1b3cac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-67ea37b1-a0c0-4ab8-aab8-a576a01b8606,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-f999e315-2411-4dae-a768-5aadb95bbe68,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-044d251b-98c3-46f8-ba29-ac4a88a5e26a,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-d9a35050-555d-4694-ab7b-d66b2f6af228,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-af87ca72-4b82-465f-8ddd-cc496363cafc,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-403e441d-5e22-490d-95b3-b7a186b7d46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-1b01df80-2073-4a42-baa8-e2f9ef3cf86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781671238-172.17.0.13-1597076563564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35284,DS-0e8ef461-4405-4012-a2ce-984b798ab2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-ec89916a-df8a-4c0b-9d23-833b438e76d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-4f33018f-4505-401d-b15d-fdb41cd2b808,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-9767e48a-bf85-4404-85f8-3a453f201463,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-3b4a1c2f-724d-44d8-8d1f-387b7ab61228,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-90de5ac6-874b-41e6-93a7-52a7c671c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-4f84e2bc-f962-4f18-8408-4ffb44ad8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-e273b174-ec2f-4590-8942-a9a512240347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781671238-172.17.0.13-1597076563564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35284,DS-0e8ef461-4405-4012-a2ce-984b798ab2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-ec89916a-df8a-4c0b-9d23-833b438e76d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-4f33018f-4505-401d-b15d-fdb41cd2b808,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-9767e48a-bf85-4404-85f8-3a453f201463,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-3b4a1c2f-724d-44d8-8d1f-387b7ab61228,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-90de5ac6-874b-41e6-93a7-52a7c671c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-4f84e2bc-f962-4f18-8408-4ffb44ad8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-e273b174-ec2f-4590-8942-a9a512240347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041208133-172.17.0.13-1597076877448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43078,DS-a1a794c0-e4ff-453d-8216-7f27bb62356f,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-b58fc6ca-5e66-4c4d-b4db-1077aaf88f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-003edbf9-f036-41fa-8c71-69e04915a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-ec8ed3bd-19f9-4e0e-a8f4-3a94323ee3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-2463ad05-8d1d-4eef-b9d9-c708db0c4fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-273dccb8-de3c-4948-b6c2-a266753455a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-c3794f70-dc6a-4214-87df-64c40b8a5471,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-760309b1-4e2b-4228-a7b2-16362f3639c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041208133-172.17.0.13-1597076877448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43078,DS-a1a794c0-e4ff-453d-8216-7f27bb62356f,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-b58fc6ca-5e66-4c4d-b4db-1077aaf88f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-003edbf9-f036-41fa-8c71-69e04915a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-ec8ed3bd-19f9-4e0e-a8f4-3a94323ee3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-2463ad05-8d1d-4eef-b9d9-c708db0c4fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-273dccb8-de3c-4948-b6c2-a266753455a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-c3794f70-dc6a-4214-87df-64c40b8a5471,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-760309b1-4e2b-4228-a7b2-16362f3639c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931607544-172.17.0.13-1597077235260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41810,DS-5207bd51-1544-41b7-9243-0a27f0a14017,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-58ab71cd-1997-4653-97b0-0aa868b3b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-06cdcb09-9514-46b9-ba83-8feaf84e45df,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-a766f140-f082-449f-b71a-17e744c92d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-50bef897-bda3-41b3-8eaf-4f106cd3cd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-7555900e-cfe2-49b3-acdb-8fa96f5f9ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-062d9360-3af3-464e-b986-865364d20cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-74fd7eda-dcac-41bb-a3f6-85ef0549b588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931607544-172.17.0.13-1597077235260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41810,DS-5207bd51-1544-41b7-9243-0a27f0a14017,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-58ab71cd-1997-4653-97b0-0aa868b3b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-06cdcb09-9514-46b9-ba83-8feaf84e45df,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-a766f140-f082-449f-b71a-17e744c92d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-50bef897-bda3-41b3-8eaf-4f106cd3cd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-7555900e-cfe2-49b3-acdb-8fa96f5f9ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-062d9360-3af3-464e-b986-865364d20cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-74fd7eda-dcac-41bb-a3f6-85ef0549b588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 7705
