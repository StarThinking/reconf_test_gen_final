reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6984336-172.17.0.17-1597069863426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46088,DS-675a7cf5-0827-435f-8598-c160dd1faa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-2445f829-f824-4f70-ad80-b7f435718370,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-eeae4ae0-2ff2-4cc6-b9c4-1a8c45a34dde,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-1cb5332d-370a-4572-87f5-d53c9bbaa9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-32b19d76-a67d-494d-9c25-796b322f0405,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-74f1ad22-47e3-414d-8962-09177db80be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-dc7a9984-cf41-4b3c-81b3-54153902ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-7719a8e8-0314-4722-ace2-859dde245f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6984336-172.17.0.17-1597069863426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46088,DS-675a7cf5-0827-435f-8598-c160dd1faa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-2445f829-f824-4f70-ad80-b7f435718370,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-eeae4ae0-2ff2-4cc6-b9c4-1a8c45a34dde,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-1cb5332d-370a-4572-87f5-d53c9bbaa9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-32b19d76-a67d-494d-9c25-796b322f0405,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-74f1ad22-47e3-414d-8962-09177db80be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-dc7a9984-cf41-4b3c-81b3-54153902ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-7719a8e8-0314-4722-ace2-859dde245f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078093840-172.17.0.17-1597070307596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38081,DS-12dddf8d-1a5c-43ef-b623-a91b4a102f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-0b7344ed-f83f-4308-8542-21d7fe882ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-526aa864-9ece-4094-abe6-19ee7bbbb315,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-6b31bb6a-d910-4851-b788-679eac2438bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-e3ef0b20-90ef-4e9f-b383-25203c1a0bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-08d4788c-b102-4928-8f0e-4d8a746298b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-cf55fbbc-4268-4e50-8e79-ba609a1813f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-0448bad0-a9fa-48f1-b11b-43b154938fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078093840-172.17.0.17-1597070307596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38081,DS-12dddf8d-1a5c-43ef-b623-a91b4a102f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-0b7344ed-f83f-4308-8542-21d7fe882ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-526aa864-9ece-4094-abe6-19ee7bbbb315,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-6b31bb6a-d910-4851-b788-679eac2438bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-e3ef0b20-90ef-4e9f-b383-25203c1a0bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-08d4788c-b102-4928-8f0e-4d8a746298b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-cf55fbbc-4268-4e50-8e79-ba609a1813f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-0448bad0-a9fa-48f1-b11b-43b154938fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560050903-172.17.0.17-1597070572229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43794,DS-4976e3af-f51b-453f-8493-389a81043fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-8e7c5f14-0e4a-48c9-a706-4a5a43e708f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-01424786-9dbd-4b13-9471-f83b60809c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-d2354cfb-93f4-46bd-8dbe-c8192418a39b,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-a6b473e4-60d4-442a-aa14-59b9bbe85df9,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-5dae8f6a-e59d-4ae7-91f4-7aaade7bd8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-ff17604e-b909-4957-9fae-0d340a15afef,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-d3bfa6bf-cb60-432d-a7e7-12b574291c0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560050903-172.17.0.17-1597070572229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43794,DS-4976e3af-f51b-453f-8493-389a81043fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-8e7c5f14-0e4a-48c9-a706-4a5a43e708f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-01424786-9dbd-4b13-9471-f83b60809c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-d2354cfb-93f4-46bd-8dbe-c8192418a39b,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-a6b473e4-60d4-442a-aa14-59b9bbe85df9,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-5dae8f6a-e59d-4ae7-91f4-7aaade7bd8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-ff17604e-b909-4957-9fae-0d340a15afef,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-d3bfa6bf-cb60-432d-a7e7-12b574291c0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516399459-172.17.0.17-1597070920135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-5dbed936-2b76-486b-972b-7e46a966ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-221420e0-158b-4dcd-8e33-e65ed9460c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-1141aeaa-798a-4020-8505-b327da13ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-42dac993-9d2f-411b-b3a3-b44555f06a28,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-49647d18-49d2-47db-8de9-1cf2174ba4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-7b70f685-1546-4989-8fc5-460b806b8875,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-674ed04d-3457-41bc-bde0-b47fa43eaa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-cee27b2f-85d9-49bb-8306-7cb8a075455e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516399459-172.17.0.17-1597070920135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-5dbed936-2b76-486b-972b-7e46a966ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-221420e0-158b-4dcd-8e33-e65ed9460c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-1141aeaa-798a-4020-8505-b327da13ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-42dac993-9d2f-411b-b3a3-b44555f06a28,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-49647d18-49d2-47db-8de9-1cf2174ba4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-7b70f685-1546-4989-8fc5-460b806b8875,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-674ed04d-3457-41bc-bde0-b47fa43eaa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-cee27b2f-85d9-49bb-8306-7cb8a075455e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984951212-172.17.0.17-1597071001001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43863,DS-381ccb23-d7c1-4ab4-8b83-2d17201e7489,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-2510717f-2d42-435a-8e32-6ff08717acc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-89225121-5599-4238-b695-835a5c46395c,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-e093e92b-8b23-4718-9001-f91a93f52638,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-2d91c41b-0b9a-4091-b9ad-18c01e962f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-7ef0163d-9910-4fe4-bf86-113c403b2307,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-916ca7a4-21de-4c89-ab5d-e04764c0d56b,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-9302519e-b28a-46a7-bed4-06e365a43e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984951212-172.17.0.17-1597071001001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43863,DS-381ccb23-d7c1-4ab4-8b83-2d17201e7489,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-2510717f-2d42-435a-8e32-6ff08717acc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-89225121-5599-4238-b695-835a5c46395c,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-e093e92b-8b23-4718-9001-f91a93f52638,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-2d91c41b-0b9a-4091-b9ad-18c01e962f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-7ef0163d-9910-4fe4-bf86-113c403b2307,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-916ca7a4-21de-4c89-ab5d-e04764c0d56b,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-9302519e-b28a-46a7-bed4-06e365a43e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221087269-172.17.0.17-1597071363707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36782,DS-a3fdc620-8548-43e0-ac4e-d37ae8fd1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-6824936e-88bc-471c-8c4b-65d4811642ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-236c9b43-5d79-4e10-8ff3-007eee462ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-4b9bb947-9411-48d4-8e16-58f6dbc49525,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-294adfb8-2b14-464c-9d58-fd0bc8991198,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-24b96009-93dd-4229-adc0-daf2d72f8b69,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-26ea0175-528b-4cf3-9c5b-025457412238,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-4464eaa3-fd71-42cf-910a-0eb0dd1fb4f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221087269-172.17.0.17-1597071363707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36782,DS-a3fdc620-8548-43e0-ac4e-d37ae8fd1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-6824936e-88bc-471c-8c4b-65d4811642ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-236c9b43-5d79-4e10-8ff3-007eee462ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-4b9bb947-9411-48d4-8e16-58f6dbc49525,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-294adfb8-2b14-464c-9d58-fd0bc8991198,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-24b96009-93dd-4229-adc0-daf2d72f8b69,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-26ea0175-528b-4cf3-9c5b-025457412238,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-4464eaa3-fd71-42cf-910a-0eb0dd1fb4f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99689507-172.17.0.17-1597072008444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42429,DS-ba4343ab-8e11-4661-ae4e-4f97e365b5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-98d72997-092e-4e59-b1d2-2938fe58f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-0d6bf2b8-0b6e-4475-8453-ed65e9dcfea3,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-b9438787-c562-4da1-816b-2085a42c3f61,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-26a61b37-471e-4088-ab66-2f97a1637e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-e8629c7b-bbfa-41b6-8d99-4ba924819ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-35943067-2d1f-4a04-aaa7-00a815051eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-a2be32f9-2354-4e05-9c89-4dd8534ce606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99689507-172.17.0.17-1597072008444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42429,DS-ba4343ab-8e11-4661-ae4e-4f97e365b5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-98d72997-092e-4e59-b1d2-2938fe58f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-0d6bf2b8-0b6e-4475-8453-ed65e9dcfea3,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-b9438787-c562-4da1-816b-2085a42c3f61,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-26a61b37-471e-4088-ab66-2f97a1637e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-e8629c7b-bbfa-41b6-8d99-4ba924819ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-35943067-2d1f-4a04-aaa7-00a815051eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-a2be32f9-2354-4e05-9c89-4dd8534ce606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042752747-172.17.0.17-1597072039265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41247,DS-35b2ec1c-431b-491c-9747-b43883f749ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-99a19d5e-967a-4a37-89a5-e6179aef22b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-2992982a-6a7f-4cc0-ae5e-17324c6a770a,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-951d79f0-ce18-4dde-88b3-a63e303e8dca,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-e47a6a0f-484f-4ce6-9eb1-ddf8e37bc77f,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-3ad8e879-4ec5-48f3-8f62-0ca7dd3f3ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-8edae935-3a58-4fc9-bb53-755988a09f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-5e3eb1f3-2b01-4041-ae5e-898013a86d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042752747-172.17.0.17-1597072039265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41247,DS-35b2ec1c-431b-491c-9747-b43883f749ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-99a19d5e-967a-4a37-89a5-e6179aef22b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-2992982a-6a7f-4cc0-ae5e-17324c6a770a,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-951d79f0-ce18-4dde-88b3-a63e303e8dca,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-e47a6a0f-484f-4ce6-9eb1-ddf8e37bc77f,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-3ad8e879-4ec5-48f3-8f62-0ca7dd3f3ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-8edae935-3a58-4fc9-bb53-755988a09f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-5e3eb1f3-2b01-4041-ae5e-898013a86d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175208043-172.17.0.17-1597072112003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-63223c95-5dfd-4e31-8c8b-b303b1fff272,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-b33eb87d-fa04-473b-aa03-638bd4675977,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-66cf92d6-1f1c-4337-a63e-9afac02e82a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-dab198bc-3bd0-4eaa-977f-9259d085ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-1873193d-b89e-4c83-b085-a6ec9263d7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-0edaf6e1-4179-4da4-baf9-4a863241961d,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-1fa8df23-9c96-4e58-af83-c33872f1cead,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-fcbc03a7-f8df-4a89-b525-50ef2ffa5a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175208043-172.17.0.17-1597072112003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-63223c95-5dfd-4e31-8c8b-b303b1fff272,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-b33eb87d-fa04-473b-aa03-638bd4675977,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-66cf92d6-1f1c-4337-a63e-9afac02e82a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-dab198bc-3bd0-4eaa-977f-9259d085ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-1873193d-b89e-4c83-b085-a6ec9263d7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-0edaf6e1-4179-4da4-baf9-4a863241961d,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-1fa8df23-9c96-4e58-af83-c33872f1cead,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-fcbc03a7-f8df-4a89-b525-50ef2ffa5a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712196259-172.17.0.17-1597072393844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35083,DS-7a716054-71a4-4eae-94a7-24885ec15fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-241ed745-f27b-40de-94bf-b3c2e36a0802,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-35ea423b-c697-4242-b99a-e4c887ac9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-3ae692ee-256b-49bc-8933-15b0e377afde,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-a5d4f2cd-5a59-47b8-881d-90d3c0784b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-39faf55f-f91d-469c-99e1-09a53822475c,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-337e500d-8c09-4dea-9abc-e6c5b0542d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-26ac68e1-0529-4594-b891-0e9dbab243ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712196259-172.17.0.17-1597072393844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35083,DS-7a716054-71a4-4eae-94a7-24885ec15fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-241ed745-f27b-40de-94bf-b3c2e36a0802,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-35ea423b-c697-4242-b99a-e4c887ac9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-3ae692ee-256b-49bc-8933-15b0e377afde,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-a5d4f2cd-5a59-47b8-881d-90d3c0784b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-39faf55f-f91d-469c-99e1-09a53822475c,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-337e500d-8c09-4dea-9abc-e6c5b0542d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-26ac68e1-0529-4594-b891-0e9dbab243ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701590360-172.17.0.17-1597072750706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46695,DS-9882b300-0431-4224-93fb-55d2b1d1ca30,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-c9c02bef-54ca-4d74-b664-1867a7de45bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-4c4855c6-ce7b-4085-b8ec-9a0d5c605808,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-73734209-127f-46dc-9356-b9ab6b2810f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-2a6e984f-641a-4c6b-b080-648363340d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-51c6f938-6e1e-4c9d-a078-3386da1c5fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-5910cc35-feae-4640-be38-4711536b808e,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-480a2ed6-b622-438b-bcde-54f9163326c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701590360-172.17.0.17-1597072750706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46695,DS-9882b300-0431-4224-93fb-55d2b1d1ca30,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-c9c02bef-54ca-4d74-b664-1867a7de45bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-4c4855c6-ce7b-4085-b8ec-9a0d5c605808,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-73734209-127f-46dc-9356-b9ab6b2810f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-2a6e984f-641a-4c6b-b080-648363340d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-51c6f938-6e1e-4c9d-a078-3386da1c5fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-5910cc35-feae-4640-be38-4711536b808e,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-480a2ed6-b622-438b-bcde-54f9163326c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022782899-172.17.0.17-1597072832348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-90d0a7eb-d808-4ad1-8d35-de4b3c9e3f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-d8495fba-6969-4565-b00c-e6dfdd5852c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-1d4074eb-1e1c-4a86-92cf-0c03c1b12801,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-c1a42cc3-ba0a-4c46-adf7-9ccfca55996d,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-9b853c39-1187-4a44-a2e2-a0af4e38b034,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-f084dcb8-a7aa-4086-83c9-220bc49c2006,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-25cdbca6-6a00-49c4-933c-bd66181f31d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-e2ba708c-7303-4304-9cb9-16de3345b0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022782899-172.17.0.17-1597072832348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-90d0a7eb-d808-4ad1-8d35-de4b3c9e3f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-d8495fba-6969-4565-b00c-e6dfdd5852c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-1d4074eb-1e1c-4a86-92cf-0c03c1b12801,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-c1a42cc3-ba0a-4c46-adf7-9ccfca55996d,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-9b853c39-1187-4a44-a2e2-a0af4e38b034,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-f084dcb8-a7aa-4086-83c9-220bc49c2006,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-25cdbca6-6a00-49c4-933c-bd66181f31d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-e2ba708c-7303-4304-9cb9-16de3345b0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904824632-172.17.0.17-1597073024904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42912,DS-40a981d2-2895-4ad4-ac42-94bd48cd2b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-b56050e2-040f-4f47-af1c-3c1c3a726763,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-06112c87-e053-43a4-8714-60c603198376,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-6ccc038c-c792-498f-9209-00e5c5c885db,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-ed6e35a8-9a27-4542-adf4-0b56b66d432a,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-21482d4e-ecf0-4aba-be45-927fff6755a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-acabe1f7-ac39-4436-8593-6e35b8c08292,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-389bbb8b-0010-403c-a880-1f23bf364133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904824632-172.17.0.17-1597073024904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42912,DS-40a981d2-2895-4ad4-ac42-94bd48cd2b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-b56050e2-040f-4f47-af1c-3c1c3a726763,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-06112c87-e053-43a4-8714-60c603198376,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-6ccc038c-c792-498f-9209-00e5c5c885db,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-ed6e35a8-9a27-4542-adf4-0b56b66d432a,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-21482d4e-ecf0-4aba-be45-927fff6755a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-acabe1f7-ac39-4436-8593-6e35b8c08292,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-389bbb8b-0010-403c-a880-1f23bf364133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068009333-172.17.0.17-1597073145879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-952a83b9-5031-4adb-9ee7-9eadb8e634ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-2293e82e-e7ff-4b7c-95fd-e777b2d52ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-e507031e-7201-4417-a2f4-381cfabd301d,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-4ff9bfc3-6196-41c9-b18a-cdca5be35500,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-884486e3-15e6-4d90-9823-66bda376b649,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-fe61f5c6-5276-44ad-8aa9-e55501565f63,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-356779b0-3968-4181-8df1-2f7d2bc2f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-fe4b8ee3-b082-4f1a-8f09-974b3e423901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068009333-172.17.0.17-1597073145879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-952a83b9-5031-4adb-9ee7-9eadb8e634ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-2293e82e-e7ff-4b7c-95fd-e777b2d52ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-e507031e-7201-4417-a2f4-381cfabd301d,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-4ff9bfc3-6196-41c9-b18a-cdca5be35500,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-884486e3-15e6-4d90-9823-66bda376b649,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-fe61f5c6-5276-44ad-8aa9-e55501565f63,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-356779b0-3968-4181-8df1-2f7d2bc2f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-fe4b8ee3-b082-4f1a-8f09-974b3e423901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539626359-172.17.0.17-1597073452202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34327,DS-7e88a500-aca7-488e-b035-e7b98be65f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-036437c1-4963-4588-b32f-6276e430213c,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-666ab2c7-a385-4e76-b3ac-6a09f266e755,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-8a1b2e58-bdfa-4199-ba05-33ebf483f833,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-ca1c4b15-05f1-4294-a8ac-0fb4eb951da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-17e49f83-5cd2-4b1d-b355-3ace418995ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-1819a467-3da8-4026-947c-0c35102fb358,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-0bdd4f48-0ec5-4679-9e11-f60c78ab91ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539626359-172.17.0.17-1597073452202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34327,DS-7e88a500-aca7-488e-b035-e7b98be65f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-036437c1-4963-4588-b32f-6276e430213c,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-666ab2c7-a385-4e76-b3ac-6a09f266e755,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-8a1b2e58-bdfa-4199-ba05-33ebf483f833,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-ca1c4b15-05f1-4294-a8ac-0fb4eb951da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-17e49f83-5cd2-4b1d-b355-3ace418995ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-1819a467-3da8-4026-947c-0c35102fb358,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-0bdd4f48-0ec5-4679-9e11-f60c78ab91ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106649646-172.17.0.17-1597073906185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39147,DS-c293c231-0cff-44ab-a2b9-c70d0533caf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-e12bcabb-6200-4c94-8551-9a103516d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-a7f433b1-7041-4839-b02f-8db735e11680,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-46eddf52-5a1d-4643-8f13-667340a45f63,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-9c568c8a-fd09-41a4-92d6-53126bb23e44,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-db4d629c-c687-4846-acc8-0e2193f0e48f,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-cfd4bffe-cb3a-4f08-b6cc-199dce60a5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-c909ae13-8ca1-4543-a87d-c06df3d8e86a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106649646-172.17.0.17-1597073906185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39147,DS-c293c231-0cff-44ab-a2b9-c70d0533caf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-e12bcabb-6200-4c94-8551-9a103516d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-a7f433b1-7041-4839-b02f-8db735e11680,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-46eddf52-5a1d-4643-8f13-667340a45f63,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-9c568c8a-fd09-41a4-92d6-53126bb23e44,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-db4d629c-c687-4846-acc8-0e2193f0e48f,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-cfd4bffe-cb3a-4f08-b6cc-199dce60a5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-c909ae13-8ca1-4543-a87d-c06df3d8e86a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436978420-172.17.0.17-1597074027126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-3e6aab5d-cd40-471e-91b1-ef6ad6a673e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-92e7a2a3-110d-46f2-86ee-71c51222b778,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-0adf4858-bbbf-4d8f-91ba-862417131abb,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-2a7fbc80-df48-4831-bbc5-f25a87d77861,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-e2b2c0bb-63f8-46a0-a7bb-e6c0f2041455,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-241df130-4c73-44b7-9b54-71b38f817441,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-10817010-93a9-45b4-8a3f-e52856e02ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-657af5a6-206e-4d02-bb23-6be79a3a9e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436978420-172.17.0.17-1597074027126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-3e6aab5d-cd40-471e-91b1-ef6ad6a673e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-92e7a2a3-110d-46f2-86ee-71c51222b778,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-0adf4858-bbbf-4d8f-91ba-862417131abb,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-2a7fbc80-df48-4831-bbc5-f25a87d77861,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-e2b2c0bb-63f8-46a0-a7bb-e6c0f2041455,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-241df130-4c73-44b7-9b54-71b38f817441,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-10817010-93a9-45b4-8a3f-e52856e02ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-657af5a6-206e-4d02-bb23-6be79a3a9e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024020612-172.17.0.17-1597074271479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46260,DS-ed525008-2169-4a2a-811f-22de7d4121c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-def90963-4c0f-46bc-9a88-a48745abd85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-22f51905-d036-4330-b704-94b836ae7dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-a985aa95-50db-4561-98f2-1eb3d77d3cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-4d66239d-ca33-4ff0-b48c-8d0287964ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-5844d48e-ad7e-43b2-b9a2-9edbedad4b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-e1fe92f6-7149-4449-bd88-1bd156b5a589,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-b1118b51-de08-42bf-831d-468d89b03770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024020612-172.17.0.17-1597074271479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46260,DS-ed525008-2169-4a2a-811f-22de7d4121c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-def90963-4c0f-46bc-9a88-a48745abd85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-22f51905-d036-4330-b704-94b836ae7dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-a985aa95-50db-4561-98f2-1eb3d77d3cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-4d66239d-ca33-4ff0-b48c-8d0287964ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-5844d48e-ad7e-43b2-b9a2-9edbedad4b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-e1fe92f6-7149-4449-bd88-1bd156b5a589,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-b1118b51-de08-42bf-831d-468d89b03770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752341353-172.17.0.17-1597074455660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-dfade984-3e7d-4bce-ba66-040542ba25f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-e6c4dbb7-db8f-4d4a-a27f-06eacf2b90ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-7a2ded9f-bbe3-46aa-af8c-2f145f894f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-374d9e60-cb93-4ca4-ba46-f764ad513caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-9d4d25a1-7282-4a86-8c85-3b9cdc929bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-1f8a9bdc-75e4-4e10-aa96-a552dd87ef8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-fd0a53fc-b648-4b0b-a8a1-c70fb707f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-07371d25-ec3e-4af0-bad9-6c35c2af396b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752341353-172.17.0.17-1597074455660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-dfade984-3e7d-4bce-ba66-040542ba25f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-e6c4dbb7-db8f-4d4a-a27f-06eacf2b90ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-7a2ded9f-bbe3-46aa-af8c-2f145f894f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-374d9e60-cb93-4ca4-ba46-f764ad513caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-9d4d25a1-7282-4a86-8c85-3b9cdc929bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-1f8a9bdc-75e4-4e10-aa96-a552dd87ef8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-fd0a53fc-b648-4b0b-a8a1-c70fb707f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-07371d25-ec3e-4af0-bad9-6c35c2af396b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377072953-172.17.0.17-1597074489900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-9576074b-f118-4a0c-9a85-fe072c39487e,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-b7f5e72a-1b1a-43ae-b106-906667366e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-b5600aa5-3ac0-48ac-a400-499f1822c113,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-7ca81d5d-e1bd-43e9-b9a7-9bea32c73b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-b4a8888c-4d0c-4b2d-830b-54df866d4a17,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-ffe9cd55-258b-41c7-8ae0-eec7ceb882a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-a95c8a6a-9aba-4424-a04a-7464d06f9dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-108b2608-ce2a-4be6-a1b1-1b70229fc685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377072953-172.17.0.17-1597074489900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-9576074b-f118-4a0c-9a85-fe072c39487e,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-b7f5e72a-1b1a-43ae-b106-906667366e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-b5600aa5-3ac0-48ac-a400-499f1822c113,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-7ca81d5d-e1bd-43e9-b9a7-9bea32c73b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-b4a8888c-4d0c-4b2d-830b-54df866d4a17,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-ffe9cd55-258b-41c7-8ae0-eec7ceb882a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-a95c8a6a-9aba-4424-a04a-7464d06f9dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-108b2608-ce2a-4be6-a1b1-1b70229fc685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970037485-172.17.0.17-1597074531624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41939,DS-0c0bbd2c-7dbf-4439-8432-81fd33d840da,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-3c401470-0047-4347-ab25-e0fe29af61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-96bd0643-00df-474c-ab4c-91778f215f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-bfd1a92f-d1a0-495a-81c5-e8f17ffb35af,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-c24d8b53-20b1-474a-ac6a-0633de8cda81,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-7e112190-ba9f-4ee0-b4a6-98570642f853,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-1c9fc4e4-e753-4a5f-bc19-77272c6d9831,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-970d7aec-5a91-4316-955a-c374af356117,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970037485-172.17.0.17-1597074531624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41939,DS-0c0bbd2c-7dbf-4439-8432-81fd33d840da,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-3c401470-0047-4347-ab25-e0fe29af61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-96bd0643-00df-474c-ab4c-91778f215f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-bfd1a92f-d1a0-495a-81c5-e8f17ffb35af,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-c24d8b53-20b1-474a-ac6a-0633de8cda81,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-7e112190-ba9f-4ee0-b4a6-98570642f853,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-1c9fc4e4-e753-4a5f-bc19-77272c6d9831,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-970d7aec-5a91-4316-955a-c374af356117,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582898611-172.17.0.17-1597074575534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40085,DS-fabcc8dd-2c06-4289-99b1-4df6985be6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-6e36d766-f1d8-4b54-8c72-7dc43fa5e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-5376adf8-5a21-48cb-9aec-1de9b98bdcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-62272aeb-d258-471c-ac48-6f7568c2cfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-389403d1-6908-42d2-b6b7-c9c2d9a2c2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-2e918464-7179-47c3-a4c9-b7d7859fa86e,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-cb33ceab-b2fe-44ab-a42d-7e2a308fb82c,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-d8b78e4f-d680-4dc4-a102-f6174f8f0341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582898611-172.17.0.17-1597074575534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40085,DS-fabcc8dd-2c06-4289-99b1-4df6985be6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-6e36d766-f1d8-4b54-8c72-7dc43fa5e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-5376adf8-5a21-48cb-9aec-1de9b98bdcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-62272aeb-d258-471c-ac48-6f7568c2cfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-389403d1-6908-42d2-b6b7-c9c2d9a2c2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-2e918464-7179-47c3-a4c9-b7d7859fa86e,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-cb33ceab-b2fe-44ab-a42d-7e2a308fb82c,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-d8b78e4f-d680-4dc4-a102-f6174f8f0341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866601389-172.17.0.17-1597075082651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40002,DS-9384a18b-49d1-4384-ade6-7de4d1097e28,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-999bfcee-ef43-4150-88a7-df0dec9577d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-720514c3-748b-426f-a794-680a91a434b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-852e100f-dcb1-4bab-8d25-5c22f5a3823a,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-9f88affc-1192-427f-99c2-15a229b7ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-d54d95dc-0e4d-487e-a7e5-2613d7319b75,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-e7134eb5-bcf7-40a5-b3bc-8dfb0d357129,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-80d796ac-7d6d-4c6b-bc36-1d2589b87d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866601389-172.17.0.17-1597075082651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40002,DS-9384a18b-49d1-4384-ade6-7de4d1097e28,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-999bfcee-ef43-4150-88a7-df0dec9577d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-720514c3-748b-426f-a794-680a91a434b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-852e100f-dcb1-4bab-8d25-5c22f5a3823a,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-9f88affc-1192-427f-99c2-15a229b7ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-d54d95dc-0e4d-487e-a7e5-2613d7319b75,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-e7134eb5-bcf7-40a5-b3bc-8dfb0d357129,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-80d796ac-7d6d-4c6b-bc36-1d2589b87d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5861
