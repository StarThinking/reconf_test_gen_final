reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996187586-172.17.0.13-1597095654422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44349,DS-2c735b55-fadc-46ac-a1c3-48a60d0447b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-46cbe800-6f43-44c5-aec2-eed58b51326d,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-c60f3162-e999-41c1-9ba1-3cd2a5254c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-c62a89de-530e-4537-97bf-20e8a414b978,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-4906e2c0-2adf-438d-9304-a00d2f906149,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-80828726-226d-4324-b98f-e8dc7a52e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-6de7582b-f185-4c3e-b8f7-960ab0c754c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-6ce1ad49-b083-4c98-bbb5-581023a492d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996187586-172.17.0.13-1597095654422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44349,DS-2c735b55-fadc-46ac-a1c3-48a60d0447b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-46cbe800-6f43-44c5-aec2-eed58b51326d,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-c60f3162-e999-41c1-9ba1-3cd2a5254c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-c62a89de-530e-4537-97bf-20e8a414b978,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-4906e2c0-2adf-438d-9304-a00d2f906149,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-80828726-226d-4324-b98f-e8dc7a52e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-6de7582b-f185-4c3e-b8f7-960ab0c754c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-6ce1ad49-b083-4c98-bbb5-581023a492d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847432765-172.17.0.13-1597095724904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43495,DS-f339e937-b6ca-46f8-9f2d-9c6f09b09637,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-8414980a-7140-43cd-9024-3743e7ad4c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-2b6335a9-a400-4b52-92af-49017ed30fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-4dd2436e-cdb7-4563-be47-33158256cfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-2838a745-698c-4640-b9f4-5dc8c3231b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-cce5d72a-af8c-4d2d-aa53-e139e8b7df4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-d6a499b4-7f7c-4c43-8ba3-1026b4e074bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-9ede46d0-a51c-4dd7-a667-52a4f1ab392d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847432765-172.17.0.13-1597095724904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43495,DS-f339e937-b6ca-46f8-9f2d-9c6f09b09637,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-8414980a-7140-43cd-9024-3743e7ad4c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-2b6335a9-a400-4b52-92af-49017ed30fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-4dd2436e-cdb7-4563-be47-33158256cfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-2838a745-698c-4640-b9f4-5dc8c3231b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-cce5d72a-af8c-4d2d-aa53-e139e8b7df4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-d6a499b4-7f7c-4c43-8ba3-1026b4e074bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-9ede46d0-a51c-4dd7-a667-52a4f1ab392d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279199207-172.17.0.13-1597095942345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44577,DS-5350b7ef-6b66-4788-b3e8-4f341ef0870f,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-78a1590c-86af-4ce0-92ef-89ce6bc7fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-b248b155-a2ef-47b9-8757-e68eb714aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-f944083e-f3f5-4444-a6cd-8b23f89200b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-02f4004f-d259-4ad2-9602-6b916289caa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-a787a897-e260-4dc8-b8cb-2d35d1397a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-c0a4c3da-c117-4fe8-8b99-2f522e7351ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-ff5fef70-4aec-447e-994f-aab61fc4ef3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279199207-172.17.0.13-1597095942345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44577,DS-5350b7ef-6b66-4788-b3e8-4f341ef0870f,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-78a1590c-86af-4ce0-92ef-89ce6bc7fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-b248b155-a2ef-47b9-8757-e68eb714aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-f944083e-f3f5-4444-a6cd-8b23f89200b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-02f4004f-d259-4ad2-9602-6b916289caa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-a787a897-e260-4dc8-b8cb-2d35d1397a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-c0a4c3da-c117-4fe8-8b99-2f522e7351ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-ff5fef70-4aec-447e-994f-aab61fc4ef3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825443326-172.17.0.13-1597096693110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-6174b33d-7532-4624-bc75-4188c891a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-42cc5ea5-5a96-40c6-80ad-1adebfbd5ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-8d675377-ca5e-4fea-aae4-d5b60dadf9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-6d7f243a-4c80-40ca-98e0-102d989b6d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-039fd939-1068-4806-9024-2daed5cdba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-e8922fe1-ea1d-43e9-8afc-1f0e5cf9f70b,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-9dcb050b-1efe-41e0-85be-30d5de795ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-e22a48a1-cbf5-45e8-b493-cefb9ca19730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825443326-172.17.0.13-1597096693110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-6174b33d-7532-4624-bc75-4188c891a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-42cc5ea5-5a96-40c6-80ad-1adebfbd5ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-8d675377-ca5e-4fea-aae4-d5b60dadf9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-6d7f243a-4c80-40ca-98e0-102d989b6d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-039fd939-1068-4806-9024-2daed5cdba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-e8922fe1-ea1d-43e9-8afc-1f0e5cf9f70b,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-9dcb050b-1efe-41e0-85be-30d5de795ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-e22a48a1-cbf5-45e8-b493-cefb9ca19730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051042036-172.17.0.13-1597096772882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35935,DS-40d8ae29-c4c6-40a0-b7dc-b8dc075b5b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-1c1cc2b7-8ae9-4a6d-9d3e-c50ba68cefb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-e6fd9cf9-1291-4084-b94b-58df51b38c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-803c8d9e-fb83-4992-939d-c06a934f059c,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-21571a48-b097-47cf-94fd-7b7bd9406990,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-5402e706-2cb0-4622-80d0-8170f4a13e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-e5c70454-8bc1-44a9-b560-7d5102f8413b,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-1556b9f4-1eb8-4fbc-83f2-f0a3adb520da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051042036-172.17.0.13-1597096772882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35935,DS-40d8ae29-c4c6-40a0-b7dc-b8dc075b5b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-1c1cc2b7-8ae9-4a6d-9d3e-c50ba68cefb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-e6fd9cf9-1291-4084-b94b-58df51b38c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-803c8d9e-fb83-4992-939d-c06a934f059c,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-21571a48-b097-47cf-94fd-7b7bd9406990,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-5402e706-2cb0-4622-80d0-8170f4a13e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-e5c70454-8bc1-44a9-b560-7d5102f8413b,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-1556b9f4-1eb8-4fbc-83f2-f0a3adb520da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90728832-172.17.0.13-1597097172673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-510105c8-0c3a-4e94-a851-879ff885037f,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-148b23ad-8544-42d1-832e-b4ca23f14cac,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-5552ca7c-fd58-4868-87bc-efcff6db839e,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-437539da-4653-47b9-8119-68c8108b297c,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-69c16b31-b5c6-4a64-accf-a24184c6eeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-76ad7150-3003-456c-9ace-5aa9972fa606,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-ed1d3466-c49b-44c3-ad83-46ff86578091,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-1d3a83d0-efc4-4d1a-a0d7-dac9da8ce7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90728832-172.17.0.13-1597097172673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-510105c8-0c3a-4e94-a851-879ff885037f,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-148b23ad-8544-42d1-832e-b4ca23f14cac,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-5552ca7c-fd58-4868-87bc-efcff6db839e,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-437539da-4653-47b9-8119-68c8108b297c,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-69c16b31-b5c6-4a64-accf-a24184c6eeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-76ad7150-3003-456c-9ace-5aa9972fa606,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-ed1d3466-c49b-44c3-ad83-46ff86578091,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-1d3a83d0-efc4-4d1a-a0d7-dac9da8ce7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064665354-172.17.0.13-1597097444626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-8c1bfa1f-a2a0-43dc-85d5-4e78211bb382,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-1dc52565-f64a-412d-9b58-4da9bd4c2c33,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-564ad78e-a6a0-4e47-9904-5a709baf8c15,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-f958ef8a-43b9-4873-94bb-5da47c589838,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-29331cbb-ce0b-42fe-9c2e-3e104275de51,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-08889d29-0155-425c-979b-1eed5fa8ee31,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-91dac1a5-d5bf-4de4-835f-2f736ec4bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-e8b7e83c-e0e5-4fe9-a38f-f2dc18103f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064665354-172.17.0.13-1597097444626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-8c1bfa1f-a2a0-43dc-85d5-4e78211bb382,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-1dc52565-f64a-412d-9b58-4da9bd4c2c33,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-564ad78e-a6a0-4e47-9904-5a709baf8c15,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-f958ef8a-43b9-4873-94bb-5da47c589838,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-29331cbb-ce0b-42fe-9c2e-3e104275de51,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-08889d29-0155-425c-979b-1eed5fa8ee31,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-91dac1a5-d5bf-4de4-835f-2f736ec4bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-e8b7e83c-e0e5-4fe9-a38f-f2dc18103f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163951453-172.17.0.13-1597097950963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37891,DS-ae5e6ea6-964b-45cf-84d8-67e71c5eb556,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-f0f02456-b49c-4572-b188-fa8a53911462,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-d6791fac-9285-4bf4-9581-4f759a793bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-ed748558-11e8-49f1-ae72-fc689133d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-42670c63-0c67-4eeb-a458-a68e4f96e031,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-c56bc680-9756-47b9-8641-0956c23d85e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-d37d400d-a0a2-4445-a3a7-6f30b2a90964,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-5e8aa878-c37a-43e0-9f6b-9cea1a98f9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163951453-172.17.0.13-1597097950963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37891,DS-ae5e6ea6-964b-45cf-84d8-67e71c5eb556,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-f0f02456-b49c-4572-b188-fa8a53911462,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-d6791fac-9285-4bf4-9581-4f759a793bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-ed748558-11e8-49f1-ae72-fc689133d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-42670c63-0c67-4eeb-a458-a68e4f96e031,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-c56bc680-9756-47b9-8641-0956c23d85e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-d37d400d-a0a2-4445-a3a7-6f30b2a90964,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-5e8aa878-c37a-43e0-9f6b-9cea1a98f9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513768999-172.17.0.13-1597097985670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37369,DS-ec3fec6c-b09d-4668-90e1-5c8f961e168b,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-bd0f0812-d587-49f6-841c-3bc6dfcc9341,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-819de20c-82b5-4d02-9b53-ebac53434e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-48a74fd7-cb47-4ce3-a137-acc6572f4484,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-542afd57-2bc0-4efd-82f6-7ba7ed742a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-f43af1ba-adb9-4531-bc10-0969e07fc3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-0e4e76a8-8b20-47ff-afda-848797a089c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-88d7c1f1-13b9-4477-9021-ac082d448abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513768999-172.17.0.13-1597097985670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37369,DS-ec3fec6c-b09d-4668-90e1-5c8f961e168b,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-bd0f0812-d587-49f6-841c-3bc6dfcc9341,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-819de20c-82b5-4d02-9b53-ebac53434e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-48a74fd7-cb47-4ce3-a137-acc6572f4484,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-542afd57-2bc0-4efd-82f6-7ba7ed742a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-f43af1ba-adb9-4531-bc10-0969e07fc3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-0e4e76a8-8b20-47ff-afda-848797a089c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-88d7c1f1-13b9-4477-9021-ac082d448abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97112142-172.17.0.13-1597099360117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40202,DS-1a85dbd1-3a97-4911-928b-99f7f0a77ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-e43ae340-0ba1-48b3-911d-cff7651a7f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-cce44c95-2e4a-42f0-b077-d17437503824,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-80759fea-7993-4916-b508-1418fb6ea6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-c1dfcb65-55c9-486a-af5e-efe9bd201f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-8da38217-1003-4211-a186-1b0ab520770e,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-17c8a8da-821c-4d8a-8a52-c5f49e60fa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-a6c4ed95-e244-4952-975e-238a630f6e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97112142-172.17.0.13-1597099360117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40202,DS-1a85dbd1-3a97-4911-928b-99f7f0a77ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-e43ae340-0ba1-48b3-911d-cff7651a7f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-cce44c95-2e4a-42f0-b077-d17437503824,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-80759fea-7993-4916-b508-1418fb6ea6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-c1dfcb65-55c9-486a-af5e-efe9bd201f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-8da38217-1003-4211-a186-1b0ab520770e,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-17c8a8da-821c-4d8a-8a52-c5f49e60fa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-a6c4ed95-e244-4952-975e-238a630f6e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039635568-172.17.0.13-1597099550555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42802,DS-4f212088-65e0-4593-bf0c-eced8ad78504,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-cb94421b-8625-4ae8-a015-c2516d4e48c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-879e2883-992b-4a94-8ae1-6da6d628c666,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-cd9563b1-c2f6-4e72-adb7-aaef63d018c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-6d4d565a-bfe4-4763-afe9-d41e86dae26e,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-172f98ac-8d00-4713-9818-a62d914a0c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-5305bae2-faeb-4e71-8113-743bcbecee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-be3a6a81-f05a-4f5f-ad6a-6649a166f1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039635568-172.17.0.13-1597099550555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42802,DS-4f212088-65e0-4593-bf0c-eced8ad78504,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-cb94421b-8625-4ae8-a015-c2516d4e48c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-879e2883-992b-4a94-8ae1-6da6d628c666,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-cd9563b1-c2f6-4e72-adb7-aaef63d018c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-6d4d565a-bfe4-4763-afe9-d41e86dae26e,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-172f98ac-8d00-4713-9818-a62d914a0c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-5305bae2-faeb-4e71-8113-743bcbecee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-be3a6a81-f05a-4f5f-ad6a-6649a166f1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317818089-172.17.0.13-1597099976604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-2ee4a5e2-c57f-46e1-8d5b-243c746b683b,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-30b8aa5a-b454-4295-81f3-dab7069ed6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-f8711da7-8509-4ff7-a015-f379c665cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-8dc65be8-b294-48a4-b8a8-e020450c558e,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-75314724-f11c-4211-8b9d-e1d747e45c41,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-2968418e-2019-4802-b340-f7a3b7bb0611,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-a109c84d-c321-45d9-9985-efcf39ffe095,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-f05b9ba4-39b3-4b18-9964-8f5d174dbc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317818089-172.17.0.13-1597099976604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-2ee4a5e2-c57f-46e1-8d5b-243c746b683b,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-30b8aa5a-b454-4295-81f3-dab7069ed6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-f8711da7-8509-4ff7-a015-f379c665cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-8dc65be8-b294-48a4-b8a8-e020450c558e,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-75314724-f11c-4211-8b9d-e1d747e45c41,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-2968418e-2019-4802-b340-f7a3b7bb0611,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-a109c84d-c321-45d9-9985-efcf39ffe095,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-f05b9ba4-39b3-4b18-9964-8f5d174dbc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888985144-172.17.0.13-1597100083338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43507,DS-373c097a-7793-465a-b165-1ebb92d36d14,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-aab661cc-e23c-4b96-9f12-a8b777eeafb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-d1146d7b-46ba-48a9-8d8b-325ebcda2cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-bc7fa9c9-7e26-4ddf-9205-e1c461f1a107,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-0e6a6ca9-ac36-4a33-80a5-56a483c89a84,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-9886ea02-cbe3-4c4e-9ba8-587656d712af,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-d5c3ee35-2e4a-4663-a03b-ae3519282264,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-d9a080ed-7467-496a-bf9a-95a05690cf1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888985144-172.17.0.13-1597100083338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43507,DS-373c097a-7793-465a-b165-1ebb92d36d14,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-aab661cc-e23c-4b96-9f12-a8b777eeafb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-d1146d7b-46ba-48a9-8d8b-325ebcda2cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-bc7fa9c9-7e26-4ddf-9205-e1c461f1a107,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-0e6a6ca9-ac36-4a33-80a5-56a483c89a84,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-9886ea02-cbe3-4c4e-9ba8-587656d712af,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-d5c3ee35-2e4a-4663-a03b-ae3519282264,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-d9a080ed-7467-496a-bf9a-95a05690cf1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955844853-172.17.0.13-1597100122756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-8b7ae562-0b9f-4345-afbb-79c15b7aecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-cbf52663-c2c2-4d98-97b6-cf38069b99f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-ef47f60e-45ec-4be1-8a07-6fdae1d5ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-58e8ab0a-8743-4ebc-8732-ee5dccec773a,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-fe2404aa-832e-45ee-a655-619276f63e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-eddf0a84-e2f8-48b6-9e3c-1f3faeb5c784,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-a1c680e9-2693-49cb-9e8c-1e933b5a374c,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-21cf4b59-1aff-41d1-bb8e-dee66e3b4f58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955844853-172.17.0.13-1597100122756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-8b7ae562-0b9f-4345-afbb-79c15b7aecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-cbf52663-c2c2-4d98-97b6-cf38069b99f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-ef47f60e-45ec-4be1-8a07-6fdae1d5ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-58e8ab0a-8743-4ebc-8732-ee5dccec773a,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-fe2404aa-832e-45ee-a655-619276f63e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-eddf0a84-e2f8-48b6-9e3c-1f3faeb5c784,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-a1c680e9-2693-49cb-9e8c-1e933b5a374c,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-21cf4b59-1aff-41d1-bb8e-dee66e3b4f58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743105469-172.17.0.13-1597100195152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-5d399499-9d37-4a9a-a43d-3f28519206b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-dd4b32a2-bb95-4e0a-a1d1-b3a4e819c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-de8ab3f1-8848-4d34-9004-214936ae075b,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-4fc8664a-d5d8-4c1f-a0f0-92b001c33f24,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-a78b707c-a715-47f3-b480-b63e8ce0c163,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-2292a875-3057-4bef-b214-c0f1ed9dcfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-e20288f4-c772-4e3c-aea6-24a9fc36d055,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-11f165be-ed15-41c8-9eee-7098169476ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743105469-172.17.0.13-1597100195152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-5d399499-9d37-4a9a-a43d-3f28519206b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-dd4b32a2-bb95-4e0a-a1d1-b3a4e819c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-de8ab3f1-8848-4d34-9004-214936ae075b,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-4fc8664a-d5d8-4c1f-a0f0-92b001c33f24,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-a78b707c-a715-47f3-b480-b63e8ce0c163,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-2292a875-3057-4bef-b214-c0f1ed9dcfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-e20288f4-c772-4e3c-aea6-24a9fc36d055,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-11f165be-ed15-41c8-9eee-7098169476ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262665933-172.17.0.13-1597100339026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45658,DS-df5c6141-6333-433e-9252-1e3ac5f9614d,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-ad6ecaa5-80c7-4e9a-b43b-79d359e587ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-57dae06e-5a14-4f82-a99d-70bcb4c7abda,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-acfc5031-0afc-4ad4-bc20-34805cb4dd12,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-803a78f9-d8c1-4107-9a89-9d84ee932f65,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-d4d535df-3be1-4158-8940-1683a108b297,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-f53fe2a3-0726-4972-aba9-8f08f28a962c,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-71083729-a599-442c-9cdc-75783d01a908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262665933-172.17.0.13-1597100339026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45658,DS-df5c6141-6333-433e-9252-1e3ac5f9614d,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-ad6ecaa5-80c7-4e9a-b43b-79d359e587ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-57dae06e-5a14-4f82-a99d-70bcb4c7abda,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-acfc5031-0afc-4ad4-bc20-34805cb4dd12,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-803a78f9-d8c1-4107-9a89-9d84ee932f65,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-d4d535df-3be1-4158-8940-1683a108b297,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-f53fe2a3-0726-4972-aba9-8f08f28a962c,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-71083729-a599-442c-9cdc-75783d01a908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837309113-172.17.0.13-1597100563833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39413,DS-a7fc55dd-9675-40ae-af86-a22d413dfea6,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-7a54bdb0-2856-4957-b84a-436d5759a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-df0da326-8970-4307-b5b1-e95973cb5e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-c6188f59-db35-4769-9997-d866aee6bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-0c9a9254-551f-40e2-99e8-d75328ab937b,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-67a2ed23-595b-4227-bef2-6e1cf5085d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-21896771-6546-4e30-9ec8-81b692488d43,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-f9d6b98f-7e6f-4778-b633-420852d6fb26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837309113-172.17.0.13-1597100563833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39413,DS-a7fc55dd-9675-40ae-af86-a22d413dfea6,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-7a54bdb0-2856-4957-b84a-436d5759a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-df0da326-8970-4307-b5b1-e95973cb5e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-c6188f59-db35-4769-9997-d866aee6bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-0c9a9254-551f-40e2-99e8-d75328ab937b,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-67a2ed23-595b-4227-bef2-6e1cf5085d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-21896771-6546-4e30-9ec8-81b692488d43,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-f9d6b98f-7e6f-4778-b633-420852d6fb26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519553486-172.17.0.13-1597100665051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34825,DS-ac359447-ad37-4e4f-b1dc-a3d22edf90a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-59a14fe8-f0fa-4fc8-a2f4-ccdfc7a9c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-00c9e7bc-2c4c-47c8-ac55-4b41e5bd1d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-fe46e004-542e-46d5-ae24-55fad4eed5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-96da16a7-441f-4753-9883-190a007cbd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-3987862f-664d-4b13-9a2e-9e7f148cd4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-a1868c4f-33b5-4ae8-85dc-ff07fbf5bdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-763c1c78-2d4d-4a1e-b970-c912064cf286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519553486-172.17.0.13-1597100665051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34825,DS-ac359447-ad37-4e4f-b1dc-a3d22edf90a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-59a14fe8-f0fa-4fc8-a2f4-ccdfc7a9c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-00c9e7bc-2c4c-47c8-ac55-4b41e5bd1d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-fe46e004-542e-46d5-ae24-55fad4eed5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-96da16a7-441f-4753-9883-190a007cbd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-3987862f-664d-4b13-9a2e-9e7f148cd4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-a1868c4f-33b5-4ae8-85dc-ff07fbf5bdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-763c1c78-2d4d-4a1e-b970-c912064cf286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054729994-172.17.0.13-1597100795191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-c3845881-38e8-40c6-9ae4-e137ee757427,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-28571aee-165f-4c43-bd2c-2a97867bc70f,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-70a257d6-b463-4030-a31a-c4483a3b6b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-71779f09-d143-42ec-82c0-f65f57bdf56f,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-f65304b6-f3a3-48ce-b5ae-e101f8296392,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-14a49c96-c1c2-4c82-987d-db8c64260de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-545e8256-4d91-4bd8-88d2-a9e5183ca630,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-00fe6d99-d88f-4213-a3cf-e5d5d7819643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054729994-172.17.0.13-1597100795191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-c3845881-38e8-40c6-9ae4-e137ee757427,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-28571aee-165f-4c43-bd2c-2a97867bc70f,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-70a257d6-b463-4030-a31a-c4483a3b6b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-71779f09-d143-42ec-82c0-f65f57bdf56f,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-f65304b6-f3a3-48ce-b5ae-e101f8296392,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-14a49c96-c1c2-4c82-987d-db8c64260de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-545e8256-4d91-4bd8-88d2-a9e5183ca630,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-00fe6d99-d88f-4213-a3cf-e5d5d7819643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5251
