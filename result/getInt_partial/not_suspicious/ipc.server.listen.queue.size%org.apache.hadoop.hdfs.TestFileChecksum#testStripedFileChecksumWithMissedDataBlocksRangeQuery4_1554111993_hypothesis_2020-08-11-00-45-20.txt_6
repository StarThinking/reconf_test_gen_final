reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316095365-172.17.0.6-1597106771806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-8b5d717e-703d-45fa-a17a-019b3ee13008,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-66363309-a71d-48fa-acbe-2b606183bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-31f7eaef-6dba-4b6d-b753-8571b06daab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-c03ef0c7-40e1-4fae-a6d8-1b4e0cbd1185,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-6943ce47-dfd8-4b73-b840-699ca1891f89,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-e42b2f68-61da-4f31-afb3-fd2068240a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-388d8fdb-6b89-4c7c-a5b3-3d2c5cc70878,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-591eb0b1-ed28-4f56-8df2-351098a0dcac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316095365-172.17.0.6-1597106771806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-8b5d717e-703d-45fa-a17a-019b3ee13008,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-66363309-a71d-48fa-acbe-2b606183bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-31f7eaef-6dba-4b6d-b753-8571b06daab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-c03ef0c7-40e1-4fae-a6d8-1b4e0cbd1185,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-6943ce47-dfd8-4b73-b840-699ca1891f89,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-e42b2f68-61da-4f31-afb3-fd2068240a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-388d8fdb-6b89-4c7c-a5b3-3d2c5cc70878,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-591eb0b1-ed28-4f56-8df2-351098a0dcac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974184307-172.17.0.6-1597107353922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36497,DS-3e5440e4-5b43-4b5c-8ec5-9b9557d70ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-488c9ff6-4264-406d-a984-197f4c7a50d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-ff16721a-e174-4b77-9e27-c011cb0f19a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-954c9710-9907-4238-9e43-056bb7087ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-cdb378a9-6de8-42e8-98f5-dfbca387785e,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-f812dac9-0a41-4cd5-81c5-98b57b5091df,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-d65ab79a-8232-489a-bd5b-a4c51ddf049c,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-466af9e5-f0c0-48ff-9fb5-e91183076c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974184307-172.17.0.6-1597107353922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36497,DS-3e5440e4-5b43-4b5c-8ec5-9b9557d70ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-488c9ff6-4264-406d-a984-197f4c7a50d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-ff16721a-e174-4b77-9e27-c011cb0f19a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-954c9710-9907-4238-9e43-056bb7087ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-cdb378a9-6de8-42e8-98f5-dfbca387785e,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-f812dac9-0a41-4cd5-81c5-98b57b5091df,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-d65ab79a-8232-489a-bd5b-a4c51ddf049c,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-466af9e5-f0c0-48ff-9fb5-e91183076c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770859427-172.17.0.6-1597107794626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45548,DS-56e05059-eddc-48d1-834a-9d88016857b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-f1aca646-b586-451b-9ea8-9451efcc1d03,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-c47e07db-91ac-4709-89c8-c50a9586f290,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-8e621ef4-b5fa-4ee6-8312-bda04a214d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-d80b78da-3f96-4dcb-9bba-16f17747dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-c7d01705-8dae-4dec-9a62-dad2a12435fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-9ae58494-184b-48b0-9fb5-939b0b411df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-0adb3cfc-2fd1-48e4-ba8e-f39bb3a3287c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770859427-172.17.0.6-1597107794626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45548,DS-56e05059-eddc-48d1-834a-9d88016857b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-f1aca646-b586-451b-9ea8-9451efcc1d03,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-c47e07db-91ac-4709-89c8-c50a9586f290,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-8e621ef4-b5fa-4ee6-8312-bda04a214d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-d80b78da-3f96-4dcb-9bba-16f17747dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-c7d01705-8dae-4dec-9a62-dad2a12435fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-9ae58494-184b-48b0-9fb5-939b0b411df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-0adb3cfc-2fd1-48e4-ba8e-f39bb3a3287c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084132027-172.17.0.6-1597107828377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46084,DS-f71446fa-5ec7-41ee-9092-a2f6faa6b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-47ec0621-310b-4403-86db-89413e8799fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-fd301be3-584a-42e2-ad90-212b7c4da2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-6cf25a97-0100-410a-8df5-06dda5d301c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-7d161cd5-b9b4-428d-954c-4a1ee9dc48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-26532836-b4d4-47cb-b80d-4c036302d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-62f639fe-ed3b-4ac3-9f29-f24fc8854487,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-91e67f1b-940e-4064-8878-8378907ff1c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084132027-172.17.0.6-1597107828377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46084,DS-f71446fa-5ec7-41ee-9092-a2f6faa6b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-47ec0621-310b-4403-86db-89413e8799fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-fd301be3-584a-42e2-ad90-212b7c4da2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-6cf25a97-0100-410a-8df5-06dda5d301c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-7d161cd5-b9b4-428d-954c-4a1ee9dc48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-26532836-b4d4-47cb-b80d-4c036302d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-62f639fe-ed3b-4ac3-9f29-f24fc8854487,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-91e67f1b-940e-4064-8878-8378907ff1c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583475747-172.17.0.6-1597107936255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-8033c9d8-b148-4c27-9e36-2d10db51907b,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-b4a1f9f9-7b09-4bad-b301-722ec359eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-8d77e834-5ec9-4f60-b290-972d0df3d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-8b8388d8-da98-4832-8c5d-7402b70ab97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-6dbf3163-9f19-4bd1-adfc-4eeaaa9a50a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-f0e4cba9-70cd-4efa-b593-280019179b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-e621b49a-eaaf-4c4c-81d8-7a06e78e53ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-c7222c83-6d06-4d6f-87ac-9bee21a06ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583475747-172.17.0.6-1597107936255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-8033c9d8-b148-4c27-9e36-2d10db51907b,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-b4a1f9f9-7b09-4bad-b301-722ec359eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-8d77e834-5ec9-4f60-b290-972d0df3d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-8b8388d8-da98-4832-8c5d-7402b70ab97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-6dbf3163-9f19-4bd1-adfc-4eeaaa9a50a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-f0e4cba9-70cd-4efa-b593-280019179b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-e621b49a-eaaf-4c4c-81d8-7a06e78e53ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-c7222c83-6d06-4d6f-87ac-9bee21a06ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979580156-172.17.0.6-1597108257914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-e072ddda-2980-4505-974a-55c5869935ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-6e717e11-7d1b-43d9-8f10-5537c1414fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-fcbef559-5aaf-41b6-9dcc-f349126de157,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-876afa54-64ec-4d36-89f7-7f73a5ca1510,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-7a24eab5-e4b6-41c2-82cd-181b25d0287f,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-f0848be6-efeb-4183-9417-6e3d0a1b8168,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-188099d6-08a4-4369-a548-ceff018d1a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-3e961915-2752-4f33-863e-678ba570c473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979580156-172.17.0.6-1597108257914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-e072ddda-2980-4505-974a-55c5869935ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-6e717e11-7d1b-43d9-8f10-5537c1414fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-fcbef559-5aaf-41b6-9dcc-f349126de157,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-876afa54-64ec-4d36-89f7-7f73a5ca1510,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-7a24eab5-e4b6-41c2-82cd-181b25d0287f,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-f0848be6-efeb-4183-9417-6e3d0a1b8168,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-188099d6-08a4-4369-a548-ceff018d1a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-3e961915-2752-4f33-863e-678ba570c473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088119114-172.17.0.6-1597109865963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-cca71ff3-0141-4435-ae50-9537f7df32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-10d4eaa4-4988-446f-80d1-ea378dc0f8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-8c73845c-622d-405d-83a1-282ee76ea2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-5ded5061-10f9-4d35-802a-629377398069,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-0a1a01c5-1b94-4489-b877-f89399e8ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-68fb6937-75e8-41d2-b0d5-05b075316b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-0367206b-8c36-48a9-b3b8-1d504eb882cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-6267b210-ed14-49d8-ad29-91487d57c325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088119114-172.17.0.6-1597109865963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-cca71ff3-0141-4435-ae50-9537f7df32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-10d4eaa4-4988-446f-80d1-ea378dc0f8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-8c73845c-622d-405d-83a1-282ee76ea2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-5ded5061-10f9-4d35-802a-629377398069,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-0a1a01c5-1b94-4489-b877-f89399e8ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-68fb6937-75e8-41d2-b0d5-05b075316b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-0367206b-8c36-48a9-b3b8-1d504eb882cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-6267b210-ed14-49d8-ad29-91487d57c325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453419771-172.17.0.6-1597109947055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-c77b4ea9-0e78-4a85-a94c-7fcd8faf5197,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-3dc1a6bd-c73d-4559-8073-5b1ebf990e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-e65dd718-a3ce-4f8e-b871-48943fca5a32,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-eff78100-8895-4707-a20e-ce5ab2bfd484,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-97db1636-a988-49f0-8f66-e28819f32b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-e6c99b1a-5db8-4c50-bd2a-9aac383e3df5,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-c0e57156-0fbe-49fa-b71f-9ecda057893a,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-e7b9dadf-e84c-4940-ac3e-b8d8b8b68916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453419771-172.17.0.6-1597109947055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-c77b4ea9-0e78-4a85-a94c-7fcd8faf5197,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-3dc1a6bd-c73d-4559-8073-5b1ebf990e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-e65dd718-a3ce-4f8e-b871-48943fca5a32,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-eff78100-8895-4707-a20e-ce5ab2bfd484,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-97db1636-a988-49f0-8f66-e28819f32b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-e6c99b1a-5db8-4c50-bd2a-9aac383e3df5,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-c0e57156-0fbe-49fa-b71f-9ecda057893a,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-e7b9dadf-e84c-4940-ac3e-b8d8b8b68916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886451711-172.17.0.6-1597110084503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41438,DS-eef4f002-7a2d-44e9-a183-cbc8a220adf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-e5538df7-5271-4176-bb7e-06313d7a0116,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-38c6d23e-2b5a-4e13-9b03-a27cec6dabb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-8eed9fdb-a745-40e0-ba0c-4cb18c471669,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-36e41d26-4ce4-46e0-9686-644cc04985dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-130b96f7-f460-436c-855c-a4b42cf2b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-0a181d69-4d84-46c5-80b5-86119bebe8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-554ce5f8-14b6-49fa-830a-81a01188b246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886451711-172.17.0.6-1597110084503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41438,DS-eef4f002-7a2d-44e9-a183-cbc8a220adf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-e5538df7-5271-4176-bb7e-06313d7a0116,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-38c6d23e-2b5a-4e13-9b03-a27cec6dabb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-8eed9fdb-a745-40e0-ba0c-4cb18c471669,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-36e41d26-4ce4-46e0-9686-644cc04985dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-130b96f7-f460-436c-855c-a4b42cf2b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-0a181d69-4d84-46c5-80b5-86119bebe8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-554ce5f8-14b6-49fa-830a-81a01188b246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278484104-172.17.0.6-1597110223770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46873,DS-5d460802-d193-4cb9-9bb9-d5ae26a324fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-cdd2ada8-13db-4d66-896e-dbc777f23a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-3d52d11a-0042-44fb-85bf-8afd731bf55b,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-5cc89039-e9f1-49be-84ee-88adc3ba9689,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-a6a13a17-f887-4540-ad1a-5755f53f794d,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-1bea2509-6ed3-4ef3-b65f-fe46b972e232,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-2b2669c2-74ed-4a95-b154-0eca14f473ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-4514a89d-2bf4-447f-a958-3e1bc86e01d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278484104-172.17.0.6-1597110223770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46873,DS-5d460802-d193-4cb9-9bb9-d5ae26a324fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-cdd2ada8-13db-4d66-896e-dbc777f23a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-3d52d11a-0042-44fb-85bf-8afd731bf55b,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-5cc89039-e9f1-49be-84ee-88adc3ba9689,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-a6a13a17-f887-4540-ad1a-5755f53f794d,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-1bea2509-6ed3-4ef3-b65f-fe46b972e232,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-2b2669c2-74ed-4a95-b154-0eca14f473ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-4514a89d-2bf4-447f-a958-3e1bc86e01d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400352812-172.17.0.6-1597110547705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44680,DS-e70f5c3e-eac7-4df6-8f86-fa66f2a2d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-db1a60c3-8f9d-4903-9c3a-0a778646305f,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-e9e2f1f4-402f-4d16-8963-90310f3bc854,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-e8492dec-12b1-4737-82c4-139537f1d781,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-3d34931a-bbcc-48de-a3c8-7a84f3a1cc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-3d1fd4b2-aa4e-4b69-87d5-09549666bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-6b822e3d-351a-4daf-a0f2-880cad086d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-365975ab-7c6d-4a19-8155-aaa20a0dc9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400352812-172.17.0.6-1597110547705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44680,DS-e70f5c3e-eac7-4df6-8f86-fa66f2a2d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-db1a60c3-8f9d-4903-9c3a-0a778646305f,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-e9e2f1f4-402f-4d16-8963-90310f3bc854,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-e8492dec-12b1-4737-82c4-139537f1d781,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-3d34931a-bbcc-48de-a3c8-7a84f3a1cc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-3d1fd4b2-aa4e-4b69-87d5-09549666bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-6b822e3d-351a-4daf-a0f2-880cad086d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-365975ab-7c6d-4a19-8155-aaa20a0dc9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889093170-172.17.0.6-1597111434653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-77236df8-c902-4c5f-a92b-1ee8760a0b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-de8934cd-1143-46c9-931e-b302beac9948,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-f7252e27-c92e-480d-962a-24d1ed97510a,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-b7a1df35-9e21-4810-8e82-7bc17334bc55,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-292b4b1f-9b04-4960-bc93-b7b6d01738ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-7fa979cb-1fbd-4ece-a756-34021d655697,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-6e50155c-c901-47fa-b359-17929f9a17b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-0d12fc2c-e1a9-4561-9a6b-52a59fdc098c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889093170-172.17.0.6-1597111434653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-77236df8-c902-4c5f-a92b-1ee8760a0b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-de8934cd-1143-46c9-931e-b302beac9948,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-f7252e27-c92e-480d-962a-24d1ed97510a,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-b7a1df35-9e21-4810-8e82-7bc17334bc55,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-292b4b1f-9b04-4960-bc93-b7b6d01738ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-7fa979cb-1fbd-4ece-a756-34021d655697,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-6e50155c-c901-47fa-b359-17929f9a17b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-0d12fc2c-e1a9-4561-9a6b-52a59fdc098c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645147406-172.17.0.6-1597111508001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42301,DS-48774711-6ede-45ae-8fa7-6ace2e9f3321,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-ee6484f8-b6db-4b9e-9104-12d73c622e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-94d8550e-a719-4efc-8c4d-ca48efeca439,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-6406eca5-63be-4727-af23-5bba8b76ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-d001d8ca-57e0-4bb7-81ff-bcc4099a3a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-c863ad3c-4488-45c0-85af-e1e7d4c51773,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-0155585f-4bc4-4257-8fad-5936d0e1797a,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-51af236c-ede8-440b-9db3-60094f8cc33a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645147406-172.17.0.6-1597111508001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42301,DS-48774711-6ede-45ae-8fa7-6ace2e9f3321,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-ee6484f8-b6db-4b9e-9104-12d73c622e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-94d8550e-a719-4efc-8c4d-ca48efeca439,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-6406eca5-63be-4727-af23-5bba8b76ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-d001d8ca-57e0-4bb7-81ff-bcc4099a3a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-c863ad3c-4488-45c0-85af-e1e7d4c51773,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-0155585f-4bc4-4257-8fad-5936d0e1797a,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-51af236c-ede8-440b-9db3-60094f8cc33a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455376214-172.17.0.6-1597111538872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35913,DS-a68ec979-0f7a-4028-930d-f65b02324a14,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-2053996d-55d6-40e0-8cbe-8680623b8c13,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-89e54962-0432-4aad-a522-7e6a9bbff520,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-71050f14-1d84-4f13-bf6c-95f5a4672139,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-a2d98ad4-1a2a-4391-9170-73ba19ee7026,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-25fd75e9-e240-4a32-9e48-624af8a8660a,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-a1144206-cc7f-4429-8b44-de8b045c53af,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-f40f9809-2f4f-4f53-b456-96e1547ff6a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455376214-172.17.0.6-1597111538872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35913,DS-a68ec979-0f7a-4028-930d-f65b02324a14,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-2053996d-55d6-40e0-8cbe-8680623b8c13,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-89e54962-0432-4aad-a522-7e6a9bbff520,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-71050f14-1d84-4f13-bf6c-95f5a4672139,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-a2d98ad4-1a2a-4391-9170-73ba19ee7026,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-25fd75e9-e240-4a32-9e48-624af8a8660a,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-a1144206-cc7f-4429-8b44-de8b045c53af,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-f40f9809-2f4f-4f53-b456-96e1547ff6a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5357
