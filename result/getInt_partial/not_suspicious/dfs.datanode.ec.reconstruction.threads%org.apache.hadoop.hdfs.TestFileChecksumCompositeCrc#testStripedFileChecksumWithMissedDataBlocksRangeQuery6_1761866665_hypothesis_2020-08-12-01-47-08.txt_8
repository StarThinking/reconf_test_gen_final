reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8048305-172.17.0.11-1597197477749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36592,DS-e9f661c3-7937-4a82-b5dc-b28ca87a78d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-8e76690c-6388-4978-bac3-1fcf71bd170e,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-64eedbdd-1162-4a4b-9956-b04924a4a5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-ff5588ed-5295-4486-91fc-d2b5c474e51a,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-c66cefd4-2128-4fe0-aeec-42199e7fb655,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-cf14f55e-cce1-44b2-a0ba-d49b19020af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-632197e6-4403-4810-8ff3-b29bb2af4f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-c8fdf9d5-608a-47c7-ad6c-db96815ede14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8048305-172.17.0.11-1597197477749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36592,DS-e9f661c3-7937-4a82-b5dc-b28ca87a78d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-8e76690c-6388-4978-bac3-1fcf71bd170e,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-64eedbdd-1162-4a4b-9956-b04924a4a5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-ff5588ed-5295-4486-91fc-d2b5c474e51a,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-c66cefd4-2128-4fe0-aeec-42199e7fb655,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-cf14f55e-cce1-44b2-a0ba-d49b19020af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-632197e6-4403-4810-8ff3-b29bb2af4f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-c8fdf9d5-608a-47c7-ad6c-db96815ede14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033680772-172.17.0.11-1597197511535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36436,DS-b203d2aa-11c3-46ff-a99e-ca02e546c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-cc5270d1-b884-4e67-b089-1d6b1b5ac58d,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-d6fd1f61-33d7-4099-8506-9bbd5497be6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-0b0f68cf-7336-434c-b056-2cad1dfcaaab,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-c878ad74-1108-4c4c-a999-9332fbaf10e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-a5569075-b0de-4d7b-a5a4-6c085476d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-781fe633-9351-429f-ab79-d26c2b9e9fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-a678a301-8d1e-423f-bc14-21e2b72ffad5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033680772-172.17.0.11-1597197511535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36436,DS-b203d2aa-11c3-46ff-a99e-ca02e546c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-cc5270d1-b884-4e67-b089-1d6b1b5ac58d,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-d6fd1f61-33d7-4099-8506-9bbd5497be6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-0b0f68cf-7336-434c-b056-2cad1dfcaaab,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-c878ad74-1108-4c4c-a999-9332fbaf10e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-a5569075-b0de-4d7b-a5a4-6c085476d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-781fe633-9351-429f-ab79-d26c2b9e9fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-a678a301-8d1e-423f-bc14-21e2b72ffad5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814520896-172.17.0.11-1597197580948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33994,DS-8b9361ef-857c-4da5-bd3f-643e74429cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-665286c3-cd20-482d-9ccc-5c0d289f2042,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-a678f553-3812-44de-b018-807fc9c5171d,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-f80687a4-1ff6-4c0f-90f7-089bf0f872ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-a87f12e4-2626-4bfc-ac87-9e145bbf290e,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-56b90cb9-ce56-4a8a-b759-f9f6a7e98c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-30e8a83f-b4aa-4e26-9801-ac203b9d2f18,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-a0293555-165a-4a0b-a241-aef9907e8f6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814520896-172.17.0.11-1597197580948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33994,DS-8b9361ef-857c-4da5-bd3f-643e74429cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-665286c3-cd20-482d-9ccc-5c0d289f2042,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-a678f553-3812-44de-b018-807fc9c5171d,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-f80687a4-1ff6-4c0f-90f7-089bf0f872ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-a87f12e4-2626-4bfc-ac87-9e145bbf290e,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-56b90cb9-ce56-4a8a-b759-f9f6a7e98c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-30e8a83f-b4aa-4e26-9801-ac203b9d2f18,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-a0293555-165a-4a0b-a241-aef9907e8f6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720948801-172.17.0.11-1597197961743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36965,DS-37ecb250-c5db-46ba-97e2-04f9c63b10da,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-6d3f48fb-3671-4a09-9f8d-3bf556ac9442,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-d6bf0a0a-3822-4236-b66e-8e028e85e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-0c80f282-f2af-4e7d-a305-50623aab8989,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-29314235-383e-42e9-abee-2437e1591a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-19f59846-751a-4916-84ff-36f1836ad88c,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-4f74ace4-b016-4c5d-94a5-04f746e6e712,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-8179f239-6d30-46fa-a23c-de051d151415,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720948801-172.17.0.11-1597197961743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36965,DS-37ecb250-c5db-46ba-97e2-04f9c63b10da,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-6d3f48fb-3671-4a09-9f8d-3bf556ac9442,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-d6bf0a0a-3822-4236-b66e-8e028e85e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-0c80f282-f2af-4e7d-a305-50623aab8989,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-29314235-383e-42e9-abee-2437e1591a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-19f59846-751a-4916-84ff-36f1836ad88c,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-4f74ace4-b016-4c5d-94a5-04f746e6e712,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-8179f239-6d30-46fa-a23c-de051d151415,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950398473-172.17.0.11-1597198201805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-245630cd-85a7-4037-9db1-e120371e341c,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-45edf689-4084-4904-a320-d8c77f493498,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-a046f355-3391-4d49-a459-f9aee0e00da9,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-f4136bba-78b8-4c74-a918-7852d0a916ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-f1873ee4-6bd7-4844-8f16-71ba7d72f3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-4e1331a0-ba52-4919-9432-03f0c0107199,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-c21b34db-2763-4bb4-9042-34c817d7dfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-208baac7-d746-441a-93d8-d0a4d661f0ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950398473-172.17.0.11-1597198201805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-245630cd-85a7-4037-9db1-e120371e341c,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-45edf689-4084-4904-a320-d8c77f493498,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-a046f355-3391-4d49-a459-f9aee0e00da9,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-f4136bba-78b8-4c74-a918-7852d0a916ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-f1873ee4-6bd7-4844-8f16-71ba7d72f3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-4e1331a0-ba52-4919-9432-03f0c0107199,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-c21b34db-2763-4bb4-9042-34c817d7dfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-208baac7-d746-441a-93d8-d0a4d661f0ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356671461-172.17.0.11-1597198385270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46734,DS-9870e373-5c76-455f-97e5-aff7abda8dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-20636b87-417a-43bc-bcc2-2aaee1aa97a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-6ec8c295-9623-423a-9290-3c77d270decf,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-fc434bf1-034d-4581-9306-408c9befe505,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-52bec33c-9d07-46f2-850b-90302ab29260,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-c1ccc5d0-5842-485e-a8ae-b6f2d05c7994,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-717baa9a-18e5-4d13-b51b-9e0e4f826214,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-4cb9d1a8-2abc-4e54-91fa-c2d1aa8fdd01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356671461-172.17.0.11-1597198385270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46734,DS-9870e373-5c76-455f-97e5-aff7abda8dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-20636b87-417a-43bc-bcc2-2aaee1aa97a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-6ec8c295-9623-423a-9290-3c77d270decf,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-fc434bf1-034d-4581-9306-408c9befe505,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-52bec33c-9d07-46f2-850b-90302ab29260,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-c1ccc5d0-5842-485e-a8ae-b6f2d05c7994,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-717baa9a-18e5-4d13-b51b-9e0e4f826214,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-4cb9d1a8-2abc-4e54-91fa-c2d1aa8fdd01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582640242-172.17.0.11-1597198512312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-c7d176fc-63f7-4fbf-8a6d-bbb43fea711a,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-5b3e1320-b8ba-475c-bf3d-386e00ab5698,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-a02788fe-69d7-4c1e-bc72-9b8f45cb50d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-c2927b3c-6a23-4e72-93eb-fb8d0fb0253b,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-6c216313-8823-4892-9f63-c1a3e3177191,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-f2e9ffa6-3657-4d0b-9cea-82c0159bd3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-2db02789-635a-4054-89e4-eb3aed1d89a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-b0b5fa5f-b1ce-4b43-8e5f-397a93dd4817,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582640242-172.17.0.11-1597198512312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-c7d176fc-63f7-4fbf-8a6d-bbb43fea711a,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-5b3e1320-b8ba-475c-bf3d-386e00ab5698,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-a02788fe-69d7-4c1e-bc72-9b8f45cb50d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-c2927b3c-6a23-4e72-93eb-fb8d0fb0253b,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-6c216313-8823-4892-9f63-c1a3e3177191,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-f2e9ffa6-3657-4d0b-9cea-82c0159bd3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-2db02789-635a-4054-89e4-eb3aed1d89a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-b0b5fa5f-b1ce-4b43-8e5f-397a93dd4817,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648820986-172.17.0.11-1597198578853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42849,DS-3cb874f4-5d69-4480-a023-1ce86696c7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-6c7b3c64-1446-4f69-9785-9bff7b08774c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-1b064fa5-82d6-4f50-82b5-46549a05149c,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-2bb4cc3a-0470-427a-9414-e07c3b47b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-fde1363c-dd8b-4d90-a6f4-899dc1778696,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-a1d9ba40-3adc-4193-bd0d-d16d33b902a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-ce21d1d3-78c3-453b-a0d4-4f11b1173fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-22dae31a-fa74-4cb5-b62b-5a1b7c468c79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648820986-172.17.0.11-1597198578853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42849,DS-3cb874f4-5d69-4480-a023-1ce86696c7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-6c7b3c64-1446-4f69-9785-9bff7b08774c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-1b064fa5-82d6-4f50-82b5-46549a05149c,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-2bb4cc3a-0470-427a-9414-e07c3b47b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-fde1363c-dd8b-4d90-a6f4-899dc1778696,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-a1d9ba40-3adc-4193-bd0d-d16d33b902a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-ce21d1d3-78c3-453b-a0d4-4f11b1173fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-22dae31a-fa74-4cb5-b62b-5a1b7c468c79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6621986-172.17.0.11-1597198711669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46110,DS-3009c572-ed49-497d-a63a-a6f1897d0741,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-2283f82e-47e1-4590-bc3a-d78da12013d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-1cf0dff2-d396-44df-9bff-40e4ecb59c58,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-d9963090-847c-486f-a7dc-c620abc6af80,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-163dcced-864a-4ac2-828c-57c8d98517cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-98fc32ac-2052-4036-b856-bc4059bc1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-2a01d1f4-dc8a-40cf-90af-06b478ec63b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-443380fd-1e83-4348-a143-6da2c2207086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6621986-172.17.0.11-1597198711669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46110,DS-3009c572-ed49-497d-a63a-a6f1897d0741,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-2283f82e-47e1-4590-bc3a-d78da12013d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-1cf0dff2-d396-44df-9bff-40e4ecb59c58,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-d9963090-847c-486f-a7dc-c620abc6af80,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-163dcced-864a-4ac2-828c-57c8d98517cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-98fc32ac-2052-4036-b856-bc4059bc1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-2a01d1f4-dc8a-40cf-90af-06b478ec63b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-443380fd-1e83-4348-a143-6da2c2207086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873783252-172.17.0.11-1597198781497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41787,DS-bae4341d-238d-4b8a-811a-0ce80945a3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-8323476d-277d-43fb-9846-973f5f648173,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-d5e561a1-58ff-468b-8bc8-1a8f72839ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-c180392d-3ed2-4072-b9d4-09218a3d5e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-21e89785-af9a-4db7-9fd6-9c7ef17e3b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-85d0a476-654b-46ac-94fd-0dc925f50484,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-11385fae-f221-4d4b-a7b2-91ee9b246126,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-21069285-6786-4fc6-a6b4-413d68a1ef02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873783252-172.17.0.11-1597198781497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41787,DS-bae4341d-238d-4b8a-811a-0ce80945a3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-8323476d-277d-43fb-9846-973f5f648173,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-d5e561a1-58ff-468b-8bc8-1a8f72839ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-c180392d-3ed2-4072-b9d4-09218a3d5e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-21e89785-af9a-4db7-9fd6-9c7ef17e3b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-85d0a476-654b-46ac-94fd-0dc925f50484,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-11385fae-f221-4d4b-a7b2-91ee9b246126,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-21069285-6786-4fc6-a6b4-413d68a1ef02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783282760-172.17.0.11-1597199301568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41160,DS-31ff5625-dee0-44e2-98ec-4b6c1f2d49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-e1c2e72a-cfa8-4096-88bd-8bd47c91ba6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-5e3fb910-0355-4b28-bb3b-321347d64072,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-e6242928-2592-4cb5-afae-adbc306f6493,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-53ab4602-5440-47b3-84c4-4ae81a6ff3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-86d2c09f-5d3d-4be5-99ab-5adc736ab950,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-0e5654bd-971a-4617-9fcb-6967bbc97bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-c90f2a38-03f9-4185-8be3-651b86793714,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783282760-172.17.0.11-1597199301568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41160,DS-31ff5625-dee0-44e2-98ec-4b6c1f2d49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-e1c2e72a-cfa8-4096-88bd-8bd47c91ba6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-5e3fb910-0355-4b28-bb3b-321347d64072,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-e6242928-2592-4cb5-afae-adbc306f6493,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-53ab4602-5440-47b3-84c4-4ae81a6ff3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-86d2c09f-5d3d-4be5-99ab-5adc736ab950,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-0e5654bd-971a-4617-9fcb-6967bbc97bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-c90f2a38-03f9-4185-8be3-651b86793714,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005244651-172.17.0.11-1597199656089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43971,DS-0e2d364c-822f-4a39-b3b4-e0dfde2fea21,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-5015b6e0-66ee-4ef0-b73d-09170cc22944,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-457ededb-fd8e-4b7f-a488-f3bdd6cc319e,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-97bbdcbe-51f9-4db1-a64f-a575bd2a433b,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-dd9b6acc-ed05-4e5d-9d77-d4caabb1b285,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-815853db-7ce3-4188-9ec2-b70aed6575a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-9ea5e5c5-5e20-45a1-b101-1154cd736304,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-95b5039a-a55b-4d53-89fa-ab125778a952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005244651-172.17.0.11-1597199656089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43971,DS-0e2d364c-822f-4a39-b3b4-e0dfde2fea21,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-5015b6e0-66ee-4ef0-b73d-09170cc22944,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-457ededb-fd8e-4b7f-a488-f3bdd6cc319e,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-97bbdcbe-51f9-4db1-a64f-a575bd2a433b,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-dd9b6acc-ed05-4e5d-9d77-d4caabb1b285,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-815853db-7ce3-4188-9ec2-b70aed6575a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-9ea5e5c5-5e20-45a1-b101-1154cd736304,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-95b5039a-a55b-4d53-89fa-ab125778a952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914628340-172.17.0.11-1597200108282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-4bca68af-7ea2-4379-adfb-e7bda13b5816,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-93b0d79e-30d5-46b5-a90e-ae5086a12496,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-1ba04688-d0ee-4fe5-ade2-d6b2a210ffa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-dda020eb-a60d-4b82-925e-dfcce6f5b3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-8a6f1cc1-086a-4c9e-a610-5acab33988d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-ab6753c3-9f2a-4269-8550-0f50e82b0d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-953b8bde-d555-4f56-b047-64a65bdeb923,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-ab01a19b-617a-4f5b-b229-965fd3c59a07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914628340-172.17.0.11-1597200108282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-4bca68af-7ea2-4379-adfb-e7bda13b5816,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-93b0d79e-30d5-46b5-a90e-ae5086a12496,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-1ba04688-d0ee-4fe5-ade2-d6b2a210ffa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-dda020eb-a60d-4b82-925e-dfcce6f5b3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-8a6f1cc1-086a-4c9e-a610-5acab33988d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-ab6753c3-9f2a-4269-8550-0f50e82b0d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-953b8bde-d555-4f56-b047-64a65bdeb923,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-ab01a19b-617a-4f5b-b229-965fd3c59a07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489826942-172.17.0.11-1597200138138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42997,DS-1fa4b41b-8935-4e23-8211-10acd2a20ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-5cc69891-4131-480e-be91-3b63e697e875,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-970f44d6-6b4b-476a-a0b7-46620cd9d869,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-881e6ba8-1471-4f95-8259-665cecbc30ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-fa528286-2d86-4244-9d3d-d6d8bd2af063,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-6e270352-7991-4be3-ae2a-de4429df1f49,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-9cee6e02-7110-47e6-9d0e-72c246137d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-f762825c-0c85-406f-af68-45a0e0429642,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489826942-172.17.0.11-1597200138138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42997,DS-1fa4b41b-8935-4e23-8211-10acd2a20ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-5cc69891-4131-480e-be91-3b63e697e875,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-970f44d6-6b4b-476a-a0b7-46620cd9d869,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-881e6ba8-1471-4f95-8259-665cecbc30ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-fa528286-2d86-4244-9d3d-d6d8bd2af063,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-6e270352-7991-4be3-ae2a-de4429df1f49,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-9cee6e02-7110-47e6-9d0e-72c246137d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-f762825c-0c85-406f-af68-45a0e0429642,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578449929-172.17.0.11-1597200162677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-5776ab93-c213-4b48-967c-5f1cad0b8941,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-d22042fa-06bf-41f2-9d30-3226c72ffea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-d19ec384-0363-4da7-b070-d0be876588cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-bfa08f9d-ed6f-4c69-956e-d0f9df416131,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-a1b9ab5f-077d-475a-8501-d489fd66af29,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-b5d7c43a-65b1-4954-946e-3312c1602151,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-cf0226bc-b15f-4b93-9e0f-1f750df3b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-72f3182a-3329-4686-a884-adb78e36e2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578449929-172.17.0.11-1597200162677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-5776ab93-c213-4b48-967c-5f1cad0b8941,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-d22042fa-06bf-41f2-9d30-3226c72ffea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-d19ec384-0363-4da7-b070-d0be876588cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-bfa08f9d-ed6f-4c69-956e-d0f9df416131,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-a1b9ab5f-077d-475a-8501-d489fd66af29,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-b5d7c43a-65b1-4954-946e-3312c1602151,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-cf0226bc-b15f-4b93-9e0f-1f750df3b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-72f3182a-3329-4686-a884-adb78e36e2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299817405-172.17.0.11-1597200202549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37519,DS-6d7e0b28-fe6a-4f37-b02b-3917669f3fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-cab3cd46-c365-4058-99c3-608df929ea21,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-933380d4-6c61-4914-8647-839cfd4e6471,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-5a40675c-f419-40b6-9559-5b02dfac84f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-35775774-4d50-4b35-8c0d-a5f6b0cf0cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-ea244bb6-730e-4404-b6eb-50a294879884,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-4a4bf5be-de95-473d-813e-9c2d5284e205,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-809707b2-5853-4bdb-a23c-53a7ce3d3633,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299817405-172.17.0.11-1597200202549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37519,DS-6d7e0b28-fe6a-4f37-b02b-3917669f3fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-cab3cd46-c365-4058-99c3-608df929ea21,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-933380d4-6c61-4914-8647-839cfd4e6471,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-5a40675c-f419-40b6-9559-5b02dfac84f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-35775774-4d50-4b35-8c0d-a5f6b0cf0cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-ea244bb6-730e-4404-b6eb-50a294879884,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-4a4bf5be-de95-473d-813e-9c2d5284e205,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-809707b2-5853-4bdb-a23c-53a7ce3d3633,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244768631-172.17.0.11-1597200864595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46856,DS-8ef6c03b-58b3-48be-bb68-56d57d3f026b,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-fc939717-0dd7-4a93-9ada-1d809e3fcf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-14d1c91c-47a4-4c15-b648-30fc948cd89f,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-06e25d29-d068-4e56-aa8e-8b0a6e186c52,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-dc238656-0acd-4499-91ff-29dd141f5ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-8c87eb74-cf41-424d-b38e-5d42ab33e113,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-91ddd1fb-05f9-4950-bc0c-b1584efb7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-c100f40e-4481-421b-a7a8-6aa5ddf5b3f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244768631-172.17.0.11-1597200864595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46856,DS-8ef6c03b-58b3-48be-bb68-56d57d3f026b,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-fc939717-0dd7-4a93-9ada-1d809e3fcf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-14d1c91c-47a4-4c15-b648-30fc948cd89f,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-06e25d29-d068-4e56-aa8e-8b0a6e186c52,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-dc238656-0acd-4499-91ff-29dd141f5ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-8c87eb74-cf41-424d-b38e-5d42ab33e113,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-91ddd1fb-05f9-4950-bc0c-b1584efb7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-c100f40e-4481-421b-a7a8-6aa5ddf5b3f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184331303-172.17.0.11-1597200954797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45354,DS-3b169655-6ed1-4219-99fd-0c7eda099959,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-dbd0c737-bb99-4f50-8665-32aecc40297b,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-e1227480-d8d5-423d-aff9-701099a817e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-95e985cd-da80-4fe3-89ed-500bdf451a89,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-63fbad7f-1c11-42af-a363-d04b96f218d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-50ef6561-3857-4ff1-8ae5-5c1f851a86c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-38c933c5-5bb2-43bf-b9af-45be20c50fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-39a5f05e-839b-4488-b5ab-e579c27ecde9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184331303-172.17.0.11-1597200954797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45354,DS-3b169655-6ed1-4219-99fd-0c7eda099959,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-dbd0c737-bb99-4f50-8665-32aecc40297b,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-e1227480-d8d5-423d-aff9-701099a817e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-95e985cd-da80-4fe3-89ed-500bdf451a89,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-63fbad7f-1c11-42af-a363-d04b96f218d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-50ef6561-3857-4ff1-8ae5-5c1f851a86c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-38c933c5-5bb2-43bf-b9af-45be20c50fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-39a5f05e-839b-4488-b5ab-e579c27ecde9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552323882-172.17.0.11-1597201009379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-3501ee42-d22e-4d7f-927d-ca501f592ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a6ba3788-0e56-4d3a-92e2-c216b85b3931,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-f12899e9-16d7-42d0-b915-4b180df2c898,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-d2459ec5-06e3-4c2c-8400-a7b7d4f30d94,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-e5b545f2-34d3-4978-9bf5-284a2ac1414b,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-fa7feab2-85f6-4e22-90f5-5f66c7fec74d,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-e4e1b75a-3a8b-41e8-bc52-24cf8892bacf,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-6da0ec6a-bbff-4f5b-99d0-9a566efdfddb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552323882-172.17.0.11-1597201009379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-3501ee42-d22e-4d7f-927d-ca501f592ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a6ba3788-0e56-4d3a-92e2-c216b85b3931,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-f12899e9-16d7-42d0-b915-4b180df2c898,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-d2459ec5-06e3-4c2c-8400-a7b7d4f30d94,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-e5b545f2-34d3-4978-9bf5-284a2ac1414b,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-fa7feab2-85f6-4e22-90f5-5f66c7fec74d,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-e4e1b75a-3a8b-41e8-bc52-24cf8892bacf,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-6da0ec6a-bbff-4f5b-99d0-9a566efdfddb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637957490-172.17.0.11-1597201246103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37713,DS-0e35f2e2-0dcb-4322-a8f7-e84aafb46b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-2a707626-7874-434e-8705-3bd541a748c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-34bff611-af64-40c9-861f-cdcd0cec00cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-53bb563b-83da-4176-9ca9-471d8e49faf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-e3f97799-a716-4615-8d55-a2b7ebb842e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-ebc236f7-a1b6-47bd-b8a1-bcc011ebb555,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-70dd7fb1-0fad-4e3e-9acc-62218ab9e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-65e4636b-4e63-4a8f-82a5-9031bc00ad69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637957490-172.17.0.11-1597201246103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37713,DS-0e35f2e2-0dcb-4322-a8f7-e84aafb46b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-2a707626-7874-434e-8705-3bd541a748c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-34bff611-af64-40c9-861f-cdcd0cec00cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-53bb563b-83da-4176-9ca9-471d8e49faf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-e3f97799-a716-4615-8d55-a2b7ebb842e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-ebc236f7-a1b6-47bd-b8a1-bcc011ebb555,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-70dd7fb1-0fad-4e3e-9acc-62218ab9e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-65e4636b-4e63-4a8f-82a5-9031bc00ad69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134439432-172.17.0.11-1597201370003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36748,DS-935e57f6-e59d-4eb7-ab09-1fa3a8499800,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-41159368-6a17-430c-bb0e-8796f66420a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-086e9263-154d-409f-999d-53c66c1facd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-90c481f0-7eb8-44e8-a83a-50f5c5078692,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-5da15b8f-728d-4afd-8b4e-92f66c6e5442,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-6c83e18b-2a83-49f0-a6e2-e77e18d21cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-cea5852b-6ee6-404e-bf9c-68b76353e7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-dc6dffc5-97c4-4165-bf99-2275b0492acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134439432-172.17.0.11-1597201370003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36748,DS-935e57f6-e59d-4eb7-ab09-1fa3a8499800,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-41159368-6a17-430c-bb0e-8796f66420a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-086e9263-154d-409f-999d-53c66c1facd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-90c481f0-7eb8-44e8-a83a-50f5c5078692,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-5da15b8f-728d-4afd-8b4e-92f66c6e5442,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-6c83e18b-2a83-49f0-a6e2-e77e18d21cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-cea5852b-6ee6-404e-bf9c-68b76353e7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-dc6dffc5-97c4-4165-bf99-2275b0492acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823540359-172.17.0.11-1597201491018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-5afc4064-71af-4179-8a6b-a9ee18aaa545,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-43601be9-f80a-4224-bc43-d9b942cecf85,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-ed93d050-057c-4327-af8c-9f8e9e09b028,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-9f0568ab-244b-44f9-9bd3-796b44d0f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-0c158138-a963-4a90-a326-3d44f004b53a,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-8ea4678a-7644-4e31-bb7e-5081c42cc1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-82792c4f-19ce-491d-8ef0-825ec05739c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-c05785c0-5f18-4883-97a5-59a240e6d43f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823540359-172.17.0.11-1597201491018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-5afc4064-71af-4179-8a6b-a9ee18aaa545,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-43601be9-f80a-4224-bc43-d9b942cecf85,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-ed93d050-057c-4327-af8c-9f8e9e09b028,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-9f0568ab-244b-44f9-9bd3-796b44d0f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-0c158138-a963-4a90-a326-3d44f004b53a,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-8ea4678a-7644-4e31-bb7e-5081c42cc1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-82792c4f-19ce-491d-8ef0-825ec05739c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-c05785c0-5f18-4883-97a5-59a240e6d43f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771603098-172.17.0.11-1597201633864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41911,DS-a809cf6f-f74b-4ec7-8acf-dd2c5c8803ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-9ea4a0e9-d8ad-4b15-a2f1-19531f1eb9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-aec6beaf-891f-43b6-91aa-169905a1b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-201e5aa1-317d-4b92-be5f-fee6774ae7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-23e49918-31a1-47ec-b25a-404db7783d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-cf581d3c-369a-4466-8085-0309c5877984,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-6280002f-7847-4807-afb5-e117d922b1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-a7be1233-375c-468d-83dc-f966d752c1b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771603098-172.17.0.11-1597201633864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41911,DS-a809cf6f-f74b-4ec7-8acf-dd2c5c8803ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-9ea4a0e9-d8ad-4b15-a2f1-19531f1eb9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-aec6beaf-891f-43b6-91aa-169905a1b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-201e5aa1-317d-4b92-be5f-fee6774ae7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-23e49918-31a1-47ec-b25a-404db7783d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-cf581d3c-369a-4466-8085-0309c5877984,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-6280002f-7847-4807-afb5-e117d922b1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-a7be1233-375c-468d-83dc-f966d752c1b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4920
