reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228739696-172.17.0.16-1597050776893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35414,DS-316bec34-5d60-4ffe-a09a-c07a8dbf9816,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-b37372b0-59ae-4b3f-8d8a-6aed641efee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-4b243a67-ec7d-4109-b726-5868b827874c,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-cf1e678a-64fb-4e8b-bc2a-64d2e515ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-7941e001-c30e-4224-99ca-33f8946a55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-cc922d2b-bfa5-421f-b37b-fc2a270029a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-06d0675a-c7c8-449b-9cea-a4243243e005,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-e2ebe032-6c71-4667-af83-22e956f17efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228739696-172.17.0.16-1597050776893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35414,DS-316bec34-5d60-4ffe-a09a-c07a8dbf9816,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-b37372b0-59ae-4b3f-8d8a-6aed641efee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-4b243a67-ec7d-4109-b726-5868b827874c,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-cf1e678a-64fb-4e8b-bc2a-64d2e515ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-7941e001-c30e-4224-99ca-33f8946a55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-cc922d2b-bfa5-421f-b37b-fc2a270029a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-06d0675a-c7c8-449b-9cea-a4243243e005,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-e2ebe032-6c71-4667-af83-22e956f17efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172750735-172.17.0.16-1597051411401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-e371752f-efb3-4376-94ef-d53095551c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-63c5774f-59c0-44bb-bef5-19a4d6355c75,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-12fa7271-e36a-495b-980f-1de0936b9577,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-f26c78c5-389c-4b3a-b7f2-21dba581d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-2076afe6-3cc4-4718-b921-7a27a3b42344,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-cee259ae-0117-4b17-b5be-b3b44f03c771,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-b74f6cf7-e0c7-44ef-be29-eba2a84f7874,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-d06ea709-1d7f-48e7-a472-8738c4ac82f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172750735-172.17.0.16-1597051411401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-e371752f-efb3-4376-94ef-d53095551c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-63c5774f-59c0-44bb-bef5-19a4d6355c75,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-12fa7271-e36a-495b-980f-1de0936b9577,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-f26c78c5-389c-4b3a-b7f2-21dba581d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-2076afe6-3cc4-4718-b921-7a27a3b42344,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-cee259ae-0117-4b17-b5be-b3b44f03c771,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-b74f6cf7-e0c7-44ef-be29-eba2a84f7874,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-d06ea709-1d7f-48e7-a472-8738c4ac82f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281371640-172.17.0.16-1597051554072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33302,DS-fbd15715-cc1b-4753-93c9-28e42172d6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-6a710df0-ac26-49a7-93f2-49225a07896b,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-9ac22248-459c-4b13-86d0-5e101b19d029,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-f9d5b98a-377a-44ac-807c-200613237ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-5b80ff3b-a53c-455d-b15f-1051ddffdb30,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-577bc058-da7f-41fd-adfc-40bfab9749a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-75a12b6e-3e14-44b9-ad6a-eeb53a7dc2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-2517e9ea-4cd4-47d5-9bd1-3ee1cc224d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281371640-172.17.0.16-1597051554072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33302,DS-fbd15715-cc1b-4753-93c9-28e42172d6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-6a710df0-ac26-49a7-93f2-49225a07896b,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-9ac22248-459c-4b13-86d0-5e101b19d029,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-f9d5b98a-377a-44ac-807c-200613237ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-5b80ff3b-a53c-455d-b15f-1051ddffdb30,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-577bc058-da7f-41fd-adfc-40bfab9749a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-75a12b6e-3e14-44b9-ad6a-eeb53a7dc2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-2517e9ea-4cd4-47d5-9bd1-3ee1cc224d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650378457-172.17.0.16-1597051648439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35064,DS-eab1af22-3d0e-4bae-b9bc-80b4f01681f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-686798fd-5206-411d-b893-f27c398600a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-4501bbd6-daf6-4e25-b9a3-58b350367ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-6af1b374-6370-455c-b0eb-24d55a1bcc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-6d15c031-e048-45fd-9072-c3d9b3c3414b,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-88df5d7c-fa08-4d86-8dc2-690bfffddfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-944b1c7a-a81b-40fa-89a4-41282e27d967,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-fabd089e-4e22-4b2c-93fe-618bc3136f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650378457-172.17.0.16-1597051648439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35064,DS-eab1af22-3d0e-4bae-b9bc-80b4f01681f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-686798fd-5206-411d-b893-f27c398600a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-4501bbd6-daf6-4e25-b9a3-58b350367ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-6af1b374-6370-455c-b0eb-24d55a1bcc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-6d15c031-e048-45fd-9072-c3d9b3c3414b,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-88df5d7c-fa08-4d86-8dc2-690bfffddfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-944b1c7a-a81b-40fa-89a4-41282e27d967,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-fabd089e-4e22-4b2c-93fe-618bc3136f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003325663-172.17.0.16-1597051779082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34059,DS-94962833-b29c-4bea-926a-69ecb3c4abda,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-432e5503-387d-4c36-8b40-0a1c3eae9eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-1f16e02b-e6fd-474e-935d-e1e83a5ea08c,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-797d3326-0087-4683-a022-86119a7abab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-1cb80fd0-6160-464c-a5ee-11dce6da454d,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-c57d9a6e-a123-4570-aa98-54ce7c3b15a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-6297278a-0e45-48ba-8a0b-244e5379153c,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-a4fcb62f-dc96-45f5-9b12-48c2ad341334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003325663-172.17.0.16-1597051779082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34059,DS-94962833-b29c-4bea-926a-69ecb3c4abda,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-432e5503-387d-4c36-8b40-0a1c3eae9eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-1f16e02b-e6fd-474e-935d-e1e83a5ea08c,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-797d3326-0087-4683-a022-86119a7abab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-1cb80fd0-6160-464c-a5ee-11dce6da454d,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-c57d9a6e-a123-4570-aa98-54ce7c3b15a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-6297278a-0e45-48ba-8a0b-244e5379153c,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-a4fcb62f-dc96-45f5-9b12-48c2ad341334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315529149-172.17.0.16-1597051912745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34830,DS-f6bf977d-44c8-469d-8df8-f9b4020b0446,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-4abe7077-57a7-42c4-b129-edd760f9a3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-9011aa8f-5143-4030-bf46-06260f8cbc62,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-b6823e0c-ec2a-41d2-9a9d-af4ea98c7fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-e3394bdb-33d9-4ad6-9e16-bee2242b2186,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-d629dc74-72a3-446e-b1f1-1f7e04d7aa86,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-58412be4-acec-41f7-ab6b-b929f7cdc6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-7246e107-fb45-4dd1-9ea0-a5bb6bcae3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315529149-172.17.0.16-1597051912745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34830,DS-f6bf977d-44c8-469d-8df8-f9b4020b0446,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-4abe7077-57a7-42c4-b129-edd760f9a3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-9011aa8f-5143-4030-bf46-06260f8cbc62,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-b6823e0c-ec2a-41d2-9a9d-af4ea98c7fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-e3394bdb-33d9-4ad6-9e16-bee2242b2186,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-d629dc74-72a3-446e-b1f1-1f7e04d7aa86,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-58412be4-acec-41f7-ab6b-b929f7cdc6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-7246e107-fb45-4dd1-9ea0-a5bb6bcae3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320068709-172.17.0.16-1597051952664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46855,DS-63619e0d-3f99-4e87-9fe7-88f7a94d2c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-31e828e3-b189-48b6-a363-e6427a62eb77,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-71ad1b13-9e1e-493f-b573-be3f6ab1bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-d9417a1b-502b-47fa-9e02-0a721e8bfb16,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-b506c266-e048-435d-939e-adbc28e206a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-4b1cdff5-6e49-4ee6-baab-8eeca0474ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-2f450fee-404f-4bd1-a076-65cd465b2cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-1707a4e0-a85a-48f6-ba6b-e6d543563c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320068709-172.17.0.16-1597051952664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46855,DS-63619e0d-3f99-4e87-9fe7-88f7a94d2c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-31e828e3-b189-48b6-a363-e6427a62eb77,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-71ad1b13-9e1e-493f-b573-be3f6ab1bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-d9417a1b-502b-47fa-9e02-0a721e8bfb16,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-b506c266-e048-435d-939e-adbc28e206a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-4b1cdff5-6e49-4ee6-baab-8eeca0474ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-2f450fee-404f-4bd1-a076-65cd465b2cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-1707a4e0-a85a-48f6-ba6b-e6d543563c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133395081-172.17.0.16-1597052704621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35639,DS-95166d98-4c2f-47bd-b98d-9c3093fd50d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-4059d9e2-b949-4ee6-b120-bc272fda6714,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-f2b4ffd3-4ed9-4112-8eab-e824f28d0a09,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-621771ba-4a08-4774-8223-4498f4d48823,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-19b50f1b-2214-4664-9ee3-afaf2c063bad,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-88529f97-d074-4942-afa2-1ceb8e4e23ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-727bf8cc-2a9a-4f17-8c91-5ed7c9677171,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-7dc89dd0-5dd0-4de4-85b2-6df3974f6dec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133395081-172.17.0.16-1597052704621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35639,DS-95166d98-4c2f-47bd-b98d-9c3093fd50d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-4059d9e2-b949-4ee6-b120-bc272fda6714,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-f2b4ffd3-4ed9-4112-8eab-e824f28d0a09,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-621771ba-4a08-4774-8223-4498f4d48823,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-19b50f1b-2214-4664-9ee3-afaf2c063bad,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-88529f97-d074-4942-afa2-1ceb8e4e23ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-727bf8cc-2a9a-4f17-8c91-5ed7c9677171,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-7dc89dd0-5dd0-4de4-85b2-6df3974f6dec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744576210-172.17.0.16-1597053216614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-71e8311b-dc11-45e3-933b-e687f51cc459,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-2dd235db-1d81-486e-9ada-0f1d30fff682,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-94fce8fd-e589-416a-8d14-c7ad71687948,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-def8d12a-211b-405f-94f5-f8ba769c1f28,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-59d8fed4-afe5-425a-aa1e-521a4d5a7b96,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-a52d46a9-8ed7-45e3-97f8-57289feeb145,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-7040689a-9b02-4717-8591-67561fd24067,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-b3e4d9ed-1b2c-45d4-aa33-a2a3a1159476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744576210-172.17.0.16-1597053216614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-71e8311b-dc11-45e3-933b-e687f51cc459,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-2dd235db-1d81-486e-9ada-0f1d30fff682,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-94fce8fd-e589-416a-8d14-c7ad71687948,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-def8d12a-211b-405f-94f5-f8ba769c1f28,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-59d8fed4-afe5-425a-aa1e-521a4d5a7b96,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-a52d46a9-8ed7-45e3-97f8-57289feeb145,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-7040689a-9b02-4717-8591-67561fd24067,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-b3e4d9ed-1b2c-45d4-aa33-a2a3a1159476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456810880-172.17.0.16-1597053357825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41050,DS-f34645d0-86b2-45ac-a460-72d6be39519f,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-e95b000c-4fa5-472e-8b1d-06b385a5356d,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-b8ab07c7-257a-4f5c-80f3-421b0acb84fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-19e13b19-250b-4db9-9699-08bcdc859983,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-4d69526a-4858-4037-9fc2-b2c1131501e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-eb3e05d0-9a27-43ea-a88d-fb80ab5e6c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-ffc0a21a-a89f-436e-bc0f-70d2eae8200b,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-b697b902-7168-4f84-959e-380ced836c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456810880-172.17.0.16-1597053357825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41050,DS-f34645d0-86b2-45ac-a460-72d6be39519f,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-e95b000c-4fa5-472e-8b1d-06b385a5356d,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-b8ab07c7-257a-4f5c-80f3-421b0acb84fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-19e13b19-250b-4db9-9699-08bcdc859983,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-4d69526a-4858-4037-9fc2-b2c1131501e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-eb3e05d0-9a27-43ea-a88d-fb80ab5e6c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-ffc0a21a-a89f-436e-bc0f-70d2eae8200b,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-b697b902-7168-4f84-959e-380ced836c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909554599-172.17.0.16-1597053781159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40217,DS-19f6995d-03d2-439f-988c-56afcac88ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-fa23ded9-6867-4851-bab0-08235f6ce6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-42385476-f3e1-4078-b9ae-36f16ffcd80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-bb9f404a-c8fd-4725-837f-96109f7592c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-dc092960-cb40-4cb3-b396-6981880908c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-daf42ac9-2ec2-4d8f-af1b-7823a8419490,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-504e56bf-0b33-400d-a706-503bb2abaf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-9848236c-5cbe-4003-92ca-307f59e188a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909554599-172.17.0.16-1597053781159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40217,DS-19f6995d-03d2-439f-988c-56afcac88ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-fa23ded9-6867-4851-bab0-08235f6ce6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-42385476-f3e1-4078-b9ae-36f16ffcd80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-bb9f404a-c8fd-4725-837f-96109f7592c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-dc092960-cb40-4cb3-b396-6981880908c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-daf42ac9-2ec2-4d8f-af1b-7823a8419490,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-504e56bf-0b33-400d-a706-503bb2abaf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-9848236c-5cbe-4003-92ca-307f59e188a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029409510-172.17.0.16-1597054251455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-dd535412-1314-4281-8951-7ed02516b37f,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-571b1c34-bf71-4708-9f3e-83a96ecddea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-74abe118-69b0-4f7c-9536-eaa1f97ff8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-82487540-7d96-4955-8577-59b33a358032,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-e7f0dc9e-1d0e-4b03-9e77-401fa14026af,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-4fec317d-de78-4866-b2fb-84c81506bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-5bf2e04b-915a-4d23-9e0e-7a2f99d9ba22,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-987025d8-efbf-44d3-84ef-6c4030792ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029409510-172.17.0.16-1597054251455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-dd535412-1314-4281-8951-7ed02516b37f,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-571b1c34-bf71-4708-9f3e-83a96ecddea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-74abe118-69b0-4f7c-9536-eaa1f97ff8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-82487540-7d96-4955-8577-59b33a358032,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-e7f0dc9e-1d0e-4b03-9e77-401fa14026af,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-4fec317d-de78-4866-b2fb-84c81506bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-5bf2e04b-915a-4d23-9e0e-7a2f99d9ba22,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-987025d8-efbf-44d3-84ef-6c4030792ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845124562-172.17.0.16-1597054452965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-0ef0683b-ccb5-4a46-a6fe-25b0bd27a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-b272d37f-4763-4ec0-a479-a3c4e127af2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-f7911e6a-c7dd-4114-9366-d119142a5a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-8ff89058-11a7-4fe6-84f2-23ca82d8d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-8943adc6-5590-4171-9152-9b278434b642,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-c6fd6a67-39cf-4506-bc60-4ecde2ff782b,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-16d9d04d-c3fc-49f6-8758-797aef8682cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-2ede7daf-73e9-40ff-acb4-5a93cb8f17a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845124562-172.17.0.16-1597054452965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-0ef0683b-ccb5-4a46-a6fe-25b0bd27a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-b272d37f-4763-4ec0-a479-a3c4e127af2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-f7911e6a-c7dd-4114-9366-d119142a5a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-8ff89058-11a7-4fe6-84f2-23ca82d8d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-8943adc6-5590-4171-9152-9b278434b642,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-c6fd6a67-39cf-4506-bc60-4ecde2ff782b,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-16d9d04d-c3fc-49f6-8758-797aef8682cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-2ede7daf-73e9-40ff-acb4-5a93cb8f17a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673118436-172.17.0.16-1597054943897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33151,DS-4f2d5694-082d-4c3d-b958-1a86be04addf,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-1da1b21d-01a8-42d3-ac95-d7b19d2b4366,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-eb02741e-1801-40c5-bdfd-f97acd370e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-5f92d434-bd2f-4ba1-9180-04f562f21e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-3c5e8c6d-21ab-4513-834e-ad271abee960,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-5f0cd586-3ea6-432b-afd5-ccfd0789ba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-b63131db-99da-475c-8854-38d27ec03c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-67e636a2-ec55-42b4-b103-ca05cb3256c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673118436-172.17.0.16-1597054943897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33151,DS-4f2d5694-082d-4c3d-b958-1a86be04addf,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-1da1b21d-01a8-42d3-ac95-d7b19d2b4366,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-eb02741e-1801-40c5-bdfd-f97acd370e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-5f92d434-bd2f-4ba1-9180-04f562f21e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-3c5e8c6d-21ab-4513-834e-ad271abee960,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-5f0cd586-3ea6-432b-afd5-ccfd0789ba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-b63131db-99da-475c-8854-38d27ec03c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-67e636a2-ec55-42b4-b103-ca05cb3256c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204246574-172.17.0.16-1597055946514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-648517d9-1808-475d-9350-ab1ae0e2bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-430337b5-b2eb-4d92-8560-9a4a75a8e4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-64130221-c964-4ec1-9f56-011499775c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-5708662d-1a2f-4e25-8f10-ef32305b0e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-62a4a5b9-f597-4b87-b2b4-a7f9adfbe076,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-4fbabffc-718a-48e4-bdb9-2ddeffd140ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-74385e52-17d5-42b9-8c02-91b942c1f4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-7eafbd89-e438-4dba-9776-e855c77a522e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204246574-172.17.0.16-1597055946514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-648517d9-1808-475d-9350-ab1ae0e2bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-430337b5-b2eb-4d92-8560-9a4a75a8e4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-64130221-c964-4ec1-9f56-011499775c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-5708662d-1a2f-4e25-8f10-ef32305b0e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-62a4a5b9-f597-4b87-b2b4-a7f9adfbe076,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-4fbabffc-718a-48e4-bdb9-2ddeffd140ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-74385e52-17d5-42b9-8c02-91b942c1f4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-7eafbd89-e438-4dba-9776-e855c77a522e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850492144-172.17.0.16-1597056328181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35429,DS-63e69d8b-19fc-4525-8f2b-fac1b899933d,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-4bb72aed-6786-42a9-a0c6-ab5cbd0c7f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-f40f098e-a69f-4211-a596-3e7c8fe10757,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-bbbfe85f-3bd6-40f6-baa6-11072eb6c46e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-c88ce358-eddb-496a-a327-ed99138315e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-444b65fe-945b-47ea-8999-9709dcd8710a,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-57956f64-5e2e-439f-b2ec-8ce7af1d44c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-46708ba5-d9bd-4389-a5e3-7584d2373483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850492144-172.17.0.16-1597056328181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35429,DS-63e69d8b-19fc-4525-8f2b-fac1b899933d,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-4bb72aed-6786-42a9-a0c6-ab5cbd0c7f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-f40f098e-a69f-4211-a596-3e7c8fe10757,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-bbbfe85f-3bd6-40f6-baa6-11072eb6c46e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-c88ce358-eddb-496a-a327-ed99138315e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-444b65fe-945b-47ea-8999-9709dcd8710a,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-57956f64-5e2e-439f-b2ec-8ce7af1d44c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-46708ba5-d9bd-4389-a5e3-7584d2373483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716659387-172.17.0.16-1597057177091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-1e205a12-4cd2-4176-933a-2028b768d79a,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-65bc4fd6-38c4-4faf-86c1-12c4ec4ffd56,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-12f41421-08ea-4150-acf9-1d5585e544f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-89afc426-745c-46eb-b1cf-7d8bcac8ab30,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-2abdacc5-536f-426e-99fc-c0c8bbf10367,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-2d75dcb5-9e86-4623-8397-ca874750a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-6a64db5c-05cc-46b1-896f-4ea8057d8df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-5e10ef4d-bc76-4991-8cab-8c2ca2b98c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716659387-172.17.0.16-1597057177091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-1e205a12-4cd2-4176-933a-2028b768d79a,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-65bc4fd6-38c4-4faf-86c1-12c4ec4ffd56,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-12f41421-08ea-4150-acf9-1d5585e544f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-89afc426-745c-46eb-b1cf-7d8bcac8ab30,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-2abdacc5-536f-426e-99fc-c0c8bbf10367,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-2d75dcb5-9e86-4623-8397-ca874750a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-6a64db5c-05cc-46b1-896f-4ea8057d8df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-5e10ef4d-bc76-4991-8cab-8c2ca2b98c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143910081-172.17.0.16-1597057426919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-ae4aa1fc-4da2-4f48-9e3d-f8233f008a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-e1b89f36-426f-406c-b121-3ecd329261f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-82f4f4a8-e583-4f96-9393-6ac4fc8d21e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-ac5fdf54-39ad-4aa2-90e5-6fedb3465be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-b93c341c-4abc-428c-8f0d-490eb7dca93d,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-9c50cdba-f430-4444-997c-15b9e364ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-19ff7591-c678-46e5-8f24-2de5243ea155,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-ad3e7783-277f-4650-9e94-68490c6d9d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143910081-172.17.0.16-1597057426919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-ae4aa1fc-4da2-4f48-9e3d-f8233f008a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-e1b89f36-426f-406c-b121-3ecd329261f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-82f4f4a8-e583-4f96-9393-6ac4fc8d21e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-ac5fdf54-39ad-4aa2-90e5-6fedb3465be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-b93c341c-4abc-428c-8f0d-490eb7dca93d,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-9c50cdba-f430-4444-997c-15b9e364ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-19ff7591-c678-46e5-8f24-2de5243ea155,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-ad3e7783-277f-4650-9e94-68490c6d9d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6778
