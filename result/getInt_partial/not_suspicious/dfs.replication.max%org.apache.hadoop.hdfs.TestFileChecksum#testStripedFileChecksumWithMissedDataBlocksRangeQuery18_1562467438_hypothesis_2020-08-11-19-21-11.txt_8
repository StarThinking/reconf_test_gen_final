reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586210459-172.17.0.7-1597174162417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-daabad70-ec5a-4b70-a351-4df5762f6db0,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-a1b68291-debd-4f4d-acca-fc93a3a6810a,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-8662dcc9-16d1-4867-9f3d-62c083ad71f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-e6fcba06-6c4c-45c7-8657-9a9618f3bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-b1b5e7d4-7a4d-439c-b2fc-26f06f5bdde8,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-5ba54d60-feb6-49c7-a41c-9f558a672998,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-28bb803a-e5b2-4c40-8f65-ac5a62ebec27,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-1953a8d5-20fa-40b9-b549-0c63a6cd2c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586210459-172.17.0.7-1597174162417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-daabad70-ec5a-4b70-a351-4df5762f6db0,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-a1b68291-debd-4f4d-acca-fc93a3a6810a,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-8662dcc9-16d1-4867-9f3d-62c083ad71f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-e6fcba06-6c4c-45c7-8657-9a9618f3bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-b1b5e7d4-7a4d-439c-b2fc-26f06f5bdde8,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-5ba54d60-feb6-49c7-a41c-9f558a672998,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-28bb803a-e5b2-4c40-8f65-ac5a62ebec27,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-1953a8d5-20fa-40b9-b549-0c63a6cd2c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847877955-172.17.0.7-1597174624828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40094,DS-0da4879b-1e2f-4fa6-a54b-8175b6c2cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-ae78111a-5a08-42b7-b889-be84bacb1068,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-c400ffbd-bd21-4026-8542-010ae266dbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-cd6e3f40-39c4-4885-bec3-3fbbf2e03e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-091c0afc-0688-4307-bf62-01001bbbfb88,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-f3b0f3ab-b7b6-4da1-9213-a2488cbafa65,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-c271bcba-304d-436c-baed-dd32a768f81d,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-6e9eb589-9ab2-4779-8841-ae06f79aa26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847877955-172.17.0.7-1597174624828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40094,DS-0da4879b-1e2f-4fa6-a54b-8175b6c2cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-ae78111a-5a08-42b7-b889-be84bacb1068,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-c400ffbd-bd21-4026-8542-010ae266dbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-cd6e3f40-39c4-4885-bec3-3fbbf2e03e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-091c0afc-0688-4307-bf62-01001bbbfb88,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-f3b0f3ab-b7b6-4da1-9213-a2488cbafa65,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-c271bcba-304d-436c-baed-dd32a768f81d,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-6e9eb589-9ab2-4779-8841-ae06f79aa26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897701402-172.17.0.7-1597175681943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41182,DS-eb07dd6f-57a1-41bb-8694-6ef44e1a79db,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-fa7eace3-f008-4f96-a349-4bdeb98e0c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-fc84221f-b3ff-479b-a542-50d2899023c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-5f526d42-ec19-43b2-b897-a57baba17c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-68449623-2eb0-492e-8138-30144de5dabc,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-ace7ee72-ba50-433a-a834-2657a774988b,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-ab9f168f-c30c-4d71-8cfc-0d655f6e89b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-4825d4c9-0897-4b2f-a30e-bc48494febad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897701402-172.17.0.7-1597175681943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41182,DS-eb07dd6f-57a1-41bb-8694-6ef44e1a79db,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-fa7eace3-f008-4f96-a349-4bdeb98e0c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-fc84221f-b3ff-479b-a542-50d2899023c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-5f526d42-ec19-43b2-b897-a57baba17c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-68449623-2eb0-492e-8138-30144de5dabc,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-ace7ee72-ba50-433a-a834-2657a774988b,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-ab9f168f-c30c-4d71-8cfc-0d655f6e89b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-4825d4c9-0897-4b2f-a30e-bc48494febad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698318007-172.17.0.7-1597175936518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-74c04d80-536f-4cf3-861e-ff4e4145e6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-b007a1b9-f96f-4660-897f-6b4b37d6a6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-c645e38b-ee49-4d44-a60e-6c513c261140,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-24c14410-2ae2-484b-a9e0-5a0842a38c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-72472757-5ad4-4359-a5fd-65a14144b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-f3e17b19-6eb8-481d-a087-5c3c7d066b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-5c5b7a6b-4b40-4ec4-9d72-9de3e593dec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-48e375f3-4d5e-4c20-b464-a53335a31cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698318007-172.17.0.7-1597175936518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-74c04d80-536f-4cf3-861e-ff4e4145e6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-b007a1b9-f96f-4660-897f-6b4b37d6a6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-c645e38b-ee49-4d44-a60e-6c513c261140,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-24c14410-2ae2-484b-a9e0-5a0842a38c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-72472757-5ad4-4359-a5fd-65a14144b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-f3e17b19-6eb8-481d-a087-5c3c7d066b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-5c5b7a6b-4b40-4ec4-9d72-9de3e593dec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-48e375f3-4d5e-4c20-b464-a53335a31cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324880580-172.17.0.7-1597176684135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-931412a5-28f1-4386-bbb0-bf4ba0aaa4af,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-0c2bb610-25f1-475c-8634-ce9f16ad07d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-951a77bc-1633-4198-b8d3-1fb109474d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-c978999f-8a83-4ef8-8c4e-7f46ba5628fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-8f7a838a-31b1-4c8a-84fb-d51ee22117b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-a99c6ace-64c3-4107-9c07-e8d762597a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-f734e6d9-e397-4ae4-a567-d0b2542540a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-8ce2897c-0a7e-4f35-90d8-36732869f586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324880580-172.17.0.7-1597176684135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-931412a5-28f1-4386-bbb0-bf4ba0aaa4af,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-0c2bb610-25f1-475c-8634-ce9f16ad07d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-951a77bc-1633-4198-b8d3-1fb109474d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-c978999f-8a83-4ef8-8c4e-7f46ba5628fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-8f7a838a-31b1-4c8a-84fb-d51ee22117b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-a99c6ace-64c3-4107-9c07-e8d762597a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-f734e6d9-e397-4ae4-a567-d0b2542540a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-8ce2897c-0a7e-4f35-90d8-36732869f586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047055431-172.17.0.7-1597176717029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-af50e0b7-7665-4e12-a3f7-4b2c44f10534,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-5519a09e-4d4d-4403-8871-9d035a87654a,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-c4fec0eb-035c-4bbf-b16f-0058b3a5385c,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-d88a1b22-01e9-4f5f-a282-e9c7c45078f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-ff498e12-3f49-4df6-ac33-1f2810a921df,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-3932e4cb-1a93-4dee-9a64-998675073fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-64c371a1-f60f-4458-ad11-ff0f80c4d718,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-42d29db4-e3b0-4146-a798-378549c02a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047055431-172.17.0.7-1597176717029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-af50e0b7-7665-4e12-a3f7-4b2c44f10534,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-5519a09e-4d4d-4403-8871-9d035a87654a,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-c4fec0eb-035c-4bbf-b16f-0058b3a5385c,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-d88a1b22-01e9-4f5f-a282-e9c7c45078f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-ff498e12-3f49-4df6-ac33-1f2810a921df,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-3932e4cb-1a93-4dee-9a64-998675073fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-64c371a1-f60f-4458-ad11-ff0f80c4d718,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-42d29db4-e3b0-4146-a798-378549c02a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810901435-172.17.0.7-1597177227828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-30dacdfe-7202-4786-9700-c1313cd3bbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-fd9995c2-fcb2-4a88-af6f-5692afe52151,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-ff5f3319-ed78-4f6e-9f75-f1cc8bc36d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-b3a329ec-f686-477e-8a24-56013165fdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-1b41e3c2-fa41-4b1f-8079-549e0eae39b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-c101a838-f602-4193-b4b8-a42ac37cd1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-92ae64ef-5aa1-455b-97a6-4f0450751612,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-7568736b-f864-47ef-9d3b-ca7fc7ee8a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810901435-172.17.0.7-1597177227828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-30dacdfe-7202-4786-9700-c1313cd3bbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-fd9995c2-fcb2-4a88-af6f-5692afe52151,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-ff5f3319-ed78-4f6e-9f75-f1cc8bc36d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-b3a329ec-f686-477e-8a24-56013165fdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-1b41e3c2-fa41-4b1f-8079-549e0eae39b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-c101a838-f602-4193-b4b8-a42ac37cd1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-92ae64ef-5aa1-455b-97a6-4f0450751612,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-7568736b-f864-47ef-9d3b-ca7fc7ee8a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946634074-172.17.0.7-1597177331403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-2ebd3f68-b9b5-4c66-9d6a-d84880ae3687,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-86aae446-b56f-48ea-81c6-0f30621913c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-014461cd-8c0e-43a7-8198-40aaf1d71923,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-62030aae-65f2-4c6d-b891-4ec7acb69655,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-a178f338-04de-48ef-976b-492401de706b,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-bdb683bd-880e-4d2b-869c-088d1b2a58ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-a6f74442-213b-46a9-b995-b7251a6df579,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-e7ad61c9-70f2-496b-a6fe-95ae3ffe15af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946634074-172.17.0.7-1597177331403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-2ebd3f68-b9b5-4c66-9d6a-d84880ae3687,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-86aae446-b56f-48ea-81c6-0f30621913c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-014461cd-8c0e-43a7-8198-40aaf1d71923,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-62030aae-65f2-4c6d-b891-4ec7acb69655,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-a178f338-04de-48ef-976b-492401de706b,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-bdb683bd-880e-4d2b-869c-088d1b2a58ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-a6f74442-213b-46a9-b995-b7251a6df579,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-e7ad61c9-70f2-496b-a6fe-95ae3ffe15af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395746657-172.17.0.7-1597177860952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42264,DS-364c7c14-2a4d-4f15-94df-45301cda4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-46e8a885-ed41-4c02-b443-4995953cd11b,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-36159795-f225-4ec8-b261-18bb5d324e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-aeadca21-bc46-4e19-9808-357e7a68ddd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-8aea5034-0ac1-4b6d-906f-9a44beea448e,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-65c752f1-ba59-4d82-8e19-23ba76243276,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-02a91748-b1a4-4658-9165-dc2892273fac,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-45cafb7b-59e5-4b86-97f0-89c199aba728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395746657-172.17.0.7-1597177860952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42264,DS-364c7c14-2a4d-4f15-94df-45301cda4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-46e8a885-ed41-4c02-b443-4995953cd11b,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-36159795-f225-4ec8-b261-18bb5d324e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-aeadca21-bc46-4e19-9808-357e7a68ddd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-8aea5034-0ac1-4b6d-906f-9a44beea448e,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-65c752f1-ba59-4d82-8e19-23ba76243276,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-02a91748-b1a4-4658-9165-dc2892273fac,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-45cafb7b-59e5-4b86-97f0-89c199aba728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585933817-172.17.0.7-1597178239228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-5f1116d1-1db8-4d8f-923d-0c3a568261dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-e45d47f7-52c1-4afe-baff-e4aaa407cc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-6d2043a8-ce5a-417f-9861-1fa89c032955,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-3b543349-d649-4a22-a870-411595eeeb04,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-c3a7638c-a217-4dcd-b8ab-79405f9302e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-3662331c-6315-4c33-a375-4abc5ccfb35a,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-1ad7117a-ded6-45ba-a7d1-66c508667202,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-1739b4a1-0ca6-4ae0-9d63-11bb9e3a03fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585933817-172.17.0.7-1597178239228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-5f1116d1-1db8-4d8f-923d-0c3a568261dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-e45d47f7-52c1-4afe-baff-e4aaa407cc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-6d2043a8-ce5a-417f-9861-1fa89c032955,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-3b543349-d649-4a22-a870-411595eeeb04,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-c3a7638c-a217-4dcd-b8ab-79405f9302e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-3662331c-6315-4c33-a375-4abc5ccfb35a,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-1ad7117a-ded6-45ba-a7d1-66c508667202,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-1739b4a1-0ca6-4ae0-9d63-11bb9e3a03fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876553785-172.17.0.7-1597178620162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-6131426a-7658-426b-98b6-72ff01d4c966,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-c9974ec9-82dd-4c76-960f-11b276f0fe20,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-feca3c16-2c5f-4205-8e9a-b3cfe222098b,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-b3d5744b-4bae-4e38-8e13-ffb11e415d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-ae0ce614-0807-4136-9997-000574e47824,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-1bfea44c-92b0-4e6e-936a-d4e04f9dd419,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-2d4c52a9-060c-415e-a439-0e685d0164a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-52f990c2-071b-4f0d-8cc0-f754592f5e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876553785-172.17.0.7-1597178620162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-6131426a-7658-426b-98b6-72ff01d4c966,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-c9974ec9-82dd-4c76-960f-11b276f0fe20,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-feca3c16-2c5f-4205-8e9a-b3cfe222098b,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-b3d5744b-4bae-4e38-8e13-ffb11e415d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-ae0ce614-0807-4136-9997-000574e47824,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-1bfea44c-92b0-4e6e-936a-d4e04f9dd419,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-2d4c52a9-060c-415e-a439-0e685d0164a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-52f990c2-071b-4f0d-8cc0-f754592f5e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92621623-172.17.0.7-1597178663567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41014,DS-4ab16dc6-c427-4817-8da6-589d897b7b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-b48d1b3b-4dc4-47f2-b75b-eaf9cda89b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-3a832fce-2a85-46bb-be72-ff1c07b6bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-5bbad61b-dbec-4310-9ac3-b5c9a84e2e36,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-c8c67d88-0149-4391-aec1-331dbb8d81ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-fe68c1a2-6be6-4f1d-85b0-40f21d7d50ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-006c868c-5ed8-4ec8-80c8-6112488239f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-01dfb44b-c78d-485f-91b3-d313bd43b5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92621623-172.17.0.7-1597178663567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41014,DS-4ab16dc6-c427-4817-8da6-589d897b7b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-b48d1b3b-4dc4-47f2-b75b-eaf9cda89b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-3a832fce-2a85-46bb-be72-ff1c07b6bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-5bbad61b-dbec-4310-9ac3-b5c9a84e2e36,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-c8c67d88-0149-4391-aec1-331dbb8d81ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-fe68c1a2-6be6-4f1d-85b0-40f21d7d50ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-006c868c-5ed8-4ec8-80c8-6112488239f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-01dfb44b-c78d-485f-91b3-d313bd43b5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182853186-172.17.0.7-1597178768364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-9f9ee1a7-1ea6-4d7f-b769-056ab19fc977,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-45a3505c-4bfe-4bc8-a33b-3f3867edee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-fa57dc4c-3d13-48cb-b5c5-ba95225e5f65,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-1930c7a8-f953-45ee-beca-5f56f1f9315f,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-07593b5c-f305-4725-a746-47c01ddf20b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-6751a7cb-39c6-4c7e-82e1-dc32b301c5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-90ef1a25-e42d-4896-85f1-1bd4adc67c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-70141f90-0b08-4a3b-b7d5-15bdf57fe555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182853186-172.17.0.7-1597178768364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-9f9ee1a7-1ea6-4d7f-b769-056ab19fc977,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-45a3505c-4bfe-4bc8-a33b-3f3867edee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-fa57dc4c-3d13-48cb-b5c5-ba95225e5f65,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-1930c7a8-f953-45ee-beca-5f56f1f9315f,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-07593b5c-f305-4725-a746-47c01ddf20b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-6751a7cb-39c6-4c7e-82e1-dc32b301c5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-90ef1a25-e42d-4896-85f1-1bd4adc67c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-70141f90-0b08-4a3b-b7d5-15bdf57fe555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752030542-172.17.0.7-1597178809236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-57abc5aa-a996-4d1a-b646-a9bf3d92af5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-93844e4c-15ae-4c50-b02b-1f748b74e687,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-3edf61ba-e9d9-4bac-8ab1-a47cc2df3acd,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-dafb7768-9ee5-443b-b5ce-931ca3ecb8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-c1365cde-182a-45f8-b50c-13ff45b3b77e,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-85ee4206-286e-46f0-8601-af1fecb8cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-3a6601d9-7e82-4ab0-a080-3dea36300cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-73c7fead-4567-47a1-a939-eafa533615a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752030542-172.17.0.7-1597178809236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-57abc5aa-a996-4d1a-b646-a9bf3d92af5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-93844e4c-15ae-4c50-b02b-1f748b74e687,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-3edf61ba-e9d9-4bac-8ab1-a47cc2df3acd,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-dafb7768-9ee5-443b-b5ce-931ca3ecb8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-c1365cde-182a-45f8-b50c-13ff45b3b77e,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-85ee4206-286e-46f0-8601-af1fecb8cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-3a6601d9-7e82-4ab0-a080-3dea36300cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-73c7fead-4567-47a1-a939-eafa533615a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 2
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712885708-172.17.0.7-1597178879432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-f9a67bd8-94bf-4d62-aaf1-2ca70f11ed27,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-5fd688d6-876b-4522-b03b-bcf1c448b6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-4e500287-b838-4c2d-ba9d-05621b923e82,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-2ea33e9b-1d7d-4ce9-9c3b-3c53217b7ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-af33358d-9572-416b-9bb2-c488538315ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-261024ab-3cdd-4154-befb-ee7e531caa24,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-4effa44c-198e-418b-bf5f-9164ec225ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-6d136137-5741-45f8-872a-1607de334da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712885708-172.17.0.7-1597178879432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-f9a67bd8-94bf-4d62-aaf1-2ca70f11ed27,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-5fd688d6-876b-4522-b03b-bcf1c448b6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-4e500287-b838-4c2d-ba9d-05621b923e82,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-2ea33e9b-1d7d-4ce9-9c3b-3c53217b7ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-af33358d-9572-416b-9bb2-c488538315ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-261024ab-3cdd-4154-befb-ee7e531caa24,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-4effa44c-198e-418b-bf5f-9164ec225ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-6d136137-5741-45f8-872a-1607de334da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5311
