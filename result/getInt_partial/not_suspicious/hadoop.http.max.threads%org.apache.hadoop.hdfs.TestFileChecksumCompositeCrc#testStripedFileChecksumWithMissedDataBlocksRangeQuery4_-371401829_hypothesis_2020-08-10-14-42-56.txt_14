reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129486996-172.17.0.19-1597070591709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-ab57d3de-5fdc-4f94-9942-832051762d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-1f088513-4728-4973-827b-949e2500c1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-5a04a57d-aaab-4ac2-ade9-7371f42267ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-e385c68c-76cf-4383-ad18-743fd386672d,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-c7e0d96d-afac-4e18-baba-9de92240f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-1a9095a1-f8e4-43b0-970d-f9b6ecd632a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-2de89fd6-619e-46da-ae7a-c423f24dab63,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-bdede5a5-3b3f-4115-99d2-120311efc526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129486996-172.17.0.19-1597070591709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-ab57d3de-5fdc-4f94-9942-832051762d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-1f088513-4728-4973-827b-949e2500c1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-5a04a57d-aaab-4ac2-ade9-7371f42267ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-e385c68c-76cf-4383-ad18-743fd386672d,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-c7e0d96d-afac-4e18-baba-9de92240f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-1a9095a1-f8e4-43b0-970d-f9b6ecd632a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-2de89fd6-619e-46da-ae7a-c423f24dab63,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-bdede5a5-3b3f-4115-99d2-120311efc526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717040302-172.17.0.19-1597071526195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-5690dc40-f138-4331-bbe1-c2afd560abc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-1d4c4ad7-92aa-4abb-bdab-c72f75497892,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-d70e6e9e-d664-4544-a690-bae19f301f02,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-0c37fe15-4dfd-4261-a04a-3f5b8dc4935b,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-da98dd51-2647-4ac2-bc77-180dfedfb33e,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-f025c264-fc36-4538-9288-786429d567d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-650eeaf7-67dd-4c6d-a0ae-91556dcdd4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-9ee905cc-3cd8-4db0-b5fa-71d4543293a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717040302-172.17.0.19-1597071526195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-5690dc40-f138-4331-bbe1-c2afd560abc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-1d4c4ad7-92aa-4abb-bdab-c72f75497892,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-d70e6e9e-d664-4544-a690-bae19f301f02,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-0c37fe15-4dfd-4261-a04a-3f5b8dc4935b,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-da98dd51-2647-4ac2-bc77-180dfedfb33e,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-f025c264-fc36-4538-9288-786429d567d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-650eeaf7-67dd-4c6d-a0ae-91556dcdd4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-9ee905cc-3cd8-4db0-b5fa-71d4543293a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118489745-172.17.0.19-1597071642494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35816,DS-b58ccc6f-6afe-461d-8521-eda02aee2603,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-0de0ee25-4454-4256-908f-455ac7fc36ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-be99f0a0-e1c2-4104-9db0-177f4218f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-fa76240f-1773-49db-b3ef-15c169a9abee,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-6d88c59f-50f6-46a7-b764-7c0a58002a19,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-c42dbe18-a799-420a-b9d7-16cf67ba187a,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-55650a80-596b-436d-ac13-9e760bf83c33,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-b725e9f8-951a-4f10-b0df-a9892a47fe2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118489745-172.17.0.19-1597071642494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35816,DS-b58ccc6f-6afe-461d-8521-eda02aee2603,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-0de0ee25-4454-4256-908f-455ac7fc36ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-be99f0a0-e1c2-4104-9db0-177f4218f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-fa76240f-1773-49db-b3ef-15c169a9abee,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-6d88c59f-50f6-46a7-b764-7c0a58002a19,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-c42dbe18-a799-420a-b9d7-16cf67ba187a,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-55650a80-596b-436d-ac13-9e760bf83c33,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-b725e9f8-951a-4f10-b0df-a9892a47fe2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255472020-172.17.0.19-1597072585698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-17e1f7d4-b622-46a6-b748-80b7837ed00d,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-09751526-edf9-42bb-80ee-c791347e77b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-a26690ba-03cd-495a-9950-8b20e8236afa,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-aead0ddc-cce2-46d0-bbaa-6dcd929194c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-103e5321-6521-405b-950f-3af28d3cc3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-d885dd43-138b-4ad7-929b-8f60b2eab164,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-bcdde307-c854-46a6-bc4d-f4b7dd99207b,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-b47c00eb-03f4-4497-9948-eba4f4f86cee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255472020-172.17.0.19-1597072585698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-17e1f7d4-b622-46a6-b748-80b7837ed00d,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-09751526-edf9-42bb-80ee-c791347e77b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-a26690ba-03cd-495a-9950-8b20e8236afa,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-aead0ddc-cce2-46d0-bbaa-6dcd929194c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-103e5321-6521-405b-950f-3af28d3cc3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-d885dd43-138b-4ad7-929b-8f60b2eab164,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-bcdde307-c854-46a6-bc4d-f4b7dd99207b,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-b47c00eb-03f4-4497-9948-eba4f4f86cee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548036627-172.17.0.19-1597072731663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-67a5b117-479b-4536-86d2-737226fb432d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-5df0bf5f-6ef6-47b7-a910-ab55b1925e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-70c551f9-5ebf-4268-8472-5b6bd061bcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-ee37de0f-811a-46fe-b32d-71c734b65823,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-d3a735f3-a1a9-4b17-9c44-4a3cc25740ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-4cc8c854-912f-46fb-a252-ebf3897f924e,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-82ff0036-a498-4eec-a0bd-2f3658ff4da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-c66d88c2-9bd2-4e59-af16-339924be95d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548036627-172.17.0.19-1597072731663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-67a5b117-479b-4536-86d2-737226fb432d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-5df0bf5f-6ef6-47b7-a910-ab55b1925e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-70c551f9-5ebf-4268-8472-5b6bd061bcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-ee37de0f-811a-46fe-b32d-71c734b65823,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-d3a735f3-a1a9-4b17-9c44-4a3cc25740ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-4cc8c854-912f-46fb-a252-ebf3897f924e,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-82ff0036-a498-4eec-a0bd-2f3658ff4da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-c66d88c2-9bd2-4e59-af16-339924be95d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72516823-172.17.0.19-1597073051988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-3a99c5ee-ab5e-44d3-9a38-c8b6c064aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-7f074c4e-f555-4214-8140-3237b3cb0ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-c3bc8096-7216-4b1b-9e7b-40f1a9b3dc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-5c7b88fd-28ce-409a-8e4e-227f24b5aa75,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-4c1d6f9f-acde-47c5-aaf0-1f201592d239,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-72eeade8-0a8e-46a1-b7c3-a2b224dc26ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-debc2e41-dc9e-4a0b-ac11-726b11ce2688,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-286ad1fb-eb9d-4d2b-9edb-426e308f568f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72516823-172.17.0.19-1597073051988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-3a99c5ee-ab5e-44d3-9a38-c8b6c064aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-7f074c4e-f555-4214-8140-3237b3cb0ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-c3bc8096-7216-4b1b-9e7b-40f1a9b3dc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-5c7b88fd-28ce-409a-8e4e-227f24b5aa75,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-4c1d6f9f-acde-47c5-aaf0-1f201592d239,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-72eeade8-0a8e-46a1-b7c3-a2b224dc26ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-debc2e41-dc9e-4a0b-ac11-726b11ce2688,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-286ad1fb-eb9d-4d2b-9edb-426e308f568f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295499469-172.17.0.19-1597073086567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44091,DS-036767d6-a1ac-4d80-9b70-d1284558ea22,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-4a2a5830-c895-4905-9c8a-17f4aa9cd3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-c651c75c-e2a2-4310-950d-cfc290410ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-bc4c71c8-d119-4a2f-994c-3f13566d263c,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-8f159b95-324e-436b-93ee-ef11856f183b,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-921ce624-6f3c-4466-ba93-29baba053e60,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-5a456967-41c4-443b-a63c-9f2483cf62a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-5a533920-79c5-4532-baff-0031a2416580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295499469-172.17.0.19-1597073086567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44091,DS-036767d6-a1ac-4d80-9b70-d1284558ea22,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-4a2a5830-c895-4905-9c8a-17f4aa9cd3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-c651c75c-e2a2-4310-950d-cfc290410ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-bc4c71c8-d119-4a2f-994c-3f13566d263c,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-8f159b95-324e-436b-93ee-ef11856f183b,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-921ce624-6f3c-4466-ba93-29baba053e60,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-5a456967-41c4-443b-a63c-9f2483cf62a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-5a533920-79c5-4532-baff-0031a2416580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022306271-172.17.0.19-1597073238328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-4550fcd8-b47a-406a-80d7-4595966be7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-47e8645e-15e5-4bc3-baab-2d342897b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-552ac6ee-b804-4888-b809-c8627f055a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-60b17440-5e8e-406b-9e46-46beb576a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-4adc8fd0-50fe-41e6-addb-6195264c6d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-ce515e79-e11e-49bd-86e9-ae998d3a0e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-8999a2c3-4883-496f-9398-52a70c78dcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-111f92f5-19ee-44ed-bae5-c187d1656cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022306271-172.17.0.19-1597073238328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-4550fcd8-b47a-406a-80d7-4595966be7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-47e8645e-15e5-4bc3-baab-2d342897b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-552ac6ee-b804-4888-b809-c8627f055a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-60b17440-5e8e-406b-9e46-46beb576a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-4adc8fd0-50fe-41e6-addb-6195264c6d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-ce515e79-e11e-49bd-86e9-ae998d3a0e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-8999a2c3-4883-496f-9398-52a70c78dcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-111f92f5-19ee-44ed-bae5-c187d1656cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852309454-172.17.0.19-1597073460977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-2ab38281-4d40-4560-94f2-db46e34fa3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-18900613-5c1e-45c3-b453-0db7b60ac179,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-e4fb0e9f-4eaa-440d-be94-bd62c89e5a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-168becb2-8c82-4242-b86d-3504573f4b17,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-fc59492e-168c-4f61-b97c-d8282ece9003,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-c6bfec1e-412a-4079-833b-96b1bf61a891,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-ebae7562-a68d-46b5-a208-a6c9180a8346,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-89e31109-aa23-4f35-8572-ac91fa333e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852309454-172.17.0.19-1597073460977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-2ab38281-4d40-4560-94f2-db46e34fa3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-18900613-5c1e-45c3-b453-0db7b60ac179,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-e4fb0e9f-4eaa-440d-be94-bd62c89e5a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-168becb2-8c82-4242-b86d-3504573f4b17,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-fc59492e-168c-4f61-b97c-d8282ece9003,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-c6bfec1e-412a-4079-833b-96b1bf61a891,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-ebae7562-a68d-46b5-a208-a6c9180a8346,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-89e31109-aa23-4f35-8572-ac91fa333e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898427158-172.17.0.19-1597074272219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-7b9fd4dd-9266-4c67-a7b3-06d9c5cbec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-34534e97-91ce-4b2f-b943-9121b2c0ec3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-89c67076-999f-4677-9d8e-fdc227cab036,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-cdfc52c3-61c6-4e53-b5a8-aa8238c2d5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-7bccee3c-c630-499a-a7a4-fb2ea21e2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d786f77a-9c55-434e-a319-aef681ce2eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-68e3b631-d03e-4b86-8466-033d00050c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-97fde625-66a1-403a-b34f-680a98eaf657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898427158-172.17.0.19-1597074272219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-7b9fd4dd-9266-4c67-a7b3-06d9c5cbec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-34534e97-91ce-4b2f-b943-9121b2c0ec3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-89c67076-999f-4677-9d8e-fdc227cab036,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-cdfc52c3-61c6-4e53-b5a8-aa8238c2d5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-7bccee3c-c630-499a-a7a4-fb2ea21e2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d786f77a-9c55-434e-a319-aef681ce2eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-68e3b631-d03e-4b86-8466-033d00050c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-97fde625-66a1-403a-b34f-680a98eaf657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421509512-172.17.0.19-1597074618321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42849,DS-0dc6feb4-dab1-40e7-962a-338ab64aadfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-d1037837-d664-4471-9043-e04b5669724f,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-e2b85b7b-8acc-44cb-b8f6-2ddebb60b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-e9cd90c5-1b6a-43f2-993a-75f92f8cdc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3a075875-8243-4fa8-af60-9c1f8ea3cb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-77d92d61-836c-42c1-9bf3-4864f3556aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-e3543020-2af6-40c6-b9cc-4e5aa5302823,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-ff089ffe-bb3d-4d3b-bdc2-151453f75557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421509512-172.17.0.19-1597074618321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42849,DS-0dc6feb4-dab1-40e7-962a-338ab64aadfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-d1037837-d664-4471-9043-e04b5669724f,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-e2b85b7b-8acc-44cb-b8f6-2ddebb60b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-e9cd90c5-1b6a-43f2-993a-75f92f8cdc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3a075875-8243-4fa8-af60-9c1f8ea3cb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-77d92d61-836c-42c1-9bf3-4864f3556aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-e3543020-2af6-40c6-b9cc-4e5aa5302823,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-ff089ffe-bb3d-4d3b-bdc2-151453f75557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675664568-172.17.0.19-1597074999632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-0d6e8e08-7004-4848-a3e8-69d10682c1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-5f9d46e0-347a-4060-97da-b538ef389161,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-15b35de9-e2cd-429d-b0b1-d9aaf1a287cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-1b6c75fc-3141-4c00-a486-b926edd22087,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-0fbf10a9-9984-4cde-ba0c-502a52c4f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-fc465742-2f2e-4f98-9957-3a3db6971505,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-dae084bd-7f10-4ad6-bcc3-c04481b254cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-4ddf026c-81cb-401c-b6b9-d342226c43f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675664568-172.17.0.19-1597074999632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-0d6e8e08-7004-4848-a3e8-69d10682c1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-5f9d46e0-347a-4060-97da-b538ef389161,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-15b35de9-e2cd-429d-b0b1-d9aaf1a287cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-1b6c75fc-3141-4c00-a486-b926edd22087,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-0fbf10a9-9984-4cde-ba0c-502a52c4f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-fc465742-2f2e-4f98-9957-3a3db6971505,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-dae084bd-7f10-4ad6-bcc3-c04481b254cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-4ddf026c-81cb-401c-b6b9-d342226c43f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988881923-172.17.0.19-1597075116019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-6bb51ffa-af63-47ab-a9cc-6783c0b7205d,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-bbc35f7a-2376-444e-b831-3b537dce3ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-c345f15f-11d5-4591-97d4-25551b3c111c,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-877153bc-7372-49a8-96b1-ac38c8784bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-7a536479-0d2a-4f18-a0a8-4983c3caba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-7a47d06f-b36a-4846-a666-bcf5b29b2ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-41c0a1ed-4da8-4b4b-8aaf-a2e251d338dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-3b5da818-6b14-43ac-9b95-49dafab27203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988881923-172.17.0.19-1597075116019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-6bb51ffa-af63-47ab-a9cc-6783c0b7205d,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-bbc35f7a-2376-444e-b831-3b537dce3ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-c345f15f-11d5-4591-97d4-25551b3c111c,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-877153bc-7372-49a8-96b1-ac38c8784bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-7a536479-0d2a-4f18-a0a8-4983c3caba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-7a47d06f-b36a-4846-a666-bcf5b29b2ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-41c0a1ed-4da8-4b4b-8aaf-a2e251d338dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-3b5da818-6b14-43ac-9b95-49dafab27203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563448485-172.17.0.19-1597075469596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-c317f54c-1c9e-4564-aabe-416cee260ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-316fdeae-f7c8-4000-b9b8-d28e8a944f83,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-01fec9b5-bc72-46a4-88e3-e4f6c13dba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-f57c4aab-c1cd-42dc-9117-6ad6c903605e,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-c3fce657-c975-48f1-af89-0bbd68a32bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-936333f8-da26-4a83-ae05-239a7405a73f,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-b16e78b7-3647-41f2-b39a-7db123e33eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-e2c191cb-9b48-43ee-9ac6-72c0d8c0aa85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563448485-172.17.0.19-1597075469596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-c317f54c-1c9e-4564-aabe-416cee260ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-316fdeae-f7c8-4000-b9b8-d28e8a944f83,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-01fec9b5-bc72-46a4-88e3-e4f6c13dba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-f57c4aab-c1cd-42dc-9117-6ad6c903605e,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-c3fce657-c975-48f1-af89-0bbd68a32bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-936333f8-da26-4a83-ae05-239a7405a73f,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-b16e78b7-3647-41f2-b39a-7db123e33eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-e2c191cb-9b48-43ee-9ac6-72c0d8c0aa85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201842410-172.17.0.19-1597075508602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37183,DS-00a16cd3-7272-49f7-9c70-056848589579,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-d9e213bd-5523-4cff-a3c8-078a800685a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-fccd52b3-356f-4f54-b7e8-a8f689ac4838,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-371e01ab-2f01-44cd-9d01-e680c3a3cf01,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-3662d115-b579-477e-b6ea-a99676ffb099,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-adcae8fc-35b5-4b3b-8e89-e89c4e3297db,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-aeecfef6-c742-4f57-afc3-2af668a62baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-d3b80d0a-12ad-4a9f-a588-1d1d7a30459a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201842410-172.17.0.19-1597075508602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37183,DS-00a16cd3-7272-49f7-9c70-056848589579,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-d9e213bd-5523-4cff-a3c8-078a800685a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-fccd52b3-356f-4f54-b7e8-a8f689ac4838,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-371e01ab-2f01-44cd-9d01-e680c3a3cf01,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-3662d115-b579-477e-b6ea-a99676ffb099,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-adcae8fc-35b5-4b3b-8e89-e89c4e3297db,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-aeecfef6-c742-4f57-afc3-2af668a62baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-d3b80d0a-12ad-4a9f-a588-1d1d7a30459a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138703789-172.17.0.19-1597075545621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-6fe3e13d-a809-4b20-a86b-c2291a53ac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-6a11b24a-26af-452d-ac36-539d008377e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-5ea46464-cab8-4772-9a66-5388b29f6a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-6c47195d-a93b-4e85-a31b-a3c0996f1257,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-46f95109-5e21-4d93-8903-0506609f28e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-bd775509-4613-4d77-9473-b6f69aec2775,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-d5d21af1-c3b3-4d37-a762-d9857148c539,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-b934c37d-0310-4319-801e-d8ce619099f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138703789-172.17.0.19-1597075545621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-6fe3e13d-a809-4b20-a86b-c2291a53ac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-6a11b24a-26af-452d-ac36-539d008377e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-5ea46464-cab8-4772-9a66-5388b29f6a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-6c47195d-a93b-4e85-a31b-a3c0996f1257,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-46f95109-5e21-4d93-8903-0506609f28e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-bd775509-4613-4d77-9473-b6f69aec2775,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-d5d21af1-c3b3-4d37-a762-d9857148c539,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-b934c37d-0310-4319-801e-d8ce619099f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320527406-172.17.0.19-1597075627485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-b35832df-9cbf-4d41-811e-71aa52786bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-eb86cba6-7176-4658-bd89-054bb9e3afee,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-3375f7bb-4fe4-451b-ae39-7bfaf42b6f72,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-944b2b7b-2754-41e9-882c-19eaf0143d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-852993ea-5384-4f76-bae3-304246f485cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-c12e4329-d782-4690-b1b9-f74f6556e7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-82b70006-e619-46c1-bd06-7ec17be78661,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-07631ae4-464f-4343-941e-9f61d332eda1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320527406-172.17.0.19-1597075627485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-b35832df-9cbf-4d41-811e-71aa52786bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-eb86cba6-7176-4658-bd89-054bb9e3afee,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-3375f7bb-4fe4-451b-ae39-7bfaf42b6f72,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-944b2b7b-2754-41e9-882c-19eaf0143d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-852993ea-5384-4f76-bae3-304246f485cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-c12e4329-d782-4690-b1b9-f74f6556e7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-82b70006-e619-46c1-bd06-7ec17be78661,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-07631ae4-464f-4343-941e-9f61d332eda1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643742481-172.17.0.19-1597075779454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45752,DS-b321bff8-138a-4078-84db-01b49b02e584,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-233e61d2-29cd-4e9d-895a-14a9e1abcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-38efff6e-6922-4933-94f9-cab12d154d50,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-8c30dfc8-6de1-4a61-ba8c-2540931a771b,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-5c9dcc3d-2c92-4620-88c2-932f0899ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-6d92f144-60e5-4a1b-a684-0e8c00339b00,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-413542fd-9dc4-4048-b34f-1504f77699dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-8124160b-5c5d-4988-8978-358864fe7f1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643742481-172.17.0.19-1597075779454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45752,DS-b321bff8-138a-4078-84db-01b49b02e584,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-233e61d2-29cd-4e9d-895a-14a9e1abcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-38efff6e-6922-4933-94f9-cab12d154d50,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-8c30dfc8-6de1-4a61-ba8c-2540931a771b,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-5c9dcc3d-2c92-4620-88c2-932f0899ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-6d92f144-60e5-4a1b-a684-0e8c00339b00,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-413542fd-9dc4-4048-b34f-1504f77699dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-8124160b-5c5d-4988-8978-358864fe7f1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905218721-172.17.0.19-1597075858976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38477,DS-f1f1ae8f-d203-4778-8445-9cfe84e3b018,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-503e66bd-e4b2-4918-a4cd-e1ff1c761c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-221f5dec-7143-4102-9671-58f4b32b2841,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-170f175e-caf7-4a04-be3a-0df9ce8d1f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-0488c634-620d-4722-a2db-ae390aec4066,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-fa7d0510-c41f-4c21-beea-87939c389777,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-984fd386-6b78-4ba5-b729-39f2c9f5f184,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-68b32fe4-c25d-48eb-bbcc-7d3ce8773e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905218721-172.17.0.19-1597075858976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38477,DS-f1f1ae8f-d203-4778-8445-9cfe84e3b018,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-503e66bd-e4b2-4918-a4cd-e1ff1c761c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-221f5dec-7143-4102-9671-58f4b32b2841,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-170f175e-caf7-4a04-be3a-0df9ce8d1f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-0488c634-620d-4722-a2db-ae390aec4066,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-fa7d0510-c41f-4c21-beea-87939c389777,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-984fd386-6b78-4ba5-b729-39f2c9f5f184,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-68b32fe4-c25d-48eb-bbcc-7d3ce8773e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544095092-172.17.0.19-1597076042589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-87549714-d7c1-4c1d-8299-4d9b23d1cd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-b675e196-c4fb-4b40-aab2-8d0b7b21aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-19b66528-a90b-4667-82ed-485651f5ac5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-58294829-bfea-4ffc-a040-f3046fe84ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-6a8e7a96-540a-4763-b271-11d186081131,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-e10c553f-d16b-48c4-97f0-7545759d2944,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-ad0f15d0-c11c-4c75-bc91-ec817bb24b22,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-ed04851e-434c-420a-856d-57897108123d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544095092-172.17.0.19-1597076042589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-87549714-d7c1-4c1d-8299-4d9b23d1cd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-b675e196-c4fb-4b40-aab2-8d0b7b21aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-19b66528-a90b-4667-82ed-485651f5ac5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-58294829-bfea-4ffc-a040-f3046fe84ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-6a8e7a96-540a-4763-b271-11d186081131,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-e10c553f-d16b-48c4-97f0-7545759d2944,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-ad0f15d0-c11c-4c75-bc91-ec817bb24b22,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-ed04851e-434c-420a-856d-57897108123d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5593
