reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697480811-172.17.0.12-1597064294856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42744,DS-3212094b-d8bf-42fc-aaeb-04cfb712a7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-d841d96c-8910-4269-8f2e-cea1a9d2e2da,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-eabacaeb-2e78-4b82-96f6-b989d6facac2,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-83e22d42-ec79-4439-9358-002881787e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-dd6ff297-d495-4938-afcf-35a5ade290e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-346a4cbb-7662-4f3a-bc40-095e7cdc4d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-382d6779-a58d-455c-a948-ba8a85358648,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-57bc8d36-00a6-47bf-b7c1-5820b70a205e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697480811-172.17.0.12-1597064294856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42744,DS-3212094b-d8bf-42fc-aaeb-04cfb712a7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-d841d96c-8910-4269-8f2e-cea1a9d2e2da,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-eabacaeb-2e78-4b82-96f6-b989d6facac2,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-83e22d42-ec79-4439-9358-002881787e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-dd6ff297-d495-4938-afcf-35a5ade290e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-346a4cbb-7662-4f3a-bc40-095e7cdc4d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-382d6779-a58d-455c-a948-ba8a85358648,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-57bc8d36-00a6-47bf-b7c1-5820b70a205e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337003660-172.17.0.12-1597064363277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-8d298e09-3375-441a-b65b-df066bcb856d,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-a426a285-31c1-4523-aea5-ba51f3fc2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-e1103f87-5d34-41ae-af3d-273ccf54ae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-d1e15b6f-d6f1-4aa9-a03a-da6caac277d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-a5275509-ad30-4696-a34f-6c945f32d1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-404131ba-f158-445d-853c-4cdb25c3a2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-40c80302-e94e-40e7-8a16-2fcf54b89341,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-2a37bd39-4ab6-4c87-b5f3-638bcc8a38d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337003660-172.17.0.12-1597064363277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-8d298e09-3375-441a-b65b-df066bcb856d,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-a426a285-31c1-4523-aea5-ba51f3fc2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-e1103f87-5d34-41ae-af3d-273ccf54ae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-d1e15b6f-d6f1-4aa9-a03a-da6caac277d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-a5275509-ad30-4696-a34f-6c945f32d1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-404131ba-f158-445d-853c-4cdb25c3a2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-40c80302-e94e-40e7-8a16-2fcf54b89341,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-2a37bd39-4ab6-4c87-b5f3-638bcc8a38d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117553734-172.17.0.12-1597064617053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-ddc1a405-7ed1-4285-9cc9-490515af2490,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-92f29ccd-dd92-4316-b215-aba45bcef0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-366dc628-d6e1-401a-a291-1627451dd00a,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-a876e2a5-e8d4-4d00-9ed0-0214a2b20b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-e21a692a-b321-468c-a92a-dd951688e61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-322004e1-016c-46ba-a27b-6472a0182d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-42972867-79b2-4725-9c10-f08f81abc4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-edb99004-ff48-4f9b-afba-6280257a8bdd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117553734-172.17.0.12-1597064617053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-ddc1a405-7ed1-4285-9cc9-490515af2490,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-92f29ccd-dd92-4316-b215-aba45bcef0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-366dc628-d6e1-401a-a291-1627451dd00a,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-a876e2a5-e8d4-4d00-9ed0-0214a2b20b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-e21a692a-b321-468c-a92a-dd951688e61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-322004e1-016c-46ba-a27b-6472a0182d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-42972867-79b2-4725-9c10-f08f81abc4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-edb99004-ff48-4f9b-afba-6280257a8bdd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804196741-172.17.0.12-1597064687603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37793,DS-d19aa3dc-49f2-4854-8ce0-be653ca2f489,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-a38c0897-88eb-4f2e-bf43-966386f92bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-bbd1fa0c-8a16-4d32-a7e0-180579b93e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-ecd61f75-d8d3-4e35-a6cc-f832718eebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-cbc590bc-13e1-495c-82a5-a8fd3c25d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-65186938-df75-48e7-a3c9-2757491f3732,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-b720a122-421d-4020-be51-8ae24dfadead,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-28ae7fbb-e8a3-4b10-9e15-076dd8c51836,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804196741-172.17.0.12-1597064687603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37793,DS-d19aa3dc-49f2-4854-8ce0-be653ca2f489,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-a38c0897-88eb-4f2e-bf43-966386f92bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-bbd1fa0c-8a16-4d32-a7e0-180579b93e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-ecd61f75-d8d3-4e35-a6cc-f832718eebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-cbc590bc-13e1-495c-82a5-a8fd3c25d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-65186938-df75-48e7-a3c9-2757491f3732,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-b720a122-421d-4020-be51-8ae24dfadead,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-28ae7fbb-e8a3-4b10-9e15-076dd8c51836,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389642839-172.17.0.12-1597064790823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33158,DS-136297ce-b568-4c4b-9cf6-f24952b91f51,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-07f7a58c-7408-4b8e-a407-2f863180b01b,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-707150b1-3fa0-4e37-bf49-0a98a2b74ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-c51cd896-f198-4334-959c-002a340a213e,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-9062c4df-45f6-45ef-9e1a-6946cf8c832f,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-1df9585f-2f40-482a-afa0-27fbeb1c7c98,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-b1487cbc-2fee-4f5a-9b6b-7f9fa71a89fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-1100767e-435c-4fa8-a6ba-96e5fddac189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389642839-172.17.0.12-1597064790823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33158,DS-136297ce-b568-4c4b-9cf6-f24952b91f51,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-07f7a58c-7408-4b8e-a407-2f863180b01b,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-707150b1-3fa0-4e37-bf49-0a98a2b74ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-c51cd896-f198-4334-959c-002a340a213e,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-9062c4df-45f6-45ef-9e1a-6946cf8c832f,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-1df9585f-2f40-482a-afa0-27fbeb1c7c98,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-b1487cbc-2fee-4f5a-9b6b-7f9fa71a89fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-1100767e-435c-4fa8-a6ba-96e5fddac189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048226709-172.17.0.12-1597064891781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-0d164a32-b33d-45c2-bb07-1d26a5e668c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-e75018b8-28f3-434d-b1d1-f69e535ac216,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-b4fb5c3a-2898-46af-8a1b-701a2edad585,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-ebd514ce-1118-4d11-9944-d2f49890df67,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-96069fbe-3f89-481a-b390-55c4158896b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-1353a2bf-3b3a-4cc9-a99c-d203d6754029,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-1b63e185-2556-44a1-99e0-d44bc30fd977,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-c6a95472-42f4-4a67-b105-448fa92f76de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048226709-172.17.0.12-1597064891781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-0d164a32-b33d-45c2-bb07-1d26a5e668c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-e75018b8-28f3-434d-b1d1-f69e535ac216,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-b4fb5c3a-2898-46af-8a1b-701a2edad585,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-ebd514ce-1118-4d11-9944-d2f49890df67,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-96069fbe-3f89-481a-b390-55c4158896b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-1353a2bf-3b3a-4cc9-a99c-d203d6754029,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-1b63e185-2556-44a1-99e0-d44bc30fd977,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-c6a95472-42f4-4a67-b105-448fa92f76de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406022059-172.17.0.12-1597064928484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33687,DS-70145076-6f2a-4764-84c2-03012473c084,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-4c12bf4f-464f-4f2d-b1bd-bb0f5e84e5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-9a976f6d-5b57-4882-8b22-82d9efef9d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-3d268d6f-4d24-4b28-932a-f7725659d505,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-b950ac6f-2d0f-4a98-a156-05fe60e63b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-0d48c641-fbdc-4ad1-9170-2e9342282729,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-2ba7f1c9-17e2-4291-9889-bb64b5e5a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-a7c35d5e-a137-4698-89ae-d821dba0cd53,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406022059-172.17.0.12-1597064928484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33687,DS-70145076-6f2a-4764-84c2-03012473c084,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-4c12bf4f-464f-4f2d-b1bd-bb0f5e84e5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-9a976f6d-5b57-4882-8b22-82d9efef9d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-3d268d6f-4d24-4b28-932a-f7725659d505,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-b950ac6f-2d0f-4a98-a156-05fe60e63b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-0d48c641-fbdc-4ad1-9170-2e9342282729,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-2ba7f1c9-17e2-4291-9889-bb64b5e5a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-a7c35d5e-a137-4698-89ae-d821dba0cd53,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115329229-172.17.0.12-1597065062753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-5d60bd88-60ed-436f-ae83-69aafbebbc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-282d03a2-efd3-429c-9d4b-1037daac6581,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-72d741db-7003-48f6-90d9-611c8ac0156a,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-47ce5faf-639d-469c-b04d-dbc94ca36bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-af7178b6-fb9f-4d07-bb3d-7613a58092bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-24e3227d-0bd2-4bd4-88f9-0090f38497ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-09a649d4-8c07-4689-b74b-8674c74cb37c,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-4bb9d3aa-61af-4201-b3d7-9c674c6057d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115329229-172.17.0.12-1597065062753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-5d60bd88-60ed-436f-ae83-69aafbebbc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-282d03a2-efd3-429c-9d4b-1037daac6581,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-72d741db-7003-48f6-90d9-611c8ac0156a,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-47ce5faf-639d-469c-b04d-dbc94ca36bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-af7178b6-fb9f-4d07-bb3d-7613a58092bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-24e3227d-0bd2-4bd4-88f9-0090f38497ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-09a649d4-8c07-4689-b74b-8674c74cb37c,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-4bb9d3aa-61af-4201-b3d7-9c674c6057d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153835199-172.17.0.12-1597065124359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-a1ed5078-7cb7-4931-a05f-caf66f83bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-ba369567-28d6-46f7-b6fe-5221f96d199f,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-c6049b6f-8d35-4491-a86e-9f80757a7a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-f99734b3-83a3-477d-bcb3-408aff4a9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-d93530e9-d82a-4a88-9970-8cdb6eac2465,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-55b7ad75-0997-4ce1-90d4-61662236437a,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-d1f6241b-c4a2-4af0-b4fc-3472f4f431e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-9fb50f77-0f94-49f2-ba08-28c1a31048e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153835199-172.17.0.12-1597065124359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-a1ed5078-7cb7-4931-a05f-caf66f83bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-ba369567-28d6-46f7-b6fe-5221f96d199f,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-c6049b6f-8d35-4491-a86e-9f80757a7a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-f99734b3-83a3-477d-bcb3-408aff4a9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-d93530e9-d82a-4a88-9970-8cdb6eac2465,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-55b7ad75-0997-4ce1-90d4-61662236437a,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-d1f6241b-c4a2-4af0-b4fc-3472f4f431e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-9fb50f77-0f94-49f2-ba08-28c1a31048e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149703883-172.17.0.12-1597065362967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44955,DS-2985d5ee-eb9d-4781-bc5a-b429d59d88b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-169995d7-ad78-440c-b6ab-db995b276388,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-ce9f3f3a-3633-40a4-b753-c5fe63520dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-e28b9b2c-cd48-45ba-8e01-0939027013ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-dc92e114-8aeb-4f5d-9ba9-935e458c71d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-7cbc6a58-81ee-4223-847a-e5a19a53f8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-b4dd6bf7-833b-4c35-b97b-7da7e7346156,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-23b1b06f-3ad0-4c48-988f-b71df4d8216e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149703883-172.17.0.12-1597065362967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44955,DS-2985d5ee-eb9d-4781-bc5a-b429d59d88b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-169995d7-ad78-440c-b6ab-db995b276388,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-ce9f3f3a-3633-40a4-b753-c5fe63520dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-e28b9b2c-cd48-45ba-8e01-0939027013ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-dc92e114-8aeb-4f5d-9ba9-935e458c71d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-7cbc6a58-81ee-4223-847a-e5a19a53f8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-b4dd6bf7-833b-4c35-b97b-7da7e7346156,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-23b1b06f-3ad0-4c48-988f-b71df4d8216e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749754318-172.17.0.12-1597065505103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-5d00dcf1-9967-4399-a7ba-5dfc213ef178,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-3356196e-021b-400e-8c57-98d98a6ba3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-3b89ea52-80ff-4ebd-bc13-5e0b402cb63f,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-14323c92-e43d-41be-94bc-07587eaf83f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-beb6ecfb-d693-4820-9e5f-b94e1414db76,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-ae8045b3-6367-4aa9-b5db-6e6222509e37,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-3bd8b5f3-5c14-41d5-9b93-62244496aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-49fef2c3-9713-4a9a-a4e6-e607dfd45d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749754318-172.17.0.12-1597065505103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-5d00dcf1-9967-4399-a7ba-5dfc213ef178,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-3356196e-021b-400e-8c57-98d98a6ba3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-3b89ea52-80ff-4ebd-bc13-5e0b402cb63f,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-14323c92-e43d-41be-94bc-07587eaf83f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-beb6ecfb-d693-4820-9e5f-b94e1414db76,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-ae8045b3-6367-4aa9-b5db-6e6222509e37,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-3bd8b5f3-5c14-41d5-9b93-62244496aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-49fef2c3-9713-4a9a-a4e6-e607dfd45d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083337690-172.17.0.12-1597065541849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44039,DS-14d3126e-2343-42ce-8ebd-d0d9cf220a44,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-9581dbfb-c65e-479c-9d3f-56e4adb57c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-542b5a14-0963-476b-a5f9-41376c7d9248,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-3ecf7218-63b0-4957-9dde-f2d3a2952e09,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-3d0c4e4b-26e1-4e19-985d-59d34e56152b,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-b045e67e-224a-4455-a93a-4fcd672a1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-4e3ed2a7-bb17-405a-8a58-9342352d4713,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-fcb4755e-905f-4572-9467-6bf06982e0b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083337690-172.17.0.12-1597065541849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44039,DS-14d3126e-2343-42ce-8ebd-d0d9cf220a44,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-9581dbfb-c65e-479c-9d3f-56e4adb57c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-542b5a14-0963-476b-a5f9-41376c7d9248,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-3ecf7218-63b0-4957-9dde-f2d3a2952e09,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-3d0c4e4b-26e1-4e19-985d-59d34e56152b,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-b045e67e-224a-4455-a93a-4fcd672a1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-4e3ed2a7-bb17-405a-8a58-9342352d4713,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-fcb4755e-905f-4572-9467-6bf06982e0b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979644068-172.17.0.12-1597065716667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-d7adcd31-c6b1-48ce-a1c7-35dc1232d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-350fd14a-cb10-4eb8-aa5f-03f3627fed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-d7e4b3a7-3d16-4d3b-8e01-49a90127235a,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-61201033-f9a0-46d0-bcdd-74ec693a5fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-294ca256-0c58-4548-ac85-d91c3323f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-3d3e7fdf-ac34-4b67-b5c1-f8536b27dc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-8c17d85a-1aef-479b-a2c0-8e0daed3b44a,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-a47d38b7-a28a-4b07-ae24-3941e80fbc2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979644068-172.17.0.12-1597065716667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-d7adcd31-c6b1-48ce-a1c7-35dc1232d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-350fd14a-cb10-4eb8-aa5f-03f3627fed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-d7e4b3a7-3d16-4d3b-8e01-49a90127235a,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-61201033-f9a0-46d0-bcdd-74ec693a5fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-294ca256-0c58-4548-ac85-d91c3323f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-3d3e7fdf-ac34-4b67-b5c1-f8536b27dc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-8c17d85a-1aef-479b-a2c0-8e0daed3b44a,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-a47d38b7-a28a-4b07-ae24-3941e80fbc2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205826907-172.17.0.12-1597065809764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34787,DS-3dcc31d6-d76a-4405-ae2d-778469968c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-833bacbc-a693-45b8-a521-07ea77aad254,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-ba7a97b1-4e50-4286-b51b-9c82fc91297f,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-434bfaa3-e426-4913-97bc-a75353c8539a,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-2c46c10e-ee2e-4b14-8b44-18acd40c38c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-e5198f35-b517-463e-b9cb-1914286269f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-bc664bfe-5adf-4aab-9427-1dc3a33924a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-b5a61d8e-89d1-4654-a41e-656b8ad7ee7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205826907-172.17.0.12-1597065809764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34787,DS-3dcc31d6-d76a-4405-ae2d-778469968c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-833bacbc-a693-45b8-a521-07ea77aad254,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-ba7a97b1-4e50-4286-b51b-9c82fc91297f,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-434bfaa3-e426-4913-97bc-a75353c8539a,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-2c46c10e-ee2e-4b14-8b44-18acd40c38c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-e5198f35-b517-463e-b9cb-1914286269f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-bc664bfe-5adf-4aab-9427-1dc3a33924a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-b5a61d8e-89d1-4654-a41e-656b8ad7ee7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773779702-172.17.0.12-1597065950604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46240,DS-a0a3534e-b599-46c0-be92-b2f29be02363,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-9faa4dc5-94bf-4356-be9f-fffcedc2c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-ffb4953f-e97a-49d7-b8c6-ab3f96dac851,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-6a0986cc-a118-42cd-968a-2a4354a616bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-945b551a-76db-47ff-8fbb-b5def9e27cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-718be1e9-cf32-478d-9b65-cc27cfc11744,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-466c5b19-929a-413f-afcd-c4e46934963a,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-cc0f6ed2-fece-4b73-ba6f-596d6cb91ff9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773779702-172.17.0.12-1597065950604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46240,DS-a0a3534e-b599-46c0-be92-b2f29be02363,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-9faa4dc5-94bf-4356-be9f-fffcedc2c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-ffb4953f-e97a-49d7-b8c6-ab3f96dac851,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-6a0986cc-a118-42cd-968a-2a4354a616bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-945b551a-76db-47ff-8fbb-b5def9e27cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-718be1e9-cf32-478d-9b65-cc27cfc11744,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-466c5b19-929a-413f-afcd-c4e46934963a,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-cc0f6ed2-fece-4b73-ba6f-596d6cb91ff9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920729314-172.17.0.12-1597066203743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-91bbc6fe-3018-4732-9c56-b846b837f928,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-9cf93251-72ce-4996-be93-a7ea4dc09955,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-e7901dc5-7eea-40e8-a0d6-a62e1f391c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-e0533098-4904-4cb2-9904-3d13d41b5e06,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-43473ac8-b0f8-47f8-8257-27c36213ff05,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-df103cdc-0ca8-4e02-beee-20d9c86eda53,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-6dfaf69d-0d7c-4476-884b-f40e1133bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-f5ff8402-e0a0-4903-aa58-aed2b0c9501f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920729314-172.17.0.12-1597066203743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-91bbc6fe-3018-4732-9c56-b846b837f928,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-9cf93251-72ce-4996-be93-a7ea4dc09955,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-e7901dc5-7eea-40e8-a0d6-a62e1f391c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-e0533098-4904-4cb2-9904-3d13d41b5e06,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-43473ac8-b0f8-47f8-8257-27c36213ff05,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-df103cdc-0ca8-4e02-beee-20d9c86eda53,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-6dfaf69d-0d7c-4476-884b-f40e1133bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-f5ff8402-e0a0-4903-aa58-aed2b0c9501f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591267381-172.17.0.12-1597066447880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-8404d1a7-e82a-439b-ace6-1dfe63b12cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-c12ce1ee-9afb-463b-a25c-750ae7afdb57,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-390a894e-3697-497a-92ea-26e59375e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-c56bbf36-a772-492a-9744-40dcb203361a,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-caf28e57-a45b-4d66-9812-48d0708111fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-c0bbecea-fd70-438d-a675-bf4fd6d7ad71,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-4f69e9e9-b2cb-4e0a-9147-c54f77237b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-26e08655-abdc-444f-9b42-35a7b08a94a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591267381-172.17.0.12-1597066447880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-8404d1a7-e82a-439b-ace6-1dfe63b12cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-c12ce1ee-9afb-463b-a25c-750ae7afdb57,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-390a894e-3697-497a-92ea-26e59375e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-c56bbf36-a772-492a-9744-40dcb203361a,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-caf28e57-a45b-4d66-9812-48d0708111fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-c0bbecea-fd70-438d-a675-bf4fd6d7ad71,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-4f69e9e9-b2cb-4e0a-9147-c54f77237b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-26e08655-abdc-444f-9b42-35a7b08a94a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878290456-172.17.0.12-1597066659906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32855,DS-14bce052-84ae-4e7a-a5b6-78d7a401c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-53532e2a-bfe3-488f-9f4e-70347c872940,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-367e11d7-b4c8-4695-896e-36c31aada1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-69f9160f-e41f-4270-bc5b-be24cfdc7945,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-ef77860c-4141-4bf1-8207-54957d26f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-e92821bc-8d11-4c3e-8034-0e2584327ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-3f67786f-20f5-48b7-8fb8-7fb942fe6662,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-509c14ce-6294-4230-8432-2f341deaeb41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878290456-172.17.0.12-1597066659906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32855,DS-14bce052-84ae-4e7a-a5b6-78d7a401c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-53532e2a-bfe3-488f-9f4e-70347c872940,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-367e11d7-b4c8-4695-896e-36c31aada1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-69f9160f-e41f-4270-bc5b-be24cfdc7945,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-ef77860c-4141-4bf1-8207-54957d26f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-e92821bc-8d11-4c3e-8034-0e2584327ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-3f67786f-20f5-48b7-8fb8-7fb942fe6662,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-509c14ce-6294-4230-8432-2f341deaeb41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041754782-172.17.0.12-1597066697684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33541,DS-5e3bb10d-c676-4ce0-9908-d5b7a8a6ae72,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-34e30247-3929-4c24-a0e9-0d70d82c9f48,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-03116732-25f3-4429-ad0c-5a380a74c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-82e81df0-e51c-4173-b357-fed2414fb98c,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-b37f8890-a4b4-4321-90ff-19630f6d646d,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-d213aa91-cbac-4af2-a635-4ee74ad29fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-2d9ecd96-94e2-446e-90b4-e71dd4395bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-cc452197-cc12-477b-b360-5df29f413f41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041754782-172.17.0.12-1597066697684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33541,DS-5e3bb10d-c676-4ce0-9908-d5b7a8a6ae72,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-34e30247-3929-4c24-a0e9-0d70d82c9f48,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-03116732-25f3-4429-ad0c-5a380a74c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-82e81df0-e51c-4173-b357-fed2414fb98c,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-b37f8890-a4b4-4321-90ff-19630f6d646d,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-d213aa91-cbac-4af2-a635-4ee74ad29fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-2d9ecd96-94e2-446e-90b4-e71dd4395bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-cc452197-cc12-477b-b360-5df29f413f41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832898790-172.17.0.12-1597066730768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-957d6b7c-c26f-4ec5-9628-a5e1e69ea7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-5748871d-ec73-409c-85ea-4e3b3dfea7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-f9f7558d-68e9-4fe7-9269-628e38e9123b,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-22d039c1-6359-4568-a099-d654ca4ebf60,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-dfc4c025-bb8f-44e3-8ab5-2ea921438be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-af6d17a8-a787-4c87-aa30-cfcd37364251,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-3937a30b-7ba0-42c9-95fb-21594497cb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-4cb48683-9228-40ee-ae1a-40be0db5248c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832898790-172.17.0.12-1597066730768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-957d6b7c-c26f-4ec5-9628-a5e1e69ea7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-5748871d-ec73-409c-85ea-4e3b3dfea7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-f9f7558d-68e9-4fe7-9269-628e38e9123b,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-22d039c1-6359-4568-a099-d654ca4ebf60,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-dfc4c025-bb8f-44e3-8ab5-2ea921438be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-af6d17a8-a787-4c87-aa30-cfcd37364251,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-3937a30b-7ba0-42c9-95fb-21594497cb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-4cb48683-9228-40ee-ae1a-40be0db5248c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626410470-172.17.0.12-1597066891256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35800,DS-313bed33-410e-49ee-b833-cf7a69613807,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-e518996d-ae9e-433b-8986-864ad1eb8371,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-abe976dc-69c1-4301-be46-1cb0c57d23da,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-b0868edd-bc7e-40ff-a084-5c3985f43e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-9e92091b-e148-449d-959d-ba8edffe7dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-a079223f-1d44-41cd-8cc5-4e003af95002,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-504ca0dc-50ed-4ee6-8197-885189331046,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-64db0400-246f-4e14-93cf-3051618b244e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626410470-172.17.0.12-1597066891256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35800,DS-313bed33-410e-49ee-b833-cf7a69613807,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-e518996d-ae9e-433b-8986-864ad1eb8371,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-abe976dc-69c1-4301-be46-1cb0c57d23da,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-b0868edd-bc7e-40ff-a084-5c3985f43e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-9e92091b-e148-449d-959d-ba8edffe7dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-a079223f-1d44-41cd-8cc5-4e003af95002,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-504ca0dc-50ed-4ee6-8197-885189331046,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-64db0400-246f-4e14-93cf-3051618b244e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571771295-172.17.0.12-1597067001911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34080,DS-41dac43b-fcd9-4979-a888-cbea9e35ced5,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-17c9482d-d496-43fd-b462-5f8f9b46dd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-49553fff-21fd-4894-8061-f346e5d03e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-103a9f2e-7600-41da-93c2-89bb7df50856,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-4eab9ddd-2c83-43aa-b9f0-656f8bb396e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-584950cb-9090-42ba-87f5-e0a445965e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-7eaa764e-cb53-4325-929e-cacd69b44c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-6607a4b2-af68-4f3a-8ee4-ada7b8b9f783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571771295-172.17.0.12-1597067001911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34080,DS-41dac43b-fcd9-4979-a888-cbea9e35ced5,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-17c9482d-d496-43fd-b462-5f8f9b46dd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-49553fff-21fd-4894-8061-f346e5d03e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-103a9f2e-7600-41da-93c2-89bb7df50856,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-4eab9ddd-2c83-43aa-b9f0-656f8bb396e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-584950cb-9090-42ba-87f5-e0a445965e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-7eaa764e-cb53-4325-929e-cacd69b44c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-6607a4b2-af68-4f3a-8ee4-ada7b8b9f783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058884601-172.17.0.12-1597067033236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41056,DS-21379ead-1af8-4ad2-b3f3-3431a60cd9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-f226c284-bef5-4651-b014-0bb3b34e6551,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-ba04dff5-09e2-4b7e-ab9c-b2628c20acee,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-be4c30e7-fae1-472c-960c-e13cea518bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-11c605d8-04a8-4bc7-a43a-f75d43429744,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-1a919a80-af1f-445a-8f0c-edb3ae01fd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-95f22171-037e-4253-a30b-83045cf3b797,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-7cec4325-63c4-498b-8903-dcc34abf3c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058884601-172.17.0.12-1597067033236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41056,DS-21379ead-1af8-4ad2-b3f3-3431a60cd9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-f226c284-bef5-4651-b014-0bb3b34e6551,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-ba04dff5-09e2-4b7e-ab9c-b2628c20acee,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-be4c30e7-fae1-472c-960c-e13cea518bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-11c605d8-04a8-4bc7-a43a-f75d43429744,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-1a919a80-af1f-445a-8f0c-edb3ae01fd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-95f22171-037e-4253-a30b-83045cf3b797,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-7cec4325-63c4-498b-8903-dcc34abf3c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581585874-172.17.0.12-1597067134010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39743,DS-54b53d26-b1d7-4aac-8003-233efacda313,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-d06f077b-7b12-4ad7-b531-0eecf1c1d794,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-69db922b-3938-4480-bb73-6246dc2d0dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-cc91b2bc-8f35-43bb-a0da-0e51e13df588,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-20c91ef5-a5f9-41c9-8e9e-0dda7d9f067f,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-8ef5cd16-c11a-470e-bd29-a6de1a427ced,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-3d194278-0075-428d-879b-e79e8f075c69,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-f871758d-12d3-4732-b546-d35596e67599,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581585874-172.17.0.12-1597067134010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39743,DS-54b53d26-b1d7-4aac-8003-233efacda313,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-d06f077b-7b12-4ad7-b531-0eecf1c1d794,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-69db922b-3938-4480-bb73-6246dc2d0dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-cc91b2bc-8f35-43bb-a0da-0e51e13df588,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-20c91ef5-a5f9-41c9-8e9e-0dda7d9f067f,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-8ef5cd16-c11a-470e-bd29-a6de1a427ced,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-3d194278-0075-428d-879b-e79e8f075c69,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-f871758d-12d3-4732-b546-d35596e67599,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450172036-172.17.0.12-1597067164165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-3d897070-fcc1-432d-8ada-f54781bba797,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-5b7fc960-53fd-4022-a4a7-acbec8c97c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-1c99fe25-5783-4a6f-b48c-7f9ee7a0fb89,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-0ce77a8c-d3bd-4b34-b3d0-f4721f16e261,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-3bf38c4b-1f07-4488-a599-86d3f7e024cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-33ef5516-4f70-4a96-a06a-1d73e6fe7ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-ebf09f42-7235-440e-9197-366a49b0d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-5d49a641-8285-47a6-b9a1-4fa0583a3615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450172036-172.17.0.12-1597067164165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-3d897070-fcc1-432d-8ada-f54781bba797,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-5b7fc960-53fd-4022-a4a7-acbec8c97c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-1c99fe25-5783-4a6f-b48c-7f9ee7a0fb89,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-0ce77a8c-d3bd-4b34-b3d0-f4721f16e261,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-3bf38c4b-1f07-4488-a599-86d3f7e024cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-33ef5516-4f70-4a96-a06a-1d73e6fe7ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-ebf09f42-7235-440e-9197-366a49b0d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-5d49a641-8285-47a6-b9a1-4fa0583a3615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733874740-172.17.0.12-1597067273812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37091,DS-c2fa7492-c277-4544-a1f1-e7f58d21f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-03e27115-553c-4a44-9992-43e45d6831c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-d89298e2-738a-42cf-a8ae-7ad1e31ee883,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-50d7ba3e-62e2-4ff8-a461-4480b068a853,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-1961763c-289b-4e95-9346-5cba612a70b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-7aaacfb1-72b7-4437-86db-bf46e7e53b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-3bfa9c16-9340-49a6-8be4-2646b8240ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-a06ca566-8774-4dce-bfbb-cc8d8f5d4540,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733874740-172.17.0.12-1597067273812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37091,DS-c2fa7492-c277-4544-a1f1-e7f58d21f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-03e27115-553c-4a44-9992-43e45d6831c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-d89298e2-738a-42cf-a8ae-7ad1e31ee883,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-50d7ba3e-62e2-4ff8-a461-4480b068a853,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-1961763c-289b-4e95-9346-5cba612a70b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-7aaacfb1-72b7-4437-86db-bf46e7e53b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-3bfa9c16-9340-49a6-8be4-2646b8240ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-a06ca566-8774-4dce-bfbb-cc8d8f5d4540,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688596866-172.17.0.12-1597067558694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-2de52632-b022-41d8-8c5a-846c7fab46ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-92979485-d109-4802-93fb-8fbf152aa0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-811004e7-fdb5-47d4-9af7-acae7831e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-3cdab8fb-a42c-4c70-8d63-95dca62d7cad,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-8aa50c7c-d5a1-4fab-b1aa-681709b41695,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-d200c156-2fdd-4258-b0ee-e91f228774f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-6fad2931-044b-408a-bc69-842733f8c2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-6d240e80-3f09-4eab-b5a8-7f0148c883f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688596866-172.17.0.12-1597067558694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-2de52632-b022-41d8-8c5a-846c7fab46ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-92979485-d109-4802-93fb-8fbf152aa0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-811004e7-fdb5-47d4-9af7-acae7831e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-3cdab8fb-a42c-4c70-8d63-95dca62d7cad,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-8aa50c7c-d5a1-4fab-b1aa-681709b41695,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-d200c156-2fdd-4258-b0ee-e91f228774f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-6fad2931-044b-408a-bc69-842733f8c2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-6d240e80-3f09-4eab-b5a8-7f0148c883f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958426394-172.17.0.12-1597067770719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-68db4e1e-ec32-466f-b7ab-b382e2f44140,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-9f6e96a4-0340-47df-bbde-f5397f4def38,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-d0e63219-da8b-4463-bd08-d1a8d59f20fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-e865c35e-32d3-422c-bde7-33b3f28d61b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-3019bd4b-f129-4478-9819-39783e85b162,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-9b7d78e9-e83f-4cc9-9321-3f41a503f61b,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-c46bce15-853f-446c-a1de-659a8d18b471,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-d581df0a-2db3-421b-94ff-44e7fd48c6a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958426394-172.17.0.12-1597067770719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-68db4e1e-ec32-466f-b7ab-b382e2f44140,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-9f6e96a4-0340-47df-bbde-f5397f4def38,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-d0e63219-da8b-4463-bd08-d1a8d59f20fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-e865c35e-32d3-422c-bde7-33b3f28d61b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-3019bd4b-f129-4478-9819-39783e85b162,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-9b7d78e9-e83f-4cc9-9321-3f41a503f61b,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-c46bce15-853f-446c-a1de-659a8d18b471,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-d581df0a-2db3-421b-94ff-44e7fd48c6a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918853917-172.17.0.12-1597067843314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45849,DS-812ca942-fef3-405d-93b1-04fe829b9754,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-f8c444d4-5cce-41f1-b3fb-379517b30df3,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-fd5386fe-bb6d-4c43-ba14-8613b7b2902e,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-1a269d20-4985-454f-8e41-3d0dfa200ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-9855933a-4d18-4726-ab1b-e43af75efe54,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-5ae44fc1-3f9e-4c06-a281-382ac22be5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-4b23e3ba-9df9-4864-8d0e-d7a04a555bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-358e6049-9ba2-4806-8cae-82322f85e9e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918853917-172.17.0.12-1597067843314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45849,DS-812ca942-fef3-405d-93b1-04fe829b9754,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-f8c444d4-5cce-41f1-b3fb-379517b30df3,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-fd5386fe-bb6d-4c43-ba14-8613b7b2902e,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-1a269d20-4985-454f-8e41-3d0dfa200ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-9855933a-4d18-4726-ab1b-e43af75efe54,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-5ae44fc1-3f9e-4c06-a281-382ac22be5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-4b23e3ba-9df9-4864-8d0e-d7a04a555bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-358e6049-9ba2-4806-8cae-82322f85e9e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347222597-172.17.0.12-1597068171196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37057,DS-9b5d373f-8d74-4817-a90c-06b2eeb1ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-05a5d4c4-6981-4770-9659-90f344c367b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-d0748860-9bce-4c51-aec7-422b44831c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-1d0cd76c-d82a-4770-83b2-701c037b2156,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-7e1c3a2e-5d72-4c0e-9780-db3d81223582,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-7c3fc324-b56d-44ff-88dd-cf092df961f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-b4d2ef85-82b1-4e77-b305-426c55afec68,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-1c15552a-f6c4-4387-ab7f-672a95cd65f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347222597-172.17.0.12-1597068171196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37057,DS-9b5d373f-8d74-4817-a90c-06b2eeb1ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-05a5d4c4-6981-4770-9659-90f344c367b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-d0748860-9bce-4c51-aec7-422b44831c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-1d0cd76c-d82a-4770-83b2-701c037b2156,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-7e1c3a2e-5d72-4c0e-9780-db3d81223582,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-7c3fc324-b56d-44ff-88dd-cf092df961f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-b4d2ef85-82b1-4e77-b305-426c55afec68,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-1c15552a-f6c4-4387-ab7f-672a95cd65f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105126097-172.17.0.12-1597068314722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-d079f18e-32f7-450d-b396-bf2b47bee0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-ab64f460-28a5-4b20-a8de-adf7a44ad9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-80d95813-80bb-4a91-8171-b06504b8ac44,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-e2d226f3-95ff-464a-a66e-aec991193165,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-7a8381be-a32b-496d-a146-d8041ca455a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-900bc7fe-0845-4d90-9b40-a6787b143af8,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-fb848813-fa59-4065-9e05-33cd930582b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-6b9a65b4-d55b-4493-ac4f-a94cc74876b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105126097-172.17.0.12-1597068314722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-d079f18e-32f7-450d-b396-bf2b47bee0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-ab64f460-28a5-4b20-a8de-adf7a44ad9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-80d95813-80bb-4a91-8171-b06504b8ac44,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-e2d226f3-95ff-464a-a66e-aec991193165,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-7a8381be-a32b-496d-a146-d8041ca455a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-900bc7fe-0845-4d90-9b40-a6787b143af8,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-fb848813-fa59-4065-9e05-33cd930582b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-6b9a65b4-d55b-4493-ac4f-a94cc74876b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941734644-172.17.0.12-1597068451042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-bd8fa05d-3a36-4d27-aeb7-c9aa2d3770d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-cda02565-1e8d-4b9b-bb98-4b413381c943,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-9f88273c-e0fa-48df-8095-e7c0c837f1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-4ec41500-2f01-415e-b307-6ff7e638ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-3072d49d-6332-43ba-8b5e-1233746d13f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-5bf0ee97-443b-4c5f-81b8-fcd7091a8813,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-40d08302-aa4e-4f63-9026-6613887ff66c,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-bb752eea-350a-48ff-acd5-1e865f5c3b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941734644-172.17.0.12-1597068451042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-bd8fa05d-3a36-4d27-aeb7-c9aa2d3770d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-cda02565-1e8d-4b9b-bb98-4b413381c943,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-9f88273c-e0fa-48df-8095-e7c0c837f1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-4ec41500-2f01-415e-b307-6ff7e638ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-3072d49d-6332-43ba-8b5e-1233746d13f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-5bf0ee97-443b-4c5f-81b8-fcd7091a8813,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-40d08302-aa4e-4f63-9026-6613887ff66c,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-bb752eea-350a-48ff-acd5-1e865f5c3b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977637620-172.17.0.12-1597068924059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-edc5c7fc-6f4d-4372-a5fe-d7e7760adafb,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-21d3032e-cb4b-45e5-8b70-b80ea75e0e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-0025bca4-75b7-4924-a0c2-b28323afd54d,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-c04b86bd-442c-44e5-aecf-cb4bb12d7259,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-4510da08-b203-45b2-b1dc-a3f2557d8580,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-f91dcc96-0bd9-44cd-8079-04c885910a63,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-9a030981-185d-4990-8e50-d4aac776d674,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-743fec30-b057-4f8f-ac6a-0a767eb83d42,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977637620-172.17.0.12-1597068924059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-edc5c7fc-6f4d-4372-a5fe-d7e7760adafb,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-21d3032e-cb4b-45e5-8b70-b80ea75e0e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-0025bca4-75b7-4924-a0c2-b28323afd54d,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-c04b86bd-442c-44e5-aecf-cb4bb12d7259,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-4510da08-b203-45b2-b1dc-a3f2557d8580,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-f91dcc96-0bd9-44cd-8079-04c885910a63,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-9a030981-185d-4990-8e50-d4aac776d674,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-743fec30-b057-4f8f-ac6a-0a767eb83d42,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569804915-172.17.0.12-1597069097395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41987,DS-6a5a2a5d-cd21-4e98-8d55-39c2fe70fcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-87c127c9-b988-42a7-854c-301a8005b723,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-37e23426-ff7a-4091-8f6a-8d91a0b83902,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-123eb380-53fc-4e2b-9fdc-b352d93137f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-300dc911-ff71-4eeb-ab85-907f2bb49e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-339e21f2-6c09-4d73-98b8-f27ce31693d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-f8e61ada-ad7a-4f81-b7a2-56bb3683ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-a4e25979-9c93-4008-8a10-8fe392d87614,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569804915-172.17.0.12-1597069097395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41987,DS-6a5a2a5d-cd21-4e98-8d55-39c2fe70fcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-87c127c9-b988-42a7-854c-301a8005b723,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-37e23426-ff7a-4091-8f6a-8d91a0b83902,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-123eb380-53fc-4e2b-9fdc-b352d93137f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-300dc911-ff71-4eeb-ab85-907f2bb49e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-339e21f2-6c09-4d73-98b8-f27ce31693d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-f8e61ada-ad7a-4f81-b7a2-56bb3683ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-a4e25979-9c93-4008-8a10-8fe392d87614,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5186
