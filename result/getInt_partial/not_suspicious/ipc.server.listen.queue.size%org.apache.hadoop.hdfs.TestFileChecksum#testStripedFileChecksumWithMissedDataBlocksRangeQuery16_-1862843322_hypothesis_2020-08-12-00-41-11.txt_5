reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472368313-172.17.0.3-1597193468571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-ec9f1036-d57e-4e53-91e1-0b27383b5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-cc028fd2-0b54-4618-99f0-2a536ad4245a,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-cbfa7606-3321-4fad-9fb6-82f0b7c4c525,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-4a2b869b-6568-4fb2-9a44-a7b12ba643e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-d812a056-393f-47d2-b5be-77fc401c4d75,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-e4e95819-0d50-46d4-ac58-f48d925bb710,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-cf92dc31-5653-40b2-a004-a2ece4071856,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-b5485d8c-77dd-46d8-b9b5-c946c5ec2889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472368313-172.17.0.3-1597193468571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-ec9f1036-d57e-4e53-91e1-0b27383b5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-cc028fd2-0b54-4618-99f0-2a536ad4245a,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-cbfa7606-3321-4fad-9fb6-82f0b7c4c525,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-4a2b869b-6568-4fb2-9a44-a7b12ba643e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-d812a056-393f-47d2-b5be-77fc401c4d75,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-e4e95819-0d50-46d4-ac58-f48d925bb710,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-cf92dc31-5653-40b2-a004-a2ece4071856,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-b5485d8c-77dd-46d8-b9b5-c946c5ec2889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981323975-172.17.0.3-1597193679223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34198,DS-aaad2bea-eddd-4bd2-89ec-956e186dadaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-a5410810-bea9-41c3-9de8-861a22621b14,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-8baa5c7e-7d68-4933-b606-ea212d6dfdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-2ab443eb-1776-4b5c-9077-37edde91ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-7754ae5a-536b-40d3-a9cf-d781127de115,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-668cf8f5-0152-48c7-9ff2-7596bf74fa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-38f67eb8-81ad-42bc-8df7-0c5ddaa70b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-d2c40476-3e8f-414e-a754-cfc434c8456b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981323975-172.17.0.3-1597193679223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34198,DS-aaad2bea-eddd-4bd2-89ec-956e186dadaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-a5410810-bea9-41c3-9de8-861a22621b14,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-8baa5c7e-7d68-4933-b606-ea212d6dfdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-2ab443eb-1776-4b5c-9077-37edde91ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-7754ae5a-536b-40d3-a9cf-d781127de115,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-668cf8f5-0152-48c7-9ff2-7596bf74fa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-38f67eb8-81ad-42bc-8df7-0c5ddaa70b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-d2c40476-3e8f-414e-a754-cfc434c8456b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406090990-172.17.0.3-1597194068579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43539,DS-330121a2-426f-4f03-8662-31910b114d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-7f04f03e-085e-4c74-9ffc-1cd9400a5e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-e2b640c9-7df1-43dc-a800-f81efa4c1967,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-f7352f14-ca6d-499b-b4d0-7ddafbc07f37,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-cab545df-e959-4035-858b-ce56fa44b92a,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-3b8b9a38-b373-49c4-9c06-bf33062b8c17,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-572f5351-ea51-4663-ad3a-76563e40ed8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-092ef157-e5f4-4d93-b4d0-8b1d84fd376c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406090990-172.17.0.3-1597194068579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43539,DS-330121a2-426f-4f03-8662-31910b114d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-7f04f03e-085e-4c74-9ffc-1cd9400a5e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-e2b640c9-7df1-43dc-a800-f81efa4c1967,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-f7352f14-ca6d-499b-b4d0-7ddafbc07f37,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-cab545df-e959-4035-858b-ce56fa44b92a,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-3b8b9a38-b373-49c4-9c06-bf33062b8c17,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-572f5351-ea51-4663-ad3a-76563e40ed8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-092ef157-e5f4-4d93-b4d0-8b1d84fd376c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521462341-172.17.0.3-1597194616280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41810,DS-75cb0750-1764-4866-9adf-8b1734837d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-88321f13-d552-403c-924d-2a0c2f3e8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-36d496e3-016c-4498-8fba-a92a849f1eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-c9c53c49-632f-4114-a1e0-b4ae70cb0071,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-4e54abe6-d08f-45c2-a6b4-61384d3f0522,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-b7dcfa6c-1325-4972-bf4e-833746ae9050,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-98ddaec9-0151-422b-8241-965343a531ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-17ac3a17-9ee7-4c84-b9c7-6fd6c0e6ffc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521462341-172.17.0.3-1597194616280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41810,DS-75cb0750-1764-4866-9adf-8b1734837d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-88321f13-d552-403c-924d-2a0c2f3e8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-36d496e3-016c-4498-8fba-a92a849f1eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-c9c53c49-632f-4114-a1e0-b4ae70cb0071,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-4e54abe6-d08f-45c2-a6b4-61384d3f0522,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-b7dcfa6c-1325-4972-bf4e-833746ae9050,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-98ddaec9-0151-422b-8241-965343a531ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-17ac3a17-9ee7-4c84-b9c7-6fd6c0e6ffc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706637897-172.17.0.3-1597195077230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37303,DS-c0186a9f-1509-4278-ae3f-8b72121a6b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-7e5f3a94-8a10-4247-b5fe-09daa62ea7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-9ced8911-a7ee-44b0-b222-c424f80de206,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-08941fb7-03d3-4f0f-9f35-6f31f4a5310c,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-7bf20c34-8d2a-405f-b26a-e9d0e30c7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-01f06fd0-6631-4d26-8474-df5b15abbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-133fc965-0f83-45e9-9510-373691fba202,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-9eb651b7-7293-42a2-8e15-33979bd15146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706637897-172.17.0.3-1597195077230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37303,DS-c0186a9f-1509-4278-ae3f-8b72121a6b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-7e5f3a94-8a10-4247-b5fe-09daa62ea7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-9ced8911-a7ee-44b0-b222-c424f80de206,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-08941fb7-03d3-4f0f-9f35-6f31f4a5310c,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-7bf20c34-8d2a-405f-b26a-e9d0e30c7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-01f06fd0-6631-4d26-8474-df5b15abbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-133fc965-0f83-45e9-9510-373691fba202,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-9eb651b7-7293-42a2-8e15-33979bd15146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620793746-172.17.0.3-1597195178258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42183,DS-63c11133-7c82-4ec1-a202-13ba6fc7b312,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-6275bd12-aeec-451f-9c7c-265da467522d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-290716ac-09f7-4c3c-a11a-27ce2cd4db1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-791fa67d-976a-4bcc-b1b5-56c0e73a4ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-0155c120-605b-437e-b84f-451bc0702a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-094d2d64-4f76-4105-a039-990d9d733c59,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-8841a4cc-1a10-42ea-ab74-a304791831f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c0fcfd8d-5a7c-469f-9842-cd9cfce2403b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620793746-172.17.0.3-1597195178258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42183,DS-63c11133-7c82-4ec1-a202-13ba6fc7b312,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-6275bd12-aeec-451f-9c7c-265da467522d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-290716ac-09f7-4c3c-a11a-27ce2cd4db1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-791fa67d-976a-4bcc-b1b5-56c0e73a4ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-0155c120-605b-437e-b84f-451bc0702a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-094d2d64-4f76-4105-a039-990d9d733c59,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-8841a4cc-1a10-42ea-ab74-a304791831f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c0fcfd8d-5a7c-469f-9842-cd9cfce2403b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447062689-172.17.0.3-1597195425336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44724,DS-a28876fc-ab40-45f4-8127-f3cd8dffb676,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-bcdce039-1efb-48b0-8e62-53d0f9180053,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-aafdd874-3583-4682-8bb6-ee7e05bc2f58,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-e4346994-3d7c-4aeb-91be-2e969e78ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-ff76912b-9209-45fd-b793-0efbfa4c94be,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-0b8b8634-4dd9-408e-b87c-236c7a4cd1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-48de2687-80ce-4cb6-8aef-a7258864426d,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-4480c284-873c-4360-aef4-00edb0801eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447062689-172.17.0.3-1597195425336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44724,DS-a28876fc-ab40-45f4-8127-f3cd8dffb676,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-bcdce039-1efb-48b0-8e62-53d0f9180053,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-aafdd874-3583-4682-8bb6-ee7e05bc2f58,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-e4346994-3d7c-4aeb-91be-2e969e78ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-ff76912b-9209-45fd-b793-0efbfa4c94be,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-0b8b8634-4dd9-408e-b87c-236c7a4cd1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-48de2687-80ce-4cb6-8aef-a7258864426d,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-4480c284-873c-4360-aef4-00edb0801eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745034502-172.17.0.3-1597195671328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-175ac859-5041-4a89-acf9-1a0db1b2a796,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-63dc7434-bf9c-432d-8d5c-ddc5def7efae,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-f95e63ec-15bd-4819-9ef3-acc2cdc510ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-19b5797d-45af-4b40-9fb0-2ba1bf3835fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-366cdd54-7131-438c-91d2-06a59d11b3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-12e7f26a-992d-467f-b216-427670a40667,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-82d07864-13f7-41a8-ab53-35175f3b832d,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-89640ada-aaf5-40fb-a9e5-a38da87b5143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745034502-172.17.0.3-1597195671328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-175ac859-5041-4a89-acf9-1a0db1b2a796,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-63dc7434-bf9c-432d-8d5c-ddc5def7efae,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-f95e63ec-15bd-4819-9ef3-acc2cdc510ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-19b5797d-45af-4b40-9fb0-2ba1bf3835fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-366cdd54-7131-438c-91d2-06a59d11b3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-12e7f26a-992d-467f-b216-427670a40667,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-82d07864-13f7-41a8-ab53-35175f3b832d,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-89640ada-aaf5-40fb-a9e5-a38da87b5143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005415922-172.17.0.3-1597195808742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36379,DS-3009bd7f-24fc-462a-b372-5da6faa2924f,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-1988ecae-6277-4437-95db-3c17e0d915c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-289fb742-05ae-481d-b874-833eef35ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-32501a93-a116-46d5-839d-0d12059d8f59,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-70057769-a5b8-41f6-b1f1-66911f663179,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-e35bdb2b-6dbd-4e4f-beb0-128f91bcf03e,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-0c8e4e63-45a7-44b6-8790-1324f0cdd647,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-f0b7a941-a782-49cd-83b4-f7f83c7e0e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005415922-172.17.0.3-1597195808742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36379,DS-3009bd7f-24fc-462a-b372-5da6faa2924f,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-1988ecae-6277-4437-95db-3c17e0d915c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-289fb742-05ae-481d-b874-833eef35ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-32501a93-a116-46d5-839d-0d12059d8f59,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-70057769-a5b8-41f6-b1f1-66911f663179,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-e35bdb2b-6dbd-4e4f-beb0-128f91bcf03e,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-0c8e4e63-45a7-44b6-8790-1324f0cdd647,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-f0b7a941-a782-49cd-83b4-f7f83c7e0e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955339182-172.17.0.3-1597195869350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42798,DS-f89acd96-254c-4157-9282-3e8d68fd0855,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-af4f18a5-82fb-48c3-8c5e-667d8a0d37a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-a961ee2e-8227-4106-a361-c928710df506,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-e1dff42a-3620-4534-9ca9-e267c0b8f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-e11cc6aa-bb4a-468d-a760-a6c595140f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-c446576d-c666-40a6-a934-a1fbd231a769,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-d4c5e1e1-89e5-45ec-9583-46a4f4531925,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-623bc95b-13a4-45fc-a263-3325e44fc1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955339182-172.17.0.3-1597195869350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42798,DS-f89acd96-254c-4157-9282-3e8d68fd0855,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-af4f18a5-82fb-48c3-8c5e-667d8a0d37a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-a961ee2e-8227-4106-a361-c928710df506,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-e1dff42a-3620-4534-9ca9-e267c0b8f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-e11cc6aa-bb4a-468d-a760-a6c595140f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-c446576d-c666-40a6-a934-a1fbd231a769,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-d4c5e1e1-89e5-45ec-9583-46a4f4531925,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-623bc95b-13a4-45fc-a263-3325e44fc1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760933606-172.17.0.3-1597196020539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-7b85e3a4-f9c3-4825-9641-6d5e58e40547,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-f6fc3af2-7ee9-4119-a5ef-249db66f3d89,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-6a8bef98-367e-430e-8786-ff0f12035ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-25f0ddcf-cd78-491a-bc01-0cd22b662c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-5d8fd2cc-f6bb-48b6-a993-ade05da7df9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-0a9d8e0d-b3d0-43f3-8f57-2670e72dea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-f0a9ac34-4b1c-447e-8a6b-93b939afb596,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-425f3dcf-5ae9-4b03-ac6f-e581c10b8d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760933606-172.17.0.3-1597196020539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-7b85e3a4-f9c3-4825-9641-6d5e58e40547,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-f6fc3af2-7ee9-4119-a5ef-249db66f3d89,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-6a8bef98-367e-430e-8786-ff0f12035ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-25f0ddcf-cd78-491a-bc01-0cd22b662c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-5d8fd2cc-f6bb-48b6-a993-ade05da7df9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-0a9d8e0d-b3d0-43f3-8f57-2670e72dea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-f0a9ac34-4b1c-447e-8a6b-93b939afb596,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-425f3dcf-5ae9-4b03-ac6f-e581c10b8d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526968597-172.17.0.3-1597196523717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35400,DS-8dc04792-ac58-4d13-9801-40c770578f75,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-766b54af-e403-4a7f-b00e-ba6e424716c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-d148e63a-6bc9-447f-a003-753531aa2bad,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-1d40e955-f0c8-4daf-a6fb-3348b1c18372,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-a20906c9-473d-430f-ab9c-2b7737b0a03e,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-a6c576d2-b05f-4fba-8b23-b82be49619c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-022c8825-14ef-443a-b2d5-672ebf6ac055,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-251ff15d-1a80-4825-99f0-8dc9b9e905fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526968597-172.17.0.3-1597196523717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35400,DS-8dc04792-ac58-4d13-9801-40c770578f75,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-766b54af-e403-4a7f-b00e-ba6e424716c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-d148e63a-6bc9-447f-a003-753531aa2bad,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-1d40e955-f0c8-4daf-a6fb-3348b1c18372,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-a20906c9-473d-430f-ab9c-2b7737b0a03e,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-a6c576d2-b05f-4fba-8b23-b82be49619c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-022c8825-14ef-443a-b2d5-672ebf6ac055,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-251ff15d-1a80-4825-99f0-8dc9b9e905fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926223437-172.17.0.3-1597196641105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33385,DS-125ed427-18af-49ae-84d3-8bf5d816383d,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-7ea53a84-8378-48cf-872c-78a56af3c2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-aa28b63a-85df-4d66-88a5-8acca62c7690,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-d5af6415-ca11-4f06-9363-25bf7c50eef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-536aacf0-5cf7-4c36-9f9d-4ce523cc0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-7e68822b-0306-4cdd-993c-3f9f7ae0c840,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-385e5ec6-f8f0-44f4-8bea-c1a8ae517de8,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-8490cca4-6b4e-4413-be04-75b5f31533cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926223437-172.17.0.3-1597196641105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33385,DS-125ed427-18af-49ae-84d3-8bf5d816383d,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-7ea53a84-8378-48cf-872c-78a56af3c2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-aa28b63a-85df-4d66-88a5-8acca62c7690,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-d5af6415-ca11-4f06-9363-25bf7c50eef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-536aacf0-5cf7-4c36-9f9d-4ce523cc0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-7e68822b-0306-4cdd-993c-3f9f7ae0c840,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-385e5ec6-f8f0-44f4-8bea-c1a8ae517de8,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-8490cca4-6b4e-4413-be04-75b5f31533cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793135281-172.17.0.3-1597196804286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44166,DS-911b4483-be40-456d-a233-4e11f9b8f3be,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-289378e5-eff8-4465-84d5-7329c5770b27,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-b3fb1f87-7e07-4eb0-97b6-deb1be37b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-0abab509-29d4-40b0-ab3a-5869885c22af,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-3eaa4fdd-ceb6-4de6-b01e-2a0d40662cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-a4bf7de8-8378-4ba4-8eae-c827041f5f83,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-992f7e9b-6faf-4d62-9d1c-2cf316d4637d,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-cf2365ac-f56b-4f6b-85c9-0b6d07dc2b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793135281-172.17.0.3-1597196804286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44166,DS-911b4483-be40-456d-a233-4e11f9b8f3be,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-289378e5-eff8-4465-84d5-7329c5770b27,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-b3fb1f87-7e07-4eb0-97b6-deb1be37b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-0abab509-29d4-40b0-ab3a-5869885c22af,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-3eaa4fdd-ceb6-4de6-b01e-2a0d40662cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-a4bf7de8-8378-4ba4-8eae-c827041f5f83,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-992f7e9b-6faf-4d62-9d1c-2cf316d4637d,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-cf2365ac-f56b-4f6b-85c9-0b6d07dc2b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382886607-172.17.0.3-1597197149183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44971,DS-cf48d698-7804-4c35-92bf-1eae232a66f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-d30c3209-fbab-4777-8de6-bb198ba6f1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-7f18f7b6-67c0-4a92-880f-c40627599d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-a3ea8a8f-22df-4ce7-8ec8-6e5327ac2b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-d6db7b66-3682-4e40-a173-13623564c9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-8c096b87-8952-41d6-b6ff-dec355f7f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-4df1fbe3-6e5d-44fb-8e83-83cd1abe4c29,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-8966c804-cb60-4ba1-b904-80ec2dfa1d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382886607-172.17.0.3-1597197149183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44971,DS-cf48d698-7804-4c35-92bf-1eae232a66f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-d30c3209-fbab-4777-8de6-bb198ba6f1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-7f18f7b6-67c0-4a92-880f-c40627599d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-a3ea8a8f-22df-4ce7-8ec8-6e5327ac2b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-d6db7b66-3682-4e40-a173-13623564c9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-8c096b87-8952-41d6-b6ff-dec355f7f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-4df1fbe3-6e5d-44fb-8e83-83cd1abe4c29,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-8966c804-cb60-4ba1-b904-80ec2dfa1d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903375257-172.17.0.3-1597197525285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-46d1c8f4-e9d7-4fcc-a94c-1578bb6f4bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-091ed8c5-587c-4b34-8b38-31d722111aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-88f467f7-83d2-413d-99cc-8af467458419,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-ab0bc866-e04b-4203-99f2-28c449aae5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-8f7976bc-0d9a-4f98-be61-212d14f97e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-3b4ec3d0-4c49-4cf1-a2a3-1878b15cd7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-6caef495-6a0d-4275-96c8-601cb43d621e,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-469db883-6e83-46ad-947e-d6e24c5a95ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903375257-172.17.0.3-1597197525285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-46d1c8f4-e9d7-4fcc-a94c-1578bb6f4bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-091ed8c5-587c-4b34-8b38-31d722111aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-88f467f7-83d2-413d-99cc-8af467458419,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-ab0bc866-e04b-4203-99f2-28c449aae5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-8f7976bc-0d9a-4f98-be61-212d14f97e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-3b4ec3d0-4c49-4cf1-a2a3-1878b15cd7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-6caef495-6a0d-4275-96c8-601cb43d621e,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-469db883-6e83-46ad-947e-d6e24c5a95ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897394803-172.17.0.3-1597197662049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46463,DS-b22dcf7c-0359-4da1-8c0b-5c915b03ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-e002b4c7-ee92-4f0b-a8fb-b5b773b709c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-cfa48a8c-ed13-4c51-996c-e02a38c03c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-b7f51284-1039-4e2e-9441-3037c6586ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-56849955-88db-4657-988b-95e6aec7f158,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-5f137d19-cad2-43ee-b3fe-fa0f907e65bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-b45eaf41-76d9-4e4b-8623-57ea7a499073,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-226c7459-1f50-494b-8be0-5066b48acaf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897394803-172.17.0.3-1597197662049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46463,DS-b22dcf7c-0359-4da1-8c0b-5c915b03ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-e002b4c7-ee92-4f0b-a8fb-b5b773b709c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-cfa48a8c-ed13-4c51-996c-e02a38c03c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-b7f51284-1039-4e2e-9441-3037c6586ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-56849955-88db-4657-988b-95e6aec7f158,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-5f137d19-cad2-43ee-b3fe-fa0f907e65bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-b45eaf41-76d9-4e4b-8623-57ea7a499073,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-226c7459-1f50-494b-8be0-5066b48acaf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4836
