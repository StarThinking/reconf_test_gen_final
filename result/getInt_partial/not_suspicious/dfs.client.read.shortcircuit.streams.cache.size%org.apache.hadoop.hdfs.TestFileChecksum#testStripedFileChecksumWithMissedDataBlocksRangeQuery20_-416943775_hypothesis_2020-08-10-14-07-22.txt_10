reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977881537-172.17.0.21-1597069038429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32843,DS-dcc814e6-2ad8-47c4-a325-d59568e9e8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-7cab8072-9513-498a-aaef-374fe69e90f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-f4bab0ca-2f8d-4806-82ba-dea35ebfb1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-b52706b1-06ea-42e0-8434-6e8075f9d0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-5b801089-8ccd-4cc8-9a2a-02478ff20bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-7ae766a3-8f34-474d-bad0-88228820a2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-cebfc934-11d3-4ccc-bb20-76b6ab5c716e,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-dae30800-6fdd-4cc0-9b04-1fcdb5d8725f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977881537-172.17.0.21-1597069038429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32843,DS-dcc814e6-2ad8-47c4-a325-d59568e9e8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-7cab8072-9513-498a-aaef-374fe69e90f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-f4bab0ca-2f8d-4806-82ba-dea35ebfb1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-b52706b1-06ea-42e0-8434-6e8075f9d0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-5b801089-8ccd-4cc8-9a2a-02478ff20bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-7ae766a3-8f34-474d-bad0-88228820a2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-cebfc934-11d3-4ccc-bb20-76b6ab5c716e,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-dae30800-6fdd-4cc0-9b04-1fcdb5d8725f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079708657-172.17.0.21-1597069229021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33748,DS-7bc8faaa-d0e3-4a58-8f09-319faf5d4902,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-fa817b3f-1da1-4a0e-84bf-67fdea0a7526,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-bdf1da08-ed9e-4f9b-9388-cf537f962a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-e0b1dfbd-239e-4180-87ae-a8b9bbbf5938,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-636983e1-4a74-436d-913a-88cf3ba0d657,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-6ccc0719-89f8-42a2-8a67-3fca52ba4d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-153c1b6b-a87a-40c9-b88a-0088043d75bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-1030836f-fb5d-440d-a92d-2f17e20381ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079708657-172.17.0.21-1597069229021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33748,DS-7bc8faaa-d0e3-4a58-8f09-319faf5d4902,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-fa817b3f-1da1-4a0e-84bf-67fdea0a7526,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-bdf1da08-ed9e-4f9b-9388-cf537f962a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-e0b1dfbd-239e-4180-87ae-a8b9bbbf5938,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-636983e1-4a74-436d-913a-88cf3ba0d657,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-6ccc0719-89f8-42a2-8a67-3fca52ba4d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-153c1b6b-a87a-40c9-b88a-0088043d75bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-1030836f-fb5d-440d-a92d-2f17e20381ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753387396-172.17.0.21-1597069699334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42100,DS-beaf9b9d-98d9-436a-9299-3ef12f9a6180,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-5d4e17bf-5113-4234-a5e7-4c3fe9d037a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-0f4ccc2c-10c2-4493-b76e-ab9e69b299f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-a3cb1789-6fc6-4004-8ada-dc318ab82b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-6dfaf28c-7b5e-4724-a721-79b590d6ded2,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-248d88ad-41b6-4143-ad37-d160edce8176,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-6f6c7136-819a-4418-9157-93666aa90da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-f88e5540-b84b-4a9e-a68e-20b47fd9ef81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753387396-172.17.0.21-1597069699334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42100,DS-beaf9b9d-98d9-436a-9299-3ef12f9a6180,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-5d4e17bf-5113-4234-a5e7-4c3fe9d037a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-0f4ccc2c-10c2-4493-b76e-ab9e69b299f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-a3cb1789-6fc6-4004-8ada-dc318ab82b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-6dfaf28c-7b5e-4724-a721-79b590d6ded2,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-248d88ad-41b6-4143-ad37-d160edce8176,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-6f6c7136-819a-4418-9157-93666aa90da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-f88e5540-b84b-4a9e-a68e-20b47fd9ef81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901668758-172.17.0.21-1597070121014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-53763bcf-1ebb-453e-a174-326c932eabe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-94f99dcc-72a8-4901-b498-da84b6a836b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-7b414778-4465-4f6a-a0d6-cd234bcd88a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-f35fa0d2-f38b-43ad-93c6-25c25efe9ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-894d6032-0dac-4373-8846-8c594ad9198c,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-5791dd1b-ace8-4f4e-bdb1-124be5ce5b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-660c263d-9170-4bf8-a943-c40843d14aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-d3fecee8-c360-474a-a7ce-e779c66a9e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901668758-172.17.0.21-1597070121014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-53763bcf-1ebb-453e-a174-326c932eabe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-94f99dcc-72a8-4901-b498-da84b6a836b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-7b414778-4465-4f6a-a0d6-cd234bcd88a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-f35fa0d2-f38b-43ad-93c6-25c25efe9ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-894d6032-0dac-4373-8846-8c594ad9198c,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-5791dd1b-ace8-4f4e-bdb1-124be5ce5b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-660c263d-9170-4bf8-a943-c40843d14aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-d3fecee8-c360-474a-a7ce-e779c66a9e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564721387-172.17.0.21-1597070487309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-336324eb-9b64-479f-b0db-44aa6e80e7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-e8680633-835d-4788-9225-78eda957a44b,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-c43bb415-56fd-4453-9365-3f7ae377c966,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-a4439ce7-ee25-4b5e-beb4-742c9afd6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-8e86e01a-2827-46c9-81fa-d87afb3b4583,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-51075994-7e9f-49a8-b65d-b64c375b85ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-17721ef6-6ab0-48ca-af2e-7da4605b91f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-df433790-87d2-4d99-bfd0-b366ae5855d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564721387-172.17.0.21-1597070487309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-336324eb-9b64-479f-b0db-44aa6e80e7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-e8680633-835d-4788-9225-78eda957a44b,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-c43bb415-56fd-4453-9365-3f7ae377c966,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-a4439ce7-ee25-4b5e-beb4-742c9afd6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-8e86e01a-2827-46c9-81fa-d87afb3b4583,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-51075994-7e9f-49a8-b65d-b64c375b85ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-17721ef6-6ab0-48ca-af2e-7da4605b91f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-df433790-87d2-4d99-bfd0-b366ae5855d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106175298-172.17.0.21-1597070618922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-90a9fb6c-ea65-4cd2-9ab2-e13d051c2e65,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-3a5ca2e8-e2f2-458b-8447-2f03cd3c97fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-f30cf546-89ec-48c3-94d0-82defc56059a,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-5ad050e0-c5b4-40fb-8557-a5beab24cb18,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-84b2f9fc-9d4c-48c5-8d45-0eedb9d9f69a,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-5402e7a9-5ccc-43f4-a5f0-4403e067b654,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-de829b49-3ef0-41b8-895f-8ea53b722ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-f3837575-7edb-4d36-9ff7-f7794a3d7967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106175298-172.17.0.21-1597070618922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-90a9fb6c-ea65-4cd2-9ab2-e13d051c2e65,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-3a5ca2e8-e2f2-458b-8447-2f03cd3c97fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-f30cf546-89ec-48c3-94d0-82defc56059a,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-5ad050e0-c5b4-40fb-8557-a5beab24cb18,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-84b2f9fc-9d4c-48c5-8d45-0eedb9d9f69a,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-5402e7a9-5ccc-43f4-a5f0-4403e067b654,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-de829b49-3ef0-41b8-895f-8ea53b722ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-f3837575-7edb-4d36-9ff7-f7794a3d7967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940776588-172.17.0.21-1597070666996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-10db5ab2-f1d0-47ff-a0a6-799ea5f016c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-548e6634-8bf4-4f10-9e70-c8e51664b664,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-17e6a2a4-20c2-4359-a4f2-8b7f5b2362f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-1730c91b-783d-459b-b394-58a8618bdad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-c9bf7412-7ba1-493b-9ff1-479bfe5c398f,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-7f6cbbb2-c357-4da6-9dc5-8ebc8c1fc955,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-2f23709f-0757-4126-920f-02880960519d,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-0c6638d2-5712-42dd-9c9b-c7f19d9fff3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940776588-172.17.0.21-1597070666996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-10db5ab2-f1d0-47ff-a0a6-799ea5f016c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-548e6634-8bf4-4f10-9e70-c8e51664b664,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-17e6a2a4-20c2-4359-a4f2-8b7f5b2362f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-1730c91b-783d-459b-b394-58a8618bdad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-c9bf7412-7ba1-493b-9ff1-479bfe5c398f,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-7f6cbbb2-c357-4da6-9dc5-8ebc8c1fc955,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-2f23709f-0757-4126-920f-02880960519d,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-0c6638d2-5712-42dd-9c9b-c7f19d9fff3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318621622-172.17.0.21-1597071014635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34262,DS-3aa8f7f6-7c0c-4f4d-89bb-d606d746ec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-eee481e1-7c8d-48a6-b817-a6b1a0c446a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-77e592c2-9556-494a-94a7-d0a530394be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-532d8c11-4dae-4a15-8ddc-49caccd0a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-a338d23d-c183-46e7-852d-69587cb68f79,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-e63e9786-67c7-4cf5-a5b9-cd916431f91e,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-a23bbdc5-fc3b-42bb-8155-f2da0b7d2226,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-ba6268e1-72ce-455f-9773-4b9789f70a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318621622-172.17.0.21-1597071014635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34262,DS-3aa8f7f6-7c0c-4f4d-89bb-d606d746ec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-eee481e1-7c8d-48a6-b817-a6b1a0c446a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-77e592c2-9556-494a-94a7-d0a530394be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-532d8c11-4dae-4a15-8ddc-49caccd0a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-a338d23d-c183-46e7-852d-69587cb68f79,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-e63e9786-67c7-4cf5-a5b9-cd916431f91e,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-a23bbdc5-fc3b-42bb-8155-f2da0b7d2226,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-ba6268e1-72ce-455f-9773-4b9789f70a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822826206-172.17.0.21-1597071050733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-84eada32-2807-4bd8-a39f-6965903ee7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-c055b35c-e0ae-4503-bba6-741f770a17e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-22c8632f-f102-495d-aca1-912664b6ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-9ded887f-a3ba-4006-ac7d-ef9aec9748fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-3a87b9e0-cefb-4daa-a909-2df8a2bf6ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-295321f1-4e30-42ba-a03b-dbaa0633d6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-3be0df63-0210-47f0-9665-b3656498111b,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-3661f716-8ac9-4694-a10d-89993407da7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822826206-172.17.0.21-1597071050733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-84eada32-2807-4bd8-a39f-6965903ee7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-c055b35c-e0ae-4503-bba6-741f770a17e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-22c8632f-f102-495d-aca1-912664b6ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-9ded887f-a3ba-4006-ac7d-ef9aec9748fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-3a87b9e0-cefb-4daa-a909-2df8a2bf6ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-295321f1-4e30-42ba-a03b-dbaa0633d6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-3be0df63-0210-47f0-9665-b3656498111b,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-3661f716-8ac9-4694-a10d-89993407da7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215855470-172.17.0.21-1597071231381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-79c84df0-1afd-49ff-9fe4-f83c10385136,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-26129041-36d2-41a7-bf6c-f85471a930d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-5675f25d-07a7-408a-96ce-a9fc7b6b83cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-391980e0-c1f4-4b41-aea5-8f8ad2da50c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-180153eb-f133-4737-b233-2351f55e96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-09002fb6-e0e1-4148-a2e8-fc69991b88ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-f18cdf26-db43-4b43-a49c-3ef20e2a3ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-c452f16a-7f8f-47aa-af75-259d75d735c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215855470-172.17.0.21-1597071231381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-79c84df0-1afd-49ff-9fe4-f83c10385136,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-26129041-36d2-41a7-bf6c-f85471a930d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-5675f25d-07a7-408a-96ce-a9fc7b6b83cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-391980e0-c1f4-4b41-aea5-8f8ad2da50c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-180153eb-f133-4737-b233-2351f55e96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-09002fb6-e0e1-4148-a2e8-fc69991b88ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-f18cdf26-db43-4b43-a49c-3ef20e2a3ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-c452f16a-7f8f-47aa-af75-259d75d735c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260022884-172.17.0.21-1597072343859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33522,DS-806f76e8-8877-4b37-858d-4c813054b06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-c2b53175-c1a6-4696-87a5-00fe360f7632,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-d27aa41a-a647-4ce7-8248-bb7b1adc26a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-0200a66b-b3ac-4586-8480-8d7638f6dea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-1bdc259d-9be4-45f2-b892-af9ba6f8df42,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-4f05e807-a431-4ba3-afdb-f9fcda6b8d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-a8efa90e-d9a1-424e-a8e4-d2f6f1212202,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-72f61084-1fcf-4656-8e9e-e00d1e4dc26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260022884-172.17.0.21-1597072343859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33522,DS-806f76e8-8877-4b37-858d-4c813054b06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-c2b53175-c1a6-4696-87a5-00fe360f7632,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-d27aa41a-a647-4ce7-8248-bb7b1adc26a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-0200a66b-b3ac-4586-8480-8d7638f6dea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-1bdc259d-9be4-45f2-b892-af9ba6f8df42,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-4f05e807-a431-4ba3-afdb-f9fcda6b8d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-a8efa90e-d9a1-424e-a8e4-d2f6f1212202,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-72f61084-1fcf-4656-8e9e-e00d1e4dc26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195484483-172.17.0.21-1597072397194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-b6c13388-01d3-45db-bb99-a132684d140a,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-2927bb58-ff4e-426c-a97d-82e32c92ee04,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-397f7a71-72c4-4bc6-9307-d6c9e82cdeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-084e76da-7cbd-4440-988c-72b8151b41d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-ac496d3e-8568-4b13-99d8-40e3d792417c,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-f86c0681-4e86-4bdb-a0e6-be62fba1486d,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-4fdc9713-fc33-4b8b-8f4d-84c193344cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-799fafd8-8453-484a-9821-724163c6fb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195484483-172.17.0.21-1597072397194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-b6c13388-01d3-45db-bb99-a132684d140a,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-2927bb58-ff4e-426c-a97d-82e32c92ee04,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-397f7a71-72c4-4bc6-9307-d6c9e82cdeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-084e76da-7cbd-4440-988c-72b8151b41d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-ac496d3e-8568-4b13-99d8-40e3d792417c,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-f86c0681-4e86-4bdb-a0e6-be62fba1486d,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-4fdc9713-fc33-4b8b-8f4d-84c193344cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-799fafd8-8453-484a-9821-724163c6fb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743543364-172.17.0.21-1597072523581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35450,DS-dea31c9b-cccf-4bef-b605-0a1afe8f2454,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-409d75ce-9fa4-4fae-8b98-dbdae73a6208,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-300612fd-abb6-4017-bf4d-e614276dbc53,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-0493969e-5c2d-4b2a-96f7-3057b4959bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-57fbf711-b26d-4345-ada2-ac30db77f143,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-f57b28b6-4c78-4e52-b070-6c89216aa527,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-253ab81e-2357-4bf2-a841-eea25dc138cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-3384835a-98ef-4a17-981e-f53e8fcdabe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743543364-172.17.0.21-1597072523581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35450,DS-dea31c9b-cccf-4bef-b605-0a1afe8f2454,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-409d75ce-9fa4-4fae-8b98-dbdae73a6208,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-300612fd-abb6-4017-bf4d-e614276dbc53,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-0493969e-5c2d-4b2a-96f7-3057b4959bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-57fbf711-b26d-4345-ada2-ac30db77f143,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-f57b28b6-4c78-4e52-b070-6c89216aa527,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-253ab81e-2357-4bf2-a841-eea25dc138cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-3384835a-98ef-4a17-981e-f53e8fcdabe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101946575-172.17.0.21-1597073712005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32965,DS-aea32e49-cc61-47af-92bd-70d2c8ae01e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-85956002-9c2a-42f3-be69-90e69366a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-28450e25-2df4-4267-848b-b1b5c3366eae,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-58865337-a8d1-4b33-a87a-70558eeed9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-0a8fbf7d-8cc4-4bcb-aa44-b2668511038b,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-a6d4bba2-5505-426d-8769-cc0945b4d7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-1b06a847-956f-4a2c-8166-b7f1fbb3679b,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-5a15ef48-4357-4bf6-8282-1fe5588c1c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101946575-172.17.0.21-1597073712005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32965,DS-aea32e49-cc61-47af-92bd-70d2c8ae01e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-85956002-9c2a-42f3-be69-90e69366a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-28450e25-2df4-4267-848b-b1b5c3366eae,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-58865337-a8d1-4b33-a87a-70558eeed9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-0a8fbf7d-8cc4-4bcb-aa44-b2668511038b,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-a6d4bba2-5505-426d-8769-cc0945b4d7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-1b06a847-956f-4a2c-8166-b7f1fbb3679b,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-5a15ef48-4357-4bf6-8282-1fe5588c1c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313390279-172.17.0.21-1597074031275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41178,DS-cbe35649-b6ab-4cc2-bab0-a74f6e8da396,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-40adfc92-f776-4be8-9ab0-9c0ad926173d,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-71706d2d-3c78-4cb8-8fbf-682fd2b866f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-c6a074df-b3b7-4ee1-b521-39da2dfc628e,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-faaca944-f84f-4213-87d8-ed038813442a,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-b16a3c56-6b1b-48e9-b6cf-ee41efcdf1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-f4ebda93-114b-481a-9ed5-4b70f113f921,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-a4d4f746-ec86-4871-8e27-cca7614b86ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313390279-172.17.0.21-1597074031275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41178,DS-cbe35649-b6ab-4cc2-bab0-a74f6e8da396,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-40adfc92-f776-4be8-9ab0-9c0ad926173d,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-71706d2d-3c78-4cb8-8fbf-682fd2b866f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-c6a074df-b3b7-4ee1-b521-39da2dfc628e,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-faaca944-f84f-4213-87d8-ed038813442a,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-b16a3c56-6b1b-48e9-b6cf-ee41efcdf1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-f4ebda93-114b-481a-9ed5-4b70f113f921,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-a4d4f746-ec86-4871-8e27-cca7614b86ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 262144
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190708783-172.17.0.21-1597074538468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44453,DS-9dc5c533-c0b7-4161-94ff-a58c39a32829,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-bff24448-49f2-438e-906b-3817c666c863,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-96eab41f-8b07-4cc4-8598-ba1ee17f7bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-9d124cc0-aeae-48b5-8ab4-5559d42c788b,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-757fa6ac-b7b7-4b0c-97f2-ce6c268440ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-7bad5365-700e-44f2-9929-fbf80c7612ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-06385bd3-f7df-49fc-af56-13247bbdd72e,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-51b71443-cc17-4e5b-b401-1a53b0b19a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190708783-172.17.0.21-1597074538468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44453,DS-9dc5c533-c0b7-4161-94ff-a58c39a32829,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-bff24448-49f2-438e-906b-3817c666c863,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-96eab41f-8b07-4cc4-8598-ba1ee17f7bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-9d124cc0-aeae-48b5-8ab4-5559d42c788b,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-757fa6ac-b7b7-4b0c-97f2-ce6c268440ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-7bad5365-700e-44f2-9929-fbf80c7612ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-06385bd3-f7df-49fc-af56-13247bbdd72e,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-51b71443-cc17-4e5b-b401-1a53b0b19a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6760
