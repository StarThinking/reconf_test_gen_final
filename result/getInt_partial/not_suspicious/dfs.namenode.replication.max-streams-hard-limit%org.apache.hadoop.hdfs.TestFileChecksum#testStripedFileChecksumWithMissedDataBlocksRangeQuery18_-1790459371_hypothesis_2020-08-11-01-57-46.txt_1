reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171818172-172.17.0.15-1597111474724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-9d30a818-f737-4a03-8bb5-6c5f98425978,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-c8561b46-cf49-438b-9fe4-c863e9e8bbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-0a5ba6d1-1785-437c-bd5f-df7a6d6d1c47,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-44b95361-dc61-4dd0-8871-ae73299a19bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-cbf09faa-0ac5-4e24-9755-6822403c359f,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-decf4013-23ff-4bbd-b63d-0845ea7f254e,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-ca98954c-80f3-4623-8a6b-58ae177ede02,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-231f7f6a-ca3f-4c39-8244-e7ca7a359476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171818172-172.17.0.15-1597111474724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-9d30a818-f737-4a03-8bb5-6c5f98425978,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-c8561b46-cf49-438b-9fe4-c863e9e8bbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-0a5ba6d1-1785-437c-bd5f-df7a6d6d1c47,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-44b95361-dc61-4dd0-8871-ae73299a19bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-cbf09faa-0ac5-4e24-9755-6822403c359f,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-decf4013-23ff-4bbd-b63d-0845ea7f254e,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-ca98954c-80f3-4623-8a6b-58ae177ede02,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-231f7f6a-ca3f-4c39-8244-e7ca7a359476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5077238-172.17.0.15-1597112022047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-5aa1ceaf-014e-4b44-b375-28202416dca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-8f4b915d-614c-47f3-b7ef-17f837cd5bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-ccaff4c7-ce0f-4513-93ad-fd75862805ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-a38ac9f7-f649-4c26-b603-245266489d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-679b06d7-6551-4a8f-86a2-85f7e8ccce13,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-9df1a9d5-c700-4a79-97c0-31750193495c,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-8d2763e5-8285-4c7b-86c2-7c849e178b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-7c00cc90-ed70-41a9-9887-49793711db77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5077238-172.17.0.15-1597112022047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-5aa1ceaf-014e-4b44-b375-28202416dca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-8f4b915d-614c-47f3-b7ef-17f837cd5bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-ccaff4c7-ce0f-4513-93ad-fd75862805ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-a38ac9f7-f649-4c26-b603-245266489d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-679b06d7-6551-4a8f-86a2-85f7e8ccce13,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-9df1a9d5-c700-4a79-97c0-31750193495c,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-8d2763e5-8285-4c7b-86c2-7c849e178b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-7c00cc90-ed70-41a9-9887-49793711db77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057152490-172.17.0.15-1597112424059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34750,DS-4830cc43-ac43-4107-a084-1498d7711322,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-c61cfa4f-f740-4f5e-b3c0-6d435e824040,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-f354264d-3226-4782-aa94-513a0266c328,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-e22aeaf8-d7de-455e-8928-abb4c2b3abfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-4dab37fe-494b-45df-a3ad-0987c5a20030,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-8fd4444e-4afa-4709-8d90-c26a0788e516,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-e152b888-b871-47d0-82e0-ccfe6fda9589,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-5c076a1c-4c29-47bb-ac0a-eb5a9f018327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057152490-172.17.0.15-1597112424059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34750,DS-4830cc43-ac43-4107-a084-1498d7711322,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-c61cfa4f-f740-4f5e-b3c0-6d435e824040,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-f354264d-3226-4782-aa94-513a0266c328,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-e22aeaf8-d7de-455e-8928-abb4c2b3abfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-4dab37fe-494b-45df-a3ad-0987c5a20030,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-8fd4444e-4afa-4709-8d90-c26a0788e516,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-e152b888-b871-47d0-82e0-ccfe6fda9589,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-5c076a1c-4c29-47bb-ac0a-eb5a9f018327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586352816-172.17.0.15-1597112628931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45134,DS-9ac273cd-b3d9-4b84-a4c7-9ecc8e0ecb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-64ad537e-ffec-4581-83a6-c0f3124ccaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-d78fd83b-e4a6-4404-a873-317b51f9db88,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-fce73f6a-3a60-4168-9038-ae1ad39ae2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-33f96e59-e264-4a13-be44-4ff628d7cc35,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-3100eef8-91ad-4006-8c5c-7d8556cac5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-06c9b28b-7893-493d-bdfe-0b01a86db4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-9a29880c-5440-481d-9616-2914341b88e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586352816-172.17.0.15-1597112628931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45134,DS-9ac273cd-b3d9-4b84-a4c7-9ecc8e0ecb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-64ad537e-ffec-4581-83a6-c0f3124ccaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-d78fd83b-e4a6-4404-a873-317b51f9db88,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-fce73f6a-3a60-4168-9038-ae1ad39ae2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-33f96e59-e264-4a13-be44-4ff628d7cc35,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-3100eef8-91ad-4006-8c5c-7d8556cac5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-06c9b28b-7893-493d-bdfe-0b01a86db4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-9a29880c-5440-481d-9616-2914341b88e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15265834-172.17.0.15-1597112755868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-72a9a58a-b29a-47fc-99ce-1054049976b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-9952d62f-6d4e-4c5d-b495-a029b93d73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-c8173e62-b343-4590-8a56-630ba0c89999,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-686e9e42-0148-4b5c-99a6-6849b8e044ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-3b149c94-329b-4bf7-a8e2-72896d9ff7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-539fb058-7f5d-41f4-85a1-bdf1b2f4d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-a2d242b3-fc85-45db-83fe-e7196bfb04a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-3675a1ec-84f0-4416-9ae7-bb271468e039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15265834-172.17.0.15-1597112755868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-72a9a58a-b29a-47fc-99ce-1054049976b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-9952d62f-6d4e-4c5d-b495-a029b93d73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-c8173e62-b343-4590-8a56-630ba0c89999,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-686e9e42-0148-4b5c-99a6-6849b8e044ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-3b149c94-329b-4bf7-a8e2-72896d9ff7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-539fb058-7f5d-41f4-85a1-bdf1b2f4d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-a2d242b3-fc85-45db-83fe-e7196bfb04a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-3675a1ec-84f0-4416-9ae7-bb271468e039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154813780-172.17.0.15-1597113042801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36531,DS-994aa444-e790-4102-b3f6-afa134828010,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-3dc484dc-18be-4000-ab0d-b24f27bbd0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-53f980ec-9df0-4977-aad2-4ad705c44d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-e2a88bbf-f364-449c-a907-f2defc062900,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-ae173af5-b54f-4913-aa6b-70bd43985df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-0d1a709f-824b-4c35-b31c-4dca76187a53,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-addca9d2-cf11-456e-a504-84bd13c13cff,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-36cffbae-01fd-499b-b552-c61981c5ccba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154813780-172.17.0.15-1597113042801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36531,DS-994aa444-e790-4102-b3f6-afa134828010,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-3dc484dc-18be-4000-ab0d-b24f27bbd0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-53f980ec-9df0-4977-aad2-4ad705c44d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-e2a88bbf-f364-449c-a907-f2defc062900,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-ae173af5-b54f-4913-aa6b-70bd43985df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-0d1a709f-824b-4c35-b31c-4dca76187a53,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-addca9d2-cf11-456e-a504-84bd13c13cff,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-36cffbae-01fd-499b-b552-c61981c5ccba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318695853-172.17.0.15-1597113699697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-b21ce7a4-c6d5-4702-ae63-b37daa53613f,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-f7097cbf-b710-4bf0-bff0-4d52cca41b32,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-e1910e3b-d45a-4612-a37b-d02716947879,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-e875e23c-d25e-4018-9565-19c0fbf83d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-b02b5933-2d7f-4397-acb8-5755b9a105f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-441372a9-4bb4-4cc4-abf9-8b84787fcd56,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-ab3265d4-be81-4c01-9e92-73cb45c5cb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-01f3930a-3342-458e-a4bc-f24fbc985b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318695853-172.17.0.15-1597113699697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-b21ce7a4-c6d5-4702-ae63-b37daa53613f,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-f7097cbf-b710-4bf0-bff0-4d52cca41b32,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-e1910e3b-d45a-4612-a37b-d02716947879,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-e875e23c-d25e-4018-9565-19c0fbf83d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-b02b5933-2d7f-4397-acb8-5755b9a105f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-441372a9-4bb4-4cc4-abf9-8b84787fcd56,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-ab3265d4-be81-4c01-9e92-73cb45c5cb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-01f3930a-3342-458e-a4bc-f24fbc985b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096144206-172.17.0.15-1597114319964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-cfbfd1c6-7125-47f9-965a-b4c877c80019,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-5ba1892d-a28e-4461-a003-bc77109dbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-15851a68-3155-4acc-aa84-a96f2547b8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-20b51c72-6a04-4cea-8a8d-dd00c43826d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-82bf4369-2f82-4b50-a340-d9126c5bfc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-9bfe31e1-6519-46b9-a869-2769e8998f25,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-4702f1f6-012a-45e2-973d-6e05597308b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-f0d1a833-f614-4ab8-a33e-b52035c22115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096144206-172.17.0.15-1597114319964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-cfbfd1c6-7125-47f9-965a-b4c877c80019,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-5ba1892d-a28e-4461-a003-bc77109dbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-15851a68-3155-4acc-aa84-a96f2547b8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-20b51c72-6a04-4cea-8a8d-dd00c43826d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-82bf4369-2f82-4b50-a340-d9126c5bfc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-9bfe31e1-6519-46b9-a869-2769e8998f25,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-4702f1f6-012a-45e2-973d-6e05597308b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-f0d1a833-f614-4ab8-a33e-b52035c22115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587579122-172.17.0.15-1597114354448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43870,DS-2c8429c5-4d1d-4612-97a0-55e4fd1d45c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-39faa6c7-b20a-4105-8082-f5fd0901131b,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-37a23110-3aa2-4e06-86fa-5576312fbf36,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-2d0b5324-51b9-48ce-a48c-83f477247f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-6ba63c07-3ff5-4966-90a3-163af8f0d109,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-1a4ead6d-84a0-4cc6-a454-d64e0ede29b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-e6e37591-0aed-4bf4-bbae-ab0d37590319,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-2b100e2f-a19b-4d02-ab5c-fab32f7183db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587579122-172.17.0.15-1597114354448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43870,DS-2c8429c5-4d1d-4612-97a0-55e4fd1d45c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-39faa6c7-b20a-4105-8082-f5fd0901131b,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-37a23110-3aa2-4e06-86fa-5576312fbf36,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-2d0b5324-51b9-48ce-a48c-83f477247f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-6ba63c07-3ff5-4966-90a3-163af8f0d109,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-1a4ead6d-84a0-4cc6-a454-d64e0ede29b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-e6e37591-0aed-4bf4-bbae-ab0d37590319,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-2b100e2f-a19b-4d02-ab5c-fab32f7183db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160582678-172.17.0.15-1597114614450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45389,DS-0dee6712-182f-4cc3-b423-42cbdb020b34,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-5a6d62ec-9a85-46b5-a138-828ba5c6ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-48835079-5186-4e45-8bbd-d6db3818bedf,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-3fb57573-0534-4bf9-a46b-6bfee935ee99,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-9fdcb322-5e0c-442a-85bb-5f924bb140cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-5e7bdb26-702d-4014-91af-2ef50e226e08,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-add925a8-168e-4fbe-aac2-3a732755a882,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-1be45f8e-1d7d-49b5-9752-720cdcea0b3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160582678-172.17.0.15-1597114614450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45389,DS-0dee6712-182f-4cc3-b423-42cbdb020b34,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-5a6d62ec-9a85-46b5-a138-828ba5c6ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-48835079-5186-4e45-8bbd-d6db3818bedf,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-3fb57573-0534-4bf9-a46b-6bfee935ee99,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-9fdcb322-5e0c-442a-85bb-5f924bb140cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-5e7bdb26-702d-4014-91af-2ef50e226e08,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-add925a8-168e-4fbe-aac2-3a732755a882,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-1be45f8e-1d7d-49b5-9752-720cdcea0b3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14164006-172.17.0.15-1597114974557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36275,DS-e863f01a-1ba7-4da8-8374-c84013ba7054,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-015b263d-0956-47a2-8662-8e4924ab0115,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-f9bcce15-1cfd-495a-84df-5dd7f367cff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-95ae891f-5745-4f5a-945a-0e043a954682,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-54cb996e-38ce-49a6-b91a-e7d0cf7456ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-e21e5f64-cac9-47d7-a28b-73fe7da305c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-1ca15e67-b959-4062-977b-ad0ff0be015f,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-bc499f1e-6bf2-40f5-a583-b40f1249d259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14164006-172.17.0.15-1597114974557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36275,DS-e863f01a-1ba7-4da8-8374-c84013ba7054,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-015b263d-0956-47a2-8662-8e4924ab0115,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-f9bcce15-1cfd-495a-84df-5dd7f367cff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-95ae891f-5745-4f5a-945a-0e043a954682,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-54cb996e-38ce-49a6-b91a-e7d0cf7456ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-e21e5f64-cac9-47d7-a28b-73fe7da305c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-1ca15e67-b959-4062-977b-ad0ff0be015f,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-bc499f1e-6bf2-40f5-a583-b40f1249d259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206308530-172.17.0.15-1597115054275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34428,DS-b566dc22-966d-456f-917d-50a6f4130f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-f448576d-0a3d-4d77-8630-8a4e20c0b0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-f6b500e7-70f4-4884-b8ab-f9db853161a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-edc41c09-d371-4050-8f17-6631ee3041c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-b329c5c3-4683-43e9-94a8-401377dc5793,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-ced0beb0-b80d-4569-85c8-835347dc7c27,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-edbf296d-9740-45c5-9d68-367b69275bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-90d88f2c-da19-4c6c-bc8d-6e204828e074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206308530-172.17.0.15-1597115054275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34428,DS-b566dc22-966d-456f-917d-50a6f4130f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-f448576d-0a3d-4d77-8630-8a4e20c0b0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-f6b500e7-70f4-4884-b8ab-f9db853161a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-edc41c09-d371-4050-8f17-6631ee3041c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-b329c5c3-4683-43e9-94a8-401377dc5793,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-ced0beb0-b80d-4569-85c8-835347dc7c27,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-edbf296d-9740-45c5-9d68-367b69275bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-90d88f2c-da19-4c6c-bc8d-6e204828e074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382106816-172.17.0.15-1597115888114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33002,DS-ceadd0ef-a060-4069-8655-a3f2dd1e6790,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-c03672cf-94a4-400c-b97e-1da569159551,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-274a4061-fe5f-4122-a6c5-a0d008643557,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-62a5b848-4b8a-4913-99a5-dea9aa8f0877,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-69d68784-464b-4199-82b2-1525b21ea50b,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-653b4fbe-ff77-4302-be7b-28c5b25e7e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-93d09b1e-804b-422b-be53-24478a0a09e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-5b1760fd-3f95-417c-b52e-f167ebd3993f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382106816-172.17.0.15-1597115888114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33002,DS-ceadd0ef-a060-4069-8655-a3f2dd1e6790,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-c03672cf-94a4-400c-b97e-1da569159551,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-274a4061-fe5f-4122-a6c5-a0d008643557,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-62a5b848-4b8a-4913-99a5-dea9aa8f0877,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-69d68784-464b-4199-82b2-1525b21ea50b,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-653b4fbe-ff77-4302-be7b-28c5b25e7e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-93d09b1e-804b-422b-be53-24478a0a09e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-5b1760fd-3f95-417c-b52e-f167ebd3993f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922677551-172.17.0.15-1597117120044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-3ce96d74-ac4d-4f8d-b745-4c631e68d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-edf29af9-2d28-4dc7-812c-c0d16404d8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-59c492d9-0724-4a73-9283-23cc89bc607c,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-60954615-9bf1-4ba9-a421-992a0142eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-b2c5ad0d-64fc-4b0a-8567-04ade42196b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-91dcdcab-a08a-4ef4-8595-1551120303cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-f5ab92f9-d9f2-4969-be5a-16e8b245b26a,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-3a7510eb-93e4-4d81-8bdc-7d0700d31ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922677551-172.17.0.15-1597117120044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-3ce96d74-ac4d-4f8d-b745-4c631e68d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-edf29af9-2d28-4dc7-812c-c0d16404d8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-59c492d9-0724-4a73-9283-23cc89bc607c,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-60954615-9bf1-4ba9-a421-992a0142eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-b2c5ad0d-64fc-4b0a-8567-04ade42196b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-91dcdcab-a08a-4ef4-8595-1551120303cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-f5ab92f9-d9f2-4969-be5a-16e8b245b26a,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-3a7510eb-93e4-4d81-8bdc-7d0700d31ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 8
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925804824-172.17.0.15-1597117199244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-22fbc5e3-c7e1-4ccf-9d0c-078e86e4e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-fea47eb9-247d-4fea-9f52-01f3c63c2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-f114e4c9-ad07-49cd-a1e4-9c0a6bf8277e,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-e83c2da8-1f32-4604-ae2f-920f348d7afd,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-dda97904-2da2-4b2d-9e7b-2e10e876346b,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-04d19fea-a65d-415e-8996-0c4b82d7e67f,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-d008085d-65ba-400d-803d-f2eef85c7e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-6599a2e1-fca8-4de2-9da4-1146695a90ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925804824-172.17.0.15-1597117199244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-22fbc5e3-c7e1-4ccf-9d0c-078e86e4e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-fea47eb9-247d-4fea-9f52-01f3c63c2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-f114e4c9-ad07-49cd-a1e4-9c0a6bf8277e,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-e83c2da8-1f32-4604-ae2f-920f348d7afd,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-dda97904-2da2-4b2d-9e7b-2e10e876346b,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-04d19fea-a65d-415e-8996-0c4b82d7e67f,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-d008085d-65ba-400d-803d-f2eef85c7e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-6599a2e1-fca8-4de2-9da4-1146695a90ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 6557
