reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724180197-172.17.0.20-1597063806651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-4201db1a-024e-474f-9cca-10e994f41907,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-d4aa488d-9a32-471b-8485-9d920875adca,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-96b3b8ef-608e-4dc0-822f-e54a35657c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-3d09ead1-5974-4c20-88ef-15d5cff785b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-226bee89-5b57-4293-be80-3fd42388fb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-aea13412-e18d-4c90-89eb-49a51f72e724,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-eaae949d-6b6b-49ae-8fb1-f40559a504c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-7526ec56-6b20-43f0-9932-4bcaf662d94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724180197-172.17.0.20-1597063806651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-4201db1a-024e-474f-9cca-10e994f41907,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-d4aa488d-9a32-471b-8485-9d920875adca,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-96b3b8ef-608e-4dc0-822f-e54a35657c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-3d09ead1-5974-4c20-88ef-15d5cff785b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-226bee89-5b57-4293-be80-3fd42388fb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-aea13412-e18d-4c90-89eb-49a51f72e724,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-eaae949d-6b6b-49ae-8fb1-f40559a504c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-7526ec56-6b20-43f0-9932-4bcaf662d94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394818797-172.17.0.20-1597064198916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-22e25aba-c086-4263-95ac-eee52ffd6bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-89faf351-abce-4e40-ada4-a67e7cc2b9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-f186716c-1e21-49b0-8a89-63af658a9260,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-c5694205-0dcb-4f30-8fd1-b19a48fc09ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-8f940308-dd47-4ad7-9a74-52545c31bcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-8dccddb4-2824-47f1-b379-15414f826fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-e5adf66b-86bc-47b1-af9d-789baf149c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-703bb0d7-d525-4d23-a829-b3bcb2559979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394818797-172.17.0.20-1597064198916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-22e25aba-c086-4263-95ac-eee52ffd6bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-89faf351-abce-4e40-ada4-a67e7cc2b9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-f186716c-1e21-49b0-8a89-63af658a9260,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-c5694205-0dcb-4f30-8fd1-b19a48fc09ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-8f940308-dd47-4ad7-9a74-52545c31bcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-8dccddb4-2824-47f1-b379-15414f826fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-e5adf66b-86bc-47b1-af9d-789baf149c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-703bb0d7-d525-4d23-a829-b3bcb2559979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088788706-172.17.0.20-1597064733182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-673cc62c-2819-4a6b-b048-13ee9bacc826,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-15d86a19-8975-4a9f-80fe-64bc6922ebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-d52fc431-cbf1-49e2-b61d-a1deec9d900f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-e36e830d-2b50-403f-b422-e52e39ae9889,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-5d04015a-ab2a-401a-b63b-bcd1abe53cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-b28a740e-95d6-4360-b80f-c5ce0cb56a27,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-963e3380-8670-4716-9cc5-394e13404064,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-6a76add7-eb66-40d2-8abe-71649ddcef52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088788706-172.17.0.20-1597064733182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-673cc62c-2819-4a6b-b048-13ee9bacc826,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-15d86a19-8975-4a9f-80fe-64bc6922ebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-d52fc431-cbf1-49e2-b61d-a1deec9d900f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-e36e830d-2b50-403f-b422-e52e39ae9889,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-5d04015a-ab2a-401a-b63b-bcd1abe53cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-b28a740e-95d6-4360-b80f-c5ce0cb56a27,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-963e3380-8670-4716-9cc5-394e13404064,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-6a76add7-eb66-40d2-8abe-71649ddcef52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154185778-172.17.0.20-1597064770655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39677,DS-f1529c11-c35d-4986-b28a-3a63bf7fa0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-7df5a434-a60c-45e5-b9d2-363f0b6f0bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-877cb2c4-19d8-4272-967e-f49e84b162d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-cbfbf39f-734c-43e5-997e-99976a160e39,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-8e57efae-e7a1-4abc-995f-0eb581b695da,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-35930246-13b1-46b9-8281-ef8c2032d350,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-cfac1961-170d-40d7-a555-ad65904eba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-f51ffe82-11c3-45ea-a637-851bfe3e3d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154185778-172.17.0.20-1597064770655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39677,DS-f1529c11-c35d-4986-b28a-3a63bf7fa0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-7df5a434-a60c-45e5-b9d2-363f0b6f0bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-877cb2c4-19d8-4272-967e-f49e84b162d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-cbfbf39f-734c-43e5-997e-99976a160e39,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-8e57efae-e7a1-4abc-995f-0eb581b695da,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-35930246-13b1-46b9-8281-ef8c2032d350,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-cfac1961-170d-40d7-a555-ad65904eba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-f51ffe82-11c3-45ea-a637-851bfe3e3d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249831945-172.17.0.20-1597065543530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33305,DS-647737c2-84bb-42c3-8fe1-e4e91e3e3c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-6acf045d-332e-4053-8e61-cd0196df40c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-b7d91d51-72ad-4d82-8ec2-e649db8724b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-a39eebf8-09f7-48a1-a8dd-5699130bfe56,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-25844f9b-78e1-4488-b918-c506ee3761fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-97cb166d-49c8-4601-822c-0d382e5d3909,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-e9dd2e73-bad2-4d5c-9e0f-8e7a4c707c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-f3cfc194-f0e3-496f-b3e3-72cc123fcded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249831945-172.17.0.20-1597065543530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33305,DS-647737c2-84bb-42c3-8fe1-e4e91e3e3c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-6acf045d-332e-4053-8e61-cd0196df40c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-b7d91d51-72ad-4d82-8ec2-e649db8724b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-a39eebf8-09f7-48a1-a8dd-5699130bfe56,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-25844f9b-78e1-4488-b918-c506ee3761fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-97cb166d-49c8-4601-822c-0d382e5d3909,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-e9dd2e73-bad2-4d5c-9e0f-8e7a4c707c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-f3cfc194-f0e3-496f-b3e3-72cc123fcded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659443361-172.17.0.20-1597065722599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42524,DS-2eb1f146-4474-477b-aebd-3d728972db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-5569a1a7-4e99-47c2-ae2d-dc6faddb53d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-ac8b837c-a753-4038-9a25-9b423ede7452,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-f3e07dd7-a43c-4da7-853f-692f9f43dd31,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-74d8450c-4c6f-4a8f-b077-f18286b2b574,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-dcc056ee-05cc-433d-bc93-823f05376dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-211d1d1d-18fb-49f6-babe-5a7838c32d47,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-b58731db-a293-48d7-b33e-cc8750129e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659443361-172.17.0.20-1597065722599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42524,DS-2eb1f146-4474-477b-aebd-3d728972db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-5569a1a7-4e99-47c2-ae2d-dc6faddb53d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-ac8b837c-a753-4038-9a25-9b423ede7452,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-f3e07dd7-a43c-4da7-853f-692f9f43dd31,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-74d8450c-4c6f-4a8f-b077-f18286b2b574,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-dcc056ee-05cc-433d-bc93-823f05376dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-211d1d1d-18fb-49f6-babe-5a7838c32d47,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-b58731db-a293-48d7-b33e-cc8750129e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956484626-172.17.0.20-1597065834688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-852d0a2a-a508-4272-9a98-ae02327d15a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-811ef7e2-717b-452b-b296-4ddbae769450,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-b9488030-06f6-4a56-bdc0-86a988678af7,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-ac37e886-6dfc-4f4d-b939-ac5bce5f2408,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-3b0dc0ec-4e20-4842-9e96-1c8b40586ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-91ece742-fc1d-4e66-8936-6d40d9302ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-0a673009-21ff-4147-a539-210d3717eb01,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-26d4f845-79b1-4f5a-a2b8-b41e40a83642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956484626-172.17.0.20-1597065834688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-852d0a2a-a508-4272-9a98-ae02327d15a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-811ef7e2-717b-452b-b296-4ddbae769450,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-b9488030-06f6-4a56-bdc0-86a988678af7,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-ac37e886-6dfc-4f4d-b939-ac5bce5f2408,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-3b0dc0ec-4e20-4842-9e96-1c8b40586ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-91ece742-fc1d-4e66-8936-6d40d9302ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-0a673009-21ff-4147-a539-210d3717eb01,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-26d4f845-79b1-4f5a-a2b8-b41e40a83642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596753995-172.17.0.20-1597066245530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34063,DS-4dd30db2-8665-4f56-b878-4f49bb551dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-38577242-0f5d-4cf7-a72b-a9b4b430352b,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-208ac1ed-4771-4eaa-a0a7-afe0b30a7abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-3db1fdd7-0a51-436f-9899-a44fb91ec97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-69993ab2-9c96-4ced-a243-fd7d6f39ce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-0b021b9e-baca-495a-bde3-62cb9f98ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-95dcc138-1caa-43b1-a9fa-b3116624682a,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-0f70a058-0a25-47c3-b788-3f5e0ca6578b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596753995-172.17.0.20-1597066245530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34063,DS-4dd30db2-8665-4f56-b878-4f49bb551dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-38577242-0f5d-4cf7-a72b-a9b4b430352b,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-208ac1ed-4771-4eaa-a0a7-afe0b30a7abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-3db1fdd7-0a51-436f-9899-a44fb91ec97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-69993ab2-9c96-4ced-a243-fd7d6f39ce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-0b021b9e-baca-495a-bde3-62cb9f98ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-95dcc138-1caa-43b1-a9fa-b3116624682a,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-0f70a058-0a25-47c3-b788-3f5e0ca6578b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176591883-172.17.0.20-1597066687389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44417,DS-bb6918f6-f74a-427c-b6c8-1ae9bbd1223d,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-c37fe1a7-41aa-49eb-9ade-fd8c2953e16b,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-aab13de8-2820-4007-8626-36eb51e5ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-a4145ac1-3ca5-4237-83f6-637d96cc1526,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-019c9f54-14ac-4e24-9dfc-ec027fbe88b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-34c3f1ad-17a5-4e19-97b2-44f9c0b4e2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-40050877-577a-4636-8925-74291ec599ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-b48e44bd-8898-40de-8176-e95f970825a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176591883-172.17.0.20-1597066687389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44417,DS-bb6918f6-f74a-427c-b6c8-1ae9bbd1223d,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-c37fe1a7-41aa-49eb-9ade-fd8c2953e16b,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-aab13de8-2820-4007-8626-36eb51e5ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-a4145ac1-3ca5-4237-83f6-637d96cc1526,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-019c9f54-14ac-4e24-9dfc-ec027fbe88b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-34c3f1ad-17a5-4e19-97b2-44f9c0b4e2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-40050877-577a-4636-8925-74291ec599ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-b48e44bd-8898-40de-8176-e95f970825a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975748733-172.17.0.20-1597066834121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42412,DS-890e91d1-6ca4-4e15-b020-30e95e477c72,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-203aa780-3522-43ed-92f0-29758b78817e,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-639645aa-fd56-4625-8bbc-518ac985f637,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-cbc5afb5-a05a-4950-bb51-b95352f00121,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-8e239c2d-d4d5-4868-9499-8111ae1f77cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-7c1220f5-4329-4842-8aa4-50a53992470f,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-473313aa-8d89-484f-aff6-64c4c963bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-936e4722-0b8f-48b0-ae87-fbd85267a87e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975748733-172.17.0.20-1597066834121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42412,DS-890e91d1-6ca4-4e15-b020-30e95e477c72,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-203aa780-3522-43ed-92f0-29758b78817e,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-639645aa-fd56-4625-8bbc-518ac985f637,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-cbc5afb5-a05a-4950-bb51-b95352f00121,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-8e239c2d-d4d5-4868-9499-8111ae1f77cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-7c1220f5-4329-4842-8aa4-50a53992470f,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-473313aa-8d89-484f-aff6-64c4c963bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-936e4722-0b8f-48b0-ae87-fbd85267a87e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202671211-172.17.0.20-1597066990829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-ff806f6e-1311-4916-b71f-5e27edf3fe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-dd90ebe2-0f27-408a-a496-c258121d8e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-789c061a-94c3-4c36-ab36-8b7f163fc7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-cfba5177-5d43-4253-bf60-0e405dcebf97,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-2dda4a23-c6ae-4c18-b0d8-edbc81c48b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-7859d1be-944a-42c6-9453-a04240ebdb66,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-9e6c8c18-5c58-4d84-93d7-25f878becdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-6e3dc3c8-45de-44ff-8b13-276f7bfe26a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202671211-172.17.0.20-1597066990829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-ff806f6e-1311-4916-b71f-5e27edf3fe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-dd90ebe2-0f27-408a-a496-c258121d8e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-789c061a-94c3-4c36-ab36-8b7f163fc7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-cfba5177-5d43-4253-bf60-0e405dcebf97,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-2dda4a23-c6ae-4c18-b0d8-edbc81c48b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-7859d1be-944a-42c6-9453-a04240ebdb66,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-9e6c8c18-5c58-4d84-93d7-25f878becdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-6e3dc3c8-45de-44ff-8b13-276f7bfe26a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2000613055-172.17.0.20-1597067435081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40889,DS-0daea97f-9e2d-43d8-a88a-6ade52afd936,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-f7821cc7-aa64-4e19-9584-babc20ea0def,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-fc3192ea-0b59-4d45-8660-c44f1e8f10a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-d1d9bf7f-d9be-4ac0-93b2-21da91851c23,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-de81d0f6-3a94-4856-9993-71d01f465de5,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-42d238a5-3870-46f7-a013-3bef2b40c775,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-efadfd94-6451-4b9d-8c06-9a34e5c8def3,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-2a184025-12b9-4f9e-bc2b-d09ad2f8e69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2000613055-172.17.0.20-1597067435081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40889,DS-0daea97f-9e2d-43d8-a88a-6ade52afd936,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-f7821cc7-aa64-4e19-9584-babc20ea0def,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-fc3192ea-0b59-4d45-8660-c44f1e8f10a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-d1d9bf7f-d9be-4ac0-93b2-21da91851c23,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-de81d0f6-3a94-4856-9993-71d01f465de5,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-42d238a5-3870-46f7-a013-3bef2b40c775,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-efadfd94-6451-4b9d-8c06-9a34e5c8def3,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-2a184025-12b9-4f9e-bc2b-d09ad2f8e69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126251924-172.17.0.20-1597067482920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43079,DS-d62ec6a4-744c-476a-8dc5-f74879c4552d,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-cda5357c-0796-4638-9222-f8e8b89ad2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-62ebeb91-80b2-49f6-a954-9c266e531d82,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-059e7f55-8993-4de7-a2a7-52bab3fd5f17,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-acf95f4b-58da-48f4-a9cf-663bbf775e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-ab079c09-1049-4e8e-ab95-a3265335b045,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-625462bf-64b9-4932-b7d0-bccd0a98cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-c86f83dc-9c39-41c6-b7b8-6c40cea1f6d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126251924-172.17.0.20-1597067482920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43079,DS-d62ec6a4-744c-476a-8dc5-f74879c4552d,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-cda5357c-0796-4638-9222-f8e8b89ad2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-62ebeb91-80b2-49f6-a954-9c266e531d82,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-059e7f55-8993-4de7-a2a7-52bab3fd5f17,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-acf95f4b-58da-48f4-a9cf-663bbf775e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-ab079c09-1049-4e8e-ab95-a3265335b045,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-625462bf-64b9-4932-b7d0-bccd0a98cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-c86f83dc-9c39-41c6-b7b8-6c40cea1f6d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137993509-172.17.0.20-1597067666594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-da7a034e-4777-4418-8cea-874e6f4b42c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-13762596-75ea-49ec-9a22-6bd595adb876,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-a4c789f8-3e66-4c5f-b06d-bf8287f8986f,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-4dccf28b-b22d-4302-82fb-0bc9ae979f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-cffa014b-f0e8-4e6f-acff-11e3dcfcd0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-893f7297-3455-465d-bd5f-d3a95bb4c013,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-e6dc4e0b-6b81-416e-a17a-fe8d917fc192,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-5bb010f2-4a44-4979-bc94-76b36ab73f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137993509-172.17.0.20-1597067666594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-da7a034e-4777-4418-8cea-874e6f4b42c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-13762596-75ea-49ec-9a22-6bd595adb876,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-a4c789f8-3e66-4c5f-b06d-bf8287f8986f,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-4dccf28b-b22d-4302-82fb-0bc9ae979f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-cffa014b-f0e8-4e6f-acff-11e3dcfcd0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-893f7297-3455-465d-bd5f-d3a95bb4c013,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-e6dc4e0b-6b81-416e-a17a-fe8d917fc192,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-5bb010f2-4a44-4979-bc94-76b36ab73f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298857021-172.17.0.20-1597068984607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-de036a37-1e2e-4fd3-bbf6-d529a7733909,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0933d15d-9b12-4872-bc76-7031e5a544db,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-be558bf7-8682-449b-b1f6-5b8173220d51,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-0eaf995b-00cd-4aa8-a820-57c42f8a1e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-6ce3cedf-f9be-496e-b206-cedd34347e44,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-88ada870-7a55-4c88-a8ac-e031dac3bab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-2b24217c-f859-4cda-8529-f7038a3e23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-b3e65497-5393-45f8-b5dc-56f0306254d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298857021-172.17.0.20-1597068984607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-de036a37-1e2e-4fd3-bbf6-d529a7733909,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0933d15d-9b12-4872-bc76-7031e5a544db,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-be558bf7-8682-449b-b1f6-5b8173220d51,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-0eaf995b-00cd-4aa8-a820-57c42f8a1e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-6ce3cedf-f9be-496e-b206-cedd34347e44,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-88ada870-7a55-4c88-a8ac-e031dac3bab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-2b24217c-f859-4cda-8529-f7038a3e23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-b3e65497-5393-45f8-b5dc-56f0306254d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325043131-172.17.0.20-1597069111762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35397,DS-0a2c6a31-fe82-484c-8b2d-c5dc90241647,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-2b41f8d5-43c9-4308-89d4-d1adfc441ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-7fdf3dc8-e0b4-49b6-ac2b-05299e1e5756,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-2546630d-b372-4295-b8ad-0077bd763be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-8bbd48f5-46af-40d0-9eda-bfc2a78bb6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-3388a9ec-7880-4c6a-bb80-75af9c5d3303,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-c078152f-98e0-4d99-86ce-f16f3378c806,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-41720e5e-16f3-42ff-aad8-19198630367f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325043131-172.17.0.20-1597069111762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35397,DS-0a2c6a31-fe82-484c-8b2d-c5dc90241647,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-2b41f8d5-43c9-4308-89d4-d1adfc441ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-7fdf3dc8-e0b4-49b6-ac2b-05299e1e5756,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-2546630d-b372-4295-b8ad-0077bd763be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-8bbd48f5-46af-40d0-9eda-bfc2a78bb6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-3388a9ec-7880-4c6a-bb80-75af9c5d3303,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-c078152f-98e0-4d99-86ce-f16f3378c806,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-41720e5e-16f3-42ff-aad8-19198630367f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159905174-172.17.0.20-1597069447377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33828,DS-d3753cd1-b049-4eb6-9949-7142d227f5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-99b432df-571b-45a8-8135-f650762ac5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-3a906f94-a07e-4473-88f1-6b5850841be7,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-a313d8ce-260f-455f-ba76-2b73909c0eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-c7fb6a26-e533-4399-b2d9-3507a3bae230,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-245fff03-dc06-4869-af34-9e8217ad624b,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-58e04f72-7f0d-4b7e-9cc2-2ecf630dae01,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b463d130-0691-4275-9412-a64b933a2c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159905174-172.17.0.20-1597069447377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33828,DS-d3753cd1-b049-4eb6-9949-7142d227f5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-99b432df-571b-45a8-8135-f650762ac5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-3a906f94-a07e-4473-88f1-6b5850841be7,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-a313d8ce-260f-455f-ba76-2b73909c0eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-c7fb6a26-e533-4399-b2d9-3507a3bae230,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-245fff03-dc06-4869-af34-9e8217ad624b,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-58e04f72-7f0d-4b7e-9cc2-2ecf630dae01,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b463d130-0691-4275-9412-a64b933a2c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316477059-172.17.0.20-1597070168624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35991,DS-cb78084e-e804-4d2d-b699-2cd78df9ff09,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-6ff2dc41-5235-4464-bc63-db437ddf0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-e16cabe8-5ba1-41d9-943d-000d4b729f55,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-d30e7661-e07b-470b-a3a9-8e865d5cf9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-5224964f-6652-477a-bd5a-488d63844a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-42d65e01-538f-474e-b37a-1ab104ea52a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-cd01d014-9ae7-4b4b-8714-127a5d72a2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-0a62fda6-a6ce-4769-a086-d4d7b7334576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316477059-172.17.0.20-1597070168624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35991,DS-cb78084e-e804-4d2d-b699-2cd78df9ff09,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-6ff2dc41-5235-4464-bc63-db437ddf0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-e16cabe8-5ba1-41d9-943d-000d4b729f55,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-d30e7661-e07b-470b-a3a9-8e865d5cf9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-5224964f-6652-477a-bd5a-488d63844a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-42d65e01-538f-474e-b37a-1ab104ea52a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-cd01d014-9ae7-4b4b-8714-127a5d72a2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-0a62fda6-a6ce-4769-a086-d4d7b7334576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6768
