reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049104518-172.17.0.10-1597047874833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-59163826-5cde-4778-9f87-901c43d66d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-1d5b877c-5bc8-4703-b796-c82104476998,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-f2095cd9-a15c-43ac-b23d-62e332095e28,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-c0edf7f7-1e68-496b-a46a-02996c9a2aca,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-0c160cc8-1837-47c8-82a8-0623548da700,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-8dcc918c-d625-4e9c-8c3c-868aecd84838,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-5481b26b-9a11-46fe-b6f0-76f6875d2980,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-61256e12-81fc-4d61-87a8-e7f5aa1824f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049104518-172.17.0.10-1597047874833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-59163826-5cde-4778-9f87-901c43d66d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-1d5b877c-5bc8-4703-b796-c82104476998,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-f2095cd9-a15c-43ac-b23d-62e332095e28,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-c0edf7f7-1e68-496b-a46a-02996c9a2aca,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-0c160cc8-1837-47c8-82a8-0623548da700,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-8dcc918c-d625-4e9c-8c3c-868aecd84838,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-5481b26b-9a11-46fe-b6f0-76f6875d2980,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-61256e12-81fc-4d61-87a8-e7f5aa1824f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473577739-172.17.0.10-1597048421217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-2c07916f-1941-4b77-8b8f-f9d546cd8f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-d02796ef-1948-430f-9000-6ff1cd3beec5,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-466d7149-c64a-4fae-a86a-3ead23611b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-d64b78c7-5291-492a-a08c-b885b4729177,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-9190bf9c-b5d7-4087-971e-896b4981f9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-d5f86ec6-1b4e-4397-8c44-c974c751967e,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-79104455-e1a4-4373-8edc-61de7c7fce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-0fe2d636-b840-495f-b8ee-7bc4fadad84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473577739-172.17.0.10-1597048421217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-2c07916f-1941-4b77-8b8f-f9d546cd8f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-d02796ef-1948-430f-9000-6ff1cd3beec5,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-466d7149-c64a-4fae-a86a-3ead23611b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-d64b78c7-5291-492a-a08c-b885b4729177,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-9190bf9c-b5d7-4087-971e-896b4981f9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-d5f86ec6-1b4e-4397-8c44-c974c751967e,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-79104455-e1a4-4373-8edc-61de7c7fce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-0fe2d636-b840-495f-b8ee-7bc4fadad84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275545298-172.17.0.10-1597048494496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36678,DS-a16a5c12-4c65-4402-93c1-43986cb2b354,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-20b9f557-83a0-4605-a840-d5ec50366435,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-843413e4-56dc-4a53-89f1-dba0c4b61674,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-3df05b25-4da1-4685-beee-bb3dff8cf7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-2e6c1f41-747b-4aef-b1a8-e457bf2588de,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-62fc68ba-96aa-46a7-bbd2-4d0d4a6a7210,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-52a68bdb-f522-4cfa-8980-afdda74279b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-93323862-9aac-40a8-b07e-b899bdfbf50a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275545298-172.17.0.10-1597048494496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36678,DS-a16a5c12-4c65-4402-93c1-43986cb2b354,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-20b9f557-83a0-4605-a840-d5ec50366435,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-843413e4-56dc-4a53-89f1-dba0c4b61674,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-3df05b25-4da1-4685-beee-bb3dff8cf7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-2e6c1f41-747b-4aef-b1a8-e457bf2588de,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-62fc68ba-96aa-46a7-bbd2-4d0d4a6a7210,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-52a68bdb-f522-4cfa-8980-afdda74279b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-93323862-9aac-40a8-b07e-b899bdfbf50a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308782106-172.17.0.10-1597048747481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43264,DS-27778d55-f1ce-4250-ba70-5055df40ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-a7e6f9db-5cca-4fcc-95ea-582f07d10855,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-fe270114-645e-43c3-a067-b7d4338576db,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-d865b43b-afaa-4784-aedc-967114c1a971,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-5285dfcd-2c5f-4ca3-bcb3-8159c84e8366,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-65712eb8-5dd7-4010-8b3b-bb4fcc1cef06,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-fab0b5d9-56e9-4b81-9ec7-c8653a5833c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-c3d0d017-75c3-4f11-9463-c02846f4e988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308782106-172.17.0.10-1597048747481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43264,DS-27778d55-f1ce-4250-ba70-5055df40ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-a7e6f9db-5cca-4fcc-95ea-582f07d10855,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-fe270114-645e-43c3-a067-b7d4338576db,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-d865b43b-afaa-4784-aedc-967114c1a971,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-5285dfcd-2c5f-4ca3-bcb3-8159c84e8366,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-65712eb8-5dd7-4010-8b3b-bb4fcc1cef06,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-fab0b5d9-56e9-4b81-9ec7-c8653a5833c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-c3d0d017-75c3-4f11-9463-c02846f4e988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800303879-172.17.0.10-1597049367552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37335,DS-0f1cc26c-19f5-4bbc-b3f9-0ea99b5e885c,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-150f7adf-1ae5-4c9c-8b2f-180deaf28fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-5478e9aa-b842-4661-b10a-f30469e56934,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-40dbb4ac-69c8-4c3d-afe8-f973c59e7067,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-f6e417d6-0833-43dd-b6a4-8852cb67dabe,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-223f4268-c23c-4942-a4ba-184bbc0491d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-2ca22023-38b3-42da-a22f-cb3ef416f976,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-7c5dbd3f-8848-4586-b2a6-f69464ebd2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800303879-172.17.0.10-1597049367552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37335,DS-0f1cc26c-19f5-4bbc-b3f9-0ea99b5e885c,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-150f7adf-1ae5-4c9c-8b2f-180deaf28fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-5478e9aa-b842-4661-b10a-f30469e56934,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-40dbb4ac-69c8-4c3d-afe8-f973c59e7067,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-f6e417d6-0833-43dd-b6a4-8852cb67dabe,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-223f4268-c23c-4942-a4ba-184bbc0491d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-2ca22023-38b3-42da-a22f-cb3ef416f976,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-7c5dbd3f-8848-4586-b2a6-f69464ebd2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745552168-172.17.0.10-1597049434897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-5d2cd982-0e20-40e3-b20a-6341a16c3820,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-9b3dd179-8738-4e4f-aac4-9d2c297952d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-58a41191-d56a-4aae-9021-5b9167fa6a92,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-ca437950-a6f4-411c-afee-fa4414e09013,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-1618bcfb-f4f1-4579-b1c5-e9fb0414dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-8f2f7cca-879b-42cd-9eb3-3619052749c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-531a8bd0-71a0-4cab-9090-d217aacd4985,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-79b6fa52-f974-4933-96ca-d8b9ed0c4b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745552168-172.17.0.10-1597049434897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-5d2cd982-0e20-40e3-b20a-6341a16c3820,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-9b3dd179-8738-4e4f-aac4-9d2c297952d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-58a41191-d56a-4aae-9021-5b9167fa6a92,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-ca437950-a6f4-411c-afee-fa4414e09013,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-1618bcfb-f4f1-4579-b1c5-e9fb0414dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-8f2f7cca-879b-42cd-9eb3-3619052749c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-531a8bd0-71a0-4cab-9090-d217aacd4985,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-79b6fa52-f974-4933-96ca-d8b9ed0c4b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979030332-172.17.0.10-1597049647009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37614,DS-654a6e5e-069a-4259-a051-d9168d12b27a,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-1f41a820-eb61-4465-8e73-fd357bd0e4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-e603e103-b254-43a0-91aa-19f35e9ff66e,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-5b4b6042-1824-48c1-97d0-22c0eac69f05,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-10339f34-5c11-4d9f-8cba-357204d50162,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-61ebe1d3-e5d3-490f-91e2-40e0aa5c4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-c9c53974-0e61-4cae-a24f-63b337ed9cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-bc04821e-61b3-4046-a3a4-dc9986c5c2e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979030332-172.17.0.10-1597049647009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37614,DS-654a6e5e-069a-4259-a051-d9168d12b27a,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-1f41a820-eb61-4465-8e73-fd357bd0e4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-e603e103-b254-43a0-91aa-19f35e9ff66e,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-5b4b6042-1824-48c1-97d0-22c0eac69f05,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-10339f34-5c11-4d9f-8cba-357204d50162,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-61ebe1d3-e5d3-490f-91e2-40e0aa5c4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-c9c53974-0e61-4cae-a24f-63b337ed9cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-bc04821e-61b3-4046-a3a4-dc9986c5c2e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075277445-172.17.0.10-1597049898623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44701,DS-f2e30a3f-cd23-4079-906e-9032d9811410,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-366bd6ba-2af7-41a9-a11c-f827d61f6812,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-3061f919-d213-4f05-96dd-dd2361c83fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-5eb65897-82c8-4ac8-be89-e0e4d7c69726,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-8e1e5e73-fdfb-4921-8139-69a9bb205ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-8a445e83-e71a-41c5-8d67-67cda31be1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-96924861-443f-45ea-a783-08e2e81e50e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-4ec9d21a-3c47-4579-a686-fc4ddbb8981a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075277445-172.17.0.10-1597049898623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44701,DS-f2e30a3f-cd23-4079-906e-9032d9811410,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-366bd6ba-2af7-41a9-a11c-f827d61f6812,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-3061f919-d213-4f05-96dd-dd2361c83fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-5eb65897-82c8-4ac8-be89-e0e4d7c69726,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-8e1e5e73-fdfb-4921-8139-69a9bb205ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-8a445e83-e71a-41c5-8d67-67cda31be1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-96924861-443f-45ea-a783-08e2e81e50e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-4ec9d21a-3c47-4579-a686-fc4ddbb8981a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979137289-172.17.0.10-1597050916632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45353,DS-63895cc3-d898-47f8-b736-61e072a54814,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-25dd64c0-1eaf-445c-a1db-23155ca92e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-fca39c20-c4e9-4029-8b1e-19d49c791940,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-4cb67b7b-ee9d-48b9-ae13-9f6138dbdd82,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-25870298-d118-4e27-9afc-c962afd31601,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-88c28511-58f5-4a0e-be22-01c885ed9550,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-3909d5e6-738b-4433-817d-8dec7f2076f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-39ef1d16-ac3a-4626-be89-23f461ee043f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979137289-172.17.0.10-1597050916632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45353,DS-63895cc3-d898-47f8-b736-61e072a54814,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-25dd64c0-1eaf-445c-a1db-23155ca92e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-fca39c20-c4e9-4029-8b1e-19d49c791940,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-4cb67b7b-ee9d-48b9-ae13-9f6138dbdd82,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-25870298-d118-4e27-9afc-c962afd31601,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-88c28511-58f5-4a0e-be22-01c885ed9550,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-3909d5e6-738b-4433-817d-8dec7f2076f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-39ef1d16-ac3a-4626-be89-23f461ee043f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241912659-172.17.0.10-1597050952295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-649909d1-1667-4bed-83c3-498d5470c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-c479732f-1128-4a4c-b9c6-b368c1d82d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-1d258f72-154a-489b-921a-e1e1a13fcfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-99650995-214e-4a16-9c40-a2802ca0d283,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-d551ceb3-98f8-4407-88b7-b5eab2af3179,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-5f03351d-5383-47af-ad62-3f8636f3f976,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-02da4d3a-939e-45d7-93ee-609e03fa2db1,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-7f032c77-c8fe-458d-8f13-db337ce22c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241912659-172.17.0.10-1597050952295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-649909d1-1667-4bed-83c3-498d5470c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-c479732f-1128-4a4c-b9c6-b368c1d82d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-1d258f72-154a-489b-921a-e1e1a13fcfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-99650995-214e-4a16-9c40-a2802ca0d283,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-d551ceb3-98f8-4407-88b7-b5eab2af3179,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-5f03351d-5383-47af-ad62-3f8636f3f976,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-02da4d3a-939e-45d7-93ee-609e03fa2db1,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-7f032c77-c8fe-458d-8f13-db337ce22c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630264158-172.17.0.10-1597051020724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40206,DS-ac9f10a1-ce7a-4062-a624-c1c705e1545c,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-a627eaed-2888-47e3-955b-8e0a77a6575f,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-6133e866-dd9a-41b2-adc2-efef877fe6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-64229a1a-7b88-47a2-bddc-858b79e741b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-7e892ac0-18d2-40a8-979b-44fe7aa44dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-b84855f4-3ffb-4bb5-9971-54add3e3ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-f2d6c6f9-6d08-46b9-af5b-d1c919798cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-b1d978dc-c460-4d34-a2b4-24cb82303076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630264158-172.17.0.10-1597051020724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40206,DS-ac9f10a1-ce7a-4062-a624-c1c705e1545c,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-a627eaed-2888-47e3-955b-8e0a77a6575f,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-6133e866-dd9a-41b2-adc2-efef877fe6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-64229a1a-7b88-47a2-bddc-858b79e741b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-7e892ac0-18d2-40a8-979b-44fe7aa44dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-b84855f4-3ffb-4bb5-9971-54add3e3ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-f2d6c6f9-6d08-46b9-af5b-d1c919798cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-b1d978dc-c460-4d34-a2b4-24cb82303076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176280336-172.17.0.10-1597051087442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34290,DS-dff50317-3283-4be1-b961-27bea7c852b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-6d1e4870-0924-41b2-84b4-8a7ecfaf00d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-09013c9a-3493-4495-9dec-fc5719e64532,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-a733511d-ddde-44c8-aa1e-b54295bd0b01,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-6bcf71ad-7262-4e88-913e-18eafc7e8f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-5e0ff36f-379e-487c-85e3-f49ed68284f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-de5a35bf-8b57-4c90-bcf7-35a51b23d2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-d64675b5-3fd0-4ad2-99cb-c32c800d53fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176280336-172.17.0.10-1597051087442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34290,DS-dff50317-3283-4be1-b961-27bea7c852b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-6d1e4870-0924-41b2-84b4-8a7ecfaf00d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-09013c9a-3493-4495-9dec-fc5719e64532,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-a733511d-ddde-44c8-aa1e-b54295bd0b01,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-6bcf71ad-7262-4e88-913e-18eafc7e8f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-5e0ff36f-379e-487c-85e3-f49ed68284f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-de5a35bf-8b57-4c90-bcf7-35a51b23d2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-d64675b5-3fd0-4ad2-99cb-c32c800d53fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457224891-172.17.0.10-1597051583317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45861,DS-7533fa12-166f-4d2d-9a51-c0267a408bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-6edf349e-079f-42cd-810f-d7a83e47c50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-08de140a-baa3-4363-8757-431943610a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-549b5cc0-9f99-40a5-b107-3a190fc925de,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-d6128325-ac8f-4dcc-9d48-a2eb6ee8450a,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-504cabe6-5dd0-4e53-a7cd-dcbffbf618cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-bea23ffd-5ec0-42cd-ab7a-f1f7ce6265f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-15510faf-46a9-4f03-89ab-3bbe614bc4f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457224891-172.17.0.10-1597051583317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45861,DS-7533fa12-166f-4d2d-9a51-c0267a408bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-6edf349e-079f-42cd-810f-d7a83e47c50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-08de140a-baa3-4363-8757-431943610a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-549b5cc0-9f99-40a5-b107-3a190fc925de,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-d6128325-ac8f-4dcc-9d48-a2eb6ee8450a,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-504cabe6-5dd0-4e53-a7cd-dcbffbf618cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-bea23ffd-5ec0-42cd-ab7a-f1f7ce6265f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-15510faf-46a9-4f03-89ab-3bbe614bc4f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135222155-172.17.0.10-1597052375687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45092,DS-ceaae6a4-fc53-4265-beba-2b091e16683b,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-4c720121-502a-4fc9-bc5d-d3325d14400a,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-ecb23f1a-69a5-44ce-bf1a-965833d34a48,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-a0bf7438-4b9f-47d2-ad94-7bcb2c09c3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-3126291e-7f96-4bad-95cc-21037dfd5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-8cd3ff88-2e95-4b84-85ba-3e3b54519af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-35f3473a-b3aa-4779-b5f4-92b5d526a616,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-909c7838-8c86-48db-a2fa-ecb08515cbbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135222155-172.17.0.10-1597052375687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45092,DS-ceaae6a4-fc53-4265-beba-2b091e16683b,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-4c720121-502a-4fc9-bc5d-d3325d14400a,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-ecb23f1a-69a5-44ce-bf1a-965833d34a48,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-a0bf7438-4b9f-47d2-ad94-7bcb2c09c3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-3126291e-7f96-4bad-95cc-21037dfd5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-8cd3ff88-2e95-4b84-85ba-3e3b54519af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-35f3473a-b3aa-4779-b5f4-92b5d526a616,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-909c7838-8c86-48db-a2fa-ecb08515cbbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142392900-172.17.0.10-1597052512516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-bf6a4730-2fa1-4a3d-85f3-d6d4f34212a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-c8f0b46e-2f5c-4b59-bd19-6a27545a0889,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-5210d7e6-fcea-42a1-ac5d-7ae38ff12001,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-63a18889-e172-4adb-b424-a42f61ede42c,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-9ff34754-aca2-4c70-ba88-285669e4d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-13eb8552-2192-4876-a2fe-098f3a1072bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-e73ccd7e-d2ed-4256-a704-7ad9c5fe8a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-3bed7641-0335-4223-8078-024ec9e3d995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142392900-172.17.0.10-1597052512516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-bf6a4730-2fa1-4a3d-85f3-d6d4f34212a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-c8f0b46e-2f5c-4b59-bd19-6a27545a0889,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-5210d7e6-fcea-42a1-ac5d-7ae38ff12001,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-63a18889-e172-4adb-b424-a42f61ede42c,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-9ff34754-aca2-4c70-ba88-285669e4d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-13eb8552-2192-4876-a2fe-098f3a1072bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-e73ccd7e-d2ed-4256-a704-7ad9c5fe8a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-3bed7641-0335-4223-8078-024ec9e3d995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5429
