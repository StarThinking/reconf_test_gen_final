reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468887925-172.17.0.18-1597110677991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37636,DS-f1d868df-aaa8-4666-821b-746e8f3ed483,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-7aa37b19-168e-44b4-88b4-2d9824d14dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-0556feea-1ac9-46b6-b1a2-19b3d349f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-2c62397d-f97b-460b-aca6-9a2e30df3a52,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-94db90bb-e259-42aa-9d4e-8b096911ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-103a9221-6cb5-4f51-926b-9ded6c675257,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-8cf9432a-3fa7-4e32-a076-01db4d416a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-18ab6f14-3b3e-473e-9d02-b285dfa849b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468887925-172.17.0.18-1597110677991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37636,DS-f1d868df-aaa8-4666-821b-746e8f3ed483,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-7aa37b19-168e-44b4-88b4-2d9824d14dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-0556feea-1ac9-46b6-b1a2-19b3d349f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-2c62397d-f97b-460b-aca6-9a2e30df3a52,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-94db90bb-e259-42aa-9d4e-8b096911ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-103a9221-6cb5-4f51-926b-9ded6c675257,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-8cf9432a-3fa7-4e32-a076-01db4d416a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-18ab6f14-3b3e-473e-9d02-b285dfa849b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721399751-172.17.0.18-1597110956012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-cf8e703b-0d85-4597-a520-5281ad58dd61,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-2221f228-dc56-4f75-8472-4cbbdea5126e,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-6d36534b-18aa-4396-98ec-75e5542fea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-21973465-ec06-4d57-9b65-4042827fe828,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-1ae3d200-a409-4ffa-a494-e995f2648f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-69acca6c-523a-46f9-b5aa-1b9d52ce19b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-6d6fac6d-84b2-40af-92cc-436346231047,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-aaf72d97-012b-4d2b-931a-465deec3b7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721399751-172.17.0.18-1597110956012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-cf8e703b-0d85-4597-a520-5281ad58dd61,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-2221f228-dc56-4f75-8472-4cbbdea5126e,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-6d36534b-18aa-4396-98ec-75e5542fea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-21973465-ec06-4d57-9b65-4042827fe828,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-1ae3d200-a409-4ffa-a494-e995f2648f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-69acca6c-523a-46f9-b5aa-1b9d52ce19b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-6d6fac6d-84b2-40af-92cc-436346231047,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-aaf72d97-012b-4d2b-931a-465deec3b7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452022904-172.17.0.18-1597111146109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-406464fe-351e-4cf7-be03-329a1203b663,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-6a1cdca2-5e05-476d-a867-e5f064109e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-db1211e8-01a9-49ed-87f6-fb0ab5a443a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-5f643dd8-c2a6-4ed1-a0de-b790e96edccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-3bcb0dbf-8bb2-4d0f-81c8-d5534e120452,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-76be2d88-e009-4b81-a797-c9e5fe7f5b76,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-8ff3e919-0d88-4739-ba2f-c25d1f21766e,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-1c134f84-9246-4c0e-b4db-58b444dbd383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452022904-172.17.0.18-1597111146109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-406464fe-351e-4cf7-be03-329a1203b663,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-6a1cdca2-5e05-476d-a867-e5f064109e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-db1211e8-01a9-49ed-87f6-fb0ab5a443a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-5f643dd8-c2a6-4ed1-a0de-b790e96edccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-3bcb0dbf-8bb2-4d0f-81c8-d5534e120452,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-76be2d88-e009-4b81-a797-c9e5fe7f5b76,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-8ff3e919-0d88-4739-ba2f-c25d1f21766e,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-1c134f84-9246-4c0e-b4db-58b444dbd383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783397905-172.17.0.18-1597111245252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34037,DS-bd54d31d-c52e-4f5d-9fed-efa1a86fc421,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-e1284dea-f851-495b-8387-9e4be553eeba,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-99bc7811-1d2b-4362-8a7a-e43f20507c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-805ae856-ae64-4a96-9029-4fb729524c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-9a88a10a-ed83-4e8a-ad91-87d39bf05adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-1353304e-99df-4560-8f41-10cd36e875a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-93333634-188e-4995-b977-36acf34e25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-fd26fa56-409d-4aa3-9da7-49a132b09591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783397905-172.17.0.18-1597111245252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34037,DS-bd54d31d-c52e-4f5d-9fed-efa1a86fc421,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-e1284dea-f851-495b-8387-9e4be553eeba,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-99bc7811-1d2b-4362-8a7a-e43f20507c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-805ae856-ae64-4a96-9029-4fb729524c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-9a88a10a-ed83-4e8a-ad91-87d39bf05adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-1353304e-99df-4560-8f41-10cd36e875a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-93333634-188e-4995-b977-36acf34e25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-fd26fa56-409d-4aa3-9da7-49a132b09591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076294904-172.17.0.18-1597111339854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43733,DS-40b185e6-5f9b-47ac-9198-94e0ad3f7c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-cc48a909-b63b-433c-b2c1-f68cb8c31598,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-5068d29f-b269-41d8-a508-46bb5eb02808,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-a41595d6-322e-4bf4-b56b-b5b92bf3e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-b4e32909-0945-4c93-b46b-19cd876dac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-a0d96c80-3c88-49a3-9da9-49402d8445da,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-07e86ae3-27e5-4312-8805-28959b021a44,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-d45e055a-588c-4732-bb7d-1d745e0a9937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076294904-172.17.0.18-1597111339854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43733,DS-40b185e6-5f9b-47ac-9198-94e0ad3f7c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-cc48a909-b63b-433c-b2c1-f68cb8c31598,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-5068d29f-b269-41d8-a508-46bb5eb02808,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-a41595d6-322e-4bf4-b56b-b5b92bf3e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-b4e32909-0945-4c93-b46b-19cd876dac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-a0d96c80-3c88-49a3-9da9-49402d8445da,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-07e86ae3-27e5-4312-8805-28959b021a44,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-d45e055a-588c-4732-bb7d-1d745e0a9937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440286592-172.17.0.18-1597111515637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-b7077825-08ea-47ff-8de2-0a7368fcb6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-9d7b4e77-df71-4fc0-9598-a265c8691251,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-f3fd5dba-3028-4374-812b-34aac02dfe85,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-ead93736-323a-4e92-b973-8136d3c68f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-80fd6022-039e-41ff-93f1-9e36f166f740,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-2594bc27-f916-44f5-86a1-214830e92e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-8e3e8fcf-d591-4f36-82f5-e84e88431a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-57cbbef0-8b33-4ce7-922d-42913da606ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440286592-172.17.0.18-1597111515637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-b7077825-08ea-47ff-8de2-0a7368fcb6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-9d7b4e77-df71-4fc0-9598-a265c8691251,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-f3fd5dba-3028-4374-812b-34aac02dfe85,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-ead93736-323a-4e92-b973-8136d3c68f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-80fd6022-039e-41ff-93f1-9e36f166f740,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-2594bc27-f916-44f5-86a1-214830e92e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-8e3e8fcf-d591-4f36-82f5-e84e88431a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-57cbbef0-8b33-4ce7-922d-42913da606ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900372435-172.17.0.18-1597111751147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-d54d8231-92b3-4579-9eed-ebd2f8485559,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-74b69c77-ffed-48af-ac24-704d73b54635,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-8bc7ff38-26eb-4634-8db6-de5e3c591f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-e2a88b36-905c-4739-9364-f384b21c2589,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-89986c10-506a-402f-b175-da838fb39d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-c306ea6d-07e2-4f73-8548-4ee98213b2de,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-00c0d1df-a3a0-4361-87d6-01ffb2d56bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-13043710-be02-4f5b-aae7-6261a43febbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900372435-172.17.0.18-1597111751147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-d54d8231-92b3-4579-9eed-ebd2f8485559,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-74b69c77-ffed-48af-ac24-704d73b54635,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-8bc7ff38-26eb-4634-8db6-de5e3c591f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-e2a88b36-905c-4739-9364-f384b21c2589,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-89986c10-506a-402f-b175-da838fb39d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-c306ea6d-07e2-4f73-8548-4ee98213b2de,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-00c0d1df-a3a0-4361-87d6-01ffb2d56bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-13043710-be02-4f5b-aae7-6261a43febbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491407928-172.17.0.18-1597112236499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38871,DS-e9956e33-1c0a-466b-bd7c-a7ea1e3b1ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-bedc5237-7f05-43c7-9b4e-712abc0e2f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-d7361723-9065-47d8-83cb-80f3c6ed14b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-ef86b0c0-b762-4382-b570-c745d0d3a4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-2bc077a2-745a-46c0-bb8d-0bafc596a2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-de5beed1-5653-4444-a79d-a3eda7d3d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-bfd587f0-8226-40fe-b9f0-d7e8708177de,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-9c2f997d-1a6f-4eb4-8b6d-4b89e115b1bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491407928-172.17.0.18-1597112236499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38871,DS-e9956e33-1c0a-466b-bd7c-a7ea1e3b1ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-bedc5237-7f05-43c7-9b4e-712abc0e2f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-d7361723-9065-47d8-83cb-80f3c6ed14b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-ef86b0c0-b762-4382-b570-c745d0d3a4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-2bc077a2-745a-46c0-bb8d-0bafc596a2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-de5beed1-5653-4444-a79d-a3eda7d3d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-bfd587f0-8226-40fe-b9f0-d7e8708177de,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-9c2f997d-1a6f-4eb4-8b6d-4b89e115b1bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139987043-172.17.0.18-1597112601977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36025,DS-ed6c775e-e615-46b2-bc6c-4e7cc10364ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-96493fd5-c432-449c-9473-258f3fa8240d,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-b590151f-7a29-4d17-bce2-3566fb107c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-88f9592a-79b3-45a1-848a-c3f885425716,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-83a6d440-f6d6-4a9f-8c4d-06fa2f1fb888,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-87a2366b-72b7-43bf-833b-7dcca7ee9536,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-1d3e1076-63a4-496a-bb38-1eab985ab706,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-d9c18a3e-a06e-484f-80c9-0c1f1f3bb89c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139987043-172.17.0.18-1597112601977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36025,DS-ed6c775e-e615-46b2-bc6c-4e7cc10364ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-96493fd5-c432-449c-9473-258f3fa8240d,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-b590151f-7a29-4d17-bce2-3566fb107c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-88f9592a-79b3-45a1-848a-c3f885425716,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-83a6d440-f6d6-4a9f-8c4d-06fa2f1fb888,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-87a2366b-72b7-43bf-833b-7dcca7ee9536,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-1d3e1076-63a4-496a-bb38-1eab985ab706,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-d9c18a3e-a06e-484f-80c9-0c1f1f3bb89c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805843041-172.17.0.18-1597112954195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35446,DS-a0c4322c-9fa5-4bb4-a6ff-aa924c6b99ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-cfffbd06-73cc-4c69-b7f8-9d9d6831ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-c2d5d062-7de0-4375-b2f1-fc82bf069887,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-91a710c0-5ba8-421f-832b-108fb013db47,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-468a99fe-9ca7-464e-88f9-b286170060fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-c3eba410-9230-435e-a6cd-fbfc23f296a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-55279d8a-1191-4c8b-ba97-b9c8732b941c,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-22802a45-ce54-4c91-8575-812facec2ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805843041-172.17.0.18-1597112954195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35446,DS-a0c4322c-9fa5-4bb4-a6ff-aa924c6b99ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-cfffbd06-73cc-4c69-b7f8-9d9d6831ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-c2d5d062-7de0-4375-b2f1-fc82bf069887,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-91a710c0-5ba8-421f-832b-108fb013db47,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-468a99fe-9ca7-464e-88f9-b286170060fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-c3eba410-9230-435e-a6cd-fbfc23f296a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-55279d8a-1191-4c8b-ba97-b9c8732b941c,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-22802a45-ce54-4c91-8575-812facec2ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650884831-172.17.0.18-1597113028684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-49d15b08-7122-40c8-b319-8c4428610902,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-0f3c4b55-4b3a-428d-8e66-4b8403033eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-c699e97a-fad0-4b23-926d-9b4336968b82,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-38e8fa8a-e5b0-4ca3-bd04-a5f6366572dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-60cfabee-2299-4c00-895b-7f5ef28fedbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-66dffad7-2cd9-4c46-844f-69f616a63008,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-c22a81be-0c3f-427d-9054-f46cb878ece7,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-1325a74c-06ac-4461-8c54-6e667f27b166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650884831-172.17.0.18-1597113028684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-49d15b08-7122-40c8-b319-8c4428610902,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-0f3c4b55-4b3a-428d-8e66-4b8403033eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-c699e97a-fad0-4b23-926d-9b4336968b82,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-38e8fa8a-e5b0-4ca3-bd04-a5f6366572dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-60cfabee-2299-4c00-895b-7f5ef28fedbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-66dffad7-2cd9-4c46-844f-69f616a63008,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-c22a81be-0c3f-427d-9054-f46cb878ece7,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-1325a74c-06ac-4461-8c54-6e667f27b166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332567408-172.17.0.18-1597113175065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38488,DS-29a839a9-80f7-4528-a002-2fc981a5c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-8fb22e1c-29ac-46d5-8168-0a06e4f33772,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-4d8ce879-c29c-46dd-b883-d75813dc3868,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-02f92d3d-f2db-4a61-880d-03c4fd160b72,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-129ac799-0e11-488a-a890-5b05ef5228f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-d09eba43-8f41-4115-ae51-364795c9bcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-9b2f1e54-6eaf-4574-8d62-b78977bc4ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-ec2e9bf3-d6c3-4984-955b-784ebe9c4c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332567408-172.17.0.18-1597113175065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38488,DS-29a839a9-80f7-4528-a002-2fc981a5c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-8fb22e1c-29ac-46d5-8168-0a06e4f33772,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-4d8ce879-c29c-46dd-b883-d75813dc3868,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-02f92d3d-f2db-4a61-880d-03c4fd160b72,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-129ac799-0e11-488a-a890-5b05ef5228f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-d09eba43-8f41-4115-ae51-364795c9bcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-9b2f1e54-6eaf-4574-8d62-b78977bc4ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-ec2e9bf3-d6c3-4984-955b-784ebe9c4c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736306809-172.17.0.18-1597113321075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-41383328-1c83-49b5-9bf7-ac2f643ecfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-5a627785-3766-4be1-92b6-989c96319cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-b98a23c9-4284-4d4d-aab1-53479867d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-a14fa365-f7cd-4a25-9953-07a95bef35b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-3a5c1108-b137-4f13-a346-6424f28c96e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-05d1a23c-cf1d-4e86-b7d0-747eca029a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-6a06cab1-e28c-421d-bbd1-bf0ee81cab45,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-134205e1-7d92-412b-8408-43c37b8e4a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736306809-172.17.0.18-1597113321075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-41383328-1c83-49b5-9bf7-ac2f643ecfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-5a627785-3766-4be1-92b6-989c96319cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-b98a23c9-4284-4d4d-aab1-53479867d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-a14fa365-f7cd-4a25-9953-07a95bef35b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-3a5c1108-b137-4f13-a346-6424f28c96e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-05d1a23c-cf1d-4e86-b7d0-747eca029a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-6a06cab1-e28c-421d-bbd1-bf0ee81cab45,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-134205e1-7d92-412b-8408-43c37b8e4a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490129962-172.17.0.18-1597113360708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-f6c02011-9ea5-46b1-af45-d91e61ae65ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-ae86ff48-724b-466f-8642-adb263cfdeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-f341eda0-dbf7-445d-92b8-c8c428a316ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-7326cd30-e2e9-4cf8-a08e-cd28bcffdd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-39307d2f-9610-4249-857a-84460655c735,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-ac55697a-a612-4713-80ba-6320c77b6b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-45b0e602-ab68-4385-95ce-26034ea89ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-811ba1e3-0648-48b5-bf54-0b765ef42141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490129962-172.17.0.18-1597113360708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-f6c02011-9ea5-46b1-af45-d91e61ae65ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-ae86ff48-724b-466f-8642-adb263cfdeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-f341eda0-dbf7-445d-92b8-c8c428a316ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-7326cd30-e2e9-4cf8-a08e-cd28bcffdd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-39307d2f-9610-4249-857a-84460655c735,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-ac55697a-a612-4713-80ba-6320c77b6b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-45b0e602-ab68-4385-95ce-26034ea89ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-811ba1e3-0648-48b5-bf54-0b765ef42141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335438320-172.17.0.18-1597113575714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34971,DS-90f8e2c0-807d-4acd-b5e0-3bd3c4e0833a,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-52b3b7e5-dd29-44df-8886-ed8f58d3f5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-4ce3efbd-51fc-4716-9425-f72b775aee36,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-f2f0fa84-9705-4d33-a8d0-808423325c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-338655b6-3c51-4d07-940d-8ca06cee9c38,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-7ee437c4-5bef-4e7d-8a49-2d5248e82ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-b1631311-288e-4bcf-96c7-630873a86324,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-c55237b0-27e8-48a4-be14-017c93098d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335438320-172.17.0.18-1597113575714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34971,DS-90f8e2c0-807d-4acd-b5e0-3bd3c4e0833a,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-52b3b7e5-dd29-44df-8886-ed8f58d3f5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-4ce3efbd-51fc-4716-9425-f72b775aee36,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-f2f0fa84-9705-4d33-a8d0-808423325c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-338655b6-3c51-4d07-940d-8ca06cee9c38,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-7ee437c4-5bef-4e7d-8a49-2d5248e82ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-b1631311-288e-4bcf-96c7-630873a86324,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-c55237b0-27e8-48a4-be14-017c93098d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280821798-172.17.0.18-1597114287222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44820,DS-af6f1343-b9a4-4113-8440-b7b3e2c38247,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-34c3dcb5-1715-4c1f-9e3c-861cf0c02204,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-8672c1fd-29ac-4cc0-a381-f2c0f4d8f338,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-8236a5b0-d390-44e2-9da5-135f25591ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-24e9c127-ee58-4f16-9609-ea30a0558d54,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-f26e3cfc-67b1-4b45-997c-68e59f32f3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-d494bff3-9e8b-43d1-9a88-37749094cdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-590f7d9c-057e-4df9-8abb-e14b090fab1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280821798-172.17.0.18-1597114287222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44820,DS-af6f1343-b9a4-4113-8440-b7b3e2c38247,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-34c3dcb5-1715-4c1f-9e3c-861cf0c02204,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-8672c1fd-29ac-4cc0-a381-f2c0f4d8f338,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-8236a5b0-d390-44e2-9da5-135f25591ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-24e9c127-ee58-4f16-9609-ea30a0558d54,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-f26e3cfc-67b1-4b45-997c-68e59f32f3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-d494bff3-9e8b-43d1-9a88-37749094cdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-590f7d9c-057e-4df9-8abb-e14b090fab1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915740231-172.17.0.18-1597114603217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33743,DS-12af67d0-5b90-4d71-b910-20e0f516727a,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-8b0d45d9-2c9d-4f98-a573-1aa8e24170d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-7a21cd29-4e14-49a6-abc7-4344349d1773,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-8fd85fe7-9c08-442f-bce3-f1952a30d19c,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-8cd783f0-c95e-48dd-a0fa-dee15b2dd39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-9ff57c68-7d7f-4a4c-984a-39b7950d4d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-61ddb9ea-e789-486c-bd95-682e74719f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-832d153c-a130-45f3-9060-b717e81654fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915740231-172.17.0.18-1597114603217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33743,DS-12af67d0-5b90-4d71-b910-20e0f516727a,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-8b0d45d9-2c9d-4f98-a573-1aa8e24170d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-7a21cd29-4e14-49a6-abc7-4344349d1773,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-8fd85fe7-9c08-442f-bce3-f1952a30d19c,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-8cd783f0-c95e-48dd-a0fa-dee15b2dd39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-9ff57c68-7d7f-4a4c-984a-39b7950d4d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-61ddb9ea-e789-486c-bd95-682e74719f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-832d153c-a130-45f3-9060-b717e81654fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547179852-172.17.0.18-1597114731774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-54e34a29-4655-41a4-91b4-edbcf4f06411,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-4343861c-9d5d-45a3-b8e8-c09ffb00be6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-5b5470a0-2099-4ed7-bae2-c419647770f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-b8d08d71-8866-499b-9f55-4c4a99939425,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-3374cdb0-e1b9-4f19-8a9e-47c67a7b3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-533269bd-dc0e-4f46-8fd1-4963105fa0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-18055613-8110-42c7-b550-f5fbb578038a,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-58dbf2a0-85e8-4a2c-8ec8-36cf14896408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547179852-172.17.0.18-1597114731774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-54e34a29-4655-41a4-91b4-edbcf4f06411,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-4343861c-9d5d-45a3-b8e8-c09ffb00be6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-5b5470a0-2099-4ed7-bae2-c419647770f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-b8d08d71-8866-499b-9f55-4c4a99939425,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-3374cdb0-e1b9-4f19-8a9e-47c67a7b3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-533269bd-dc0e-4f46-8fd1-4963105fa0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-18055613-8110-42c7-b550-f5fbb578038a,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-58dbf2a0-85e8-4a2c-8ec8-36cf14896408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202230401-172.17.0.18-1597115049398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38751,DS-cf246933-fbc1-4f61-b4ea-47cbc10f275f,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-810d0fa0-8927-4641-bbfc-f253ac0a82d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-3face522-f119-4931-9e3f-faff99dff025,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-f41c2c97-ef26-44b3-95b4-409cac8bd5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-736d9dcc-3ea4-40a8-9d94-c37516895297,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-2b14ef32-bd35-4dfd-9369-20466947cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-20c6ef8d-3144-4f65-b456-a378e9c789a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-7b62fc15-2b15-4904-994e-0cbf3f91f375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202230401-172.17.0.18-1597115049398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38751,DS-cf246933-fbc1-4f61-b4ea-47cbc10f275f,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-810d0fa0-8927-4641-bbfc-f253ac0a82d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-3face522-f119-4931-9e3f-faff99dff025,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-f41c2c97-ef26-44b3-95b4-409cac8bd5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-736d9dcc-3ea4-40a8-9d94-c37516895297,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-2b14ef32-bd35-4dfd-9369-20466947cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-20c6ef8d-3144-4f65-b456-a378e9c789a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-7b62fc15-2b15-4904-994e-0cbf3f91f375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876575682-172.17.0.18-1597115353855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-14af8de5-b1f1-4442-b7fa-6733a8ff9dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-aa878c03-aea1-4350-bba8-78b932c33c82,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-a140545d-6450-4216-8ccf-3c4e7b35ddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-16ef1a7d-d0b3-45b0-865a-13e0abeec27a,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-f365ea79-fdcb-44c1-9517-775e98c05ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-b8ee6ab6-28fa-41af-beac-5add1b8eaf88,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-abfd91b4-2f92-42b4-bdeb-443a9193828c,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-f08fa47d-73a7-4f0c-8d88-a47371c204a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876575682-172.17.0.18-1597115353855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-14af8de5-b1f1-4442-b7fa-6733a8ff9dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-aa878c03-aea1-4350-bba8-78b932c33c82,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-a140545d-6450-4216-8ccf-3c4e7b35ddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-16ef1a7d-d0b3-45b0-865a-13e0abeec27a,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-f365ea79-fdcb-44c1-9517-775e98c05ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-b8ee6ab6-28fa-41af-beac-5add1b8eaf88,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-abfd91b4-2f92-42b4-bdeb-443a9193828c,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-f08fa47d-73a7-4f0c-8d88-a47371c204a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435653769-172.17.0.18-1597115442487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-f80f5fde-740f-402f-8893-d45fe26af2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-931047b5-9f2e-41b7-8bd8-c9095c63b083,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-dfca1a99-b817-4618-b85b-64d47ff14625,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-0eb75521-210f-49b4-b8b8-a8619b90300b,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-2c32230b-fbe5-4bcc-9a0b-e1d0529c3b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-2a404294-dfca-4a03-bd47-006dd54800a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-854bf3f1-39ae-4991-a823-cf690875887c,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-20655969-5313-4ac1-b6d0-2c3dad3aeffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435653769-172.17.0.18-1597115442487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-f80f5fde-740f-402f-8893-d45fe26af2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-931047b5-9f2e-41b7-8bd8-c9095c63b083,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-dfca1a99-b817-4618-b85b-64d47ff14625,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-0eb75521-210f-49b4-b8b8-a8619b90300b,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-2c32230b-fbe5-4bcc-9a0b-e1d0529c3b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-2a404294-dfca-4a03-bd47-006dd54800a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-854bf3f1-39ae-4991-a823-cf690875887c,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-20655969-5313-4ac1-b6d0-2c3dad3aeffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579704379-172.17.0.18-1597115703155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45989,DS-5b71321b-2992-494b-8f25-40d480589f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-87afe063-aae9-426a-9d81-7d78a8cece37,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-6dfa1b7f-2710-4f83-ae51-f11926c9b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-d19fc63d-cde0-460b-91f2-155c7ed6e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-9e7f4064-ecbf-4617-9f4d-95f3574d32c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-98d18778-8f7e-48ab-9023-f0bb5ce4e68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-029148b8-6b8f-45c7-b9ed-628e625fedeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-9b841e78-2669-4464-8ce9-0544245b36a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579704379-172.17.0.18-1597115703155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45989,DS-5b71321b-2992-494b-8f25-40d480589f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-87afe063-aae9-426a-9d81-7d78a8cece37,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-6dfa1b7f-2710-4f83-ae51-f11926c9b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-d19fc63d-cde0-460b-91f2-155c7ed6e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-9e7f4064-ecbf-4617-9f4d-95f3574d32c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-98d18778-8f7e-48ab-9023-f0bb5ce4e68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-029148b8-6b8f-45c7-b9ed-628e625fedeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-9b841e78-2669-4464-8ce9-0544245b36a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5120
