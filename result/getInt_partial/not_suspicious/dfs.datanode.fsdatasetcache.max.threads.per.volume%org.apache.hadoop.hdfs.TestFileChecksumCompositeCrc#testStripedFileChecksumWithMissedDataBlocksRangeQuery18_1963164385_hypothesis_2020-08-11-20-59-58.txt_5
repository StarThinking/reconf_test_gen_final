reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134617908-172.17.0.19-1597179905070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-90f7d0da-cb92-459c-927b-e9f788ebea36,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-6f720fa7-d22e-45e8-9a85-8b41eae0dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-78329f6f-b608-4731-a837-cc06555e3926,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-6e142c94-cbc3-4569-9754-a02ef0230df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-ba6b8c68-f97f-4abf-a70c-732a83e986a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-b6651ce6-ae4b-4138-9b43-7a98989da67e,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-2d6669de-9ad0-460c-9523-6b724c6aa06c,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-58d51d55-a4c5-4f5b-93eb-579538cb22ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134617908-172.17.0.19-1597179905070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-90f7d0da-cb92-459c-927b-e9f788ebea36,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-6f720fa7-d22e-45e8-9a85-8b41eae0dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-78329f6f-b608-4731-a837-cc06555e3926,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-6e142c94-cbc3-4569-9754-a02ef0230df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-ba6b8c68-f97f-4abf-a70c-732a83e986a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-b6651ce6-ae4b-4138-9b43-7a98989da67e,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-2d6669de-9ad0-460c-9523-6b724c6aa06c,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-58d51d55-a4c5-4f5b-93eb-579538cb22ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102681536-172.17.0.19-1597180165297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-786cbd24-0b6b-419f-8313-d849c312e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-36c69fe6-73cf-4c90-95b8-dc8411e3ca66,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-b9862ea6-3ed4-4c34-8f8f-433411750fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-6ed6ee3c-a3d0-45e1-88ce-58ea4234b724,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-30bcadec-399e-4a7a-83eb-b96133b9b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-a4d7e8e6-f338-4731-96eb-74c89e832c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-4e4519bb-b7d5-4c1c-808d-862430172078,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-03d13a9d-42da-488e-90ed-2263d495610d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102681536-172.17.0.19-1597180165297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-786cbd24-0b6b-419f-8313-d849c312e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-36c69fe6-73cf-4c90-95b8-dc8411e3ca66,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-b9862ea6-3ed4-4c34-8f8f-433411750fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-6ed6ee3c-a3d0-45e1-88ce-58ea4234b724,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-30bcadec-399e-4a7a-83eb-b96133b9b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-a4d7e8e6-f338-4731-96eb-74c89e832c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-4e4519bb-b7d5-4c1c-808d-862430172078,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-03d13a9d-42da-488e-90ed-2263d495610d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132749179-172.17.0.19-1597180341444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37437,DS-164188f6-c121-4bf0-9396-bf9bc22730ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-add38a41-e65f-4a10-b844-003e38f504f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-f697dc88-17ef-4887-89fa-f1ce4cc78774,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-a934fe26-83b2-42b8-807e-5924929eea95,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-b2ac56b8-a0f0-4abf-b9d1-ac8c90dc4614,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-dfac8fdd-d225-4c41-80bf-06ce0060bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-a10ed2e3-95ee-4c79-b068-a1e595dc373a,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-5c3a2d2a-0651-4794-a5ef-baf64cd09a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132749179-172.17.0.19-1597180341444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37437,DS-164188f6-c121-4bf0-9396-bf9bc22730ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-add38a41-e65f-4a10-b844-003e38f504f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-f697dc88-17ef-4887-89fa-f1ce4cc78774,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-a934fe26-83b2-42b8-807e-5924929eea95,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-b2ac56b8-a0f0-4abf-b9d1-ac8c90dc4614,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-dfac8fdd-d225-4c41-80bf-06ce0060bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-a10ed2e3-95ee-4c79-b068-a1e595dc373a,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-5c3a2d2a-0651-4794-a5ef-baf64cd09a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359197592-172.17.0.19-1597180557719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-fe35a59e-835f-461b-8c03-b55620333fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-15c5d0fd-5f0c-4e0c-b1fe-b89e18c31af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-1206f02a-5bb4-4fb4-8050-456da85d7d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-9dd80bf8-7f8d-442e-93be-902f554764c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-ac23d84b-1fa0-4525-b808-d1e59c214b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-a54a5572-0e8e-4b29-9108-378c9a5bd171,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-8d3f2bea-4764-4b66-baa7-3f6efa44eec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-fea2902a-278c-4879-b683-46b790ff4884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359197592-172.17.0.19-1597180557719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-fe35a59e-835f-461b-8c03-b55620333fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-15c5d0fd-5f0c-4e0c-b1fe-b89e18c31af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-1206f02a-5bb4-4fb4-8050-456da85d7d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-9dd80bf8-7f8d-442e-93be-902f554764c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-ac23d84b-1fa0-4525-b808-d1e59c214b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-a54a5572-0e8e-4b29-9108-378c9a5bd171,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-8d3f2bea-4764-4b66-baa7-3f6efa44eec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-fea2902a-278c-4879-b683-46b790ff4884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463339332-172.17.0.19-1597180622690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-63a3b29b-a3f8-4de4-a952-1a9dadeda58f,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-bf4c2220-3c38-48bc-a155-804e56c9a881,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-eab703bc-e4bd-4f21-b02d-0db94b4c8bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-366c42aa-1a49-4a97-b234-beabfc9755ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-a7c08fee-4342-4334-97b7-80ae210bce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-3dc95250-413a-492f-b867-daa1af85d013,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-db6ee5f5-b9da-475d-b6f9-a29ca10621a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-6b584058-5bc3-4aa0-9b59-638a62a0075c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463339332-172.17.0.19-1597180622690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-63a3b29b-a3f8-4de4-a952-1a9dadeda58f,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-bf4c2220-3c38-48bc-a155-804e56c9a881,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-eab703bc-e4bd-4f21-b02d-0db94b4c8bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-366c42aa-1a49-4a97-b234-beabfc9755ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-a7c08fee-4342-4334-97b7-80ae210bce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-3dc95250-413a-492f-b867-daa1af85d013,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-db6ee5f5-b9da-475d-b6f9-a29ca10621a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-6b584058-5bc3-4aa0-9b59-638a62a0075c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761312175-172.17.0.19-1597181026389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-59c1aa57-26af-4dcb-9fc3-8b42b1dd9a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-813a3c07-0052-4cbc-b224-a1301f5f1ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-bb073170-2e4e-4455-8724-34f7bc94c0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-9f3475c4-0f7e-4b89-8bb2-7c44a53f2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-2389ceee-8114-4b91-9d32-ca0a5286ba0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-9b24d8e1-2242-4d46-a397-087e85080c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-825eed29-58ba-47aa-a744-9b386d402587,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-aca06582-72c6-4a05-b166-b96c0e0a5791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761312175-172.17.0.19-1597181026389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-59c1aa57-26af-4dcb-9fc3-8b42b1dd9a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-813a3c07-0052-4cbc-b224-a1301f5f1ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-bb073170-2e4e-4455-8724-34f7bc94c0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-9f3475c4-0f7e-4b89-8bb2-7c44a53f2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-2389ceee-8114-4b91-9d32-ca0a5286ba0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-9b24d8e1-2242-4d46-a397-087e85080c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-825eed29-58ba-47aa-a744-9b386d402587,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-aca06582-72c6-4a05-b166-b96c0e0a5791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127634480-172.17.0.19-1597182460685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33628,DS-ffb25fec-27ee-48df-bee3-80cb33421b29,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-9fd17d47-e708-4cd9-9a56-86d21b162adb,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-80903cf9-5ec5-44f2-bba4-2346a6902133,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-4fc874db-85b3-4868-8d1f-383f61edaa51,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-cc2aa2ef-d835-47d6-88d8-25cecae22c21,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-80289f02-bf0a-40d9-9366-db3ad7143386,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-87a73003-5eb1-4bc4-84e8-cd09183fb679,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-4c7559db-c5b3-42f8-891b-2a6d7eef166f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127634480-172.17.0.19-1597182460685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33628,DS-ffb25fec-27ee-48df-bee3-80cb33421b29,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-9fd17d47-e708-4cd9-9a56-86d21b162adb,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-80903cf9-5ec5-44f2-bba4-2346a6902133,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-4fc874db-85b3-4868-8d1f-383f61edaa51,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-cc2aa2ef-d835-47d6-88d8-25cecae22c21,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-80289f02-bf0a-40d9-9366-db3ad7143386,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-87a73003-5eb1-4bc4-84e8-cd09183fb679,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-4c7559db-c5b3-42f8-891b-2a6d7eef166f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274534481-172.17.0.19-1597182501144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33305,DS-789dd64a-271c-40ae-b441-845d19e71466,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-deb1d310-0c8c-4df2-a9ac-1c075df37df3,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-719e40bc-780c-4a5e-9a71-af8233b89dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-533a43be-4211-48b6-a545-1475da2af1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-ee1c4361-4533-4eea-afcc-966febee25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-03f3cc4d-69f4-429d-8224-2057ecfb3403,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-f7f2ebcb-5e48-4081-b03e-a28c79aa91b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-fb8a225d-935c-495b-8f75-8ac6c2100656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274534481-172.17.0.19-1597182501144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33305,DS-789dd64a-271c-40ae-b441-845d19e71466,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-deb1d310-0c8c-4df2-a9ac-1c075df37df3,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-719e40bc-780c-4a5e-9a71-af8233b89dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-533a43be-4211-48b6-a545-1475da2af1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-ee1c4361-4533-4eea-afcc-966febee25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-03f3cc4d-69f4-429d-8224-2057ecfb3403,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-f7f2ebcb-5e48-4081-b03e-a28c79aa91b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-fb8a225d-935c-495b-8f75-8ac6c2100656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052898588-172.17.0.19-1597183738020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-8eb12f7b-7815-4fb1-aa02-03c4005efc94,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-ba628ed0-703f-4d51-a2df-aa686e041d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-b56689ff-c141-419e-b8f2-e6efb8747dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-5f31e9b1-e5af-447b-8f10-85775e36ef11,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-d151c3f2-7a05-49ef-bf56-4fe96a9efb90,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-1d5462ad-0456-442c-93c2-1a8f7cbebb32,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-2299fa43-aa3f-4f69-89cf-0f514570e0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-7f36ddd0-a1ba-409c-8f00-2e4eacc0265d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052898588-172.17.0.19-1597183738020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-8eb12f7b-7815-4fb1-aa02-03c4005efc94,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-ba628ed0-703f-4d51-a2df-aa686e041d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-b56689ff-c141-419e-b8f2-e6efb8747dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-5f31e9b1-e5af-447b-8f10-85775e36ef11,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-d151c3f2-7a05-49ef-bf56-4fe96a9efb90,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-1d5462ad-0456-442c-93c2-1a8f7cbebb32,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-2299fa43-aa3f-4f69-89cf-0f514570e0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-7f36ddd0-a1ba-409c-8f00-2e4eacc0265d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364592700-172.17.0.19-1597184006462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-4148fbec-d4fe-435e-ab36-ae614a50ca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-a197b131-b837-4910-8ae0-40375e4b887e,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-3d1e9952-662a-4e9b-9c27-693188a36092,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-9a6e32a6-01c9-4f42-a4bd-3bcb6085a806,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-62f6e17d-a454-4ccb-b2c5-7628f1c81258,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-148a9dad-6ff1-4887-aa07-cd851fc2a50d,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-611cde5d-a533-40ce-946a-f2ea40f83ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-8d3a6edc-2a4c-4003-b138-376db8e3f324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364592700-172.17.0.19-1597184006462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-4148fbec-d4fe-435e-ab36-ae614a50ca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-a197b131-b837-4910-8ae0-40375e4b887e,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-3d1e9952-662a-4e9b-9c27-693188a36092,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-9a6e32a6-01c9-4f42-a4bd-3bcb6085a806,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-62f6e17d-a454-4ccb-b2c5-7628f1c81258,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-148a9dad-6ff1-4887-aa07-cd851fc2a50d,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-611cde5d-a533-40ce-946a-f2ea40f83ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-8d3a6edc-2a4c-4003-b138-376db8e3f324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341043898-172.17.0.19-1597184858690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-bac4b88c-d0f8-4007-bb80-f85b11ae6f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-c5022348-6a65-4642-b421-8e869d37d236,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-3547738e-5ca9-48fe-a903-546088dd913b,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-bf9dfcd5-22ef-459a-b84f-6e377a2b1977,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-c385da2b-f0fc-45b7-83d5-abd02acd2cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-1ba8146c-5fc6-4f98-a1d9-83fa729e9bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-914626e9-5c10-4fcc-93db-5c68ee08a0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-efa91613-ba68-4e1b-b3f1-558aba8fdd92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341043898-172.17.0.19-1597184858690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-bac4b88c-d0f8-4007-bb80-f85b11ae6f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-c5022348-6a65-4642-b421-8e869d37d236,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-3547738e-5ca9-48fe-a903-546088dd913b,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-bf9dfcd5-22ef-459a-b84f-6e377a2b1977,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-c385da2b-f0fc-45b7-83d5-abd02acd2cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-1ba8146c-5fc6-4f98-a1d9-83fa729e9bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-914626e9-5c10-4fcc-93db-5c68ee08a0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-efa91613-ba68-4e1b-b3f1-558aba8fdd92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5317
