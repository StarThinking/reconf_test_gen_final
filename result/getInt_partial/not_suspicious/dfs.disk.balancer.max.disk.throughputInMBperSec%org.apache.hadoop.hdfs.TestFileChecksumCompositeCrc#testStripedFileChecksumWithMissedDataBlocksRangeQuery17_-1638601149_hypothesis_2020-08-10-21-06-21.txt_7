reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336328882-172.17.0.9-1597093885699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34055,DS-2a58a550-6f0b-460b-86de-aeb5e193f7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-fd2fe7ad-c49f-4b26-9d6f-5deed238adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-6783dee4-131f-49a3-a262-eab55580f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-9d054802-1de1-4d7c-8c6b-33e765a9c627,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-13baae3b-1cb1-4d75-82c4-9e112c7f98ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-ed2e287b-11e5-44a1-9d99-e751e8bbf520,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-044c6976-ac99-47a0-86a1-c305e8f3dc63,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-cac3ba45-a7d8-4cc8-9958-3b964562bb9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336328882-172.17.0.9-1597093885699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34055,DS-2a58a550-6f0b-460b-86de-aeb5e193f7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-fd2fe7ad-c49f-4b26-9d6f-5deed238adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-6783dee4-131f-49a3-a262-eab55580f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-9d054802-1de1-4d7c-8c6b-33e765a9c627,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-13baae3b-1cb1-4d75-82c4-9e112c7f98ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-ed2e287b-11e5-44a1-9d99-e751e8bbf520,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-044c6976-ac99-47a0-86a1-c305e8f3dc63,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-cac3ba45-a7d8-4cc8-9958-3b964562bb9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085262571-172.17.0.9-1597094256590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-cf810189-1a88-4bfa-bc03-74a25b91fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-df92f141-6da0-4707-9df3-db0717c2a8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-18e55224-7020-49c5-8504-cf9fb9dc618e,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-8fe1fc52-9329-4fcb-b90d-0e8ed9302808,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-b7317e90-8654-493b-9836-52b4bd5caf16,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-019aad32-01a8-4875-94b2-c98c2d2f2ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-f2f3799c-1e32-4f67-b6be-21d7e89d4391,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-c3073943-949f-414f-8acb-d73e4f8e05e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085262571-172.17.0.9-1597094256590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-cf810189-1a88-4bfa-bc03-74a25b91fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-df92f141-6da0-4707-9df3-db0717c2a8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-18e55224-7020-49c5-8504-cf9fb9dc618e,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-8fe1fc52-9329-4fcb-b90d-0e8ed9302808,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-b7317e90-8654-493b-9836-52b4bd5caf16,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-019aad32-01a8-4875-94b2-c98c2d2f2ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-f2f3799c-1e32-4f67-b6be-21d7e89d4391,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-c3073943-949f-414f-8acb-d73e4f8e05e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458501740-172.17.0.9-1597094437130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34382,DS-d1cdc0eb-99be-4c5f-a2e0-6b27b5de6714,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-2934e683-082a-4bdb-96a0-80e22f882648,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-28741856-23a5-4b83-9a7c-a88326e5b40c,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-31bf3cae-d50d-4be2-830a-bf32266b019b,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-f587bcf8-37f9-46a9-98bd-280f1bf194a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-eee54ee3-4302-44c1-8c09-a41300b05fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-40ac5b67-1182-4fac-9c7c-013eb58fa596,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-e64442d9-e538-4657-bde2-e154b6169606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458501740-172.17.0.9-1597094437130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34382,DS-d1cdc0eb-99be-4c5f-a2e0-6b27b5de6714,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-2934e683-082a-4bdb-96a0-80e22f882648,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-28741856-23a5-4b83-9a7c-a88326e5b40c,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-31bf3cae-d50d-4be2-830a-bf32266b019b,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-f587bcf8-37f9-46a9-98bd-280f1bf194a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-eee54ee3-4302-44c1-8c09-a41300b05fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-40ac5b67-1182-4fac-9c7c-013eb58fa596,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-e64442d9-e538-4657-bde2-e154b6169606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515421631-172.17.0.9-1597094537273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35878,DS-f82b8b37-3e0c-4345-9529-980f8229b834,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-6f311069-bfe9-4325-83e6-530562ecf49f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-d4ad497f-86e6-41f4-9393-4465998d4679,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-29c860a6-a360-421d-976b-2be1a629d8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-9fe770ea-37ed-4df9-9af5-8659140eafae,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-87bd9477-00cc-4fc9-96a3-3a8b7e158449,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-333575da-5536-42bc-b6d9-adaf18d1975f,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-9bcff08e-83df-42fd-99a9-b46560ed6f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515421631-172.17.0.9-1597094537273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35878,DS-f82b8b37-3e0c-4345-9529-980f8229b834,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-6f311069-bfe9-4325-83e6-530562ecf49f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-d4ad497f-86e6-41f4-9393-4465998d4679,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-29c860a6-a360-421d-976b-2be1a629d8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-9fe770ea-37ed-4df9-9af5-8659140eafae,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-87bd9477-00cc-4fc9-96a3-3a8b7e158449,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-333575da-5536-42bc-b6d9-adaf18d1975f,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-9bcff08e-83df-42fd-99a9-b46560ed6f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055950963-172.17.0.9-1597094645890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37817,DS-a8b6d2bc-2398-4707-a464-d820c7a48d45,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-66d6f24a-cd93-4950-be70-124ade9d202a,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-80c832e7-93e1-4619-a538-de8b3f7e0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-efb05cd1-ac42-428d-8470-a70409ce8506,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-9e374b2f-73fa-4a05-aa64-a9f023f504c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-b4677e90-de7a-4830-89a7-b6e105aec87b,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-76b45f1c-e601-41c4-90b8-d0492d3b7274,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-1388e910-cbab-4007-ba7f-4be7e5e95104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055950963-172.17.0.9-1597094645890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37817,DS-a8b6d2bc-2398-4707-a464-d820c7a48d45,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-66d6f24a-cd93-4950-be70-124ade9d202a,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-80c832e7-93e1-4619-a538-de8b3f7e0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-efb05cd1-ac42-428d-8470-a70409ce8506,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-9e374b2f-73fa-4a05-aa64-a9f023f504c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-b4677e90-de7a-4830-89a7-b6e105aec87b,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-76b45f1c-e601-41c4-90b8-d0492d3b7274,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-1388e910-cbab-4007-ba7f-4be7e5e95104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813002106-172.17.0.9-1597094682036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-b4b489d2-0fb5-4d4e-8735-82e8294c1bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-f50d5390-7fb2-40e8-8db9-c9234c800fee,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-758c38ca-d179-43bc-935a-df7f57cf433f,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-7c51d277-15ae-49b9-be6b-18d8adcc09b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-7c2f1ae5-2715-4496-b319-d267d16af719,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-7fdc01d9-9f8a-481a-ae20-a9bc863693f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-463797a7-cbe1-406b-8ac7-0a4f26eb6ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-9540a2dc-3875-4ddb-84d2-818c09731b48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813002106-172.17.0.9-1597094682036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-b4b489d2-0fb5-4d4e-8735-82e8294c1bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-f50d5390-7fb2-40e8-8db9-c9234c800fee,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-758c38ca-d179-43bc-935a-df7f57cf433f,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-7c51d277-15ae-49b9-be6b-18d8adcc09b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-7c2f1ae5-2715-4496-b319-d267d16af719,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-7fdc01d9-9f8a-481a-ae20-a9bc863693f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-463797a7-cbe1-406b-8ac7-0a4f26eb6ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-9540a2dc-3875-4ddb-84d2-818c09731b48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645673581-172.17.0.9-1597094810955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34221,DS-51a83ee2-b719-4897-86a3-d1febb4c344f,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-1eb43fad-0a33-4d50-aba9-9d0f39b412d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-53da4a59-63b4-4844-a143-0e7d5396d084,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-e729f7ac-af63-499e-9a42-11b186a5cf29,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-3f203b1e-7dae-4f16-b9d7-438cee6d1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-141ec13d-425b-4cf3-83eb-142b3d0b370c,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-d9dff61c-dd73-44a2-9b88-5f6a15a9dfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-3a707269-0c48-4b92-aef1-0fdcf4cacaf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645673581-172.17.0.9-1597094810955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34221,DS-51a83ee2-b719-4897-86a3-d1febb4c344f,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-1eb43fad-0a33-4d50-aba9-9d0f39b412d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-53da4a59-63b4-4844-a143-0e7d5396d084,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-e729f7ac-af63-499e-9a42-11b186a5cf29,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-3f203b1e-7dae-4f16-b9d7-438cee6d1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-141ec13d-425b-4cf3-83eb-142b3d0b370c,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-d9dff61c-dd73-44a2-9b88-5f6a15a9dfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-3a707269-0c48-4b92-aef1-0fdcf4cacaf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319957058-172.17.0.9-1597094842385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-3cc47825-7c82-4807-9713-a5555451a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-72aa081f-334f-425c-803d-874910929cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-6c77688d-7eca-4d25-b160-c00f13cf2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-5007c799-095f-4f5b-928e-cdecb37f2258,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-a4627380-f1b0-417a-9834-ee49eda9598a,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-512c8fad-23a7-4799-bdb5-3746938e3b71,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-c5106f78-5e66-437c-b009-29051aef4bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-e9e4d98c-6f05-4bc1-9735-fef1432b73bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319957058-172.17.0.9-1597094842385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-3cc47825-7c82-4807-9713-a5555451a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-72aa081f-334f-425c-803d-874910929cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-6c77688d-7eca-4d25-b160-c00f13cf2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-5007c799-095f-4f5b-928e-cdecb37f2258,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-a4627380-f1b0-417a-9834-ee49eda9598a,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-512c8fad-23a7-4799-bdb5-3746938e3b71,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-c5106f78-5e66-437c-b009-29051aef4bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-e9e4d98c-6f05-4bc1-9735-fef1432b73bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713800858-172.17.0.9-1597094947039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45157,DS-5df19a76-594b-4482-8122-10d4c9da7799,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-57faf23f-c9b0-4f8e-beeb-aa3a971f6b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-c9645a45-757d-429e-87b5-4c6b76ae9430,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-c90b1610-12f2-4d61-bab9-aa9c55edeff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-b2c07d7e-3066-4e70-ae50-b3f552eee9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ec83ce53-981b-459e-a5ee-35dc47970a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-735a92cb-f71e-4649-b27e-d5adb5684209,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-c12d4b37-3c25-4014-a8b8-ff1b23527d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713800858-172.17.0.9-1597094947039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45157,DS-5df19a76-594b-4482-8122-10d4c9da7799,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-57faf23f-c9b0-4f8e-beeb-aa3a971f6b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-c9645a45-757d-429e-87b5-4c6b76ae9430,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-c90b1610-12f2-4d61-bab9-aa9c55edeff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-b2c07d7e-3066-4e70-ae50-b3f552eee9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ec83ce53-981b-459e-a5ee-35dc47970a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-735a92cb-f71e-4649-b27e-d5adb5684209,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-c12d4b37-3c25-4014-a8b8-ff1b23527d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602830861-172.17.0.9-1597095492135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44874,DS-c745b0a5-c9c0-4290-86b6-f6080f11d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-41f9f1df-d5bc-4721-a7d3-1aeebf5e63b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-0075d6b6-e0d6-4944-b0a6-b7dbf467a03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-08a2746a-3167-46a5-bb91-3a7e6b647161,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-df199814-865e-44b2-bfa9-d044a7498d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c49f0ee0-d2e1-4160-a480-ec44dd9af85b,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-725cc504-e387-4ecb-9056-4deff695c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-f240603f-45b6-42ce-91c4-bf04bc4916e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602830861-172.17.0.9-1597095492135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44874,DS-c745b0a5-c9c0-4290-86b6-f6080f11d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-41f9f1df-d5bc-4721-a7d3-1aeebf5e63b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-0075d6b6-e0d6-4944-b0a6-b7dbf467a03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-08a2746a-3167-46a5-bb91-3a7e6b647161,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-df199814-865e-44b2-bfa9-d044a7498d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c49f0ee0-d2e1-4160-a480-ec44dd9af85b,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-725cc504-e387-4ecb-9056-4deff695c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-f240603f-45b6-42ce-91c4-bf04bc4916e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817846157-172.17.0.9-1597095617495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39143,DS-a3db67a2-4934-4a42-8dbb-b4407c83e5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-bc2888ce-a4fe-467f-80bd-17d51c4630ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-228f126c-4fa0-4319-bb86-1ad64bfe47ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-2b69f8bc-1f15-43d2-818c-c54961953377,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-a5b706ed-fa19-4dfe-a072-d62a119db119,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-ad6b1d39-a2e5-4124-8452-59508fed53dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-3339c79f-b78a-40e0-8160-405008f968e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-1f328d29-39ad-4ee8-afcc-fb5e75b52788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817846157-172.17.0.9-1597095617495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39143,DS-a3db67a2-4934-4a42-8dbb-b4407c83e5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-bc2888ce-a4fe-467f-80bd-17d51c4630ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-228f126c-4fa0-4319-bb86-1ad64bfe47ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-2b69f8bc-1f15-43d2-818c-c54961953377,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-a5b706ed-fa19-4dfe-a072-d62a119db119,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-ad6b1d39-a2e5-4124-8452-59508fed53dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-3339c79f-b78a-40e0-8160-405008f968e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-1f328d29-39ad-4ee8-afcc-fb5e75b52788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467928797-172.17.0.9-1597095715806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37920,DS-0359c774-a86e-414f-8e3c-f56031497e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-b86cad13-91a9-4984-afd8-fd4c1534266d,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-1dee4de9-f5c1-4bb3-b682-656f8981af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-6ae7fc62-1009-4c9a-8619-e481841a7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-f59b88cd-b673-4f94-89ff-4bccb4c8ea88,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-5dacdb5d-4ac0-4b8b-be5a-960cd1bb1f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-57af4cb6-c7a0-4663-afe4-8f43290d0242,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-dcf47424-8a9e-4ba5-8244-64bdeb4d7670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467928797-172.17.0.9-1597095715806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37920,DS-0359c774-a86e-414f-8e3c-f56031497e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-b86cad13-91a9-4984-afd8-fd4c1534266d,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-1dee4de9-f5c1-4bb3-b682-656f8981af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-6ae7fc62-1009-4c9a-8619-e481841a7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-f59b88cd-b673-4f94-89ff-4bccb4c8ea88,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-5dacdb5d-4ac0-4b8b-be5a-960cd1bb1f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-57af4cb6-c7a0-4663-afe4-8f43290d0242,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-dcf47424-8a9e-4ba5-8244-64bdeb4d7670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843597896-172.17.0.9-1597095889822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44245,DS-c45d964d-8702-4c23-8818-80e5ae488b42,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-4ccf843d-6771-4a06-b1a8-2c307a7f89eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-cc4f1a91-e46a-4951-a21f-67d6c763a150,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-51917fc8-f54c-4280-ac51-8b5a52a8d15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-99792a28-b99f-4559-9547-e43f4267ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-3103b4f3-9e4b-4861-a018-4e8440cd6331,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-e1d77ab3-bbca-4be8-99c4-c517a2df4de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-00ac36ae-f6f1-4ae8-982b-c339d7f38dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843597896-172.17.0.9-1597095889822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44245,DS-c45d964d-8702-4c23-8818-80e5ae488b42,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-4ccf843d-6771-4a06-b1a8-2c307a7f89eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-cc4f1a91-e46a-4951-a21f-67d6c763a150,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-51917fc8-f54c-4280-ac51-8b5a52a8d15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-99792a28-b99f-4559-9547-e43f4267ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-3103b4f3-9e4b-4861-a018-4e8440cd6331,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-e1d77ab3-bbca-4be8-99c4-c517a2df4de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-00ac36ae-f6f1-4ae8-982b-c339d7f38dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043191362-172.17.0.9-1597096565947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-987eadbe-9b4b-4768-8dc8-b21a3ef11b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-d748a108-9ad3-4e6a-bc5a-3b5c0b9628dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-fa1f2085-1ec7-473b-8f37-ba8cfc6213af,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-7ef84f19-7e82-4901-b2de-e3ac43a33e03,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-ccf8b582-64e8-4710-9ab0-6825721ad43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-91063a63-0e8e-411e-a38b-a2ebc6c02aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-548826b3-27dc-4fba-9483-b75724c112a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-e014703a-d2d1-4ab5-9e1c-0091e626bb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043191362-172.17.0.9-1597096565947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-987eadbe-9b4b-4768-8dc8-b21a3ef11b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-d748a108-9ad3-4e6a-bc5a-3b5c0b9628dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-fa1f2085-1ec7-473b-8f37-ba8cfc6213af,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-7ef84f19-7e82-4901-b2de-e3ac43a33e03,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-ccf8b582-64e8-4710-9ab0-6825721ad43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-91063a63-0e8e-411e-a38b-a2ebc6c02aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-548826b3-27dc-4fba-9483-b75724c112a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-e014703a-d2d1-4ab5-9e1c-0091e626bb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908556433-172.17.0.9-1597096607521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42539,DS-e3a63b1a-49db-4bcc-a094-b46e526f5e85,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-cfd77f98-4a8e-41ae-9522-08011744d653,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-3330fc07-bfdc-4cc1-8d56-34cbc897b7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-167b7b79-4047-49ac-9202-5539a3b017d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-2ec504e6-4cbf-4db0-a906-a40b5c4b843c,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-60c4bfbf-3bc2-4f6b-b726-8b12b654c317,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-dd021b79-2ce5-42a9-9a62-31c50944fe49,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-ebd05775-ded7-4da0-b965-9446abfc0107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908556433-172.17.0.9-1597096607521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42539,DS-e3a63b1a-49db-4bcc-a094-b46e526f5e85,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-cfd77f98-4a8e-41ae-9522-08011744d653,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-3330fc07-bfdc-4cc1-8d56-34cbc897b7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-167b7b79-4047-49ac-9202-5539a3b017d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-2ec504e6-4cbf-4db0-a906-a40b5c4b843c,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-60c4bfbf-3bc2-4f6b-b726-8b12b654c317,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-dd021b79-2ce5-42a9-9a62-31c50944fe49,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-ebd05775-ded7-4da0-b965-9446abfc0107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765923456-172.17.0.9-1597096757630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39018,DS-6ac29cdc-4c68-459d-a715-05c689fc6293,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-9d6ab36f-990f-4cf5-817a-b24755196df5,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-60f84599-e2cc-43a8-952b-c653b503de31,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-e8f792c6-8c69-4c95-90a5-fface4d908b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-a38fa701-69a5-48c5-991b-4b79b24aff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-9d9cff8e-e1b1-45dd-b4e1-d6349d24864b,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-6afa3512-c05a-4257-b5ff-eb0287ecb75a,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-af50045d-4362-47d0-b1c4-5574fc3ce734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765923456-172.17.0.9-1597096757630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39018,DS-6ac29cdc-4c68-459d-a715-05c689fc6293,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-9d6ab36f-990f-4cf5-817a-b24755196df5,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-60f84599-e2cc-43a8-952b-c653b503de31,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-e8f792c6-8c69-4c95-90a5-fface4d908b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-a38fa701-69a5-48c5-991b-4b79b24aff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-9d9cff8e-e1b1-45dd-b4e1-d6349d24864b,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-6afa3512-c05a-4257-b5ff-eb0287ecb75a,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-af50045d-4362-47d0-b1c4-5574fc3ce734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391457703-172.17.0.9-1597096823610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-a15de108-5052-4ee6-aec1-eb56368bc5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-562c032a-9555-4c97-a096-92745542ba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-09065172-a292-4ec2-a259-9f2b026a85a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-410a852e-1b27-4861-8a28-c5409a8b8d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-71c85c57-f3f7-40ba-bc06-0e90a335dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-c1cf5f61-6782-4d0f-a319-d0d33a538862,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-0fb17ad5-2734-43d2-8159-c3e993624dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0468c367-f0ef-4034-bfec-8e42cdf4b7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391457703-172.17.0.9-1597096823610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-a15de108-5052-4ee6-aec1-eb56368bc5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-562c032a-9555-4c97-a096-92745542ba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-09065172-a292-4ec2-a259-9f2b026a85a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-410a852e-1b27-4861-8a28-c5409a8b8d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-71c85c57-f3f7-40ba-bc06-0e90a335dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-c1cf5f61-6782-4d0f-a319-d0d33a538862,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-0fb17ad5-2734-43d2-8159-c3e993624dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0468c367-f0ef-4034-bfec-8e42cdf4b7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794454256-172.17.0.9-1597097137293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37498,DS-a6dff063-4cc2-43b0-b555-fc10faf3b357,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-58b1cb74-9ec0-46a1-bf00-e80c23a4a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-cd4cc868-0caf-4212-8ab9-b28c66ccefe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-2acc708b-89ac-4b99-a576-b69927ba45ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-109a7cfd-1245-49aa-a4cc-b8ae9beaffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-19212913-3dba-40dd-bbc2-8b93efa21a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-6a48ad5e-2bf4-40f7-a79e-bd28e8129806,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-a7b57330-312a-4da1-97da-4717d07ab1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794454256-172.17.0.9-1597097137293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37498,DS-a6dff063-4cc2-43b0-b555-fc10faf3b357,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-58b1cb74-9ec0-46a1-bf00-e80c23a4a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-cd4cc868-0caf-4212-8ab9-b28c66ccefe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-2acc708b-89ac-4b99-a576-b69927ba45ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-109a7cfd-1245-49aa-a4cc-b8ae9beaffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-19212913-3dba-40dd-bbc2-8b93efa21a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-6a48ad5e-2bf4-40f7-a79e-bd28e8129806,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-a7b57330-312a-4da1-97da-4717d07ab1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634904876-172.17.0.9-1597097242955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-69e510b4-d842-4f24-989b-f16030be0ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-c615d59c-d694-4ce1-828d-1997cec25305,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-b4b184b8-4a4d-4e76-b446-e43c7e9e0a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-5cc248e8-b730-4ceb-bc81-91f5fc81cf52,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-a7bd1d6e-89c7-4455-84d5-2d5dc51a1810,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-016eeceb-70ba-4088-ad4a-770322cc344a,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-ea5e1382-d012-4326-94dd-5aaa8e8a526c,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-981809b3-c198-4b31-9f5b-4c1debb8c3ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634904876-172.17.0.9-1597097242955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-69e510b4-d842-4f24-989b-f16030be0ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-c615d59c-d694-4ce1-828d-1997cec25305,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-b4b184b8-4a4d-4e76-b446-e43c7e9e0a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-5cc248e8-b730-4ceb-bc81-91f5fc81cf52,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-a7bd1d6e-89c7-4455-84d5-2d5dc51a1810,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-016eeceb-70ba-4088-ad4a-770322cc344a,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-ea5e1382-d012-4326-94dd-5aaa8e8a526c,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-981809b3-c198-4b31-9f5b-4c1debb8c3ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257327501-172.17.0.9-1597097718899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42672,DS-427ef1c1-e7fb-448a-bb29-f229c9e71a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-1b08d58c-1977-4a03-bea1-7561c472a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-e135f203-a907-4c16-9477-2345f81f034f,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-2cf3edbf-25f1-452d-810b-946624741959,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-5fc0ea2f-4a0c-4c1b-bf25-44efc708aad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-3c5b15da-8dfe-4edc-ab72-0f3780ade3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-fbd4c3cb-e30a-48ba-9d63-fa0d913e2905,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-883bbd6f-4722-41c5-a5d4-c5cd0b60700d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257327501-172.17.0.9-1597097718899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42672,DS-427ef1c1-e7fb-448a-bb29-f229c9e71a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-1b08d58c-1977-4a03-bea1-7561c472a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-e135f203-a907-4c16-9477-2345f81f034f,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-2cf3edbf-25f1-452d-810b-946624741959,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-5fc0ea2f-4a0c-4c1b-bf25-44efc708aad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-3c5b15da-8dfe-4edc-ab72-0f3780ade3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-fbd4c3cb-e30a-48ba-9d63-fa0d913e2905,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-883bbd6f-4722-41c5-a5d4-c5cd0b60700d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717634065-172.17.0.9-1597098386090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-b3f213ee-bbe1-40c7-b7ad-b54e400a570f,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-ef5e86b4-2a79-49be-be52-99c4084126fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-cccb7743-42f7-41e6-bb4d-a9ac1bc77d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-67171f2b-2131-48eb-a535-74841795c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-d6bb532c-252f-449c-beb7-f7547cad7d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-e1a01e34-d538-426b-9f1d-f2dac1b4614e,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-0d489cd5-8e60-4422-a453-a1c57f5d97b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-ac8b4a1d-dc44-47c7-af80-1a39c626e786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717634065-172.17.0.9-1597098386090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-b3f213ee-bbe1-40c7-b7ad-b54e400a570f,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-ef5e86b4-2a79-49be-be52-99c4084126fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-cccb7743-42f7-41e6-bb4d-a9ac1bc77d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-67171f2b-2131-48eb-a535-74841795c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-d6bb532c-252f-449c-beb7-f7547cad7d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-e1a01e34-d538-426b-9f1d-f2dac1b4614e,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-0d489cd5-8e60-4422-a453-a1c57f5d97b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-ac8b4a1d-dc44-47c7-af80-1a39c626e786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698790011-172.17.0.9-1597098416728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-749748ce-6278-404b-9d94-7ceae89c7b40,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-dd770737-07c8-439e-8c69-7ee6566432f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-d22e1de7-4a80-461c-b7c4-d4144d580890,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-0766da13-9508-4d87-93a3-b3dcd8a86964,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-193a1ac6-569a-408e-bf0f-ca1c6e5ba485,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-bb14078e-5ddb-4d20-ae3a-057694254cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-5887ba49-f0a0-4b61-83a9-d5ef0139816c,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-eb1a5c27-01b4-48a8-812f-68439711e33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698790011-172.17.0.9-1597098416728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-749748ce-6278-404b-9d94-7ceae89c7b40,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-dd770737-07c8-439e-8c69-7ee6566432f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-d22e1de7-4a80-461c-b7c4-d4144d580890,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-0766da13-9508-4d87-93a3-b3dcd8a86964,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-193a1ac6-569a-408e-bf0f-ca1c6e5ba485,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-bb14078e-5ddb-4d20-ae3a-057694254cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-5887ba49-f0a0-4b61-83a9-d5ef0139816c,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-eb1a5c27-01b4-48a8-812f-68439711e33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411308738-172.17.0.9-1597098524448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-f46722c5-6d3e-439f-9d3d-115322619e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-219395b7-9cd1-4acc-8714-c5dd2089ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-57a66635-5733-43aa-bea1-e6fdab47de42,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-5869f308-3014-498c-b481-efaefb606a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-5b01e421-908f-4c23-82dd-de229ef9f28c,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-eb2a44c0-961e-46f7-943b-59f9eb5c639c,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-06e63142-5cf4-4488-a80c-2dc0214b94bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-70907e56-33ba-4831-b86f-a8ce7aafba5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411308738-172.17.0.9-1597098524448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-f46722c5-6d3e-439f-9d3d-115322619e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-219395b7-9cd1-4acc-8714-c5dd2089ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-57a66635-5733-43aa-bea1-e6fdab47de42,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-5869f308-3014-498c-b481-efaefb606a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-5b01e421-908f-4c23-82dd-de229ef9f28c,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-eb2a44c0-961e-46f7-943b-59f9eb5c639c,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-06e63142-5cf4-4488-a80c-2dc0214b94bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-70907e56-33ba-4831-b86f-a8ce7aafba5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5185
