reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035073365-172.17.0.4-1597046394374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-6c560fb9-4f45-493a-9cb9-0a270725526d,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-b8e38b4a-0ac0-42d1-965c-83beccf1d0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-2a621dec-74eb-43c0-8994-926c3316563e,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-f40b7bc2-e01c-4617-aa2c-f74c0482ae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-a70774c4-05ca-429e-bbf2-99bcd1acb163,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-6d2db0c5-6c73-4d7c-9c15-f574c81395b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-7706bdbf-2ee4-49db-878a-63f722f0dac8,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-0bb593df-6306-4b21-bbfd-74f8b1eaca0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035073365-172.17.0.4-1597046394374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-6c560fb9-4f45-493a-9cb9-0a270725526d,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-b8e38b4a-0ac0-42d1-965c-83beccf1d0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-2a621dec-74eb-43c0-8994-926c3316563e,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-f40b7bc2-e01c-4617-aa2c-f74c0482ae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-a70774c4-05ca-429e-bbf2-99bcd1acb163,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-6d2db0c5-6c73-4d7c-9c15-f574c81395b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-7706bdbf-2ee4-49db-878a-63f722f0dac8,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-0bb593df-6306-4b21-bbfd-74f8b1eaca0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110210260-172.17.0.4-1597046623601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35550,DS-aa035f48-8d83-4fa1-bb0d-bbbcd6f8674c,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-1df559e3-6a91-42de-abe6-75e0d994e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-bde73be5-bdd4-476e-9397-96e3df036277,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-6ae0b77b-d49e-47a2-9977-64dca2ee2364,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-92eff35f-f103-4c3a-96ca-95c8fbe5f372,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-a8efaa78-9e84-4c29-8c0d-469f0475f288,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-d1636ab3-6cd0-47ba-aea4-1fd4986fb408,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-93377a16-8f51-4617-868a-d22e965b0981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110210260-172.17.0.4-1597046623601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35550,DS-aa035f48-8d83-4fa1-bb0d-bbbcd6f8674c,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-1df559e3-6a91-42de-abe6-75e0d994e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-bde73be5-bdd4-476e-9397-96e3df036277,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-6ae0b77b-d49e-47a2-9977-64dca2ee2364,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-92eff35f-f103-4c3a-96ca-95c8fbe5f372,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-a8efaa78-9e84-4c29-8c0d-469f0475f288,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-d1636ab3-6cd0-47ba-aea4-1fd4986fb408,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-93377a16-8f51-4617-868a-d22e965b0981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775569562-172.17.0.4-1597046834194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37262,DS-1bc426af-db97-4b1e-bf52-66b2db058478,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-b639fb25-d301-4cff-86ca-7cfa93ffecaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-985c51a5-b14e-43e7-9a23-77012aaa679f,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-2a1e74a7-be6f-4d09-b4a3-e97a8b5e4794,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-e364944a-2f10-4121-9a5d-bfc077eff2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-0846680b-94f4-44ea-9f4e-a92287c9c7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-993c02bb-3467-4d0c-8c96-20af74794856,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-de3e492b-4228-42fc-9448-36e4afcfa881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775569562-172.17.0.4-1597046834194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37262,DS-1bc426af-db97-4b1e-bf52-66b2db058478,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-b639fb25-d301-4cff-86ca-7cfa93ffecaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-985c51a5-b14e-43e7-9a23-77012aaa679f,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-2a1e74a7-be6f-4d09-b4a3-e97a8b5e4794,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-e364944a-2f10-4121-9a5d-bfc077eff2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-0846680b-94f4-44ea-9f4e-a92287c9c7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-993c02bb-3467-4d0c-8c96-20af74794856,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-de3e492b-4228-42fc-9448-36e4afcfa881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324056545-172.17.0.4-1597047188648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40894,DS-caac14bf-541c-4040-be74-9f51be530e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-39a04bd9-b3ba-4942-b6ee-202fd352f9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-26b5b11a-2e26-43a5-be5c-4f36d71f914c,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-cbae4db9-f4bc-4ea4-ac2c-92c1716a1d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-b1356d03-7e3d-46c8-b2c7-6cf00864cd65,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-38c20f20-31d9-4ab5-b579-04de1a2340d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-81685739-556c-4ac9-8c16-3ef524ca8a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-2db5baed-5ba5-43c2-aa98-2b8410d33ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324056545-172.17.0.4-1597047188648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40894,DS-caac14bf-541c-4040-be74-9f51be530e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-39a04bd9-b3ba-4942-b6ee-202fd352f9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-26b5b11a-2e26-43a5-be5c-4f36d71f914c,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-cbae4db9-f4bc-4ea4-ac2c-92c1716a1d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-b1356d03-7e3d-46c8-b2c7-6cf00864cd65,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-38c20f20-31d9-4ab5-b579-04de1a2340d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-81685739-556c-4ac9-8c16-3ef524ca8a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-2db5baed-5ba5-43c2-aa98-2b8410d33ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101823608-172.17.0.4-1597047440733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-37b29165-27d5-4ea8-9113-dd0e892d5e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-0fbc5aef-1dc8-4bc8-b24d-9a81147a85ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-6eda995e-cc37-422f-9e57-dd70fe684c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-b343bd7e-9064-4418-9af5-dec1cf22ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-112bd3c2-bd98-4452-9474-d664f4944302,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-64e5c6fc-a0af-4ed0-9b7d-8a1cd7368a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-752002d1-fe6f-48b7-afa6-d65321fd60f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-bac18f5e-6138-40ff-9676-6cd6afaf1c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101823608-172.17.0.4-1597047440733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-37b29165-27d5-4ea8-9113-dd0e892d5e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-0fbc5aef-1dc8-4bc8-b24d-9a81147a85ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-6eda995e-cc37-422f-9e57-dd70fe684c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-b343bd7e-9064-4418-9af5-dec1cf22ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-112bd3c2-bd98-4452-9474-d664f4944302,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-64e5c6fc-a0af-4ed0-9b7d-8a1cd7368a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-752002d1-fe6f-48b7-afa6-d65321fd60f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-bac18f5e-6138-40ff-9676-6cd6afaf1c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238785946-172.17.0.4-1597048022161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-a80dc0b7-3f66-4bd5-8c3d-d6489796a464,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-5e36a501-2f81-4bad-9e25-c73be63ec81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-4dab9a9d-14ce-48c3-85ec-8d98f9ca7db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-0340501c-7b1f-486b-9578-c18f362f9033,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-12dcba43-ec0c-4b6b-b1b4-8e9294157012,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-0ae207ea-7171-416b-af09-d5303bc00054,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-a94c6a0a-640d-44d1-9b43-d8473e7880ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-5bfc6669-df24-4cc4-a657-7c6a4af15bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238785946-172.17.0.4-1597048022161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-a80dc0b7-3f66-4bd5-8c3d-d6489796a464,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-5e36a501-2f81-4bad-9e25-c73be63ec81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-4dab9a9d-14ce-48c3-85ec-8d98f9ca7db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-0340501c-7b1f-486b-9578-c18f362f9033,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-12dcba43-ec0c-4b6b-b1b4-8e9294157012,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-0ae207ea-7171-416b-af09-d5303bc00054,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-a94c6a0a-640d-44d1-9b43-d8473e7880ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-5bfc6669-df24-4cc4-a657-7c6a4af15bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713517927-172.17.0.4-1597048763688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38208,DS-af425c7b-c5ea-4761-9055-018d3634fae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-ad0d29a8-8700-42aa-a798-7a826f695365,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-4e39249d-3934-4713-9474-676b313c14c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-912014c1-41b3-4b99-a5bc-4c2bbab164ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-2eb40e43-dd69-46f8-a0c4-65c507090ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-6184ce13-6f51-4a89-adab-31fabff01eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-dfe63b13-5ccb-461a-bb67-95e5b6b29ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-f15f39da-a7a8-4c5e-b397-c5f976af57ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713517927-172.17.0.4-1597048763688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38208,DS-af425c7b-c5ea-4761-9055-018d3634fae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-ad0d29a8-8700-42aa-a798-7a826f695365,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-4e39249d-3934-4713-9474-676b313c14c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-912014c1-41b3-4b99-a5bc-4c2bbab164ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-2eb40e43-dd69-46f8-a0c4-65c507090ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-6184ce13-6f51-4a89-adab-31fabff01eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-dfe63b13-5ccb-461a-bb67-95e5b6b29ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-f15f39da-a7a8-4c5e-b397-c5f976af57ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703112047-172.17.0.4-1597049065309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42205,DS-a389a80d-2352-4741-bebd-cccfdacaee48,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-ff52a362-884c-4aea-884c-23d954b481f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-810f06df-702a-48ca-9972-38b9decc0c57,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-aed19205-b4e4-413a-a0bd-652e5d64aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-bab9613b-ca64-48e4-a3fa-fd716aa896ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-1afa8480-333f-4367-b704-0d2e4884dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-99d00083-67f2-473c-87f0-3aac020855d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-fc899542-8c42-4839-85d1-817e573d0827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703112047-172.17.0.4-1597049065309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42205,DS-a389a80d-2352-4741-bebd-cccfdacaee48,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-ff52a362-884c-4aea-884c-23d954b481f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-810f06df-702a-48ca-9972-38b9decc0c57,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-aed19205-b4e4-413a-a0bd-652e5d64aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-bab9613b-ca64-48e4-a3fa-fd716aa896ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-1afa8480-333f-4367-b704-0d2e4884dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-99d00083-67f2-473c-87f0-3aac020855d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-fc899542-8c42-4839-85d1-817e573d0827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934402229-172.17.0.4-1597049106011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37277,DS-17d23fc0-22a8-4af7-9103-f7635d4de085,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-c9f3e55c-ec9b-4a19-a518-0952b552a6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-bb1a37f4-a47b-422c-b3f5-544172e906cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-52ab9a74-996e-4a67-8dfd-e269f3833278,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-39e01477-0273-44c3-bb47-0c31fdffac4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-2050a754-7bb8-41d0-8614-9cb1cf8d35f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-a491cbe2-dd96-4aa3-800a-59eaf8f31268,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-3a3c9c8e-11bd-4b44-9705-e8867ce291ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934402229-172.17.0.4-1597049106011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37277,DS-17d23fc0-22a8-4af7-9103-f7635d4de085,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-c9f3e55c-ec9b-4a19-a518-0952b552a6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-bb1a37f4-a47b-422c-b3f5-544172e906cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-52ab9a74-996e-4a67-8dfd-e269f3833278,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-39e01477-0273-44c3-bb47-0c31fdffac4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-2050a754-7bb8-41d0-8614-9cb1cf8d35f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-a491cbe2-dd96-4aa3-800a-59eaf8f31268,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-3a3c9c8e-11bd-4b44-9705-e8867ce291ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026178308-172.17.0.4-1597049177972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40839,DS-9c17d06c-750b-4089-bb4e-f86b6ceb538f,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-268fc352-e8f7-4d13-a907-a6ead5528070,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-f6748b70-3043-4064-a496-5db9a60de826,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-4136c460-343a-4048-9445-cfafdcd9ca92,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-44ec5aff-3683-4cd7-b0dd-e93329addba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-14b22552-d869-4ace-be14-03e016e6137c,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-942d1d10-ee1a-4651-ba3c-7347a2f33bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-73592338-f61b-4434-8465-b848e84e1dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026178308-172.17.0.4-1597049177972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40839,DS-9c17d06c-750b-4089-bb4e-f86b6ceb538f,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-268fc352-e8f7-4d13-a907-a6ead5528070,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-f6748b70-3043-4064-a496-5db9a60de826,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-4136c460-343a-4048-9445-cfafdcd9ca92,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-44ec5aff-3683-4cd7-b0dd-e93329addba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-14b22552-d869-4ace-be14-03e016e6137c,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-942d1d10-ee1a-4651-ba3c-7347a2f33bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-73592338-f61b-4434-8465-b848e84e1dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788005939-172.17.0.4-1597050309310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-b5f95ccc-e285-4b20-9d3d-6b7e8eede904,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-7c52058a-0c6c-4e36-8cda-eeebbd97dd26,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-e5780954-682b-4984-ba14-018872df065a,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-39f14b7a-3887-40f3-b998-79b54e2edb08,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-916f2916-27be-4569-aff7-fcdef0fcaa92,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-e1b9882b-fe0c-4487-bf90-d728a1cc898e,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-477fad26-cdf1-4918-a5f5-563a5d407178,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-07a26bca-59f9-4d6d-9c58-29efbcb07d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788005939-172.17.0.4-1597050309310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-b5f95ccc-e285-4b20-9d3d-6b7e8eede904,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-7c52058a-0c6c-4e36-8cda-eeebbd97dd26,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-e5780954-682b-4984-ba14-018872df065a,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-39f14b7a-3887-40f3-b998-79b54e2edb08,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-916f2916-27be-4569-aff7-fcdef0fcaa92,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-e1b9882b-fe0c-4487-bf90-d728a1cc898e,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-477fad26-cdf1-4918-a5f5-563a5d407178,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-07a26bca-59f9-4d6d-9c58-29efbcb07d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169861919-172.17.0.4-1597050383342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40049,DS-349ead23-5fd3-4bca-9040-b985d90b6778,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-751389af-37bb-4048-b24e-107946566f30,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-5c7dcfb6-bc91-4c19-bc4b-b654808bcde7,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-3f34fc5e-8dbd-4b12-be58-ae922cf62a54,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-42985c87-f152-4e1a-b10d-ff43edd61b21,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-e533e511-91d9-4e3f-89f0-e92c6d773cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-bf89573d-1cfb-466c-a768-687cbec0b060,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-302f4136-9948-4e88-9b32-ad26f7a316ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169861919-172.17.0.4-1597050383342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40049,DS-349ead23-5fd3-4bca-9040-b985d90b6778,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-751389af-37bb-4048-b24e-107946566f30,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-5c7dcfb6-bc91-4c19-bc4b-b654808bcde7,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-3f34fc5e-8dbd-4b12-be58-ae922cf62a54,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-42985c87-f152-4e1a-b10d-ff43edd61b21,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-e533e511-91d9-4e3f-89f0-e92c6d773cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-bf89573d-1cfb-466c-a768-687cbec0b060,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-302f4136-9948-4e88-9b32-ad26f7a316ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960081014-172.17.0.4-1597051033359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-1ae83dba-f0fb-42cc-8e20-ffbbb2badc88,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-2a8aed5a-16eb-4eac-b38f-e3434f47fe39,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-dea67c71-139d-4329-8792-733055ed821e,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-99de6bc0-4609-42ab-8060-fa96dae2cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-f8beefe1-caf5-49d7-9ef5-868e506bf0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-66d60b13-8bc5-49b6-b75d-2ee1b9f66246,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-bf58a805-2036-4438-a9a5-3e76487c66b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-ee0a9563-3f34-4aee-9eae-1240c6f36aa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960081014-172.17.0.4-1597051033359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-1ae83dba-f0fb-42cc-8e20-ffbbb2badc88,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-2a8aed5a-16eb-4eac-b38f-e3434f47fe39,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-dea67c71-139d-4329-8792-733055ed821e,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-99de6bc0-4609-42ab-8060-fa96dae2cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-f8beefe1-caf5-49d7-9ef5-868e506bf0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-66d60b13-8bc5-49b6-b75d-2ee1b9f66246,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-bf58a805-2036-4438-a9a5-3e76487c66b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-ee0a9563-3f34-4aee-9eae-1240c6f36aa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5414
