reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465052356-172.17.0.5-1597195614965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46481,DS-18eaa2b1-7fd5-43aa-a46f-4fcc077fcbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-2c0aa8a7-160e-450d-9911-5862bcafd3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-6d32990b-d202-438a-b488-12e7d973a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-f3360d6b-0489-4fd3-8ed3-1fbef52c26df,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-6826988e-3118-449c-bc93-3e0bc595ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-a8dd247c-00f1-479f-a9af-d044a0deda91,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-c3fe0491-1fe7-4fa6-beb2-3cfb9bf15c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-e86af629-715b-41e2-a038-ddaaaf14db9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465052356-172.17.0.5-1597195614965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46481,DS-18eaa2b1-7fd5-43aa-a46f-4fcc077fcbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-2c0aa8a7-160e-450d-9911-5862bcafd3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-6d32990b-d202-438a-b488-12e7d973a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-f3360d6b-0489-4fd3-8ed3-1fbef52c26df,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-6826988e-3118-449c-bc93-3e0bc595ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-a8dd247c-00f1-479f-a9af-d044a0deda91,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-c3fe0491-1fe7-4fa6-beb2-3cfb9bf15c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-e86af629-715b-41e2-a038-ddaaaf14db9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969414094-172.17.0.5-1597196389273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35332,DS-b76ef54c-c17f-4d1e-9aa4-f825bfbb27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-01a7a3df-9309-440a-87d2-7aba58ae22d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-be414cda-1afa-4611-9998-672b009992c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-e3f74dec-e569-462a-9ad1-ed079dce3791,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-6e398b07-abf3-4302-bfe7-79b40b4fa552,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-15cc40ba-ecf7-47b2-898d-cad7b75aca12,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-0b772fcf-d3eb-497a-bda1-906cc5e8d287,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-73efec99-ad9c-41b5-bff0-be25404b7e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969414094-172.17.0.5-1597196389273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35332,DS-b76ef54c-c17f-4d1e-9aa4-f825bfbb27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-01a7a3df-9309-440a-87d2-7aba58ae22d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-be414cda-1afa-4611-9998-672b009992c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-e3f74dec-e569-462a-9ad1-ed079dce3791,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-6e398b07-abf3-4302-bfe7-79b40b4fa552,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-15cc40ba-ecf7-47b2-898d-cad7b75aca12,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-0b772fcf-d3eb-497a-bda1-906cc5e8d287,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-73efec99-ad9c-41b5-bff0-be25404b7e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834727031-172.17.0.5-1597196684104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-d5452666-8c76-4c0b-8fab-8d6dd0f6de51,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-de342009-6a02-45a4-bd73-460d9984a238,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-389cc23f-2f68-4904-8e34-c9c44dde6fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-7e2ddb56-b217-4310-a8c0-a232dbc7a700,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-b97b1688-5ee6-4bf5-916f-e920712e3b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-d47af134-394f-4670-9efe-e9faf858bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-554d53bc-c281-46a5-b7e6-98bb3842af87,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-26cfe5ba-626b-415e-9d40-ce8c2d86395e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834727031-172.17.0.5-1597196684104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-d5452666-8c76-4c0b-8fab-8d6dd0f6de51,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-de342009-6a02-45a4-bd73-460d9984a238,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-389cc23f-2f68-4904-8e34-c9c44dde6fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-7e2ddb56-b217-4310-a8c0-a232dbc7a700,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-b97b1688-5ee6-4bf5-916f-e920712e3b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-d47af134-394f-4670-9efe-e9faf858bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-554d53bc-c281-46a5-b7e6-98bb3842af87,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-26cfe5ba-626b-415e-9d40-ce8c2d86395e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248097409-172.17.0.5-1597197133996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-5fb336eb-98f4-40d2-8802-ac66e5e70a58,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-a748f0ed-bb56-4c53-b52e-59ccc3b37735,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-d44389eb-bcc3-4758-9e69-eec808899d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-a6084dc2-2f35-4ca6-8e60-9969c7143ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-b5875e1d-99ec-414b-8c02-18bcfbbb43d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-79d48684-7bef-424b-9bbe-9da5b3c08088,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-d287e806-ac9c-4f97-ba21-4f2c0ce3eb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-0b58feef-f0d7-4bda-a3aa-e33cd987ab24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248097409-172.17.0.5-1597197133996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-5fb336eb-98f4-40d2-8802-ac66e5e70a58,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-a748f0ed-bb56-4c53-b52e-59ccc3b37735,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-d44389eb-bcc3-4758-9e69-eec808899d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-a6084dc2-2f35-4ca6-8e60-9969c7143ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-b5875e1d-99ec-414b-8c02-18bcfbbb43d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-79d48684-7bef-424b-9bbe-9da5b3c08088,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-d287e806-ac9c-4f97-ba21-4f2c0ce3eb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-0b58feef-f0d7-4bda-a3aa-e33cd987ab24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087072179-172.17.0.5-1597197298911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46104,DS-5a0a0441-1278-4fff-9a14-f9498b077d58,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-44aa45a2-8933-423a-8a54-7d295c1f532d,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-4d997e8f-6693-41b6-b248-83ba23d4ef1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-c42265b0-6dde-41a0-8e52-ca06b64808d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-a122e963-9739-4ba6-818d-24e3179a08c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-ec02627f-9d7f-4179-8965-b6b77280faad,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-7f781071-916c-4aff-9709-b535f1a6326c,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-fef0d8a1-3430-4c22-a355-1984e61a7fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087072179-172.17.0.5-1597197298911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46104,DS-5a0a0441-1278-4fff-9a14-f9498b077d58,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-44aa45a2-8933-423a-8a54-7d295c1f532d,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-4d997e8f-6693-41b6-b248-83ba23d4ef1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-c42265b0-6dde-41a0-8e52-ca06b64808d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-a122e963-9739-4ba6-818d-24e3179a08c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-ec02627f-9d7f-4179-8965-b6b77280faad,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-7f781071-916c-4aff-9709-b535f1a6326c,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-fef0d8a1-3430-4c22-a355-1984e61a7fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283040685-172.17.0.5-1597198204629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-3890e3e1-af17-48db-bedc-37687fc4b279,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-af8ce870-4543-4f75-884a-3d07848d88af,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-c3dcb7b6-16c8-427f-a076-aaa81c4d5918,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-c57d4a15-a7a2-4a0a-9a2c-ec4373006b13,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-f5f82023-6486-4500-877f-1a2774c6c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-b5854a67-ac36-437b-b930-411c16b5b060,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-78c98149-e4a0-410c-a3c1-e223aae6d890,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-37a7dc8b-9cc4-48f8-8513-74479bd92204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283040685-172.17.0.5-1597198204629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-3890e3e1-af17-48db-bedc-37687fc4b279,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-af8ce870-4543-4f75-884a-3d07848d88af,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-c3dcb7b6-16c8-427f-a076-aaa81c4d5918,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-c57d4a15-a7a2-4a0a-9a2c-ec4373006b13,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-f5f82023-6486-4500-877f-1a2774c6c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-b5854a67-ac36-437b-b930-411c16b5b060,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-78c98149-e4a0-410c-a3c1-e223aae6d890,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-37a7dc8b-9cc4-48f8-8513-74479bd92204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680873417-172.17.0.5-1597198464158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-e36cc994-e945-42d4-a86c-5165779f6d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-3e39f785-f34d-4411-bf62-122653bc2d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-0c7d57aa-569d-47f6-ae83-fab0725469f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-9e71b59a-d19e-45cd-b7d9-e173392280c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-ee233a2a-ceca-4ac6-8e26-fb706da75bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-71a0386b-0a2e-491b-9f10-a271ea8039a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-6519d9c5-8ccb-435c-b516-4154b3bab41c,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-c9485b64-7d3c-4a1b-ab8c-50d164e1d6fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680873417-172.17.0.5-1597198464158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-e36cc994-e945-42d4-a86c-5165779f6d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-3e39f785-f34d-4411-bf62-122653bc2d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-0c7d57aa-569d-47f6-ae83-fab0725469f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-9e71b59a-d19e-45cd-b7d9-e173392280c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-ee233a2a-ceca-4ac6-8e26-fb706da75bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-71a0386b-0a2e-491b-9f10-a271ea8039a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-6519d9c5-8ccb-435c-b516-4154b3bab41c,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-c9485b64-7d3c-4a1b-ab8c-50d164e1d6fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081198887-172.17.0.5-1597198806085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-b20dc788-539b-4853-a2bd-7341fcc90ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-a877e5ea-a040-481d-9283-763bca1b986c,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-9ccc2807-45a4-4533-8823-86a4e92a05cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d7a4c7bb-ada8-4c27-8c4d-aa75839de65e,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-fb360777-2f62-4ecb-9674-de500729ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-b59c3680-6cdd-4a1f-b508-10c4c710f855,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-4d9a58e6-43eb-4e8d-9cf7-28e9702b0c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-e9aec5d9-7ce0-4643-b95f-089cd2e32cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081198887-172.17.0.5-1597198806085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-b20dc788-539b-4853-a2bd-7341fcc90ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-a877e5ea-a040-481d-9283-763bca1b986c,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-9ccc2807-45a4-4533-8823-86a4e92a05cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d7a4c7bb-ada8-4c27-8c4d-aa75839de65e,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-fb360777-2f62-4ecb-9674-de500729ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-b59c3680-6cdd-4a1f-b508-10c4c710f855,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-4d9a58e6-43eb-4e8d-9cf7-28e9702b0c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-e9aec5d9-7ce0-4643-b95f-089cd2e32cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693513066-172.17.0.5-1597198933250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42551,DS-31f5afa1-3b68-4eb2-968f-1a2e4fe0604e,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-a0ed47d9-6263-4af7-8f33-f946b2f32db3,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-35241ff0-5374-4781-83e3-58cf0982a6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-927698da-2082-4d17-a6b8-1b16adc6f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-ed28d096-ca59-47a5-a4ea-d63b91db0fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-e0f38cbf-3054-4c48-aa75-11dd9998ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-3fba9913-8376-4391-be32-70f696037382,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e5942377-4b02-4dbc-ae15-cc4cf6657906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693513066-172.17.0.5-1597198933250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42551,DS-31f5afa1-3b68-4eb2-968f-1a2e4fe0604e,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-a0ed47d9-6263-4af7-8f33-f946b2f32db3,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-35241ff0-5374-4781-83e3-58cf0982a6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-927698da-2082-4d17-a6b8-1b16adc6f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-ed28d096-ca59-47a5-a4ea-d63b91db0fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-e0f38cbf-3054-4c48-aa75-11dd9998ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-3fba9913-8376-4391-be32-70f696037382,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e5942377-4b02-4dbc-ae15-cc4cf6657906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595457359-172.17.0.5-1597199015114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-91339c3e-3151-49cc-a55d-97243334e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-b69ed0b5-3827-4dcb-94e7-11f5c698f159,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-9e81a8f6-11b9-44b9-9330-a9a0fd86bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-2e761a3b-551f-49be-9d12-10af3b723e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-9add6464-0dff-4e07-b52d-ec6dc1ebd300,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-117c8749-a146-4511-92b2-3b3fab5da2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-39431496-8345-4272-b3e5-e7bbae5bb16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-323983d9-7d22-4b4d-8c0d-40671139ce07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595457359-172.17.0.5-1597199015114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-91339c3e-3151-49cc-a55d-97243334e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-b69ed0b5-3827-4dcb-94e7-11f5c698f159,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-9e81a8f6-11b9-44b9-9330-a9a0fd86bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-2e761a3b-551f-49be-9d12-10af3b723e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-9add6464-0dff-4e07-b52d-ec6dc1ebd300,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-117c8749-a146-4511-92b2-3b3fab5da2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-39431496-8345-4272-b3e5-e7bbae5bb16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-323983d9-7d22-4b4d-8c0d-40671139ce07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6308
