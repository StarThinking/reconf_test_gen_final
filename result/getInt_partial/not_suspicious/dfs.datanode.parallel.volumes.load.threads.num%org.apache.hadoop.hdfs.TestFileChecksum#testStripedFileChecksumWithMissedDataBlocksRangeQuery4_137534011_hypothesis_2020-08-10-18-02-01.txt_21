reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894474109-172.17.0.12-1597082857289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-b6c89774-c0c6-4cae-a0fe-8c8c09e3d995,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-a4e38443-c8ab-4107-b6f3-f587efef4911,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-2efe1c9a-a816-4715-a6d4-e51051738eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-9be9c21a-8b33-4837-9747-4ad1e495d9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-9b871139-b3b2-4515-8614-17ef6fb0f343,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-34623a9f-20a7-4065-b078-eedff34c380d,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-a8a2042f-f4f0-46c2-9e65-7c99a662b394,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-6c099539-3901-47ea-ae1f-80e35290e40d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894474109-172.17.0.12-1597082857289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-b6c89774-c0c6-4cae-a0fe-8c8c09e3d995,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-a4e38443-c8ab-4107-b6f3-f587efef4911,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-2efe1c9a-a816-4715-a6d4-e51051738eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-9be9c21a-8b33-4837-9747-4ad1e495d9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-9b871139-b3b2-4515-8614-17ef6fb0f343,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-34623a9f-20a7-4065-b078-eedff34c380d,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-a8a2042f-f4f0-46c2-9e65-7c99a662b394,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-6c099539-3901-47ea-ae1f-80e35290e40d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204347303-172.17.0.12-1597084250258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36734,DS-aad7b355-afa3-4da0-aa0b-e275bd2fc59f,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-c9555059-814f-4f6d-83a8-04cc4f71398e,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-37a11113-5d3d-4ac8-a117-a601f4ca3218,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-29893e6d-1fe0-43b8-93ce-518a209a09cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-81709a94-189c-4b05-aaae-4d80c46db4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-9fc64efc-41d0-4995-b8fb-7b122fe16836,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-cd3c01d2-4e56-477e-ae8e-a3c3b556d676,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-90bccf44-a585-41da-90ce-9cf17b55e06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204347303-172.17.0.12-1597084250258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36734,DS-aad7b355-afa3-4da0-aa0b-e275bd2fc59f,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-c9555059-814f-4f6d-83a8-04cc4f71398e,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-37a11113-5d3d-4ac8-a117-a601f4ca3218,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-29893e6d-1fe0-43b8-93ce-518a209a09cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-81709a94-189c-4b05-aaae-4d80c46db4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-9fc64efc-41d0-4995-b8fb-7b122fe16836,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-cd3c01d2-4e56-477e-ae8e-a3c3b556d676,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-90bccf44-a585-41da-90ce-9cf17b55e06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002236522-172.17.0.12-1597084345474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39467,DS-45ef7cca-ac23-44e2-9ab4-6fb71f6ceedb,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-13c7e5c4-f731-4cfa-9742-297f80d01938,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-9f825c6a-d4a0-4534-99cd-ea279fd7c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-9667e24f-f3b0-4540-a0fc-c45ce6b7b2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-0a8ad8c3-aff2-4c95-86e7-cbb0fe3e12e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-8ce0bbaf-82bc-43f1-8cd0-344e3ac9d389,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-127eaad6-fc29-47c7-9842-68aeaa9367df,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-86ef9c7b-880e-43a1-aa47-0d5557535b35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002236522-172.17.0.12-1597084345474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39467,DS-45ef7cca-ac23-44e2-9ab4-6fb71f6ceedb,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-13c7e5c4-f731-4cfa-9742-297f80d01938,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-9f825c6a-d4a0-4534-99cd-ea279fd7c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-9667e24f-f3b0-4540-a0fc-c45ce6b7b2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-0a8ad8c3-aff2-4c95-86e7-cbb0fe3e12e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-8ce0bbaf-82bc-43f1-8cd0-344e3ac9d389,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-127eaad6-fc29-47c7-9842-68aeaa9367df,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-86ef9c7b-880e-43a1-aa47-0d5557535b35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642753419-172.17.0.12-1597084671728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-3ffc9f2a-5763-40ab-8a4e-a1f1f05f4018,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-dde90d22-521c-4fb1-95c0-7de0c92a00b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-c334ee93-e81d-4815-9ed2-cb2164249c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-4158bad7-caca-474b-b5d4-40ce81907836,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-5c22d4ae-82ca-454d-9b71-9a1e32a961e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-29f9e624-b779-4605-b02a-fa11a1c2f366,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-e15e861d-0b8e-428b-8175-9420c76e9bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-c800ccec-6c11-47ad-b25e-8a7d580774f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642753419-172.17.0.12-1597084671728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-3ffc9f2a-5763-40ab-8a4e-a1f1f05f4018,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-dde90d22-521c-4fb1-95c0-7de0c92a00b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-c334ee93-e81d-4815-9ed2-cb2164249c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-4158bad7-caca-474b-b5d4-40ce81907836,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-5c22d4ae-82ca-454d-9b71-9a1e32a961e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-29f9e624-b779-4605-b02a-fa11a1c2f366,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-e15e861d-0b8e-428b-8175-9420c76e9bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-c800ccec-6c11-47ad-b25e-8a7d580774f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580583909-172.17.0.12-1597084971759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35775,DS-f529c37e-9be0-44f1-9b6a-a26f839d02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-d076b8dc-e373-4534-91ee-7ea9712516c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-18fd4cfe-d160-446b-91c4-33bbe4dedbad,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-cff82d04-7dc8-4c2c-a626-b4548dedd4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-3c623bb9-ae8d-40aa-971e-0445bd854427,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-a52a9e1a-c708-4bd6-8026-191a03bc3975,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-dbf5597b-5baa-4a16-9dee-02ffc1a6106a,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-ab0b22f1-3591-4330-8da9-cbe6e86bcbe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580583909-172.17.0.12-1597084971759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35775,DS-f529c37e-9be0-44f1-9b6a-a26f839d02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-d076b8dc-e373-4534-91ee-7ea9712516c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-18fd4cfe-d160-446b-91c4-33bbe4dedbad,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-cff82d04-7dc8-4c2c-a626-b4548dedd4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-3c623bb9-ae8d-40aa-971e-0445bd854427,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-a52a9e1a-c708-4bd6-8026-191a03bc3975,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-dbf5597b-5baa-4a16-9dee-02ffc1a6106a,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-ab0b22f1-3591-4330-8da9-cbe6e86bcbe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766485307-172.17.0.12-1597085800580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40504,DS-c5e7ce4a-3f2b-48f1-b26c-5dbe04592061,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-d5e02bfb-5eca-4490-9f4d-6cb386cf0d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-0da45428-8ee5-4a08-a1f3-0a31df7189af,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-a583a237-3090-48c0-8a14-cd7c5ab67527,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-bca64e05-55ca-407b-b4a5-a5e5dd9ea25c,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-6858542e-ccd0-43c6-8172-a8d73fff03e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-2106dfb3-504b-463c-9b76-3bd8ee70f44c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-2eec42bf-db82-497c-9fd9-71b2bfe26eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766485307-172.17.0.12-1597085800580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40504,DS-c5e7ce4a-3f2b-48f1-b26c-5dbe04592061,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-d5e02bfb-5eca-4490-9f4d-6cb386cf0d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-0da45428-8ee5-4a08-a1f3-0a31df7189af,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-a583a237-3090-48c0-8a14-cd7c5ab67527,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-bca64e05-55ca-407b-b4a5-a5e5dd9ea25c,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-6858542e-ccd0-43c6-8172-a8d73fff03e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-2106dfb3-504b-463c-9b76-3bd8ee70f44c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-2eec42bf-db82-497c-9fd9-71b2bfe26eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148135529-172.17.0.12-1597086744378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46507,DS-1a218222-5dc0-4033-815b-824b936628e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-97633e7b-2ccb-4520-a156-e6b355fd27b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-52995014-5f06-4083-8f69-1f791e55aecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-a51d9fc2-36db-4a70-92e0-5226a235d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-424a396c-598d-4692-ae33-abff215326f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-db6fefcc-7a32-40b9-9a9a-cbf31e03bcec,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-b529ea85-4bfd-497b-99c5-ef515cfce794,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-15577e6b-3659-4700-8d62-f62611cc9175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148135529-172.17.0.12-1597086744378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46507,DS-1a218222-5dc0-4033-815b-824b936628e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-97633e7b-2ccb-4520-a156-e6b355fd27b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-52995014-5f06-4083-8f69-1f791e55aecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-a51d9fc2-36db-4a70-92e0-5226a235d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-424a396c-598d-4692-ae33-abff215326f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-db6fefcc-7a32-40b9-9a9a-cbf31e03bcec,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-b529ea85-4bfd-497b-99c5-ef515cfce794,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-15577e6b-3659-4700-8d62-f62611cc9175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772662556-172.17.0.12-1597087011373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-c63f4ddf-18fe-450c-ba16-c87b820e04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-05aec0f8-8c37-422c-ae1b-6c470463901b,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-0d078e5e-2a4b-4a43-b763-e288c892251a,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-a3fd46c1-7384-40f8-a24c-9f9eb3ab0079,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-bf0cfb6b-c124-4639-ba18-cc28be09df76,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-7cab0b54-29e4-482a-aa33-24c3f6572739,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-09ed350b-d8ee-423c-a4d2-f78cc182a170,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-325792fe-32cd-4e17-96ab-4851bcdedf87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772662556-172.17.0.12-1597087011373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-c63f4ddf-18fe-450c-ba16-c87b820e04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-05aec0f8-8c37-422c-ae1b-6c470463901b,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-0d078e5e-2a4b-4a43-b763-e288c892251a,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-a3fd46c1-7384-40f8-a24c-9f9eb3ab0079,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-bf0cfb6b-c124-4639-ba18-cc28be09df76,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-7cab0b54-29e4-482a-aa33-24c3f6572739,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-09ed350b-d8ee-423c-a4d2-f78cc182a170,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-325792fe-32cd-4e17-96ab-4851bcdedf87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824439623-172.17.0.12-1597087205637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42120,DS-06187391-c287-4cd5-8fe8-5cf68f1cf484,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-4585a119-49a2-40e3-a638-917c95e4e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-6948faa8-2f3b-4435-bfc3-1d4ee5ff6275,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-bb4d0a62-e03e-4b6f-918a-4284e129fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-f628509b-bd3d-42bc-b691-43fcd38cc23d,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-3b06b7b2-c3de-4d88-82da-928f6e0d8c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-8c29136e-dd83-4353-bc40-1576a2dccc22,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-31e9990f-9953-4719-8e2f-6b512bdf224e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824439623-172.17.0.12-1597087205637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42120,DS-06187391-c287-4cd5-8fe8-5cf68f1cf484,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-4585a119-49a2-40e3-a638-917c95e4e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-6948faa8-2f3b-4435-bfc3-1d4ee5ff6275,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-bb4d0a62-e03e-4b6f-918a-4284e129fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-f628509b-bd3d-42bc-b691-43fcd38cc23d,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-3b06b7b2-c3de-4d88-82da-928f6e0d8c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-8c29136e-dd83-4353-bc40-1576a2dccc22,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-31e9990f-9953-4719-8e2f-6b512bdf224e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287548114-172.17.0.12-1597087650823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46577,DS-d2c6e7c2-4567-4e7f-8eaa-62da5bceb0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-66e337be-ab15-4361-b688-036eda1c06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-0414af8f-6fc4-4eb0-9759-a84a7d77fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-ff17ac77-8616-4bad-982a-4c0477087d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-c22b179b-4f94-4058-9a1c-af1b288eed64,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-0d68d2aa-a9f3-4c6a-a625-5ab75477853a,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-d7a9bdf0-f03f-418b-814f-1cf3cb3af73e,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-9edc1fc2-e086-407d-a1fb-024972cc95da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287548114-172.17.0.12-1597087650823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46577,DS-d2c6e7c2-4567-4e7f-8eaa-62da5bceb0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-66e337be-ab15-4361-b688-036eda1c06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-0414af8f-6fc4-4eb0-9759-a84a7d77fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-ff17ac77-8616-4bad-982a-4c0477087d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-c22b179b-4f94-4058-9a1c-af1b288eed64,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-0d68d2aa-a9f3-4c6a-a625-5ab75477853a,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-d7a9bdf0-f03f-418b-814f-1cf3cb3af73e,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-9edc1fc2-e086-407d-a1fb-024972cc95da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096900468-172.17.0.12-1597087794465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41300,DS-577b32da-7345-4b45-89ff-76b88fb6fa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-4ebbca19-ac71-44ed-9a79-df923d104309,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-d13ff096-255b-4804-913f-25777b40d860,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-ce1809b3-641d-4d3d-8f0a-9385cff8e6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-64bc2f9f-5335-4472-b8a4-0c05dad092dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-6c01300d-1ed5-4de1-a56f-685e270762e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-2b025be9-12da-4e33-b386-5c60c78d4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-3ba89fc4-74f2-4064-8b7d-60ca7f73521e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096900468-172.17.0.12-1597087794465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41300,DS-577b32da-7345-4b45-89ff-76b88fb6fa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-4ebbca19-ac71-44ed-9a79-df923d104309,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-d13ff096-255b-4804-913f-25777b40d860,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-ce1809b3-641d-4d3d-8f0a-9385cff8e6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-64bc2f9f-5335-4472-b8a4-0c05dad092dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-6c01300d-1ed5-4de1-a56f-685e270762e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-2b025be9-12da-4e33-b386-5c60c78d4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-3ba89fc4-74f2-4064-8b7d-60ca7f73521e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414375470-172.17.0.12-1597087895009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34717,DS-6b54b72e-2980-4c7b-b24d-2c431301dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-494747c4-fc1c-4328-89cf-d7cafec38b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-eb476678-8de5-45ee-b5e3-08c94b27e634,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-7126df32-48af-4087-96d4-b0f6b79d759a,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-f1a521b5-c2ad-43a5-96f7-28717d157fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-23602a35-6368-476a-aae9-c2dc239204be,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-690f17c2-ff0b-4c1e-86f2-0ac720d15c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-ab224bc3-3d94-47c3-981b-0c808b5dc10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414375470-172.17.0.12-1597087895009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34717,DS-6b54b72e-2980-4c7b-b24d-2c431301dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-494747c4-fc1c-4328-89cf-d7cafec38b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-eb476678-8de5-45ee-b5e3-08c94b27e634,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-7126df32-48af-4087-96d4-b0f6b79d759a,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-f1a521b5-c2ad-43a5-96f7-28717d157fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-23602a35-6368-476a-aae9-c2dc239204be,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-690f17c2-ff0b-4c1e-86f2-0ac720d15c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-ab224bc3-3d94-47c3-981b-0c808b5dc10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702744936-172.17.0.12-1597088491390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35920,DS-51e61849-45cc-4e74-8f17-5237d41cc725,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-3c1a63a1-ec33-4607-80ed-06ef447fcc00,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-43695df8-90e4-480b-ae2a-168bb420e6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-343833eb-7614-4a41-ab1d-4eb441d7d35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-06dd0337-b715-472c-b8e1-519ffbfbb790,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-4595e00f-6e82-4b0a-876e-eae95f1dc252,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-fad781ff-d9f9-44ec-95d0-1ae38008086a,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-5e2f02fd-a321-4a11-93ad-1e91fc037948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702744936-172.17.0.12-1597088491390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35920,DS-51e61849-45cc-4e74-8f17-5237d41cc725,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-3c1a63a1-ec33-4607-80ed-06ef447fcc00,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-43695df8-90e4-480b-ae2a-168bb420e6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-343833eb-7614-4a41-ab1d-4eb441d7d35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-06dd0337-b715-472c-b8e1-519ffbfbb790,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-4595e00f-6e82-4b0a-876e-eae95f1dc252,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-fad781ff-d9f9-44ec-95d0-1ae38008086a,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-5e2f02fd-a321-4a11-93ad-1e91fc037948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355437482-172.17.0.12-1597088594496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44016,DS-8b57c5c3-df5a-4e24-b265-b24fc265ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-e604dd2b-0aeb-491f-86a6-9928ea2feb35,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-d3f3b8cd-a6d9-44ec-82e9-fb2cff49bd06,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-2d5d72ae-961c-4ada-bcd0-0966ffa14541,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-6d4c2afc-1a33-444a-971a-b75a31a5faff,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-f33ab313-58ed-4879-b442-5c9930963a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-daf0ef5a-57be-41d7-a66d-9d84f5107698,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-67e5e40e-2591-4508-be7c-543e3f8916bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355437482-172.17.0.12-1597088594496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44016,DS-8b57c5c3-df5a-4e24-b265-b24fc265ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-e604dd2b-0aeb-491f-86a6-9928ea2feb35,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-d3f3b8cd-a6d9-44ec-82e9-fb2cff49bd06,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-2d5d72ae-961c-4ada-bcd0-0966ffa14541,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-6d4c2afc-1a33-444a-971a-b75a31a5faff,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-f33ab313-58ed-4879-b442-5c9930963a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-daf0ef5a-57be-41d7-a66d-9d84f5107698,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-67e5e40e-2591-4508-be7c-543e3f8916bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60353235-172.17.0.12-1597088819070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34072,DS-3540ce3a-9352-4656-b962-1d5753bfbf04,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-bbf1be7c-7ad4-4373-9c51-29c6195e8b19,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-1e3897e6-bcde-4721-9f00-7d19af4203c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-8e84ab49-31e5-4f75-b51c-43ea276c84e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-05a58d14-0ce2-4d37-976e-c72c8732967e,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-e5e45dfd-b35d-4e69-98ed-e55044524a65,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-0e74e866-9412-4961-9184-3cabe9059fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-94df12fb-afcb-4250-a020-a62be6b919b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60353235-172.17.0.12-1597088819070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34072,DS-3540ce3a-9352-4656-b962-1d5753bfbf04,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-bbf1be7c-7ad4-4373-9c51-29c6195e8b19,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-1e3897e6-bcde-4721-9f00-7d19af4203c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-8e84ab49-31e5-4f75-b51c-43ea276c84e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-05a58d14-0ce2-4d37-976e-c72c8732967e,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-e5e45dfd-b35d-4e69-98ed-e55044524a65,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-0e74e866-9412-4961-9184-3cabe9059fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-94df12fb-afcb-4250-a020-a62be6b919b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144080187-172.17.0.12-1597088903623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34820,DS-0570f2ee-5674-4e3b-966b-17baad68145c,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-a4656652-99c2-4c35-bb24-17603301521b,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-362eda3e-58ad-46a8-b033-20a26cc7ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-fdafa981-0841-4c5c-b395-d6bc5c41669f,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-955490cf-f4f5-4c6c-9407-096c60c50c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-95a6fe6d-215f-46f6-a663-994ca97cd4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-0613e5a2-559c-4624-a0ee-58483dd0aee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-a9a452a3-1ae4-4b11-9275-7381f040dbcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144080187-172.17.0.12-1597088903623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34820,DS-0570f2ee-5674-4e3b-966b-17baad68145c,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-a4656652-99c2-4c35-bb24-17603301521b,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-362eda3e-58ad-46a8-b033-20a26cc7ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-fdafa981-0841-4c5c-b395-d6bc5c41669f,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-955490cf-f4f5-4c6c-9407-096c60c50c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-95a6fe6d-215f-46f6-a663-994ca97cd4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-0613e5a2-559c-4624-a0ee-58483dd0aee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-a9a452a3-1ae4-4b11-9275-7381f040dbcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6773
