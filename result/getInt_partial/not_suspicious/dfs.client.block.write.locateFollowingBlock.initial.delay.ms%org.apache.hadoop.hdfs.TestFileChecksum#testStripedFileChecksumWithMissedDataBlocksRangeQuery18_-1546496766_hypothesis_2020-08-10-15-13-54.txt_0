reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567527005-172.17.0.17-1597072515311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-ece1d88a-1856-41e2-8283-f74c0e9b7307,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-396411d9-cd33-4670-a51b-5b5e5a8da752,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-b4718689-2498-4305-97be-4effd49e229f,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-942d1ef0-17e1-4a31-9c23-284a4d2582d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-e07bb9e3-ea35-40f0-9ab5-0a57a07a2fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-3adab854-f64f-44e4-8f2e-ac8266819bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-ccce7cc6-e2f9-4319-be96-a4e0f6af00a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-0bede5ee-8a28-4aa5-8c41-219fe5ff5a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567527005-172.17.0.17-1597072515311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-ece1d88a-1856-41e2-8283-f74c0e9b7307,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-396411d9-cd33-4670-a51b-5b5e5a8da752,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-b4718689-2498-4305-97be-4effd49e229f,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-942d1ef0-17e1-4a31-9c23-284a4d2582d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-e07bb9e3-ea35-40f0-9ab5-0a57a07a2fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-3adab854-f64f-44e4-8f2e-ac8266819bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-ccce7cc6-e2f9-4319-be96-a4e0f6af00a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-0bede5ee-8a28-4aa5-8c41-219fe5ff5a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520798999-172.17.0.17-1597073081400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36796,DS-cc0a5c39-45b8-4e09-8795-5168296361c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-01a12df6-4d5a-48c3-8669-2e9b6ee01fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-058407f6-8bf7-4981-adc0-f2efcf48ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-6bfee8b4-ceaf-41c9-ae5d-09f5ad3337e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-f61d69ac-cacc-4a24-8880-c3563807396e,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-b2fa35ef-5951-40fb-9cf3-d901964cb441,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-16f7ba7f-df64-4bf9-b451-5f0f0ffcfd17,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-f5014a23-81a7-46d6-ad94-087032adbf22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520798999-172.17.0.17-1597073081400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36796,DS-cc0a5c39-45b8-4e09-8795-5168296361c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-01a12df6-4d5a-48c3-8669-2e9b6ee01fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-058407f6-8bf7-4981-adc0-f2efcf48ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-6bfee8b4-ceaf-41c9-ae5d-09f5ad3337e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-f61d69ac-cacc-4a24-8880-c3563807396e,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-b2fa35ef-5951-40fb-9cf3-d901964cb441,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-16f7ba7f-df64-4bf9-b451-5f0f0ffcfd17,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-f5014a23-81a7-46d6-ad94-087032adbf22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228441199-172.17.0.17-1597073113713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-a7467394-0a80-4d91-adbf-632be1831d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-fa53944b-3a03-4120-89fc-17a4146c3b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-79f6113b-8906-48e3-8961-b06eb07acf32,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-b73fa275-f992-4c02-b860-bca574f5844a,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-1003722c-333a-477c-9967-43c4c1554aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-a9efa487-5a95-4802-ac57-035a2b97051f,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-613e2ffa-e1fc-41a9-9424-4554265e3457,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-2b7de22d-c96b-44cc-8146-2940afabfc8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228441199-172.17.0.17-1597073113713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-a7467394-0a80-4d91-adbf-632be1831d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-fa53944b-3a03-4120-89fc-17a4146c3b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-79f6113b-8906-48e3-8961-b06eb07acf32,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-b73fa275-f992-4c02-b860-bca574f5844a,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-1003722c-333a-477c-9967-43c4c1554aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-a9efa487-5a95-4802-ac57-035a2b97051f,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-613e2ffa-e1fc-41a9-9424-4554265e3457,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-2b7de22d-c96b-44cc-8146-2940afabfc8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892983394-172.17.0.17-1597073364647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34897,DS-43116f06-e5a6-4a64-8255-69deb7f94a05,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-3516d6f0-18f9-42c1-82bf-e3cd6f8ea9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-fff53086-85f5-4896-b2c2-54ae5414a0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-97aed614-1487-4cff-98a5-7dfbece724b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-a2072e65-0d80-4a71-9612-966f92481d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-7011e647-5b26-4da8-9632-a497339d460e,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-7965111f-2b30-45db-bc3c-2076130b6576,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-eb07f7b8-c8c0-4a7e-b225-e099c25850b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892983394-172.17.0.17-1597073364647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34897,DS-43116f06-e5a6-4a64-8255-69deb7f94a05,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-3516d6f0-18f9-42c1-82bf-e3cd6f8ea9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-fff53086-85f5-4896-b2c2-54ae5414a0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-97aed614-1487-4cff-98a5-7dfbece724b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-a2072e65-0d80-4a71-9612-966f92481d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-7011e647-5b26-4da8-9632-a497339d460e,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-7965111f-2b30-45db-bc3c-2076130b6576,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-eb07f7b8-c8c0-4a7e-b225-e099c25850b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495320571-172.17.0.17-1597073547682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-9e0539b6-8809-4ca6-9077-3de25c08e9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-21daff6d-8180-4428-98c4-d4ec23237eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-53b37b6d-9f19-4c99-964d-2f19b88fdc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-4cc9d446-41f9-40d1-bbc6-6ddffcda652f,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-e8b899b9-cfb3-4cf3-ad6f-6bec8ee80768,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-fe310c67-ad71-435a-b7ac-895ed9e95ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-88784b56-ade7-44f0-ac9e-97d7a85eadbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-bc92d171-fa0a-4067-8926-d20af811d7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495320571-172.17.0.17-1597073547682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-9e0539b6-8809-4ca6-9077-3de25c08e9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-21daff6d-8180-4428-98c4-d4ec23237eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-53b37b6d-9f19-4c99-964d-2f19b88fdc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-4cc9d446-41f9-40d1-bbc6-6ddffcda652f,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-e8b899b9-cfb3-4cf3-ad6f-6bec8ee80768,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-fe310c67-ad71-435a-b7ac-895ed9e95ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-88784b56-ade7-44f0-ac9e-97d7a85eadbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-bc92d171-fa0a-4067-8926-d20af811d7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221137881-172.17.0.17-1597073843809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-dd34c41e-6128-4025-a5ab-4b1ffc35777c,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-1df01d44-0758-4553-a783-a4d95d3419b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-32785e67-e0a1-4a0e-8ff2-7d16d764868a,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-1942992d-5e7d-458c-8bfc-5b36922bd8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-f5f16272-f388-43e9-892f-4bdf1972d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-de2924f8-8ffc-4f0b-8cbe-ede364c9beb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-901848b2-041f-46d2-b6a3-49f59c960bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-10ba8ea0-f9a9-4ddc-825c-1efd569e43e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221137881-172.17.0.17-1597073843809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-dd34c41e-6128-4025-a5ab-4b1ffc35777c,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-1df01d44-0758-4553-a783-a4d95d3419b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-32785e67-e0a1-4a0e-8ff2-7d16d764868a,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-1942992d-5e7d-458c-8bfc-5b36922bd8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-f5f16272-f388-43e9-892f-4bdf1972d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-de2924f8-8ffc-4f0b-8cbe-ede364c9beb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-901848b2-041f-46d2-b6a3-49f59c960bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-10ba8ea0-f9a9-4ddc-825c-1efd569e43e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-64139108-172.17.0.17-1597075022678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43814,DS-5e6540b8-f21f-4f3d-97ad-5ae575450cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-109ff2cd-1b9b-4e59-8bce-65992954947b,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-5ef4c2ef-4e05-452b-a328-953802ee1d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-a39eb67d-9677-47b6-a0a0-0fcd2f2b59d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-5f39675c-5f7f-49a0-a395-cfadb6499eed,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-326ff92a-63ca-4e64-8328-952ccbe1f31f,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-f97624c0-5e72-483f-8f0b-a5313932461f,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-7177c91c-fd90-4e9a-bf49-6ca8f0faab8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-64139108-172.17.0.17-1597075022678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43814,DS-5e6540b8-f21f-4f3d-97ad-5ae575450cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-109ff2cd-1b9b-4e59-8bce-65992954947b,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-5ef4c2ef-4e05-452b-a328-953802ee1d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-a39eb67d-9677-47b6-a0a0-0fcd2f2b59d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-5f39675c-5f7f-49a0-a395-cfadb6499eed,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-326ff92a-63ca-4e64-8328-952ccbe1f31f,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-f97624c0-5e72-483f-8f0b-a5313932461f,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-7177c91c-fd90-4e9a-bf49-6ca8f0faab8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441760799-172.17.0.17-1597075130952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34194,DS-edc72256-f071-49a1-abfb-0972db9ddbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-52d897ea-1cb6-4fe4-82a6-592009de3695,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-70c6e809-b303-4520-9418-2a9f32f670cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-102a239a-a71d-466a-83e8-63ef2caeaf41,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-b7d6138a-af79-4fff-bef6-cdf26e4b6db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-0a52b49e-a923-4be6-bad5-7fd32c735ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-33fda337-945e-409f-a4af-247b1f5ae3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-92768a8e-7225-4165-8a0c-e7b19f7717f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441760799-172.17.0.17-1597075130952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34194,DS-edc72256-f071-49a1-abfb-0972db9ddbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-52d897ea-1cb6-4fe4-82a6-592009de3695,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-70c6e809-b303-4520-9418-2a9f32f670cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-102a239a-a71d-466a-83e8-63ef2caeaf41,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-b7d6138a-af79-4fff-bef6-cdf26e4b6db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-0a52b49e-a923-4be6-bad5-7fd32c735ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-33fda337-945e-409f-a4af-247b1f5ae3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-92768a8e-7225-4165-8a0c-e7b19f7717f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183369775-172.17.0.17-1597075398626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-8fa53dd1-5f3d-471f-855c-c607aca148bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-94984235-e3c7-4ac6-b243-a16473288f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-2f403791-474a-437f-9b4c-17566ad3929d,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-ca4825de-06cc-4c2f-b396-71841cbcad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-af78e285-12e1-4729-b8aa-d30c4550e422,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-d18b496f-e8ac-44cb-9a4c-74bf6700de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-888fb7d1-c38d-49fb-b495-570469541dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-20183a5e-0b27-4c5a-91f5-ff29ef507fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183369775-172.17.0.17-1597075398626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-8fa53dd1-5f3d-471f-855c-c607aca148bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-94984235-e3c7-4ac6-b243-a16473288f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-2f403791-474a-437f-9b4c-17566ad3929d,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-ca4825de-06cc-4c2f-b396-71841cbcad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-af78e285-12e1-4729-b8aa-d30c4550e422,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-d18b496f-e8ac-44cb-9a4c-74bf6700de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-888fb7d1-c38d-49fb-b495-570469541dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-20183a5e-0b27-4c5a-91f5-ff29ef507fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: test timed out after 90000 milliseconds
stackTrace: java.lang.Exception: test timed out after 90000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1218)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:292)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253208786-172.17.0.17-1597075871932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34373,DS-73930929-0ab4-4f10-8ab0-d2b8727f514f,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-78062746-481f-4e42-9c78-bad16d598b67,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-451bda26-2637-4931-b39b-824d927333b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-5914c46b-0b5b-4f49-bca7-d6d3a86a1b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-13268598-3536-4a53-9749-42f60b96c9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-55b98068-1c6a-44d1-91f1-b32a678e9d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-6d940990-9d31-4a6d-9872-9a565a1c2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-d5245fd4-4db9-4c3e-b4aa-a1daa80e4e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253208786-172.17.0.17-1597075871932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34373,DS-73930929-0ab4-4f10-8ab0-d2b8727f514f,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-78062746-481f-4e42-9c78-bad16d598b67,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-451bda26-2637-4931-b39b-824d927333b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-5914c46b-0b5b-4f49-bca7-d6d3a86a1b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-13268598-3536-4a53-9749-42f60b96c9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-55b98068-1c6a-44d1-91f1-b32a678e9d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-6d940990-9d31-4a6d-9872-9a565a1c2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-d5245fd4-4db9-4c3e-b4aa-a1daa80e4e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814595365-172.17.0.17-1597075905872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46376,DS-eedbc628-65d6-40f8-813d-b8c96c7b06d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-2b2b1d64-eb4e-47d4-ac72-de22b56590dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-9e9b9afe-5deb-4735-bf8c-1d2db3607236,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-34be8c13-3ba0-4693-9a08-f071f04a30d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-246e2f87-d49c-460b-b1d2-0ebe0406263e,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-89ebb084-0a01-486d-a01c-b398fdf056c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-6e76e53e-b1a5-446c-8ebe-0a4d89916daa,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-bc23c494-e7e0-4043-a239-02ccc69b7cf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814595365-172.17.0.17-1597075905872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46376,DS-eedbc628-65d6-40f8-813d-b8c96c7b06d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-2b2b1d64-eb4e-47d4-ac72-de22b56590dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-9e9b9afe-5deb-4735-bf8c-1d2db3607236,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-34be8c13-3ba0-4693-9a08-f071f04a30d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-246e2f87-d49c-460b-b1d2-0ebe0406263e,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-89ebb084-0a01-486d-a01c-b398fdf056c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-6e76e53e-b1a5-446c-8ebe-0a4d89916daa,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-bc23c494-e7e0-4043-a239-02ccc69b7cf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: test timed out after 90000 milliseconds
stackTrace: java.lang.Exception: test timed out after 90000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1218)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:292)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: test timed out after 90000 milliseconds
stackTrace: java.lang.Exception: test timed out after 90000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1218)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:292)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627331802-172.17.0.17-1597076980293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33322,DS-f92136cc-6c38-48b5-a7b2-b4ec69e4c8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-dbc79562-7285-486f-8dcf-49b88073c6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-06fe1643-94e4-45a3-a548-3c8da0d9c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-7d94c0a3-c246-4a84-82d6-7e0d358df4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-559538e2-4fd6-46e0-ac70-259c88afcfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-79f5075a-d16d-40d0-b567-421843401b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-d159db1a-1179-4c54-ac09-7e62fb8b4374,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-ce8bd696-0ab1-49dc-86bb-9de2a04e04cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627331802-172.17.0.17-1597076980293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33322,DS-f92136cc-6c38-48b5-a7b2-b4ec69e4c8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-dbc79562-7285-486f-8dcf-49b88073c6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-06fe1643-94e4-45a3-a548-3c8da0d9c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-7d94c0a3-c246-4a84-82d6-7e0d358df4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-559538e2-4fd6-46e0-ac70-259c88afcfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-79f5075a-d16d-40d0-b567-421843401b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-d159db1a-1179-4c54-ac09-7e62fb8b4374,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-ce8bd696-0ab1-49dc-86bb-9de2a04e04cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663946819-172.17.0.17-1597077082763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35356,DS-5294d0b9-bcda-4474-9ebd-4dc8cf23a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-aa025573-b2d6-4b3b-af06-8d6890f3934b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-40377d1a-a59c-4fc6-a483-77ecf0bc34ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-8c2a793c-b45e-42b5-ac51-c68cfabe6c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-f2be5188-8029-47c8-b57f-a68dd1726dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-aed4b5a8-fde7-407a-8f84-f047b69756f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-224e8cb6-34a9-4357-ae37-694761e6f468,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-d90c28d7-b462-4405-8810-5d3e819d192c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663946819-172.17.0.17-1597077082763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35356,DS-5294d0b9-bcda-4474-9ebd-4dc8cf23a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-aa025573-b2d6-4b3b-af06-8d6890f3934b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-40377d1a-a59c-4fc6-a483-77ecf0bc34ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-8c2a793c-b45e-42b5-ac51-c68cfabe6c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-f2be5188-8029-47c8-b57f-a68dd1726dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-aed4b5a8-fde7-407a-8f84-f047b69756f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-224e8cb6-34a9-4357-ae37-694761e6f468,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-d90c28d7-b462-4405-8810-5d3e819d192c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398136615-172.17.0.17-1597077259532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-bb84f29a-204e-440c-86dc-d108a32d47b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-90093734-9ab9-44e6-86c5-5803ff6606c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-fce2e4c7-8f72-412e-ad25-8832da79dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-e15126bf-54e9-4959-b0c3-a34da129f3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-25780f70-83e5-4b4f-8eb6-867485568b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-3027f89e-6e76-4f6f-b77d-67de21713b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-13289886-f6a4-4e75-a03e-2dfb91b40fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-0ad783a4-3d7a-4740-8bf5-c54686c90f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398136615-172.17.0.17-1597077259532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-bb84f29a-204e-440c-86dc-d108a32d47b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-90093734-9ab9-44e6-86c5-5803ff6606c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-fce2e4c7-8f72-412e-ad25-8832da79dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-e15126bf-54e9-4959-b0c3-a34da129f3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-25780f70-83e5-4b4f-8eb6-867485568b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-3027f89e-6e76-4f6f-b77d-67de21713b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-13289886-f6a4-4e75-a03e-2dfb91b40fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-0ad783a4-3d7a-4740-8bf5-c54686c90f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674632461-172.17.0.17-1597078040604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-570a0db8-f5ee-48c8-b444-2dad8632a6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-84c25685-0c22-4a40-a3db-8855b7ef0d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-f63d6ee7-aebf-471c-badd-c779d7ede910,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-79cef282-3780-4247-86ee-34b36ec28557,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-2fb4e7e6-d4c1-437f-97b3-7fd9f43cae83,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-c89996b5-59d5-4ff9-9b20-91a9f7e7bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-969bd8ef-33f9-43f2-9446-4adb204ec649,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-57c6a027-66c7-4434-bbc6-1ec35ea7c8af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674632461-172.17.0.17-1597078040604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-570a0db8-f5ee-48c8-b444-2dad8632a6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-84c25685-0c22-4a40-a3db-8855b7ef0d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-f63d6ee7-aebf-471c-badd-c779d7ede910,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-79cef282-3780-4247-86ee-34b36ec28557,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-2fb4e7e6-d4c1-437f-97b3-7fd9f43cae83,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-c89996b5-59d5-4ff9-9b20-91a9f7e7bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-969bd8ef-33f9-43f2-9446-4adb204ec649,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-57c6a027-66c7-4434-bbc6-1ec35ea7c8af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5623
