reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826012453-172.17.0.20-1597103486845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40033,DS-fc449376-c3f9-4f13-8cb1-6fa9acc0753c,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-9599697e-f993-41e4-91d4-6435bb34661a,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-1518f3e8-dbec-4269-932e-101868b8ae15,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-8a33bee0-b453-4a38-8678-9446b1d8a016,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-44ce1bc9-4297-408e-99fe-7424feda284d,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-8d2d81b0-a88b-4691-9205-29b5ad66cd33,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-f6da2ee3-68e1-4d60-9b18-ad83f5d0df3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-02f8b651-ae53-4b80-b1fc-648fbdf4cd93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826012453-172.17.0.20-1597103486845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40033,DS-fc449376-c3f9-4f13-8cb1-6fa9acc0753c,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-9599697e-f993-41e4-91d4-6435bb34661a,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-1518f3e8-dbec-4269-932e-101868b8ae15,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-8a33bee0-b453-4a38-8678-9446b1d8a016,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-44ce1bc9-4297-408e-99fe-7424feda284d,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-8d2d81b0-a88b-4691-9205-29b5ad66cd33,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-f6da2ee3-68e1-4d60-9b18-ad83f5d0df3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-02f8b651-ae53-4b80-b1fc-648fbdf4cd93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964623215-172.17.0.20-1597104069351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-477d0d87-ba16-448d-9b03-fd78a710527f,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-9e3dedc2-c9ab-4428-a62f-4886e51b1098,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-192dddcd-bcb2-4732-b8a1-b5f4310d9834,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-e6ac06ea-0692-4f1d-9e05-8d374ba1c926,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-72e3da65-a6f3-43ae-904c-83b7bba3c617,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-a14fe360-d425-4eea-94e8-95e42e5e158d,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-ed88f39a-2c16-44f2-a1db-5146a62ec646,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-701179e8-6cd6-426f-ad0f-00b8efdf5921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964623215-172.17.0.20-1597104069351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-477d0d87-ba16-448d-9b03-fd78a710527f,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-9e3dedc2-c9ab-4428-a62f-4886e51b1098,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-192dddcd-bcb2-4732-b8a1-b5f4310d9834,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-e6ac06ea-0692-4f1d-9e05-8d374ba1c926,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-72e3da65-a6f3-43ae-904c-83b7bba3c617,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-a14fe360-d425-4eea-94e8-95e42e5e158d,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-ed88f39a-2c16-44f2-a1db-5146a62ec646,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-701179e8-6cd6-426f-ad0f-00b8efdf5921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365333635-172.17.0.20-1597104511540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-fd5946b9-c33c-4d94-aeb9-ef56d93b293a,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-329c1738-5b4b-4be1-ae32-7624f449e7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-ff33c518-8f93-4be1-8126-c293acb0eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-0e114359-964e-44f7-a948-085cb7abac90,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-ae95027b-b397-4c3c-8039-3c9b4a25ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-0719d3eb-a06b-469f-9c54-61266b8d4d23,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-7e0d8707-5e94-42b7-a303-64345d7dee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-b9e818f7-571f-47b9-85d8-d1a0fbe795ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365333635-172.17.0.20-1597104511540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-fd5946b9-c33c-4d94-aeb9-ef56d93b293a,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-329c1738-5b4b-4be1-ae32-7624f449e7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-ff33c518-8f93-4be1-8126-c293acb0eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-0e114359-964e-44f7-a948-085cb7abac90,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-ae95027b-b397-4c3c-8039-3c9b4a25ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-0719d3eb-a06b-469f-9c54-61266b8d4d23,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-7e0d8707-5e94-42b7-a303-64345d7dee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-b9e818f7-571f-47b9-85d8-d1a0fbe795ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386716231-172.17.0.20-1597104762068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-c14acb89-2017-4d92-9f62-87d3dccb0ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-39e681ef-c909-45dd-9302-07d85ef2c71d,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-cb7ac89f-009f-48f0-9755-a166fd075444,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-65df853d-dcc3-4d0e-81fd-e9802a87b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-d67d0713-fcb8-4bb5-8f49-fab8b3cd60c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-bd8d90a5-b768-486f-a3e6-68c40cf5b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-49a06b71-8507-4a9f-90aa-90c146eef4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-4ea63313-3484-4ad0-89c6-a478209ef69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386716231-172.17.0.20-1597104762068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-c14acb89-2017-4d92-9f62-87d3dccb0ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-39e681ef-c909-45dd-9302-07d85ef2c71d,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-cb7ac89f-009f-48f0-9755-a166fd075444,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-65df853d-dcc3-4d0e-81fd-e9802a87b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-d67d0713-fcb8-4bb5-8f49-fab8b3cd60c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-bd8d90a5-b768-486f-a3e6-68c40cf5b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-49a06b71-8507-4a9f-90aa-90c146eef4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-4ea63313-3484-4ad0-89c6-a478209ef69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57150116-172.17.0.20-1597105382078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44825,DS-8084b8fd-8af1-4e7c-b7b1-0feb21556f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-878d51fa-a917-42d9-8d05-b76b95fd15dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-1a2b9b90-b761-4f18-9e8a-5f5165f71bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-4a452b47-f9e7-4279-8e85-15379a803633,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-e4c64e56-978c-42c2-8941-cd790af3cb84,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-a9601660-ae92-489d-b8c6-5d01e9803435,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-1dc4e7df-3454-4e50-968f-5feaa5d30ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-d46a4ace-6209-4fef-979a-deb00dd41f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57150116-172.17.0.20-1597105382078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44825,DS-8084b8fd-8af1-4e7c-b7b1-0feb21556f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-878d51fa-a917-42d9-8d05-b76b95fd15dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-1a2b9b90-b761-4f18-9e8a-5f5165f71bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-4a452b47-f9e7-4279-8e85-15379a803633,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-e4c64e56-978c-42c2-8941-cd790af3cb84,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-a9601660-ae92-489d-b8c6-5d01e9803435,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-1dc4e7df-3454-4e50-968f-5feaa5d30ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-d46a4ace-6209-4fef-979a-deb00dd41f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905591967-172.17.0.20-1597105746166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-39b853c0-0a40-4b47-a93f-70397c4d5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-8476cd0e-6f7c-443e-9a0e-18391fbcf77b,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-e7ef066b-24d9-48af-a7ef-d430a56394c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-0932f25d-939e-4d19-9f6a-757354d82572,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-dac8b204-1c38-4235-a960-bb1028345d78,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-c291b244-7870-488c-b570-be186c4456ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-e985141b-1a50-4c62-858a-032de45ea2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-3bf0363b-b1cb-4896-8232-61de2cde0cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905591967-172.17.0.20-1597105746166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-39b853c0-0a40-4b47-a93f-70397c4d5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-8476cd0e-6f7c-443e-9a0e-18391fbcf77b,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-e7ef066b-24d9-48af-a7ef-d430a56394c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-0932f25d-939e-4d19-9f6a-757354d82572,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-dac8b204-1c38-4235-a960-bb1028345d78,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-c291b244-7870-488c-b570-be186c4456ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-e985141b-1a50-4c62-858a-032de45ea2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-3bf0363b-b1cb-4896-8232-61de2cde0cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820764833-172.17.0.20-1597105988140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33573,DS-7c2c523f-ced8-4f7c-a0fa-fbfb82dddf05,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-e22f3bdd-5441-48e5-aa78-4a1b2de652e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-8be3ad5e-7ba9-4607-8a39-c3fae3b8194f,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-5cd36f91-9740-4a39-80c8-708eec8e47d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-ddce2945-df4d-4ffd-a4f1-1f15efff4445,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-bd9db243-e330-4279-9d16-cb1dda50f516,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-3b5daaa8-b72b-424a-896f-0e4ce80ab37f,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-02174de7-ec11-4312-85b4-9aaedc9a20a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820764833-172.17.0.20-1597105988140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33573,DS-7c2c523f-ced8-4f7c-a0fa-fbfb82dddf05,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-e22f3bdd-5441-48e5-aa78-4a1b2de652e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-8be3ad5e-7ba9-4607-8a39-c3fae3b8194f,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-5cd36f91-9740-4a39-80c8-708eec8e47d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-ddce2945-df4d-4ffd-a4f1-1f15efff4445,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-bd9db243-e330-4279-9d16-cb1dda50f516,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-3b5daaa8-b72b-424a-896f-0e4ce80ab37f,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-02174de7-ec11-4312-85b4-9aaedc9a20a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350061483-172.17.0.20-1597106019280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-c96570bb-8739-42ee-aa84-090e9a99e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-4a34baeb-c172-4d5a-b758-068c2e515ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-69ddb15d-f0dd-4af6-9c63-6b8dd564f6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-7e5f8be1-95a8-4bc6-8558-181a8c6813ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-8356b126-bbc2-4379-959f-6e9d20e017e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-8ec6fca5-101d-4105-b2aa-7b4d5ec872da,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-d7ae5624-f485-4ca3-9787-7a731da68f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-dacd7aab-b88f-408f-9ffe-541daebea1d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350061483-172.17.0.20-1597106019280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-c96570bb-8739-42ee-aa84-090e9a99e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-4a34baeb-c172-4d5a-b758-068c2e515ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-69ddb15d-f0dd-4af6-9c63-6b8dd564f6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-7e5f8be1-95a8-4bc6-8558-181a8c6813ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-8356b126-bbc2-4379-959f-6e9d20e017e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-8ec6fca5-101d-4105-b2aa-7b4d5ec872da,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-d7ae5624-f485-4ca3-9787-7a731da68f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-dacd7aab-b88f-408f-9ffe-541daebea1d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865315416-172.17.0.20-1597106157092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36739,DS-ff411bd1-7fca-4958-b175-fda78b16bab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-01851ee7-db31-4684-92de-045c4b18de58,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-cec31b05-31cb-415f-a15e-24fe24d8ff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-6186e754-6827-4994-9701-4b2d4c3f4ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-a69b6b59-75ad-40d0-bcec-238c3bb562ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-bf6f8f27-0994-4ad4-83c6-5155860d48b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-4ce951d5-12d2-48bd-ac14-e5286341c163,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-3342ceef-eb07-459b-a5d9-ebc3420abd76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865315416-172.17.0.20-1597106157092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36739,DS-ff411bd1-7fca-4958-b175-fda78b16bab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-01851ee7-db31-4684-92de-045c4b18de58,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-cec31b05-31cb-415f-a15e-24fe24d8ff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-6186e754-6827-4994-9701-4b2d4c3f4ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-a69b6b59-75ad-40d0-bcec-238c3bb562ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-bf6f8f27-0994-4ad4-83c6-5155860d48b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-4ce951d5-12d2-48bd-ac14-e5286341c163,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-3342ceef-eb07-459b-a5d9-ebc3420abd76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925789510-172.17.0.20-1597106293365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-2b126ddf-c602-4d73-97d5-6cf6d15801f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-607b177f-f1d5-4ac5-8b2a-9b179ba2a719,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-fa231cc9-3b61-4945-bf1a-904aebee3e73,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-bda82dcb-bf1d-4310-bb32-96e4637cdf27,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-8e2e50aa-fb7a-4e17-a0a6-91a2e00a2b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-4a8c4441-a456-4318-b7d7-71dd8f851754,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-dcbf507f-f08b-4f2e-8d92-d199549ccff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-cee3b489-6f97-432e-9825-419f72e9c297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925789510-172.17.0.20-1597106293365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-2b126ddf-c602-4d73-97d5-6cf6d15801f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-607b177f-f1d5-4ac5-8b2a-9b179ba2a719,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-fa231cc9-3b61-4945-bf1a-904aebee3e73,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-bda82dcb-bf1d-4310-bb32-96e4637cdf27,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-8e2e50aa-fb7a-4e17-a0a6-91a2e00a2b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-4a8c4441-a456-4318-b7d7-71dd8f851754,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-dcbf507f-f08b-4f2e-8d92-d199549ccff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-cee3b489-6f97-432e-9825-419f72e9c297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302963082-172.17.0.20-1597106469326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-12c929cb-79b1-4d23-9cf9-6ec8f355c291,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-5163d33c-4ef0-4d6b-959f-0771af515445,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-2d61bace-9e7f-4a20-9c3a-be543f06b882,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-b787a473-a755-4b05-b8de-dc966d29d7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-aa5c0e0f-1d01-4fa2-ad12-ae2f6e2c70c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-73c0d801-4e5d-46b6-916f-dc4fc260b3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-1a4b5ae6-f27e-46a5-bafe-3fe01c49619a,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-31c89aa3-472c-475b-ab9f-d22a783f3f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302963082-172.17.0.20-1597106469326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-12c929cb-79b1-4d23-9cf9-6ec8f355c291,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-5163d33c-4ef0-4d6b-959f-0771af515445,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-2d61bace-9e7f-4a20-9c3a-be543f06b882,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-b787a473-a755-4b05-b8de-dc966d29d7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-aa5c0e0f-1d01-4fa2-ad12-ae2f6e2c70c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-73c0d801-4e5d-46b6-916f-dc4fc260b3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-1a4b5ae6-f27e-46a5-bafe-3fe01c49619a,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-31c89aa3-472c-475b-ab9f-d22a783f3f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361248087-172.17.0.20-1597106535446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40665,DS-69473d6d-c570-48bb-974e-335fe0694a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-a6068ea4-b85e-4fc5-9748-d6b3717dd77f,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-33cb0e9d-b52c-4002-8cc5-73289dae728c,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-9c89de8a-581c-48d4-906b-42c50b4a0cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-1acba2f6-cb29-45e5-a0de-9694d81e35b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-d791f072-fdac-4c02-b469-853d0a151262,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-10f45999-dc5c-47ac-9b39-ab5d1d5d4edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-1a0d7dea-de94-4971-8772-83215c1d26b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361248087-172.17.0.20-1597106535446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40665,DS-69473d6d-c570-48bb-974e-335fe0694a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-a6068ea4-b85e-4fc5-9748-d6b3717dd77f,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-33cb0e9d-b52c-4002-8cc5-73289dae728c,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-9c89de8a-581c-48d4-906b-42c50b4a0cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-1acba2f6-cb29-45e5-a0de-9694d81e35b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-d791f072-fdac-4c02-b469-853d0a151262,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-10f45999-dc5c-47ac-9b39-ab5d1d5d4edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-1a0d7dea-de94-4971-8772-83215c1d26b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940741534-172.17.0.20-1597106910389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-6c771ac7-eb7f-4fc9-a56e-67ca2b90ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-f70eb65f-a839-441f-8dc6-c9febc8c0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-4b4df714-2085-4e2b-9677-ea90ceeb979e,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-e6c889b1-394a-43c8-a852-f772fed90a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-572b04ba-d6ee-451c-a249-3acce0488ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-8625c07b-789d-48bb-9a53-139a61e758c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-71bdb305-077c-4ce9-ad82-83596cd7a665,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-20753a4f-11cc-4f1a-8bcc-e78596c704fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940741534-172.17.0.20-1597106910389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-6c771ac7-eb7f-4fc9-a56e-67ca2b90ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-f70eb65f-a839-441f-8dc6-c9febc8c0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-4b4df714-2085-4e2b-9677-ea90ceeb979e,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-e6c889b1-394a-43c8-a852-f772fed90a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-572b04ba-d6ee-451c-a249-3acce0488ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-8625c07b-789d-48bb-9a53-139a61e758c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-71bdb305-077c-4ce9-ad82-83596cd7a665,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-20753a4f-11cc-4f1a-8bcc-e78596c704fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953351915-172.17.0.20-1597107054393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-bcc15a3e-6800-4a9d-8213-5a2a12581d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-35861152-4ae5-41d5-ba31-f7631104cc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-f6415c3e-6a01-4961-9d3f-38e9f52c72a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-831b29b7-c403-47d5-b0ea-05925a599dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-6379fd5c-ab09-4411-94e0-cba9b62dcc91,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-2d1475ae-35d9-441e-b0fb-65c88c666952,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-20cd4dfe-d0e5-4865-803a-cd8167fe21a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-41364e22-139e-48c0-88d0-0ac299d92705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953351915-172.17.0.20-1597107054393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-bcc15a3e-6800-4a9d-8213-5a2a12581d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-35861152-4ae5-41d5-ba31-f7631104cc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-f6415c3e-6a01-4961-9d3f-38e9f52c72a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-831b29b7-c403-47d5-b0ea-05925a599dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-6379fd5c-ab09-4411-94e0-cba9b62dcc91,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-2d1475ae-35d9-441e-b0fb-65c88c666952,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-20cd4dfe-d0e5-4865-803a-cd8167fe21a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-41364e22-139e-48c0-88d0-0ac299d92705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137347988-172.17.0.20-1597107163738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37510,DS-b86001d5-ef30-41da-b6cb-f0ebdb2e3bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-8a827ee3-d765-4b14-a529-071612a516b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-27d61eb5-2d69-499d-a7c8-b605e13c8b09,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-0c25ebc3-9481-46f7-b2c8-453da0fffb33,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-aa66f25b-d79e-4fbf-9a5b-8aa8708c0eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-cb8200e8-78cc-4a1c-ab7e-bb15e55fbe30,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-0b4a34c4-eb6a-417a-b1d2-a7c6e970de1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-7661c176-0239-4672-a400-dab688ba47d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137347988-172.17.0.20-1597107163738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37510,DS-b86001d5-ef30-41da-b6cb-f0ebdb2e3bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-8a827ee3-d765-4b14-a529-071612a516b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-27d61eb5-2d69-499d-a7c8-b605e13c8b09,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-0c25ebc3-9481-46f7-b2c8-453da0fffb33,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-aa66f25b-d79e-4fbf-9a5b-8aa8708c0eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-cb8200e8-78cc-4a1c-ab7e-bb15e55fbe30,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-0b4a34c4-eb6a-417a-b1d2-a7c6e970de1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-7661c176-0239-4672-a400-dab688ba47d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459134324-172.17.0.20-1597107239692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35206,DS-a483c72b-c536-4dc8-ba14-7b96d1fb1ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-3f6a9d43-960e-4029-a682-124e1bc7f954,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-d782738a-89c8-4d11-95b5-7c068b628961,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-1f778299-4cb2-48bc-b2c3-99ee60c47322,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-771ddf5a-f045-4ec3-a558-7597b03a0b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-e7d199ab-bae8-43b4-8dfe-53486ebb51aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-8beaa7cc-8a86-4edf-8c7c-1ac3c5d04a28,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-f0de8a14-93b5-45c0-9d73-74f5b167d005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459134324-172.17.0.20-1597107239692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35206,DS-a483c72b-c536-4dc8-ba14-7b96d1fb1ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-3f6a9d43-960e-4029-a682-124e1bc7f954,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-d782738a-89c8-4d11-95b5-7c068b628961,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-1f778299-4cb2-48bc-b2c3-99ee60c47322,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-771ddf5a-f045-4ec3-a558-7597b03a0b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-e7d199ab-bae8-43b4-8dfe-53486ebb51aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-8beaa7cc-8a86-4edf-8c7c-1ac3c5d04a28,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-f0de8a14-93b5-45c0-9d73-74f5b167d005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619035715-172.17.0.20-1597107693774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41855,DS-682eea1f-30c7-4d68-ab64-d03bebd0aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-9fe2603c-2d4a-48b4-b4f5-7a031410dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-1532161d-2121-4efa-b6d5-75f8a8469f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-03f37f5c-6046-44d6-8665-9b18528b5df7,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-5faeebf7-e480-4633-9bf0-8cc42441ccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-5c3ee79e-ab8c-4922-b123-13ab7b3e850b,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-169ac0d7-3a66-4357-96a9-94159375e347,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-1512cd4f-0453-436e-b2ce-7dd67a5e40b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619035715-172.17.0.20-1597107693774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41855,DS-682eea1f-30c7-4d68-ab64-d03bebd0aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-9fe2603c-2d4a-48b4-b4f5-7a031410dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-1532161d-2121-4efa-b6d5-75f8a8469f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-03f37f5c-6046-44d6-8665-9b18528b5df7,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-5faeebf7-e480-4633-9bf0-8cc42441ccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-5c3ee79e-ab8c-4922-b123-13ab7b3e850b,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-169ac0d7-3a66-4357-96a9-94159375e347,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-1512cd4f-0453-436e-b2ce-7dd67a5e40b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148042724-172.17.0.20-1597107729404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42924,DS-c88d797c-edb9-434f-9844-dc8ee9a0b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-71815891-c5d6-48e7-a734-18a6a9de3754,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-50c4d4af-20bf-439b-9857-0980e8dfdb57,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-558f7f8d-2574-4557-b965-f4cf396c1068,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-18fa628f-c302-4f19-b22c-ed1d273605a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-bbcdd6b6-1707-4783-990b-dc47c79c66f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-a9a796c2-04c6-4a30-b669-7a1495c80303,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-df26da1b-ca9b-44aa-82d7-9bef792d03e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148042724-172.17.0.20-1597107729404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42924,DS-c88d797c-edb9-434f-9844-dc8ee9a0b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-71815891-c5d6-48e7-a734-18a6a9de3754,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-50c4d4af-20bf-439b-9857-0980e8dfdb57,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-558f7f8d-2574-4557-b965-f4cf396c1068,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-18fa628f-c302-4f19-b22c-ed1d273605a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-bbcdd6b6-1707-4783-990b-dc47c79c66f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-a9a796c2-04c6-4a30-b669-7a1495c80303,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-df26da1b-ca9b-44aa-82d7-9bef792d03e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5197
