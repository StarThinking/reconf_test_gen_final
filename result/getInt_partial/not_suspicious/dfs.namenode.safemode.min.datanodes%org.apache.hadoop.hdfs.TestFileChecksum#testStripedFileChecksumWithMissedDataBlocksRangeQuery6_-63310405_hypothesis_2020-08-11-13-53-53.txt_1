reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828983886-172.17.0.6-1597154115901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-0baeca92-9847-4a1b-8afa-87c6cd64fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-685a09de-1c0f-4c8a-b944-86f94d41c236,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-4f0d0ecc-b96b-417f-ba38-317ec4610d53,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-a47058c0-0ccb-4430-84d6-d2f0a91f179b,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-5ae9ba80-3359-4258-af09-56b766a43c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-453b7a22-1a0c-4b0c-8349-19f8c14ee276,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-5c7596b7-f7db-437c-9c35-56e97940d118,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-e5099282-0626-4be5-a218-4ba8ca3f6c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828983886-172.17.0.6-1597154115901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-0baeca92-9847-4a1b-8afa-87c6cd64fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-685a09de-1c0f-4c8a-b944-86f94d41c236,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-4f0d0ecc-b96b-417f-ba38-317ec4610d53,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-a47058c0-0ccb-4430-84d6-d2f0a91f179b,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-5ae9ba80-3359-4258-af09-56b766a43c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-453b7a22-1a0c-4b0c-8349-19f8c14ee276,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-5c7596b7-f7db-437c-9c35-56e97940d118,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-e5099282-0626-4be5-a218-4ba8ca3f6c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444944890-172.17.0.6-1597154309772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-e845636b-e745-42f0-ac8c-333e0f25a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-3750cdda-cbff-4d75-bffd-7018643b516e,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-87731826-5143-4fce-9a49-c23fc8ac79af,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-672b96ae-862e-4061-a29c-4797b0b90ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-cf2ae5df-1c05-47b8-a7ff-df24a141fb05,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-80daa9da-7bd8-4988-9889-abaae3dc2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-5b52233b-a680-4274-b6e3-96928fa6fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-241f8d33-6fdd-4a90-ac6f-1d23867ece3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444944890-172.17.0.6-1597154309772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-e845636b-e745-42f0-ac8c-333e0f25a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-3750cdda-cbff-4d75-bffd-7018643b516e,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-87731826-5143-4fce-9a49-c23fc8ac79af,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-672b96ae-862e-4061-a29c-4797b0b90ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-cf2ae5df-1c05-47b8-a7ff-df24a141fb05,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-80daa9da-7bd8-4988-9889-abaae3dc2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-5b52233b-a680-4274-b6e3-96928fa6fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-241f8d33-6fdd-4a90-ac6f-1d23867ece3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469065276-172.17.0.6-1597154407590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35798,DS-f6346f45-1d5f-41e0-918c-60311738d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-f6e88fb2-a54c-466d-ae76-e048984ead0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-a8520fed-1bbe-4a8c-a224-a7e48b2737d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-1f4229b0-bb92-4bda-adf3-7b5a0d30b482,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-b45c953f-faa4-45da-945f-fb1a2228730a,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-469f0e32-fe4e-489f-bf6a-2ffe565326be,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-ba6d60d3-513a-4856-b18e-a63c2dbfc30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-f7fcabdb-4720-4c6f-847d-97ac8280c521,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469065276-172.17.0.6-1597154407590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35798,DS-f6346f45-1d5f-41e0-918c-60311738d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-f6e88fb2-a54c-466d-ae76-e048984ead0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-a8520fed-1bbe-4a8c-a224-a7e48b2737d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-1f4229b0-bb92-4bda-adf3-7b5a0d30b482,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-b45c953f-faa4-45da-945f-fb1a2228730a,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-469f0e32-fe4e-489f-bf6a-2ffe565326be,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-ba6d60d3-513a-4856-b18e-a63c2dbfc30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-f7fcabdb-4720-4c6f-847d-97ac8280c521,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362797376-172.17.0.6-1597154473121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45841,DS-22c0e8af-fa6b-442f-9d95-bb877f3ee3af,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-cddcd5fc-a1ec-4cf2-a0f6-d97dfab426e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-5e67b485-a213-4f3a-88b3-8eda63f8b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-42c981c1-63dc-4383-a024-cf1718552947,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-426c7496-fa02-4e9b-a310-73e157b47e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-5e9d82fe-9f57-4be8-8198-02add31276fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-99370322-d87f-4346-a80d-ee1c04c8c614,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-236af6fa-f518-4887-b1f7-cb0fd6831463,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362797376-172.17.0.6-1597154473121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45841,DS-22c0e8af-fa6b-442f-9d95-bb877f3ee3af,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-cddcd5fc-a1ec-4cf2-a0f6-d97dfab426e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-5e67b485-a213-4f3a-88b3-8eda63f8b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-42c981c1-63dc-4383-a024-cf1718552947,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-426c7496-fa02-4e9b-a310-73e157b47e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-5e9d82fe-9f57-4be8-8198-02add31276fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-99370322-d87f-4346-a80d-ee1c04c8c614,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-236af6fa-f518-4887-b1f7-cb0fd6831463,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708181904-172.17.0.6-1597154617585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37649,DS-e0701c3b-f4ea-41ea-bc65-fe7430e59912,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-0ac3289d-210a-4362-9df1-a7bd790421c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-4aca8dc1-8971-4ec4-a943-5d6ad462221f,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-dfb0e83f-f38d-42fe-8adb-49fd6a6c3420,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-9e3f4808-1714-44ad-b674-e35c9457af12,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-3cbe470f-51f1-47eb-93da-00cd95ede713,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-119782fd-5cdf-48b0-bcaa-275b41f88e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-a7650fa3-16b1-4365-9660-089956ada9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708181904-172.17.0.6-1597154617585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37649,DS-e0701c3b-f4ea-41ea-bc65-fe7430e59912,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-0ac3289d-210a-4362-9df1-a7bd790421c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-4aca8dc1-8971-4ec4-a943-5d6ad462221f,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-dfb0e83f-f38d-42fe-8adb-49fd6a6c3420,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-9e3f4808-1714-44ad-b674-e35c9457af12,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-3cbe470f-51f1-47eb-93da-00cd95ede713,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-119782fd-5cdf-48b0-bcaa-275b41f88e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-a7650fa3-16b1-4365-9660-089956ada9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414178844-172.17.0.6-1597154718297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41575,DS-575e8446-4c0a-44d4-89ce-05ca0ce2865f,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-129349b8-9d5c-4974-8ee5-2aceada6813d,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-da957071-a9a2-494b-864b-76eccb1c1ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-1345387e-63e5-49c0-9646-01987980e9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-2abb4494-61fd-4078-bf26-bb2cf1c67f31,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-eb29de95-0a45-4d60-9b73-cd3e5fb51384,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-781c63b0-5af0-49b2-9efb-65933f57b910,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-95e89fe7-1ecf-463c-b9ab-f172307617ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414178844-172.17.0.6-1597154718297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41575,DS-575e8446-4c0a-44d4-89ce-05ca0ce2865f,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-129349b8-9d5c-4974-8ee5-2aceada6813d,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-da957071-a9a2-494b-864b-76eccb1c1ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-1345387e-63e5-49c0-9646-01987980e9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-2abb4494-61fd-4078-bf26-bb2cf1c67f31,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-eb29de95-0a45-4d60-9b73-cd3e5fb51384,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-781c63b0-5af0-49b2-9efb-65933f57b910,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-95e89fe7-1ecf-463c-b9ab-f172307617ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124852790-172.17.0.6-1597154752635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37621,DS-06f7bf60-3121-478d-8177-8ba99b23b559,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-ccae00be-35d7-49b8-b953-4caac8172811,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-d006e871-0fa1-4648-aaba-590b03376f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-1001a467-69d2-4274-8eac-c4df6fd841dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-7ebff9d7-3a7d-44b2-8457-4439cd9fbff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-0bb09f99-5562-4637-9363-5817858783d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-b6d84a6d-fe6f-442f-a6dd-53e11f4f9de0,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-b9fb286a-0d5d-447e-8b0a-1e041d97c7cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124852790-172.17.0.6-1597154752635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37621,DS-06f7bf60-3121-478d-8177-8ba99b23b559,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-ccae00be-35d7-49b8-b953-4caac8172811,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-d006e871-0fa1-4648-aaba-590b03376f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-1001a467-69d2-4274-8eac-c4df6fd841dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-7ebff9d7-3a7d-44b2-8457-4439cd9fbff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-0bb09f99-5562-4637-9363-5817858783d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-b6d84a6d-fe6f-442f-a6dd-53e11f4f9de0,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-b9fb286a-0d5d-447e-8b0a-1e041d97c7cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459278201-172.17.0.6-1597154816616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40922,DS-28492d16-9956-41b5-9159-7354cd0f7e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-9e6172db-b0f0-41dc-8ebc-5141ec93efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-f5522960-8471-4b53-b2c4-f5765a251147,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-b456b1d5-1679-4b03-abc2-eb4beccf3f79,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-d9bc994d-7e3d-40ac-b1de-2e64fcb1272e,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-5eae66bf-0563-4f4b-a5f6-7738bbc2d00b,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-fd143a46-d441-4422-8fc2-4c275edf0cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-90fdb96b-bebb-4c6c-9a21-e16a9755ef1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459278201-172.17.0.6-1597154816616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40922,DS-28492d16-9956-41b5-9159-7354cd0f7e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-9e6172db-b0f0-41dc-8ebc-5141ec93efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-f5522960-8471-4b53-b2c4-f5765a251147,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-b456b1d5-1679-4b03-abc2-eb4beccf3f79,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-d9bc994d-7e3d-40ac-b1de-2e64fcb1272e,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-5eae66bf-0563-4f4b-a5f6-7738bbc2d00b,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-fd143a46-d441-4422-8fc2-4c275edf0cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-90fdb96b-bebb-4c6c-9a21-e16a9755ef1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079413839-172.17.0.6-1597154926675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43329,DS-4c4304b2-b698-4fd4-8f34-db6bfeeff4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-47e05528-de21-450d-99e4-a19354a958fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-d3323b9f-541a-4b12-aff1-602f9f74a1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-15cff97a-31ee-4107-9a50-32fe790dc21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-fb322364-9912-48b0-a7fc-c28f507f783c,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-15984acf-7005-4104-a95a-823c105040c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-a48049dc-49de-4f70-ad34-a56f43bd994f,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-e5223b22-bebf-409d-8add-b2c5783b2e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079413839-172.17.0.6-1597154926675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43329,DS-4c4304b2-b698-4fd4-8f34-db6bfeeff4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-47e05528-de21-450d-99e4-a19354a958fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-d3323b9f-541a-4b12-aff1-602f9f74a1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-15cff97a-31ee-4107-9a50-32fe790dc21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-fb322364-9912-48b0-a7fc-c28f507f783c,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-15984acf-7005-4104-a95a-823c105040c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-a48049dc-49de-4f70-ad34-a56f43bd994f,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-e5223b22-bebf-409d-8add-b2c5783b2e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345653089-172.17.0.6-1597155071442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-7055787d-3eb8-445b-918a-9217fac1fcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-448911d3-893b-4391-819b-f5f5c4b2a751,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-b78c1e12-f00c-481f-a7f9-494b4b453c35,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-f77be411-9338-4d78-a45d-3a86325efafd,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-e1f50698-bf0e-4eac-8b7c-96adde89aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-c5d05f54-1f43-46a8-b231-9004cebc7d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-c829d360-f013-4a07-be9c-da56d50efc20,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-ee606dd9-cf70-45a5-a0d3-613bb9477aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345653089-172.17.0.6-1597155071442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-7055787d-3eb8-445b-918a-9217fac1fcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-448911d3-893b-4391-819b-f5f5c4b2a751,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-b78c1e12-f00c-481f-a7f9-494b4b453c35,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-f77be411-9338-4d78-a45d-3a86325efafd,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-e1f50698-bf0e-4eac-8b7c-96adde89aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-c5d05f54-1f43-46a8-b231-9004cebc7d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-c829d360-f013-4a07-be9c-da56d50efc20,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-ee606dd9-cf70-45a5-a0d3-613bb9477aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141924407-172.17.0.6-1597155368101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44971,DS-482a47ec-f5b4-4bbf-b3a9-a71840879021,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-7aba2e7a-e2f4-4a48-b13c-72a37827209b,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-8624ee1a-1591-4e67-a1be-ae853c60eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-dd33745a-8646-425e-a814-c0d1d087936d,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-e8ea6f67-ceb1-4134-94e2-71edac50207b,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-bf7e8a53-6449-4ef6-9b7d-333f7d84e63f,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-9e29e395-ba32-4b60-9f27-cc970be97d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-20435655-0f94-47af-95e2-47e222f1a322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141924407-172.17.0.6-1597155368101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44971,DS-482a47ec-f5b4-4bbf-b3a9-a71840879021,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-7aba2e7a-e2f4-4a48-b13c-72a37827209b,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-8624ee1a-1591-4e67-a1be-ae853c60eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-dd33745a-8646-425e-a814-c0d1d087936d,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-e8ea6f67-ceb1-4134-94e2-71edac50207b,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-bf7e8a53-6449-4ef6-9b7d-333f7d84e63f,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-9e29e395-ba32-4b60-9f27-cc970be97d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-20435655-0f94-47af-95e2-47e222f1a322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685623804-172.17.0.6-1597155601423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37310,DS-046a5dd8-97a3-4923-a278-11d7144e86ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-7c03e0b3-c0fa-469d-9c0a-9b533ca7835d,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-38a330f8-cf4c-4360-b4ef-336c0a7fdea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-b5b95b29-5597-4f95-98c8-9e2270e9fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-d7c02490-dcd3-492a-ba0c-6c612b0b5628,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-62cf6219-6bbe-464e-9c3c-7b593b67f6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-32e6f61e-d344-4c39-8d9c-ba6a2ccda6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-20373334-39cb-4be7-8c2f-0d02cf218736,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685623804-172.17.0.6-1597155601423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37310,DS-046a5dd8-97a3-4923-a278-11d7144e86ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-7c03e0b3-c0fa-469d-9c0a-9b533ca7835d,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-38a330f8-cf4c-4360-b4ef-336c0a7fdea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-b5b95b29-5597-4f95-98c8-9e2270e9fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-d7c02490-dcd3-492a-ba0c-6c612b0b5628,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-62cf6219-6bbe-464e-9c3c-7b593b67f6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-32e6f61e-d344-4c39-8d9c-ba6a2ccda6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-20373334-39cb-4be7-8c2f-0d02cf218736,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102370320-172.17.0.6-1597155638918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45925,DS-92f12397-52cc-49ba-9a90-1c062911f176,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-4d899f6b-7141-4ebd-a4cb-5eafd561be76,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-c2958707-20d7-4df5-979f-3550da2c6410,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-5ee68722-b873-4fff-9eaf-1dccf7565e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-632ddaf2-be3f-450e-8f9f-22bf64d432d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-f7a7d142-33fb-4e09-a4bb-356f65e50302,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-b972b0ab-c2e6-45bc-b6e6-b84a27e60708,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-1370a082-a88e-47d8-ad4e-be55d6c223f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102370320-172.17.0.6-1597155638918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45925,DS-92f12397-52cc-49ba-9a90-1c062911f176,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-4d899f6b-7141-4ebd-a4cb-5eafd561be76,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-c2958707-20d7-4df5-979f-3550da2c6410,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-5ee68722-b873-4fff-9eaf-1dccf7565e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-632ddaf2-be3f-450e-8f9f-22bf64d432d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-f7a7d142-33fb-4e09-a4bb-356f65e50302,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-b972b0ab-c2e6-45bc-b6e6-b84a27e60708,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-1370a082-a88e-47d8-ad4e-be55d6c223f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42658459-172.17.0.6-1597155680892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33573,DS-d58b9324-99a3-4339-ae8c-edb9a8997483,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-b1d64de3-4a1e-4e34-848a-c0fdaf69ec69,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-03cb6fd0-5d91-4df7-9a8c-2775b7f5260d,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-5a361615-68d2-4650-9072-8f86afc8394f,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-23f61bb1-0ce3-446a-a6c7-07627711250f,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-48c02f4a-e5d4-45d6-8eb6-bd1bef6a57c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-5ccb8013-0021-46f8-a9e9-7f66f62d00e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-f87981d4-021a-4fd3-9f69-9cd85d10a898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42658459-172.17.0.6-1597155680892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33573,DS-d58b9324-99a3-4339-ae8c-edb9a8997483,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-b1d64de3-4a1e-4e34-848a-c0fdaf69ec69,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-03cb6fd0-5d91-4df7-9a8c-2775b7f5260d,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-5a361615-68d2-4650-9072-8f86afc8394f,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-23f61bb1-0ce3-446a-a6c7-07627711250f,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-48c02f4a-e5d4-45d6-8eb6-bd1bef6a57c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-5ccb8013-0021-46f8-a9e9-7f66f62d00e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-f87981d4-021a-4fd3-9f69-9cd85d10a898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450124204-172.17.0.6-1597155826909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-9f9d944f-b20a-42f0-99de-8ee7d5bcb9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-b5d52869-5bb5-4719-a24f-3f3cc60a9f07,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-79921e82-1e4e-4860-9cd5-acecf27c30a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-3cd2bc0a-e5ac-4f8a-a1b6-b52d47586901,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-7f2e7847-fda2-4ae0-acc9-9a59cb2d1c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-c880bffa-a7c8-47c3-8614-ef825d94d71c,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-3925292a-0811-40ab-8d4a-5c5d65c3e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-055b1c6a-fce1-49b5-9daf-6d66ae466fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450124204-172.17.0.6-1597155826909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-9f9d944f-b20a-42f0-99de-8ee7d5bcb9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-b5d52869-5bb5-4719-a24f-3f3cc60a9f07,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-79921e82-1e4e-4860-9cd5-acecf27c30a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-3cd2bc0a-e5ac-4f8a-a1b6-b52d47586901,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-7f2e7847-fda2-4ae0-acc9-9a59cb2d1c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-c880bffa-a7c8-47c3-8614-ef825d94d71c,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-3925292a-0811-40ab-8d4a-5c5d65c3e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-055b1c6a-fce1-49b5-9daf-6d66ae466fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090269381-172.17.0.6-1597155865366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-80e20cf2-af1c-44ec-8aea-9b439bd11e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-0e676391-b967-4573-9e1c-94d433f4d9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-6071f294-fdf1-4617-879d-61a33f014f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-51e48851-c528-4db1-96ef-a5bbde4d382b,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-4eedfa77-caa9-40ed-b437-c5fa99b3c8be,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-b8026af5-ce85-4169-a789-ae59741f13fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-52dbe304-2c6a-4f21-9be3-496323d446bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-466b540f-e5c3-483d-a8cc-ba7f651d5f74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090269381-172.17.0.6-1597155865366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-80e20cf2-af1c-44ec-8aea-9b439bd11e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-0e676391-b967-4573-9e1c-94d433f4d9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-6071f294-fdf1-4617-879d-61a33f014f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-51e48851-c528-4db1-96ef-a5bbde4d382b,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-4eedfa77-caa9-40ed-b437-c5fa99b3c8be,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-b8026af5-ce85-4169-a789-ae59741f13fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-52dbe304-2c6a-4f21-9be3-496323d446bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-466b540f-e5c3-483d-a8cc-ba7f651d5f74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349008993-172.17.0.6-1597155971863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42587,DS-001d8300-e8bc-4fe7-827b-44ef9cd52693,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-cd645e96-33b1-4616-a7b7-a659dd26d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-729681b3-ec44-4bc7-b1a2-9aa38058d037,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-ab80401d-5487-4d9c-9cac-64ce7cd9c65e,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-04d5cea7-c7fd-4afe-bef3-6860fb228ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-518265c5-8318-4fbc-871e-b2d44f5ddad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-76a8e1e5-9119-43fe-9293-d6ea19137498,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-7b67e419-12b3-4908-85b4-2a8e04d00d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349008993-172.17.0.6-1597155971863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42587,DS-001d8300-e8bc-4fe7-827b-44ef9cd52693,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-cd645e96-33b1-4616-a7b7-a659dd26d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-729681b3-ec44-4bc7-b1a2-9aa38058d037,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-ab80401d-5487-4d9c-9cac-64ce7cd9c65e,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-04d5cea7-c7fd-4afe-bef3-6860fb228ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-518265c5-8318-4fbc-871e-b2d44f5ddad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-76a8e1e5-9119-43fe-9293-d6ea19137498,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-7b67e419-12b3-4908-85b4-2a8e04d00d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627272377-172.17.0.6-1597156118574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-4ca97292-269d-4800-877a-67dc2ab229ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-1342df5f-3101-4cc8-a34f-74ab0c0d9aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-bdff28e3-4831-4bf1-827c-1dc47448d9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-bcefe141-cc8e-41f4-bdd7-46fed73f3815,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-4ebdff05-7e5b-45ff-9754-d1cbb6558512,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-1384093b-b7ed-42d5-bebe-cbb0f386f06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-36521c52-b824-4df9-8f9b-71fa75f3299c,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-cf4ab55a-bf15-4653-8782-53a26517f41b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627272377-172.17.0.6-1597156118574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-4ca97292-269d-4800-877a-67dc2ab229ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-1342df5f-3101-4cc8-a34f-74ab0c0d9aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-bdff28e3-4831-4bf1-827c-1dc47448d9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-bcefe141-cc8e-41f4-bdd7-46fed73f3815,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-4ebdff05-7e5b-45ff-9754-d1cbb6558512,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-1384093b-b7ed-42d5-bebe-cbb0f386f06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-36521c52-b824-4df9-8f9b-71fa75f3299c,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-cf4ab55a-bf15-4653-8782-53a26517f41b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095364210-172.17.0.6-1597156199711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40362,DS-66a3f9e8-6b0c-408f-b4e8-8662d8df92ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-5609fd6f-f665-4cd9-b208-fe6df219cd61,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-7bfc192f-1ed6-4e64-9fec-2ac89dacee8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-2f7dc67d-5746-4f8a-966c-f92e4c1ffb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-96ec6348-ce54-4d38-964a-84162c6361a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-dea86220-c1bd-4e12-a071-fd0fa7b64b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-95feba1f-780d-498d-b77f-e5a6db969bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-adf5ee83-25ae-4839-a399-bff9e21df37e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095364210-172.17.0.6-1597156199711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40362,DS-66a3f9e8-6b0c-408f-b4e8-8662d8df92ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-5609fd6f-f665-4cd9-b208-fe6df219cd61,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-7bfc192f-1ed6-4e64-9fec-2ac89dacee8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-2f7dc67d-5746-4f8a-966c-f92e4c1ffb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-96ec6348-ce54-4d38-964a-84162c6361a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-dea86220-c1bd-4e12-a071-fd0fa7b64b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-95feba1f-780d-498d-b77f-e5a6db969bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-adf5ee83-25ae-4839-a399-bff9e21df37e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620816448-172.17.0.6-1597156437175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-1b496ebf-da2e-4cfb-8734-ff30ba5029d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-56425831-980e-4ea0-a2e4-9c230bc1738f,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-0354d6b9-3fc1-48c7-a1d9-c6792e5c3040,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-ba7c7952-0725-435e-8ab0-2a8c190a6b35,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-422bfeae-d22c-4a4e-be77-5dd05221b819,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-d468947c-f68a-4d5e-8232-9446fa528157,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-a09196c0-134c-4a37-8e93-e5c1eeb50c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-1d16af40-920c-407c-a086-0d275641b20e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620816448-172.17.0.6-1597156437175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-1b496ebf-da2e-4cfb-8734-ff30ba5029d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-56425831-980e-4ea0-a2e4-9c230bc1738f,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-0354d6b9-3fc1-48c7-a1d9-c6792e5c3040,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-ba7c7952-0725-435e-8ab0-2a8c190a6b35,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-422bfeae-d22c-4a4e-be77-5dd05221b819,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-d468947c-f68a-4d5e-8232-9446fa528157,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-a09196c0-134c-4a37-8e93-e5c1eeb50c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-1d16af40-920c-407c-a086-0d275641b20e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406564424-172.17.0.6-1597156662558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40241,DS-8863e255-752d-4dfd-978d-51fec70a31a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-e8ae1d43-a77b-463f-bcce-a0ed4035c235,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-ecb6f14d-f6df-47b7-8978-215e1a9fdf20,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-b3f65f19-c330-4453-9716-df266f59b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-ab82952c-e5d6-4d3e-9d24-2de698d95339,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-870b554a-80dc-4d95-8f96-1732ce6eb1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-8062cfb4-e8d4-4a34-8664-67d27de3fbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-38a395a9-ed0b-4071-a20b-9b648c52ff29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406564424-172.17.0.6-1597156662558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40241,DS-8863e255-752d-4dfd-978d-51fec70a31a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-e8ae1d43-a77b-463f-bcce-a0ed4035c235,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-ecb6f14d-f6df-47b7-8978-215e1a9fdf20,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-b3f65f19-c330-4453-9716-df266f59b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-ab82952c-e5d6-4d3e-9d24-2de698d95339,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-870b554a-80dc-4d95-8f96-1732ce6eb1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-8062cfb4-e8d4-4a34-8664-67d27de3fbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-38a395a9-ed0b-4071-a20b-9b648c52ff29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300249280-172.17.0.6-1597156734807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44804,DS-f0e011ba-83f2-4394-9ff0-25559d523651,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-df86d349-a7d7-441c-9ba3-c3fc7ccf7d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-7c89078e-40f0-4583-a169-98ad4d6fda95,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-7a5d5aa1-9884-4235-98c0-13dbb6e22a75,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-73b4faa5-c1e7-4fcb-8407-55ef3e6e9d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-7ffb8942-5867-44e5-be5a-9e270fe999d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-bb6d49d1-0095-4dac-9d4f-80247b2a3ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-f4079590-8c77-4193-a35f-03c14b4ca768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300249280-172.17.0.6-1597156734807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44804,DS-f0e011ba-83f2-4394-9ff0-25559d523651,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-df86d349-a7d7-441c-9ba3-c3fc7ccf7d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-7c89078e-40f0-4583-a169-98ad4d6fda95,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-7a5d5aa1-9884-4235-98c0-13dbb6e22a75,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-73b4faa5-c1e7-4fcb-8407-55ef3e6e9d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-7ffb8942-5867-44e5-be5a-9e270fe999d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-bb6d49d1-0095-4dac-9d4f-80247b2a3ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-f4079590-8c77-4193-a35f-03c14b4ca768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117853254-172.17.0.6-1597156777082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-f6053804-5439-47cf-aa05-8f6e5b70bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-8670cb73-862f-4461-80fb-49284677cae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-0354a899-5bad-44b7-a56c-a36f3fab394e,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f16107f3-9cfc-4f6a-99a8-84fd5ec61502,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-313ff616-60f2-4133-98c2-fd386a8d796a,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-b1e4f2f9-b4ed-49ba-b17d-006d9366d003,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-d87b8696-a53c-4cb8-bf62-c2d14b610148,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-d5cad993-791c-433d-9c1c-000ba95138fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117853254-172.17.0.6-1597156777082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-f6053804-5439-47cf-aa05-8f6e5b70bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-8670cb73-862f-4461-80fb-49284677cae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-0354a899-5bad-44b7-a56c-a36f3fab394e,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f16107f3-9cfc-4f6a-99a8-84fd5ec61502,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-313ff616-60f2-4133-98c2-fd386a8d796a,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-b1e4f2f9-b4ed-49ba-b17d-006d9366d003,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-d87b8696-a53c-4cb8-bf62-c2d14b610148,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-d5cad993-791c-433d-9c1c-000ba95138fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273258502-172.17.0.6-1597156877899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37222,DS-cac11e1a-df13-474d-8c73-334d97fc036f,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-3a3c5805-0e8e-4194-857f-8b1b0b88d74f,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-d2479877-3aa3-405c-9a58-04e34d7e0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-15dcc42b-ff0e-4b81-bea5-14adfd0cdd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-40b51a58-4664-4cc4-922c-51c1b12a7ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-a746290f-add1-43bd-90d5-6d0b43862e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-bc059265-7c05-4496-bc27-ae137a9aac51,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-023f7d98-4da7-49bc-b469-5f660ec5a29b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273258502-172.17.0.6-1597156877899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37222,DS-cac11e1a-df13-474d-8c73-334d97fc036f,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-3a3c5805-0e8e-4194-857f-8b1b0b88d74f,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-d2479877-3aa3-405c-9a58-04e34d7e0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-15dcc42b-ff0e-4b81-bea5-14adfd0cdd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-40b51a58-4664-4cc4-922c-51c1b12a7ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-a746290f-add1-43bd-90d5-6d0b43862e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-bc059265-7c05-4496-bc27-ae137a9aac51,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-023f7d98-4da7-49bc-b469-5f660ec5a29b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396134660-172.17.0.6-1597157195038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-58454e49-93f0-4a20-a01b-c0c61d3eec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-56bb0616-00bc-4d32-b202-134f8c4a9906,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-827f6166-ce72-40ef-b2b2-d3009f501f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-19c01c07-d77d-4cdc-84f5-a8cbf2383023,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-d12c3c1b-6521-40cb-b31f-50478a576996,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-35b769eb-50ec-451d-b714-ca0b7384600a,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-70c8933e-f169-44e3-b2cd-36bec33c30f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-35b83ad4-2ced-4240-9974-109de099002f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396134660-172.17.0.6-1597157195038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-58454e49-93f0-4a20-a01b-c0c61d3eec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-56bb0616-00bc-4d32-b202-134f8c4a9906,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-827f6166-ce72-40ef-b2b2-d3009f501f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-19c01c07-d77d-4cdc-84f5-a8cbf2383023,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-d12c3c1b-6521-40cb-b31f-50478a576996,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-35b769eb-50ec-451d-b714-ca0b7384600a,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-70c8933e-f169-44e3-b2cd-36bec33c30f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-35b83ad4-2ced-4240-9974-109de099002f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254129371-172.17.0.6-1597157480890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42403,DS-68d31e20-fa37-4c3f-bc69-57f8c05b5ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-5e2c9573-9408-4949-9f9e-7eb3f60afdde,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-fe5c80ff-eef9-4f6a-b429-8fbfc8e03e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-225a87bd-9389-40f4-a4d9-9f1896781b64,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-d8b4150e-6da7-4952-9640-1a96658f1e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-71d0dd6b-b698-4017-8c25-5fd4b57b1d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-c0b08fa0-85e6-44d0-bdad-47d6d349efea,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-d32c6f31-97dd-4eab-8a5c-6f96605524b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254129371-172.17.0.6-1597157480890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42403,DS-68d31e20-fa37-4c3f-bc69-57f8c05b5ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-5e2c9573-9408-4949-9f9e-7eb3f60afdde,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-fe5c80ff-eef9-4f6a-b429-8fbfc8e03e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-225a87bd-9389-40f4-a4d9-9f1896781b64,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-d8b4150e-6da7-4952-9640-1a96658f1e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-71d0dd6b-b698-4017-8c25-5fd4b57b1d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-c0b08fa0-85e6-44d0-bdad-47d6d349efea,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-d32c6f31-97dd-4eab-8a5c-6f96605524b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464998343-172.17.0.6-1597157617554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41383,DS-203a1d81-8c09-4c2b-ae19-e19ccd464936,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-2a7fe06a-f708-4c05-9122-e8c5a07256c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-c3885d9a-ae57-4b8f-aa40-df84e181a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-5345870a-c82d-440f-aecb-58995feab389,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-b095cb8c-56fc-4515-b78e-1d7a9312b690,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-c809da4c-a74d-4674-8d60-b5b5b612143b,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-606fa6ba-d8ca-41d4-a72b-ac5742e2dcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-e49e0eb5-6d9b-49de-b41e-9270e896bdc6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464998343-172.17.0.6-1597157617554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41383,DS-203a1d81-8c09-4c2b-ae19-e19ccd464936,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-2a7fe06a-f708-4c05-9122-e8c5a07256c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-c3885d9a-ae57-4b8f-aa40-df84e181a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-5345870a-c82d-440f-aecb-58995feab389,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-b095cb8c-56fc-4515-b78e-1d7a9312b690,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-c809da4c-a74d-4674-8d60-b5b5b612143b,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-606fa6ba-d8ca-41d4-a72b-ac5742e2dcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-e49e0eb5-6d9b-49de-b41e-9270e896bdc6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664674409-172.17.0.6-1597157844654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-fa6a64d0-a205-4fe6-a00d-51bdf7744837,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-b988fb5d-c868-4af5-962b-d74ba188e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-a111dc34-8909-4dc8-ae89-3bd92ed82a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-3109c471-1460-4101-8ed2-e039b595d55f,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-81778f60-1122-4630-b0f1-e4a5bd7d52e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-9c7c2847-1c7d-40ef-a975-ab2b761b7d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-fe463518-e813-47d3-93d1-4547f11f3ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-e345dc85-6d31-4b0e-b178-38f6bff2f03b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664674409-172.17.0.6-1597157844654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-fa6a64d0-a205-4fe6-a00d-51bdf7744837,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-b988fb5d-c868-4af5-962b-d74ba188e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-a111dc34-8909-4dc8-ae89-3bd92ed82a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-3109c471-1460-4101-8ed2-e039b595d55f,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-81778f60-1122-4630-b0f1-e4a5bd7d52e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-9c7c2847-1c7d-40ef-a975-ab2b761b7d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-fe463518-e813-47d3-93d1-4547f11f3ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-e345dc85-6d31-4b0e-b178-38f6bff2f03b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171686488-172.17.0.6-1597157918583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-abee5238-63b2-4292-b024-88646b795609,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-f656fbf2-97fd-48ea-a99e-2d92def3bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-f9dc27ed-f4c8-441d-8490-ebdd0e9392c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-c1433622-9f0b-43e7-8c19-b173f9355f99,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-d8d79b6a-c6d7-4b0f-8b66-2359788fe29a,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-eea0a102-fcb4-460c-a778-2e0ac013b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-fedf0e36-4c95-4aff-ba9a-2de81f507177,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-540412fd-f9fd-405e-8153-eaf97f921798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171686488-172.17.0.6-1597157918583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-abee5238-63b2-4292-b024-88646b795609,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-f656fbf2-97fd-48ea-a99e-2d92def3bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-f9dc27ed-f4c8-441d-8490-ebdd0e9392c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-c1433622-9f0b-43e7-8c19-b173f9355f99,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-d8d79b6a-c6d7-4b0f-8b66-2359788fe29a,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-eea0a102-fcb4-460c-a778-2e0ac013b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-fedf0e36-4c95-4aff-ba9a-2de81f507177,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-540412fd-f9fd-405e-8153-eaf97f921798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291900893-172.17.0.6-1597158028274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33906,DS-bb3b4d95-015c-47ae-bbdf-34253be183be,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-3a896864-f3f0-4081-b19f-3fac98ff98d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-44603024-2bfb-4d18-b136-0a76ed8868dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-f7abc086-f854-4b5d-9061-0d81f3566dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-2404496a-6055-453e-a423-20aa8b9c0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-3be9c3bc-d89b-4f29-93e2-17fbaa3c3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-24c7332d-83d1-4c8c-83f3-27287c69f448,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-3b643f17-aa3d-45d5-83c8-d3985b1f1bd3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291900893-172.17.0.6-1597158028274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33906,DS-bb3b4d95-015c-47ae-bbdf-34253be183be,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-3a896864-f3f0-4081-b19f-3fac98ff98d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-44603024-2bfb-4d18-b136-0a76ed8868dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-f7abc086-f854-4b5d-9061-0d81f3566dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-2404496a-6055-453e-a423-20aa8b9c0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-3be9c3bc-d89b-4f29-93e2-17fbaa3c3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-24c7332d-83d1-4c8c-83f3-27287c69f448,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-3b643f17-aa3d-45d5-83c8-d3985b1f1bd3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533248835-172.17.0.6-1597158328237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-10b8c278-3098-41bd-9440-c4b980b3131f,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-0034ab76-ef45-4739-96b9-485205ed6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-4034954e-d80e-4949-8962-c1614a4ecf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-34d6dc07-5adb-4a66-bf6c-b8cdd3f597cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-04ade299-3bf2-4fe0-b650-bc049afed17c,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-696c77ed-3b88-4f8a-ad3b-f3ba65e7bf45,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-c0bcd670-1a3b-4f78-b17d-24b494342a16,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-60f59807-e9cd-4bb1-9a60-38f6efd9b504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533248835-172.17.0.6-1597158328237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-10b8c278-3098-41bd-9440-c4b980b3131f,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-0034ab76-ef45-4739-96b9-485205ed6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-4034954e-d80e-4949-8962-c1614a4ecf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-34d6dc07-5adb-4a66-bf6c-b8cdd3f597cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-04ade299-3bf2-4fe0-b650-bc049afed17c,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-696c77ed-3b88-4f8a-ad3b-f3ba65e7bf45,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-c0bcd670-1a3b-4f78-b17d-24b494342a16,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-60f59807-e9cd-4bb1-9a60-38f6efd9b504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609732864-172.17.0.6-1597158361413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-fc97f411-8fda-45eb-af40-ca394e703771,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-86996674-40e7-411d-a8f6-1ef901af16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-3eca9abc-3178-4e51-8e5a-e42915f07f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-30b3f959-6376-415a-a485-82656fca5453,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-d9637dc6-2c4c-49b8-b594-714606326bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-adfe37a2-7d8b-4c7d-9a76-7125464539ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-feb896ec-a96f-4ccf-b0bc-4314452f0263,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-c9b0c599-7227-493c-969b-c141ac175a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609732864-172.17.0.6-1597158361413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-fc97f411-8fda-45eb-af40-ca394e703771,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-86996674-40e7-411d-a8f6-1ef901af16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-3eca9abc-3178-4e51-8e5a-e42915f07f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-30b3f959-6376-415a-a485-82656fca5453,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-d9637dc6-2c4c-49b8-b594-714606326bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-adfe37a2-7d8b-4c7d-9a76-7125464539ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-feb896ec-a96f-4ccf-b0bc-4314452f0263,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-c9b0c599-7227-493c-969b-c141ac175a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243737484-172.17.0.6-1597158616412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-3dedbbc4-86e0-4185-99b3-d5da10cf4170,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-69e8d668-55f7-4a0d-bfdc-cd89aca147ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-b83b7503-eb1d-4bfe-bacb-ae912a423e80,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-ee0cdc1d-9c24-4409-a4a0-49329d8c82fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-eceb61a9-90e6-4b5e-a2f6-920fbe242f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-b82db10a-9063-414b-b402-73e7c17a4144,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-7f39cef4-94ad-445b-9302-abdbbe82f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-df953384-70b0-419e-9fcf-c0055e10cb55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243737484-172.17.0.6-1597158616412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-3dedbbc4-86e0-4185-99b3-d5da10cf4170,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-69e8d668-55f7-4a0d-bfdc-cd89aca147ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-b83b7503-eb1d-4bfe-bacb-ae912a423e80,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-ee0cdc1d-9c24-4409-a4a0-49329d8c82fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-eceb61a9-90e6-4b5e-a2f6-920fbe242f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-b82db10a-9063-414b-b402-73e7c17a4144,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-7f39cef4-94ad-445b-9302-abdbbe82f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-df953384-70b0-419e-9fcf-c0055e10cb55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488579217-172.17.0.6-1597159041378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45568,DS-dcbf88fa-d81b-4592-9842-8102b14d4589,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-c72d1ed7-11a7-40de-815e-7f51ed883596,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-b15c54c3-4aa3-4fa0-921f-1a9fbb08ad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-46ff2118-e295-458a-bd7b-7f77317dd162,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-e8fb38b1-6aaf-4482-b506-b84a3c4b2528,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-9e498f1b-817a-43b7-838a-8398c218a0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-2783a6c8-2fd2-4e9f-b0fc-145cdd3846e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-f3f0ca1e-951f-4402-b00e-1d6b6b8132c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488579217-172.17.0.6-1597159041378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45568,DS-dcbf88fa-d81b-4592-9842-8102b14d4589,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-c72d1ed7-11a7-40de-815e-7f51ed883596,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-b15c54c3-4aa3-4fa0-921f-1a9fbb08ad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-46ff2118-e295-458a-bd7b-7f77317dd162,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-e8fb38b1-6aaf-4482-b506-b84a3c4b2528,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-9e498f1b-817a-43b7-838a-8398c218a0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-2783a6c8-2fd2-4e9f-b0fc-145cdd3846e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-f3f0ca1e-951f-4402-b00e-1d6b6b8132c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216723127-172.17.0.6-1597159158962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-5417aca0-6399-4ced-83ab-5f7caa91d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-288e01e8-379f-4068-b85f-1c38e4889a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-5dceee28-17bb-4fcb-9b49-2bb1cc2f6648,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-268774d2-3446-4501-8e0a-d0db5bf499b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-576149b4-977e-4e0f-8262-23cdea553033,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-e20624dc-ac32-43ad-bb9c-b38c87da68e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-98ab5aad-866a-4373-a65b-3f17c4567d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-abbfb125-5d69-4f70-b197-5e98d0c1ab75,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216723127-172.17.0.6-1597159158962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-5417aca0-6399-4ced-83ab-5f7caa91d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-288e01e8-379f-4068-b85f-1c38e4889a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-5dceee28-17bb-4fcb-9b49-2bb1cc2f6648,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-268774d2-3446-4501-8e0a-d0db5bf499b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-576149b4-977e-4e0f-8262-23cdea553033,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-e20624dc-ac32-43ad-bb9c-b38c87da68e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-98ab5aad-866a-4373-a65b-3f17c4567d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-abbfb125-5d69-4f70-b197-5e98d0c1ab75,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321937046-172.17.0.6-1597159264345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42134,DS-da8e5552-afd9-449f-bcde-942c7f2d2ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-580de552-90cf-47af-9d63-6d46019aa900,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-45ad47e4-90ba-43a1-b524-e29ee5ebfd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-a2b6aa0a-5632-4a97-aa19-f520d26335bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-ec13ff93-2bf5-4e08-9642-8510e174fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-80e20f94-6e77-4253-8365-be61ee9af7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-bce679ef-ce38-4da7-81ea-391deb1ce966,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-a3846db9-de0d-46e6-98e4-00b4aeba787b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321937046-172.17.0.6-1597159264345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42134,DS-da8e5552-afd9-449f-bcde-942c7f2d2ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-580de552-90cf-47af-9d63-6d46019aa900,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-45ad47e4-90ba-43a1-b524-e29ee5ebfd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-a2b6aa0a-5632-4a97-aa19-f520d26335bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-ec13ff93-2bf5-4e08-9642-8510e174fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-80e20f94-6e77-4253-8365-be61ee9af7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-bce679ef-ce38-4da7-81ea-391deb1ce966,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-a3846db9-de0d-46e6-98e4-00b4aeba787b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392201583-172.17.0.6-1597159342150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-f8a2c00e-a58e-4626-806a-1fb2870298d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-79fe1347-a962-4c45-85c8-81c6e59f59b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-a547bb66-fc58-4a3a-9fef-098fb08af1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-e3bd378f-5eba-4080-b1f6-258f34344ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-40fd0a9b-ec9c-414b-b0bf-0623f588ab02,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-74750c2b-53a5-4137-857a-a8a097ac3a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-67349da5-dbaa-4d43-82dd-8f271e0c9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-b3f346da-a9a9-429e-a56f-aa51546fa652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392201583-172.17.0.6-1597159342150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-f8a2c00e-a58e-4626-806a-1fb2870298d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-79fe1347-a962-4c45-85c8-81c6e59f59b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-a547bb66-fc58-4a3a-9fef-098fb08af1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-e3bd378f-5eba-4080-b1f6-258f34344ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-40fd0a9b-ec9c-414b-b0bf-0623f588ab02,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-74750c2b-53a5-4137-857a-a8a097ac3a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-67349da5-dbaa-4d43-82dd-8f271e0c9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-b3f346da-a9a9-429e-a56f-aa51546fa652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 5507
