reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056632823-172.17.0.6-1597150561109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41274,DS-a9ee2c23-fb9f-4ab2-984f-2cd0074ca2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-a6edeb3c-bd51-43c7-b7f6-f4b319c41432,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-0d495d4d-08fb-4527-a335-a2ff29aaa5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-f49820da-49e4-45c1-8a38-aa7d87861841,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-deea5d9e-c3bf-4070-a4c8-8c4ef4a2f3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-82d939bc-2de6-41b2-8298-21c947382c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-cc949f71-2546-4f8d-8374-efbe84ee309d,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-c370fb43-3248-4274-aa75-b723cf2e1ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056632823-172.17.0.6-1597150561109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41274,DS-a9ee2c23-fb9f-4ab2-984f-2cd0074ca2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-a6edeb3c-bd51-43c7-b7f6-f4b319c41432,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-0d495d4d-08fb-4527-a335-a2ff29aaa5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-f49820da-49e4-45c1-8a38-aa7d87861841,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-deea5d9e-c3bf-4070-a4c8-8c4ef4a2f3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-82d939bc-2de6-41b2-8298-21c947382c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-cc949f71-2546-4f8d-8374-efbe84ee309d,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-c370fb43-3248-4274-aa75-b723cf2e1ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076392949-172.17.0.6-1597150857954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38479,DS-50f36cd7-9537-492b-bd34-aea55b3bd9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-2b9b1346-2c8a-496b-be0a-9c0dd24b2c61,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-db9a7d58-1797-4533-b4d8-e46338345cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-62f3704e-990f-49e5-9b6a-7712d466395e,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-84b7be65-33e2-481e-9c5e-6f898a06d379,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-317a728d-d44d-4b19-886c-226171ac5550,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-1feb59a2-258d-414c-9bf3-434a70828105,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-4111ee4d-4671-4632-972f-25e650edac82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076392949-172.17.0.6-1597150857954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38479,DS-50f36cd7-9537-492b-bd34-aea55b3bd9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-2b9b1346-2c8a-496b-be0a-9c0dd24b2c61,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-db9a7d58-1797-4533-b4d8-e46338345cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-62f3704e-990f-49e5-9b6a-7712d466395e,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-84b7be65-33e2-481e-9c5e-6f898a06d379,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-317a728d-d44d-4b19-886c-226171ac5550,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-1feb59a2-258d-414c-9bf3-434a70828105,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-4111ee4d-4671-4632-972f-25e650edac82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-698288861-172.17.0.6-1597151436342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-b4f2612b-8dd5-4732-80fa-9b563edecb31,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-a09595b3-d5a6-430f-9597-dbd1477df8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-2622ef04-197f-4580-ac04-7cb516d68d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-6e97c1ea-c642-48fc-a0e8-2cfbe5e3e0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-9df8e6a8-2635-4134-9f14-84194abcac80,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-1c4f16e4-27b8-4061-937f-27d1588e8f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-2bc5c5cf-81ee-419e-a650-948f81262759,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-d3f44dcc-fbf2-44fa-afb2-4f785a923020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-698288861-172.17.0.6-1597151436342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-b4f2612b-8dd5-4732-80fa-9b563edecb31,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-a09595b3-d5a6-430f-9597-dbd1477df8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-2622ef04-197f-4580-ac04-7cb516d68d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-6e97c1ea-c642-48fc-a0e8-2cfbe5e3e0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-9df8e6a8-2635-4134-9f14-84194abcac80,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-1c4f16e4-27b8-4061-937f-27d1588e8f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-2bc5c5cf-81ee-419e-a650-948f81262759,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-d3f44dcc-fbf2-44fa-afb2-4f785a923020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694090443-172.17.0.6-1597151711149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-417fa6ab-ec04-491e-a1e4-0e3b7ccd89c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-fab9e061-7c26-41ea-86df-859f6cc4b9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-866c2bd8-038d-4726-a183-46fa3e5e6f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-88ce6699-a5de-4b19-9ad0-57895d5625f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-7eec04e2-3f27-47aa-a0dc-40ddb9486fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-35d09840-0a36-4b12-a4ee-cebe50feaae8,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-b6a4921a-7e9e-41f3-bce6-1ace880ab502,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-50f8c959-c3fb-413d-b07e-0d019e513174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694090443-172.17.0.6-1597151711149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-417fa6ab-ec04-491e-a1e4-0e3b7ccd89c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-fab9e061-7c26-41ea-86df-859f6cc4b9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-866c2bd8-038d-4726-a183-46fa3e5e6f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-88ce6699-a5de-4b19-9ad0-57895d5625f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-7eec04e2-3f27-47aa-a0dc-40ddb9486fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-35d09840-0a36-4b12-a4ee-cebe50feaae8,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-b6a4921a-7e9e-41f3-bce6-1ace880ab502,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-50f8c959-c3fb-413d-b07e-0d019e513174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760500591-172.17.0.6-1597151872925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37367,DS-8ef845d9-868a-4cbb-a9de-16e1b0cbaf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-b10b28a2-e212-45db-8008-472beeb38fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-6bc52308-6f60-45d3-b6bd-5eed38680c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-b1168672-7c72-4aa4-ac13-4be1f442cf67,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-a747de0f-41fd-4c41-96ba-b267b78ff843,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-c94b885f-1eff-4c9d-9258-98eebaef0753,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-d7f1fea7-3216-428a-94f3-9fd954cbd488,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-9a8414c2-d9aa-403c-8f78-729147e6fc99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760500591-172.17.0.6-1597151872925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37367,DS-8ef845d9-868a-4cbb-a9de-16e1b0cbaf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-b10b28a2-e212-45db-8008-472beeb38fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-6bc52308-6f60-45d3-b6bd-5eed38680c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-b1168672-7c72-4aa4-ac13-4be1f442cf67,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-a747de0f-41fd-4c41-96ba-b267b78ff843,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-c94b885f-1eff-4c9d-9258-98eebaef0753,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-d7f1fea7-3216-428a-94f3-9fd954cbd488,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-9a8414c2-d9aa-403c-8f78-729147e6fc99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968719835-172.17.0.6-1597151940807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41926,DS-4c9422a6-ce75-438d-b5a0-1428d0e0e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-aee0254e-4666-45ed-9df7-f5ae20d6f853,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-92f4f0ae-64fe-4d27-9b5d-b253c7fa82c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-50afaaef-253e-4198-85a0-7c99972f9296,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-e5156ddd-4868-4850-b916-1843ad668fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-361d74d7-eca8-4e5e-bc80-f660134cb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-f9b16dee-e895-4d7e-8312-333e6af054d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-0e8ce810-0364-494f-92b1-af73b2bd7365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968719835-172.17.0.6-1597151940807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41926,DS-4c9422a6-ce75-438d-b5a0-1428d0e0e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-aee0254e-4666-45ed-9df7-f5ae20d6f853,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-92f4f0ae-64fe-4d27-9b5d-b253c7fa82c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-50afaaef-253e-4198-85a0-7c99972f9296,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-e5156ddd-4868-4850-b916-1843ad668fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-361d74d7-eca8-4e5e-bc80-f660134cb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-f9b16dee-e895-4d7e-8312-333e6af054d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-0e8ce810-0364-494f-92b1-af73b2bd7365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439729565-172.17.0.6-1597152002786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-d8b9e19f-62a5-4ba9-b8e1-e0c225b93972,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-c550a769-b8fc-4f73-bf69-9f075420de61,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-ead59fd0-8ec3-4eb9-8165-2bcc170f636d,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-a06f629c-a214-4c8c-aa91-c831539db3de,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-e180e017-3b15-41f5-996a-4e6f64bf48da,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-ef3cea4b-8fff-4ef5-bb33-76298c27f240,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-c03dd5f7-55bd-4cec-8d2e-e706774a9b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-5ae792c0-a6bd-4dff-8181-10b6f3d8aaf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439729565-172.17.0.6-1597152002786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-d8b9e19f-62a5-4ba9-b8e1-e0c225b93972,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-c550a769-b8fc-4f73-bf69-9f075420de61,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-ead59fd0-8ec3-4eb9-8165-2bcc170f636d,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-a06f629c-a214-4c8c-aa91-c831539db3de,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-e180e017-3b15-41f5-996a-4e6f64bf48da,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-ef3cea4b-8fff-4ef5-bb33-76298c27f240,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-c03dd5f7-55bd-4cec-8d2e-e706774a9b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-5ae792c0-a6bd-4dff-8181-10b6f3d8aaf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389757874-172.17.0.6-1597152374754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-73714abe-42eb-434f-8533-397f2ca5e80d,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-d47d36d0-647a-4e2d-97b7-e5ac82727ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-c7765df5-9263-46ac-833c-abf117c09c02,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-bac9114d-c378-4aba-9260-75b7b20cbf12,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-b34e8f86-92c4-446b-9f02-3406e08757ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-83ec7afc-bfa8-4e0d-9c62-ab01cc020f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-cf7fb361-a32b-4f60-a21a-90bd6bcd1502,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-2c9fe9a5-1e82-4d4c-97d7-d67ec1adc8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389757874-172.17.0.6-1597152374754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-73714abe-42eb-434f-8533-397f2ca5e80d,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-d47d36d0-647a-4e2d-97b7-e5ac82727ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-c7765df5-9263-46ac-833c-abf117c09c02,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-bac9114d-c378-4aba-9260-75b7b20cbf12,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-b34e8f86-92c4-446b-9f02-3406e08757ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-83ec7afc-bfa8-4e0d-9c62-ab01cc020f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-cf7fb361-a32b-4f60-a21a-90bd6bcd1502,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-2c9fe9a5-1e82-4d4c-97d7-d67ec1adc8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105760997-172.17.0.6-1597152501960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32804,DS-9683c150-9bfc-4399-91eb-4dab15e7ded5,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-26d22691-98cf-41ac-8c08-36ec4a306e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-4420913d-1e16-413a-a2ec-b0a0b4f9e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-af40397e-463c-47d7-baad-19fbc3b68787,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-87952b3c-8456-4b05-83a5-ec6a01fe4ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-76b614f0-cff7-4408-9a6e-ca3f89e66db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-54d8c53b-9185-4c28-b436-3de39ba3407a,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-1499ba4a-5bb3-4675-97ff-24dff1d114e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105760997-172.17.0.6-1597152501960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32804,DS-9683c150-9bfc-4399-91eb-4dab15e7ded5,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-26d22691-98cf-41ac-8c08-36ec4a306e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-4420913d-1e16-413a-a2ec-b0a0b4f9e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-af40397e-463c-47d7-baad-19fbc3b68787,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-87952b3c-8456-4b05-83a5-ec6a01fe4ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-76b614f0-cff7-4408-9a6e-ca3f89e66db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-54d8c53b-9185-4c28-b436-3de39ba3407a,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-1499ba4a-5bb3-4675-97ff-24dff1d114e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573340049-172.17.0.6-1597153079938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-617d9b46-24a5-4e5f-b1ef-0c49e146253a,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-ffd35f59-66ae-4699-9da7-d04d0df1e349,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-629f62f7-f691-4cdd-805f-4b00584b3fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-fea69a99-0899-4d6c-a0d3-35d062e203d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-28b6d12c-c412-430b-aab3-b0a1b2fee581,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-b9fb3280-8970-4836-bafa-d47938a396d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-37c1863e-555a-4aac-8452-d488b876a8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-5b4698fc-c869-4c86-ba5a-e4900a9740a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573340049-172.17.0.6-1597153079938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-617d9b46-24a5-4e5f-b1ef-0c49e146253a,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-ffd35f59-66ae-4699-9da7-d04d0df1e349,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-629f62f7-f691-4cdd-805f-4b00584b3fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-fea69a99-0899-4d6c-a0d3-35d062e203d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-28b6d12c-c412-430b-aab3-b0a1b2fee581,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-b9fb3280-8970-4836-bafa-d47938a396d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-37c1863e-555a-4aac-8452-d488b876a8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-5b4698fc-c869-4c86-ba5a-e4900a9740a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847093593-172.17.0.6-1597154074103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39178,DS-47a26cbf-52f1-4eab-beba-790341fb516c,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-c3a6a5fa-1134-4bec-b202-832dad516fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-74eee21d-9241-48be-9551-50cbbbd37b02,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-b41100b6-4b48-4194-a921-4dc4a385c26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-abd4fbbd-835f-4ebd-a620-8b06bab395f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-4d6152b4-e59d-4023-b1e2-25c3e84f0e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-9527f3f9-5b70-4575-919c-ffb74481fe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-af4fe872-7829-4fde-9f6c-bb6f8b5dc90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847093593-172.17.0.6-1597154074103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39178,DS-47a26cbf-52f1-4eab-beba-790341fb516c,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-c3a6a5fa-1134-4bec-b202-832dad516fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-74eee21d-9241-48be-9551-50cbbbd37b02,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-b41100b6-4b48-4194-a921-4dc4a385c26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-abd4fbbd-835f-4ebd-a620-8b06bab395f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-4d6152b4-e59d-4023-b1e2-25c3e84f0e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-9527f3f9-5b70-4575-919c-ffb74481fe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-af4fe872-7829-4fde-9f6c-bb6f8b5dc90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979633561-172.17.0.6-1597154149546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-27aec61d-4378-4fc0-bd03-e746ddd30a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-8f39b911-dcdd-498f-97f7-5d7626606437,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-18ac388f-7d43-4ade-9992-aca1d9ae6814,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-ef1d469b-cc79-47f4-84c2-82918657abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-3046e25f-46af-48df-a054-38edb028ca6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-5ee75c8c-8817-4606-996e-aefa88020967,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-79632870-6160-4cbf-9119-28d7dd1e32b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-276d39d1-82fd-47b3-9466-d92bc8e63def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979633561-172.17.0.6-1597154149546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-27aec61d-4378-4fc0-bd03-e746ddd30a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-8f39b911-dcdd-498f-97f7-5d7626606437,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-18ac388f-7d43-4ade-9992-aca1d9ae6814,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-ef1d469b-cc79-47f4-84c2-82918657abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-3046e25f-46af-48df-a054-38edb028ca6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-5ee75c8c-8817-4606-996e-aefa88020967,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-79632870-6160-4cbf-9119-28d7dd1e32b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-276d39d1-82fd-47b3-9466-d92bc8e63def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220037363-172.17.0.6-1597154737177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34521,DS-51473518-be6f-40e0-a5a9-3974f772024a,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-4db3cb74-6277-450b-9ce7-24c4d18ac3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-bd4ba35b-dea4-462d-b26f-3d3e26c972e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-0ccddffd-5d91-43d4-b98e-145706c18de8,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-7169c771-b8e9-4b48-ba80-15301e987178,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-d0a9a14b-222a-4f31-86d7-f9827d3075c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-c9a3cfca-c5e6-4c36-aeb1-b7c715549224,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-ed238732-7bf2-4893-b200-173f8fcf0646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220037363-172.17.0.6-1597154737177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34521,DS-51473518-be6f-40e0-a5a9-3974f772024a,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-4db3cb74-6277-450b-9ce7-24c4d18ac3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-bd4ba35b-dea4-462d-b26f-3d3e26c972e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-0ccddffd-5d91-43d4-b98e-145706c18de8,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-7169c771-b8e9-4b48-ba80-15301e987178,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-d0a9a14b-222a-4f31-86d7-f9827d3075c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-c9a3cfca-c5e6-4c36-aeb1-b7c715549224,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-ed238732-7bf2-4893-b200-173f8fcf0646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5145
