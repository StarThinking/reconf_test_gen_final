reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929624209-172.17.0.17-1597038947203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-1f97a230-59b1-48d4-a002-a97b39112462,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-811225b3-e5af-487b-9ab9-3d21033a7d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-93cfefb2-866c-457f-8b24-edd5b09a272b,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-75c237a4-bb9e-44d2-bd87-9675c1140332,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-1b288e38-59e2-4e72-8a46-a5109fa26eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-5e4039a3-e42e-4e94-8916-cf677ad7060a,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-582ae341-ce73-472e-9e5e-634c07419228,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-8e635a19-3db3-4d4b-8354-03fcc65eb0c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929624209-172.17.0.17-1597038947203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-1f97a230-59b1-48d4-a002-a97b39112462,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-811225b3-e5af-487b-9ab9-3d21033a7d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-93cfefb2-866c-457f-8b24-edd5b09a272b,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-75c237a4-bb9e-44d2-bd87-9675c1140332,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-1b288e38-59e2-4e72-8a46-a5109fa26eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-5e4039a3-e42e-4e94-8916-cf677ad7060a,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-582ae341-ce73-472e-9e5e-634c07419228,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-8e635a19-3db3-4d4b-8354-03fcc65eb0c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13278475-172.17.0.17-1597038973900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41477,DS-ed406816-a407-4935-b998-b141ae370c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-737f4aad-bbf0-4851-968b-0cfa2448b48f,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-7341b149-8a42-469b-ac26-e095fecb9677,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-4e66e13c-d1d6-4b08-a4c8-e1d903484f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-eaf387cb-12e1-41a4-932e-d9dea9f051cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-4970f38d-1d33-4967-8242-b2b1c2400a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-6d2a77d2-8d70-4837-a337-ddf637b4ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-0ceb37a6-4b5c-4e44-8b75-5dffac5fba68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13278475-172.17.0.17-1597038973900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41477,DS-ed406816-a407-4935-b998-b141ae370c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-737f4aad-bbf0-4851-968b-0cfa2448b48f,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-7341b149-8a42-469b-ac26-e095fecb9677,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-4e66e13c-d1d6-4b08-a4c8-e1d903484f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-eaf387cb-12e1-41a4-932e-d9dea9f051cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-4970f38d-1d33-4967-8242-b2b1c2400a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-6d2a77d2-8d70-4837-a337-ddf637b4ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-0ceb37a6-4b5c-4e44-8b75-5dffac5fba68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940374709-172.17.0.17-1597039127393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34854,DS-02b9a7a2-3436-4ffb-a2f9-94af44810854,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-c65c3c6f-1ec2-42b6-bf82-c528cc88c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-9db7d3a4-4962-454a-b834-3c40d8b32973,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-d5946eca-a5a0-4a42-b8b4-a63c351a07b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-48c4313d-24eb-4090-9e5e-70bcea55ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-2d7ce140-43b4-4e1e-8fce-e39477e9f586,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-c9c49872-c084-4f64-a777-147610488f87,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-075e0b16-3379-4622-a805-5c1b1d3cbe3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940374709-172.17.0.17-1597039127393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34854,DS-02b9a7a2-3436-4ffb-a2f9-94af44810854,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-c65c3c6f-1ec2-42b6-bf82-c528cc88c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-9db7d3a4-4962-454a-b834-3c40d8b32973,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-d5946eca-a5a0-4a42-b8b4-a63c351a07b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-48c4313d-24eb-4090-9e5e-70bcea55ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-2d7ce140-43b4-4e1e-8fce-e39477e9f586,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-c9c49872-c084-4f64-a777-147610488f87,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-075e0b16-3379-4622-a805-5c1b1d3cbe3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473670199-172.17.0.17-1597039207197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-f164b8d2-fa10-4a7a-90c1-5777a8edc2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-5c25152d-9e91-4bfb-87a9-f0635a9968c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-d2d56a9f-431c-42e5-980e-e463f38a7b59,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-804912c6-fa26-4583-aade-7d7f5d1d3655,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-92e3bfbc-0c29-4e8d-8d6e-00c53a005dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-fab9b804-2cc3-4fef-8758-a39d24d3dfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-4a77f98f-9db1-449a-aa84-889af659287d,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-44fccbf5-d3bf-49fb-ab13-96ffef94ef63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473670199-172.17.0.17-1597039207197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-f164b8d2-fa10-4a7a-90c1-5777a8edc2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-5c25152d-9e91-4bfb-87a9-f0635a9968c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-d2d56a9f-431c-42e5-980e-e463f38a7b59,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-804912c6-fa26-4583-aade-7d7f5d1d3655,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-92e3bfbc-0c29-4e8d-8d6e-00c53a005dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-fab9b804-2cc3-4fef-8758-a39d24d3dfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-4a77f98f-9db1-449a-aa84-889af659287d,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-44fccbf5-d3bf-49fb-ab13-96ffef94ef63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103161677-172.17.0.17-1597039321430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39747,DS-82edb169-a474-4f0b-85eb-f5f8c28dccba,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-de12d66c-1d31-4e4b-ba6e-c2f2974cf71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-c7f87945-275c-4a0a-8f23-6493ed73f86f,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-ccff1d3b-5840-449f-9c06-3ab89eb4376a,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-7ddd89f6-3a3b-4e89-908b-372f6bccc1de,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-56c75c85-9d3b-43fa-975e-f0eb4692db15,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-a56e9ded-2ecb-4836-a272-e9ec202d526d,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-57a07f19-72ac-48dd-9d8f-baf363e6ef42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103161677-172.17.0.17-1597039321430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39747,DS-82edb169-a474-4f0b-85eb-f5f8c28dccba,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-de12d66c-1d31-4e4b-ba6e-c2f2974cf71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-c7f87945-275c-4a0a-8f23-6493ed73f86f,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-ccff1d3b-5840-449f-9c06-3ab89eb4376a,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-7ddd89f6-3a3b-4e89-908b-372f6bccc1de,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-56c75c85-9d3b-43fa-975e-f0eb4692db15,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-a56e9ded-2ecb-4836-a272-e9ec202d526d,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-57a07f19-72ac-48dd-9d8f-baf363e6ef42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257127745-172.17.0.17-1597039401226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42739,DS-9eddfd1d-03fb-40bd-bce0-4a635b289d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-852f7329-95c8-441a-afb0-9f45ff4416ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-4f62e957-bd4d-49b1-a3d1-8b48e6bd15ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-e2f94bb6-1ed1-461e-9f7b-873a329609b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-36ba77a9-e007-4375-8dbd-8d6b14d3122b,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-c5905bb6-42a1-4118-ac1c-1c08985a5bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-d415227b-53e0-430c-b22a-83deec11923c,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-ad3ff49d-40f7-4f1b-a835-d407c2b52454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257127745-172.17.0.17-1597039401226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42739,DS-9eddfd1d-03fb-40bd-bce0-4a635b289d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-852f7329-95c8-441a-afb0-9f45ff4416ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-4f62e957-bd4d-49b1-a3d1-8b48e6bd15ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-e2f94bb6-1ed1-461e-9f7b-873a329609b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-36ba77a9-e007-4375-8dbd-8d6b14d3122b,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-c5905bb6-42a1-4118-ac1c-1c08985a5bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-d415227b-53e0-430c-b22a-83deec11923c,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-ad3ff49d-40f7-4f1b-a835-d407c2b52454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462351904-172.17.0.17-1597039443609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-25e83950-a9e0-41c3-aba9-77bd7177fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-c7594031-c3ac-488e-91c9-7e520341bf92,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-a3ff9b53-79c0-4a8f-a745-7d91b804ffe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-7e18f1ce-419c-40fc-8d02-8f0cca8c9f29,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-48418f59-e7b8-4cc0-8ccd-1f34d4492e19,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-19646edd-826a-4d13-b0a2-b6084f3313a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-f26bc5de-0f81-4069-920f-8eb1b864d350,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-85da4c0c-05a6-408a-808b-04883c560ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462351904-172.17.0.17-1597039443609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-25e83950-a9e0-41c3-aba9-77bd7177fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-c7594031-c3ac-488e-91c9-7e520341bf92,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-a3ff9b53-79c0-4a8f-a745-7d91b804ffe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-7e18f1ce-419c-40fc-8d02-8f0cca8c9f29,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-48418f59-e7b8-4cc0-8ccd-1f34d4492e19,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-19646edd-826a-4d13-b0a2-b6084f3313a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-f26bc5de-0f81-4069-920f-8eb1b864d350,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-85da4c0c-05a6-408a-808b-04883c560ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471062279-172.17.0.17-1597039877262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42772,DS-0328eed1-19c0-4851-bba4-2a79def0c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-23a52fb6-f109-4cda-9da1-bedea102c747,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-40029a01-ff36-4524-a4d1-7117b199fb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-751cab73-7282-4501-b70a-6feb4e31c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-4d74cec4-7b7a-49a6-977f-2fa6b301694b,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-d19afcf4-f8d5-4650-ac7d-4f74be4c8c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-3678364f-f7a9-401b-a567-3882c52db5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-1c055038-2f55-46c9-a570-9add6e97e1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471062279-172.17.0.17-1597039877262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42772,DS-0328eed1-19c0-4851-bba4-2a79def0c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-23a52fb6-f109-4cda-9da1-bedea102c747,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-40029a01-ff36-4524-a4d1-7117b199fb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-751cab73-7282-4501-b70a-6feb4e31c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-4d74cec4-7b7a-49a6-977f-2fa6b301694b,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-d19afcf4-f8d5-4650-ac7d-4f74be4c8c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-3678364f-f7a9-401b-a567-3882c52db5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-1c055038-2f55-46c9-a570-9add6e97e1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562643372-172.17.0.17-1597039977235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-7229307e-f7ae-4433-b9a1-c51446ea30b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-6666a8d9-1ec0-40f7-ac7c-c5f8704262c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-b78de92b-68e0-43da-b425-a535ed57aa86,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-71643516-068e-4e3c-a860-b498e2311215,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-efaefd27-0c4a-4c29-acd0-8e373732b750,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-2a3112eb-5eb3-4a4a-a21d-40c2bc4cd89a,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-b0c259ae-2b82-4b2e-922a-c0b60c91f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-1ea88734-b172-440b-b41e-a4fedb9d0ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562643372-172.17.0.17-1597039977235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-7229307e-f7ae-4433-b9a1-c51446ea30b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-6666a8d9-1ec0-40f7-ac7c-c5f8704262c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-b78de92b-68e0-43da-b425-a535ed57aa86,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-71643516-068e-4e3c-a860-b498e2311215,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-efaefd27-0c4a-4c29-acd0-8e373732b750,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-2a3112eb-5eb3-4a4a-a21d-40c2bc4cd89a,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-b0c259ae-2b82-4b2e-922a-c0b60c91f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-1ea88734-b172-440b-b41e-a4fedb9d0ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801886325-172.17.0.17-1597040441426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-b88397f8-c960-4d61-81b3-f0fb864a1872,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-af7b2425-a089-422f-bec7-db35cddb0987,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-bc1eed6e-732c-4e62-aad0-8bc354b8de49,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-99643d22-076d-461b-8ecc-8c61fbd6d182,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-4f11dcb7-986b-4c52-b972-fa91fdd87a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-152e8d60-022a-492a-8060-ca3e8023c1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-04754d60-c810-4c24-a5b0-b6b44692bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-250c0823-08d0-4344-b5f6-eef594179ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801886325-172.17.0.17-1597040441426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-b88397f8-c960-4d61-81b3-f0fb864a1872,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-af7b2425-a089-422f-bec7-db35cddb0987,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-bc1eed6e-732c-4e62-aad0-8bc354b8de49,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-99643d22-076d-461b-8ecc-8c61fbd6d182,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-4f11dcb7-986b-4c52-b972-fa91fdd87a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-152e8d60-022a-492a-8060-ca3e8023c1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-04754d60-c810-4c24-a5b0-b6b44692bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-250c0823-08d0-4344-b5f6-eef594179ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601361778-172.17.0.17-1597040582265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-0d928262-1703-464f-a336-fc499cd1b8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-b436b081-25f1-4b16-8420-c5d27297c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-fc16b7c7-d06e-4190-908f-d834a3368610,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-fe564e74-9beb-49a0-91ad-ae071db097b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-fbbccf2b-396b-4959-ae37-24632dd16cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-8824311b-fb91-4e74-a250-903bf599a3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-19e93cf6-56d5-4e38-83de-8b2309bc2ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-7477507c-a78f-4c83-a128-81f16f5011af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601361778-172.17.0.17-1597040582265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-0d928262-1703-464f-a336-fc499cd1b8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-b436b081-25f1-4b16-8420-c5d27297c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-fc16b7c7-d06e-4190-908f-d834a3368610,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-fe564e74-9beb-49a0-91ad-ae071db097b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-fbbccf2b-396b-4959-ae37-24632dd16cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-8824311b-fb91-4e74-a250-903bf599a3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-19e93cf6-56d5-4e38-83de-8b2309bc2ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-7477507c-a78f-4c83-a128-81f16f5011af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45910748-172.17.0.17-1597041463797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-7bb9dcf1-3bd0-4aad-a30a-a194048c9306,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-869d781c-db36-46ef-8f66-9ae50537c388,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-13ad0bfc-9e9d-4f29-82f0-05d7e5b5d6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-032f3ba1-97ee-4c75-9567-e52be5b4d711,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-c67ee36d-b354-4edc-92d4-d8f34695137d,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-eff39f08-2b6f-4bf4-9a49-0fd3e45774be,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-5c1ba165-fb3b-4cb6-8773-369a2f4bb488,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-29a262c7-16c8-4ae2-a256-07f9980d3855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45910748-172.17.0.17-1597041463797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-7bb9dcf1-3bd0-4aad-a30a-a194048c9306,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-869d781c-db36-46ef-8f66-9ae50537c388,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-13ad0bfc-9e9d-4f29-82f0-05d7e5b5d6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-032f3ba1-97ee-4c75-9567-e52be5b4d711,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-c67ee36d-b354-4edc-92d4-d8f34695137d,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-eff39f08-2b6f-4bf4-9a49-0fd3e45774be,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-5c1ba165-fb3b-4cb6-8773-369a2f4bb488,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-29a262c7-16c8-4ae2-a256-07f9980d3855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085288487-172.17.0.17-1597042177159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-aab4d09a-fc6d-478b-9d75-978de895d9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-829a3b0b-2db6-4c32-8231-5211b95addab,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-9195a8aa-774b-465d-ad79-c1f7739bc51e,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-504e37f4-26fc-4499-b969-95beed9f5160,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-75927e0a-2cc7-4bc6-8481-25d13b56666e,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-3d6e3042-898c-4217-962f-45a88bf8f0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-6c8fb71a-b02e-4d44-b4c5-57fa1c411472,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-4c8599ac-d330-45bf-bf1e-b5cba7758c9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085288487-172.17.0.17-1597042177159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-aab4d09a-fc6d-478b-9d75-978de895d9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-829a3b0b-2db6-4c32-8231-5211b95addab,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-9195a8aa-774b-465d-ad79-c1f7739bc51e,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-504e37f4-26fc-4499-b969-95beed9f5160,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-75927e0a-2cc7-4bc6-8481-25d13b56666e,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-3d6e3042-898c-4217-962f-45a88bf8f0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-6c8fb71a-b02e-4d44-b4c5-57fa1c411472,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-4c8599ac-d330-45bf-bf1e-b5cba7758c9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389300068-172.17.0.17-1597042394116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33169,DS-ffe5af82-dc42-40f4-9221-7245247d7c14,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-390705cc-eb6c-4fb7-8c0d-ff082d7ad5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-613e1da2-67d0-497a-8ef6-4ae34251effd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-8b223579-8093-413c-9672-13fc598ffbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-1291b1f6-b50d-4657-bf63-2c16de28c275,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-937bddc5-2c56-44cc-bcf3-f6e1ba901fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-6e02338d-4b17-4d00-b495-3a0d0b0b08be,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-ae4a6806-7362-4072-8bb2-3e381f19be9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389300068-172.17.0.17-1597042394116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33169,DS-ffe5af82-dc42-40f4-9221-7245247d7c14,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-390705cc-eb6c-4fb7-8c0d-ff082d7ad5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-613e1da2-67d0-497a-8ef6-4ae34251effd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-8b223579-8093-413c-9672-13fc598ffbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-1291b1f6-b50d-4657-bf63-2c16de28c275,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-937bddc5-2c56-44cc-bcf3-f6e1ba901fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-6e02338d-4b17-4d00-b495-3a0d0b0b08be,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-ae4a6806-7362-4072-8bb2-3e381f19be9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539502760-172.17.0.17-1597042576253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45428,DS-45eb2e6e-15a4-4b36-a3cc-cb3831ebedd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-b5a1aa57-38eb-45f6-b263-5cfbaef06628,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-9210590e-2f2d-4710-a28c-a5402a435acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-1c61c442-4e57-438a-8cc5-0b3eb5c74829,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-6bf64a6b-d637-4eee-a4a8-1e8a171f66ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-935344ff-1c42-4f84-9dd7-685c6f5149b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-7d42723f-3807-41aa-8c6d-0007ce8e18c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-81b378c1-ee6f-48c3-ac26-baf0cacc1d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539502760-172.17.0.17-1597042576253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45428,DS-45eb2e6e-15a4-4b36-a3cc-cb3831ebedd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-b5a1aa57-38eb-45f6-b263-5cfbaef06628,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-9210590e-2f2d-4710-a28c-a5402a435acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-1c61c442-4e57-438a-8cc5-0b3eb5c74829,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-6bf64a6b-d637-4eee-a4a8-1e8a171f66ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-935344ff-1c42-4f84-9dd7-685c6f5149b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-7d42723f-3807-41aa-8c6d-0007ce8e18c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-81b378c1-ee6f-48c3-ac26-baf0cacc1d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044656674-172.17.0.17-1597043082583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45003,DS-883484a3-17de-454e-be05-de8de24f8175,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-916edbdf-7364-4bd2-97ea-6a823cf9a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-924f21a0-a4f3-45e5-b202-7ff656aa13b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-a5d34b6e-1a5c-4827-8559-4a8f27d38885,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-106bd647-96e2-4808-9af5-55a93d2cdb25,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-5c0b8a99-0e5d-49fb-8900-e4dccf34018c,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-dfcee3c5-873e-4163-9bc3-a9cbac4f3458,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-bb929d86-d119-4ede-a72d-2e6814a81fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044656674-172.17.0.17-1597043082583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45003,DS-883484a3-17de-454e-be05-de8de24f8175,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-916edbdf-7364-4bd2-97ea-6a823cf9a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-924f21a0-a4f3-45e5-b202-7ff656aa13b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-a5d34b6e-1a5c-4827-8559-4a8f27d38885,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-106bd647-96e2-4808-9af5-55a93d2cdb25,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-5c0b8a99-0e5d-49fb-8900-e4dccf34018c,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-dfcee3c5-873e-4163-9bc3-a9cbac4f3458,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-bb929d86-d119-4ede-a72d-2e6814a81fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694269115-172.17.0.17-1597043162417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46511,DS-66c915a4-e384-4aba-b771-dbeb3b9cccec,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-592dbc7b-41cb-43d6-ae45-b8d91ad33439,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-581a4186-53dd-473a-adbb-9d2f024f3c27,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-492f9a2e-ea4a-46f4-adde-7f7276116bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-d339a867-d3ab-49ab-9fd6-47713f25f6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-3a28d160-7b42-4fd4-96d1-81a5c8c0aec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-36c74901-d321-4f93-9fbe-061108551d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-3719fcf2-53df-4d9e-9d4e-41da4e6ff38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694269115-172.17.0.17-1597043162417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46511,DS-66c915a4-e384-4aba-b771-dbeb3b9cccec,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-592dbc7b-41cb-43d6-ae45-b8d91ad33439,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-581a4186-53dd-473a-adbb-9d2f024f3c27,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-492f9a2e-ea4a-46f4-adde-7f7276116bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-d339a867-d3ab-49ab-9fd6-47713f25f6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-3a28d160-7b42-4fd4-96d1-81a5c8c0aec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-36c74901-d321-4f93-9fbe-061108551d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-3719fcf2-53df-4d9e-9d4e-41da4e6ff38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497533173-172.17.0.17-1597043379282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-58dd9c30-661f-4966-917e-829591f20a38,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-f188c574-27c0-482f-b1a8-a994e7a22292,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-6e9f999b-f58a-4a5d-8bf7-e2064cbe3a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-9cdec434-550a-4693-a3b2-817a38b73863,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-2c50af85-390a-4f45-86b1-57d41f486a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-924b69e2-a325-40a0-b130-4e7503010968,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-a7752a1a-eb20-404d-87d9-59133e134b88,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-794fab15-c852-46a7-8e51-1d1f1b5c32b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497533173-172.17.0.17-1597043379282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-58dd9c30-661f-4966-917e-829591f20a38,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-f188c574-27c0-482f-b1a8-a994e7a22292,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-6e9f999b-f58a-4a5d-8bf7-e2064cbe3a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-9cdec434-550a-4693-a3b2-817a38b73863,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-2c50af85-390a-4f45-86b1-57d41f486a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-924b69e2-a325-40a0-b130-4e7503010968,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-a7752a1a-eb20-404d-87d9-59133e134b88,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-794fab15-c852-46a7-8e51-1d1f1b5c32b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37446889-172.17.0.17-1597043455798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40714,DS-f66d51ef-5b4a-419a-b760-c117ad0ba3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-9bdc21f0-cba6-40e1-a757-8c72ed017b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-f9f0d0d3-41dd-4fdb-ad59-72f2e9a99433,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-861238f9-2df5-4155-829d-448ae47886b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-a5909152-f6ee-40e5-850f-78f33c453df1,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-544ccbc8-dbaf-42d7-b509-f9f8ef99c501,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-bd2dc7d6-cb6b-4eb3-b9e5-9f59faa9fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-d83c3e02-52e8-44bc-8e64-f4d4b44fe47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37446889-172.17.0.17-1597043455798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40714,DS-f66d51ef-5b4a-419a-b760-c117ad0ba3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-9bdc21f0-cba6-40e1-a757-8c72ed017b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-f9f0d0d3-41dd-4fdb-ad59-72f2e9a99433,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-861238f9-2df5-4155-829d-448ae47886b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-a5909152-f6ee-40e5-850f-78f33c453df1,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-544ccbc8-dbaf-42d7-b509-f9f8ef99c501,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-bd2dc7d6-cb6b-4eb3-b9e5-9f59faa9fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-d83c3e02-52e8-44bc-8e64-f4d4b44fe47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753399521-172.17.0.17-1597043572856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34852,DS-13e93faa-9131-4a7c-a2e6-32c79ad0a1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-b3d0dbfb-0c5b-4df9-a759-b6752b565248,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-369e9771-cdaa-4ab4-89cb-310972ebb9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-0f28b810-d2aa-4a55-91fc-f690b6232acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-2a145195-9508-4090-84a0-839c6b733d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-fecfb03e-1033-4087-902c-700c69f2a1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-aee2f6e0-48af-4b4f-9eb4-6c88eb39c6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-3662e882-ab91-40db-868c-fb92beb6df82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753399521-172.17.0.17-1597043572856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34852,DS-13e93faa-9131-4a7c-a2e6-32c79ad0a1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-b3d0dbfb-0c5b-4df9-a759-b6752b565248,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-369e9771-cdaa-4ab4-89cb-310972ebb9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-0f28b810-d2aa-4a55-91fc-f690b6232acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-2a145195-9508-4090-84a0-839c6b733d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-fecfb03e-1033-4087-902c-700c69f2a1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-aee2f6e0-48af-4b4f-9eb4-6c88eb39c6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-3662e882-ab91-40db-868c-fb92beb6df82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5532
