reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951892426-172.17.0.15-1597121244275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40062,DS-e46ea791-ef52-401e-97ed-cfe19f39b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-9491634c-0ed7-42c3-b3a9-e06e5cb6553b,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-1effd9ea-1dbf-4b7a-a789-fd4664a6fa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-f9709121-af21-49c9-ae82-d35e03a18b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-bfc0d9ad-a2e6-460c-9b96-9c8a5eab2397,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-1b73fe3a-a100-4e34-9e15-11d806d58e09,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-50b4a184-4ea3-4d99-994c-1c52df3f8d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-164fae48-fbf7-4eb8-af73-e905bd0f6b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951892426-172.17.0.15-1597121244275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40062,DS-e46ea791-ef52-401e-97ed-cfe19f39b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-9491634c-0ed7-42c3-b3a9-e06e5cb6553b,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-1effd9ea-1dbf-4b7a-a789-fd4664a6fa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-f9709121-af21-49c9-ae82-d35e03a18b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-bfc0d9ad-a2e6-460c-9b96-9c8a5eab2397,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-1b73fe3a-a100-4e34-9e15-11d806d58e09,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-50b4a184-4ea3-4d99-994c-1c52df3f8d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-164fae48-fbf7-4eb8-af73-e905bd0f6b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894504177-172.17.0.15-1597121322767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-b226242c-b4fb-4687-a333-b4420ab28830,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-7e0a2e05-713c-468f-8203-c4685b8c11a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-227b24b6-5ec1-4020-a42c-65da27ba1c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-866ffb15-d105-476d-ba48-cd8798711eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-a93525ee-c15c-4510-a208-af09f01bce92,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-ca5fd0d0-3e75-4279-a80b-3fd837fde370,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-4db11e20-76dc-4e8a-a3a1-6dc66e3cbb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-0cac6c22-65b8-43fe-92e8-8b07f75fc836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894504177-172.17.0.15-1597121322767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-b226242c-b4fb-4687-a333-b4420ab28830,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-7e0a2e05-713c-468f-8203-c4685b8c11a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-227b24b6-5ec1-4020-a42c-65da27ba1c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-866ffb15-d105-476d-ba48-cd8798711eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-a93525ee-c15c-4510-a208-af09f01bce92,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-ca5fd0d0-3e75-4279-a80b-3fd837fde370,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-4db11e20-76dc-4e8a-a3a1-6dc66e3cbb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-0cac6c22-65b8-43fe-92e8-8b07f75fc836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490735308-172.17.0.15-1597121659702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-9c8306dc-e684-4a81-9edc-5dec6d615c18,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-1e308bdd-8318-4a13-91ea-f1dc03ddbebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-525ee435-42ef-43b3-b74f-821477f955d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-83581f2e-903a-47b1-a6c5-e2bd76556f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-da3b41d6-1ce6-4181-a87a-9855c401dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-40f248f7-efc5-41c4-9cd7-dbedd22aac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-e67dac48-51c4-4d73-84c9-709d72883555,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-43b28f4b-75b9-45c1-b3ed-cc407c73d2a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490735308-172.17.0.15-1597121659702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-9c8306dc-e684-4a81-9edc-5dec6d615c18,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-1e308bdd-8318-4a13-91ea-f1dc03ddbebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-525ee435-42ef-43b3-b74f-821477f955d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-83581f2e-903a-47b1-a6c5-e2bd76556f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-da3b41d6-1ce6-4181-a87a-9855c401dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-40f248f7-efc5-41c4-9cd7-dbedd22aac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-e67dac48-51c4-4d73-84c9-709d72883555,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-43b28f4b-75b9-45c1-b3ed-cc407c73d2a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882046940-172.17.0.15-1597121697262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45530,DS-23b0c7f6-b813-440a-b1cf-d79d9f7e0d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-81cb84b8-91fc-4cd8-ba9d-b1997f4d5223,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-0bed6b80-4ee8-4e89-99ab-2cd2b1fb5637,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-417718b7-7d6b-4f0c-b8db-c04743d3c0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-88bb19a1-ad2e-4631-8984-86808673a581,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-c1d7fc59-39fd-48d3-a88a-31f85fd1b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-04bed1a9-0871-4f9a-aa53-0c0ef09ac1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-4a647927-d70c-4ed4-bdcd-df62b8174f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882046940-172.17.0.15-1597121697262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45530,DS-23b0c7f6-b813-440a-b1cf-d79d9f7e0d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-81cb84b8-91fc-4cd8-ba9d-b1997f4d5223,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-0bed6b80-4ee8-4e89-99ab-2cd2b1fb5637,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-417718b7-7d6b-4f0c-b8db-c04743d3c0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-88bb19a1-ad2e-4631-8984-86808673a581,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-c1d7fc59-39fd-48d3-a88a-31f85fd1b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-04bed1a9-0871-4f9a-aa53-0c0ef09ac1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-4a647927-d70c-4ed4-bdcd-df62b8174f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503370969-172.17.0.15-1597122162249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-737eae73-2afa-44d0-82ca-aa34a87693c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-a39c3461-75f7-4b1c-b5ad-95b0bb5a6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-cbb5ff75-dc07-4f77-8c71-2be3130b1a03,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-3640d0be-b5e2-4107-9f42-4940762b5782,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-1c24295d-53d8-4c72-b1d5-dbabc9b7276d,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-b27bb213-0f13-4156-b8d7-eb5096d357ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-a84087d6-392c-4de3-8ffa-7fcaaa3d246f,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-bce92176-853f-490a-a96e-06eb83f12a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503370969-172.17.0.15-1597122162249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-737eae73-2afa-44d0-82ca-aa34a87693c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-a39c3461-75f7-4b1c-b5ad-95b0bb5a6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-cbb5ff75-dc07-4f77-8c71-2be3130b1a03,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-3640d0be-b5e2-4107-9f42-4940762b5782,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-1c24295d-53d8-4c72-b1d5-dbabc9b7276d,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-b27bb213-0f13-4156-b8d7-eb5096d357ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-a84087d6-392c-4de3-8ffa-7fcaaa3d246f,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-bce92176-853f-490a-a96e-06eb83f12a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918740099-172.17.0.15-1597123118793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33557,DS-01d4f2d1-fa67-4829-a354-94a971060b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-c0ca9d1c-281f-4166-b557-cd5dfcd8b1de,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-503c6cce-b937-4471-b02d-0e74248817c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-96d14594-b23c-4adc-baf1-6965db92e8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-dcee68f3-99a9-43cc-aa47-6599fc5cdc34,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-e45464c9-5436-4cda-a259-98acfd441ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-aa5b961f-b265-4442-9eb6-7fed9e486b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-3539e128-0a8f-466f-bfbb-e862362f2ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918740099-172.17.0.15-1597123118793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33557,DS-01d4f2d1-fa67-4829-a354-94a971060b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-c0ca9d1c-281f-4166-b557-cd5dfcd8b1de,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-503c6cce-b937-4471-b02d-0e74248817c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-96d14594-b23c-4adc-baf1-6965db92e8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-dcee68f3-99a9-43cc-aa47-6599fc5cdc34,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-e45464c9-5436-4cda-a259-98acfd441ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-aa5b961f-b265-4442-9eb6-7fed9e486b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-3539e128-0a8f-466f-bfbb-e862362f2ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866077938-172.17.0.15-1597124663084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-b21a310d-22c9-4170-8504-e488a41b1608,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-56c1114c-45cf-442a-a96f-e402f17153e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-482855a7-666f-4327-bcad-04bc6c0b933d,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-b5760012-515e-4bac-978e-de06fcc8a431,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-07131240-0bb0-480f-b5df-2588b37d5233,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-5c711cc2-bbff-47da-8279-d03243e2676c,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-04b17c98-0783-44d5-8c54-bcfead5371d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-925ef0fb-f0e7-4cdb-8b62-2870b2b68ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866077938-172.17.0.15-1597124663084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-b21a310d-22c9-4170-8504-e488a41b1608,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-56c1114c-45cf-442a-a96f-e402f17153e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-482855a7-666f-4327-bcad-04bc6c0b933d,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-b5760012-515e-4bac-978e-de06fcc8a431,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-07131240-0bb0-480f-b5df-2588b37d5233,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-5c711cc2-bbff-47da-8279-d03243e2676c,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-04b17c98-0783-44d5-8c54-bcfead5371d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-925ef0fb-f0e7-4cdb-8b62-2870b2b68ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159906100-172.17.0.15-1597124908363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43288,DS-21830a18-ebec-4d91-af0f-90f41375a432,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-4c2f84b7-bab2-4a1e-ab7d-a14f67e9643b,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-db15dc8b-b584-45e9-a64c-44b0eb5b4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-e909b3f3-9ef2-49d6-9add-4d44b92ce24f,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-be01a279-4b5f-4b85-a3a0-5070060b0477,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-2d095f5a-a548-4408-9376-cd81794b2fae,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-c80bab99-8640-4935-b0cf-d7b0e3621b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-47a90925-d51a-4e2d-9445-ca13a94a6350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159906100-172.17.0.15-1597124908363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43288,DS-21830a18-ebec-4d91-af0f-90f41375a432,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-4c2f84b7-bab2-4a1e-ab7d-a14f67e9643b,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-db15dc8b-b584-45e9-a64c-44b0eb5b4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-e909b3f3-9ef2-49d6-9add-4d44b92ce24f,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-be01a279-4b5f-4b85-a3a0-5070060b0477,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-2d095f5a-a548-4408-9376-cd81794b2fae,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-c80bab99-8640-4935-b0cf-d7b0e3621b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-47a90925-d51a-4e2d-9445-ca13a94a6350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307407008-172.17.0.15-1597125660861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-e64789cf-a389-4b7c-bd1d-3a0706c36d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-51650da2-b571-40f8-8e05-38097653e7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-64ea2f53-1aab-41f4-b7b1-792bfa4cf2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-754d56b1-5a73-4236-8045-268b0fd3283c,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-e9385fcb-d9b6-408e-8b14-f496c9ae750f,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-e9f12da1-e06e-418b-9ddb-b2ec6b28d0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-7093321c-f356-49c8-81d7-ad6a7bc1010b,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-cbebdfbc-fee3-454d-bb86-6de7170eb2bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307407008-172.17.0.15-1597125660861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-e64789cf-a389-4b7c-bd1d-3a0706c36d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-51650da2-b571-40f8-8e05-38097653e7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-64ea2f53-1aab-41f4-b7b1-792bfa4cf2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-754d56b1-5a73-4236-8045-268b0fd3283c,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-e9385fcb-d9b6-408e-8b14-f496c9ae750f,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-e9f12da1-e06e-418b-9ddb-b2ec6b28d0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-7093321c-f356-49c8-81d7-ad6a7bc1010b,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-cbebdfbc-fee3-454d-bb86-6de7170eb2bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801904634-172.17.0.15-1597125826658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-78b0e28e-c063-4b4d-9edc-81a50f61a9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-ab6bcd7e-ed62-40cd-8c53-66b7922f9c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-61d77b28-6d0c-4227-9da9-5cf0df3a134c,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-3c31ac62-6aa0-4d5d-8e83-847935e50f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-242201eb-5929-4b57-b521-e879a02e678b,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-49717991-cd51-4cb1-b79b-2f5cc435bfec,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-198d3485-0dd7-4890-b560-a1cc0159011a,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-85e89290-6edc-4406-9ca1-c0159db7cec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801904634-172.17.0.15-1597125826658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-78b0e28e-c063-4b4d-9edc-81a50f61a9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-ab6bcd7e-ed62-40cd-8c53-66b7922f9c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-61d77b28-6d0c-4227-9da9-5cf0df3a134c,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-3c31ac62-6aa0-4d5d-8e83-847935e50f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-242201eb-5929-4b57-b521-e879a02e678b,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-49717991-cd51-4cb1-b79b-2f5cc435bfec,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-198d3485-0dd7-4890-b560-a1cc0159011a,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-85e89290-6edc-4406-9ca1-c0159db7cec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501363051-172.17.0.15-1597125974813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-f71dd8f4-095a-4ba2-971b-a3cf188b690e,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-e2c4c7c5-3236-4c64-bd2a-b9b825ef6eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-932937f0-8c22-41ef-93b6-55eae6e4db9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-ec9057dc-2649-4db9-b251-1122660c0642,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-e5c40dbf-71b3-4a66-ac17-ebee792b71d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-f194ebce-6bb6-4940-adad-86430b07a366,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-73776882-89cf-405e-aa3c-b4172eeb66c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-c0c97ae0-14a4-45e9-be92-1417122d2b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501363051-172.17.0.15-1597125974813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-f71dd8f4-095a-4ba2-971b-a3cf188b690e,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-e2c4c7c5-3236-4c64-bd2a-b9b825ef6eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-932937f0-8c22-41ef-93b6-55eae6e4db9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-ec9057dc-2649-4db9-b251-1122660c0642,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-e5c40dbf-71b3-4a66-ac17-ebee792b71d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-f194ebce-6bb6-4940-adad-86430b07a366,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-73776882-89cf-405e-aa3c-b4172eeb66c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-c0c97ae0-14a4-45e9-be92-1417122d2b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5464
