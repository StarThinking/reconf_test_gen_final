reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337887207-172.17.0.7-1597137835370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40493,DS-5e492cc8-3d3c-48d1-8d3a-e463ccee3008,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-28cf6d18-373b-4f7d-a101-83165966cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-e0fc3514-fd33-4447-a719-bac3d25f11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-6f796c19-fb07-4305-a91b-84bd1c3ec845,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-ad4c4c69-70c5-4cec-a2da-6941b7e0a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-7e55ecd2-61d4-4df1-9115-327ae8ff5ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-a949e6e8-5d6b-45aa-a286-69d0f118be70,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-537f50a7-affc-4cfe-a805-c898c143e022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337887207-172.17.0.7-1597137835370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40493,DS-5e492cc8-3d3c-48d1-8d3a-e463ccee3008,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-28cf6d18-373b-4f7d-a101-83165966cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-e0fc3514-fd33-4447-a719-bac3d25f11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-6f796c19-fb07-4305-a91b-84bd1c3ec845,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-ad4c4c69-70c5-4cec-a2da-6941b7e0a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-7e55ecd2-61d4-4df1-9115-327ae8ff5ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-a949e6e8-5d6b-45aa-a286-69d0f118be70,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-537f50a7-affc-4cfe-a805-c898c143e022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528055564-172.17.0.7-1597137978444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-9635060e-9e8f-4166-945f-2fe25b0c4992,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-571cfce0-9508-4e3b-a68a-671e55b1113b,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b42fb358-084d-4932-934e-b6e7bb5ae2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-729a075c-ff7c-443c-81d3-32a27457bf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-96dfb3c9-9b97-44c7-925e-2ef30d3311e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-a4784b1a-a37b-4040-a1e4-de3e098775af,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-cbff80c5-63b8-4966-a663-4d1bd673b050,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-bc921b38-2ffd-472b-87d8-b19d6377c42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528055564-172.17.0.7-1597137978444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-9635060e-9e8f-4166-945f-2fe25b0c4992,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-571cfce0-9508-4e3b-a68a-671e55b1113b,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b42fb358-084d-4932-934e-b6e7bb5ae2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-729a075c-ff7c-443c-81d3-32a27457bf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-96dfb3c9-9b97-44c7-925e-2ef30d3311e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-a4784b1a-a37b-4040-a1e4-de3e098775af,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-cbff80c5-63b8-4966-a663-4d1bd673b050,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-bc921b38-2ffd-472b-87d8-b19d6377c42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592542123-172.17.0.7-1597138584075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43517,DS-9cce52f8-f3bc-4af2-b934-bbff7dac60cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-a236902a-43ae-49f4-b653-36462d20bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-d77b2204-57c8-4768-baef-8d06384f739c,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-9997ca1d-84cc-44e0-b145-c6c60ee5a307,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-13bcffb4-d005-456b-ac8e-45e3e203ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-f6ff73ac-31e5-4d79-9bee-878f009af374,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-68d6b3c3-577f-4f07-ad0e-f715db8c10a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-c0f73a6a-0ea8-4e93-97ad-8f9872bbd78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592542123-172.17.0.7-1597138584075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43517,DS-9cce52f8-f3bc-4af2-b934-bbff7dac60cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-a236902a-43ae-49f4-b653-36462d20bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-d77b2204-57c8-4768-baef-8d06384f739c,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-9997ca1d-84cc-44e0-b145-c6c60ee5a307,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-13bcffb4-d005-456b-ac8e-45e3e203ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-f6ff73ac-31e5-4d79-9bee-878f009af374,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-68d6b3c3-577f-4f07-ad0e-f715db8c10a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-c0f73a6a-0ea8-4e93-97ad-8f9872bbd78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826210536-172.17.0.7-1597138715309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-9f461664-3e8c-4186-b42d-0a6981681f51,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-cddf7148-e8e1-4593-8ebe-328e28deb19e,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-bb7e1ccc-a7f4-4166-b1c2-b173bee2bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-2c3c0dfd-5930-4d93-bf0a-0b35ecd0fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-27fc359b-3408-489e-9c16-8658540de3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-a2fcb798-5a32-4bb4-bfa0-2eae863607aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-fbd61911-9039-4d91-8f2c-630791299539,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-83486ad7-2fc6-4404-97fe-61c308b60256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826210536-172.17.0.7-1597138715309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-9f461664-3e8c-4186-b42d-0a6981681f51,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-cddf7148-e8e1-4593-8ebe-328e28deb19e,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-bb7e1ccc-a7f4-4166-b1c2-b173bee2bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-2c3c0dfd-5930-4d93-bf0a-0b35ecd0fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-27fc359b-3408-489e-9c16-8658540de3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-a2fcb798-5a32-4bb4-bfa0-2eae863607aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-fbd61911-9039-4d91-8f2c-630791299539,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-83486ad7-2fc6-4404-97fe-61c308b60256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850621604-172.17.0.7-1597139154381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-7c5a0bbf-2260-4d72-b0c0-31daf6370105,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-0a989042-36ba-4c3b-aadd-cbe56b5e650b,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-e565c13f-95bb-4081-a7c4-64a23b2da89e,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-6f2c6256-9769-49d3-93fd-c6afdf4cf972,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-6d53982a-52b6-4793-8c60-ce9eee309aab,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-e4fbba22-1a21-4127-9ddc-8d848df83785,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-f0405ace-db64-4cbc-8277-7d003668e000,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-4d694d77-6a30-498f-b608-f59b55651152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850621604-172.17.0.7-1597139154381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-7c5a0bbf-2260-4d72-b0c0-31daf6370105,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-0a989042-36ba-4c3b-aadd-cbe56b5e650b,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-e565c13f-95bb-4081-a7c4-64a23b2da89e,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-6f2c6256-9769-49d3-93fd-c6afdf4cf972,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-6d53982a-52b6-4793-8c60-ce9eee309aab,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-e4fbba22-1a21-4127-9ddc-8d848df83785,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-f0405ace-db64-4cbc-8277-7d003668e000,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-4d694d77-6a30-498f-b608-f59b55651152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464394558-172.17.0.7-1597139244902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-21da668e-690e-4e09-a4b3-1145a126e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-8cca6098-3188-4f8c-b0d4-6c9eef9f8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-8598058c-6387-4041-a318-000d0cfb5f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-0ecb0075-2422-4237-abcf-2fbeaf1c2c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-bec5018b-488f-4be3-b528-88448c160fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-f4b912af-b7ca-4b88-8aeb-fa4dee7c7494,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-b9862453-464b-45f2-b9e6-378a88d06347,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-3f2f33b4-39bb-4fd1-bf53-7b50261da6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464394558-172.17.0.7-1597139244902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-21da668e-690e-4e09-a4b3-1145a126e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-8cca6098-3188-4f8c-b0d4-6c9eef9f8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-8598058c-6387-4041-a318-000d0cfb5f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-0ecb0075-2422-4237-abcf-2fbeaf1c2c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-bec5018b-488f-4be3-b528-88448c160fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-f4b912af-b7ca-4b88-8aeb-fa4dee7c7494,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-b9862453-464b-45f2-b9e6-378a88d06347,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-3f2f33b4-39bb-4fd1-bf53-7b50261da6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562870002-172.17.0.7-1597139379361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-fa634596-d48c-4c49-90ff-ca4e2c3fcad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-a8711942-0532-43e9-8f5d-7eb7a03cd56a,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-a210c06c-d25c-479a-b40e-f4d8d1023778,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-0efe6f99-ba66-46e6-97fa-127f636eda84,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-0d41362f-7b96-4711-a591-065240906983,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-e6008d96-bd52-43fc-95db-9639eb7b4848,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-ca18bd0b-baec-42c3-a51d-803a3a717606,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-17f7f0cd-faad-4d58-bd0e-4a2ccf76af13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562870002-172.17.0.7-1597139379361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-fa634596-d48c-4c49-90ff-ca4e2c3fcad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-a8711942-0532-43e9-8f5d-7eb7a03cd56a,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-a210c06c-d25c-479a-b40e-f4d8d1023778,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-0efe6f99-ba66-46e6-97fa-127f636eda84,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-0d41362f-7b96-4711-a591-065240906983,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-e6008d96-bd52-43fc-95db-9639eb7b4848,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-ca18bd0b-baec-42c3-a51d-803a3a717606,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-17f7f0cd-faad-4d58-bd0e-4a2ccf76af13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717878835-172.17.0.7-1597140512765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42626,DS-91c713f1-e544-428c-9dbd-b48431a9b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-47da1db1-171f-44b7-b925-32164dd51b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-27d09f49-d6ee-4fc8-9924-23c8bee80c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-1d4a49e4-4caf-44ad-86eb-804d888e7992,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-7aca8a58-5158-4abe-aa1f-410a8d5b8f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-9e72f410-0bcd-4567-8488-43cb4e64ca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-98a46bab-e731-4332-8f8a-535ada59acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-b68018f9-86f8-4879-8712-00f416f11af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717878835-172.17.0.7-1597140512765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42626,DS-91c713f1-e544-428c-9dbd-b48431a9b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-47da1db1-171f-44b7-b925-32164dd51b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-27d09f49-d6ee-4fc8-9924-23c8bee80c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-1d4a49e4-4caf-44ad-86eb-804d888e7992,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-7aca8a58-5158-4abe-aa1f-410a8d5b8f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-9e72f410-0bcd-4567-8488-43cb4e64ca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-98a46bab-e731-4332-8f8a-535ada59acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-b68018f9-86f8-4879-8712-00f416f11af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727947581-172.17.0.7-1597141053212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36241,DS-92248921-8f15-4668-9129-23e7f941b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-e3b46986-754c-4d26-b8de-0b6a791be725,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-864a8342-cdf1-4cd4-925f-f6621c4d7193,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-d458a291-22d7-4432-8d6a-c9e8a8556671,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-9f556bf0-5af0-44d4-a91e-bc82e21e0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-2be86638-bf5e-4cf2-afd7-c7a1394ebcde,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-b0bddcd5-dba5-4d3c-8411-2463a639665d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-c25bd44c-c366-401d-a3e5-354fc10a30a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727947581-172.17.0.7-1597141053212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36241,DS-92248921-8f15-4668-9129-23e7f941b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-e3b46986-754c-4d26-b8de-0b6a791be725,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-864a8342-cdf1-4cd4-925f-f6621c4d7193,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-d458a291-22d7-4432-8d6a-c9e8a8556671,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-9f556bf0-5af0-44d4-a91e-bc82e21e0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-2be86638-bf5e-4cf2-afd7-c7a1394ebcde,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-b0bddcd5-dba5-4d3c-8411-2463a639665d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-c25bd44c-c366-401d-a3e5-354fc10a30a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703783678-172.17.0.7-1597141356253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-c84e804a-5128-4346-addc-17d596acd0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-6919a959-2bd9-4399-a52d-7dae33f0a948,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-2b112a71-8b1d-40f1-98be-f9b667e750c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-1b80972b-4b8d-4c84-b82b-fdfc5fa147d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-66cb2533-7bbb-4aa5-8303-2c30c0da6044,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-56694257-ef58-4e3f-9abf-2cff4cb04537,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-14af258d-363c-4e1c-a4da-cb2aab165f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-6446ff2c-2323-4b92-9bb5-7d2839aa3aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703783678-172.17.0.7-1597141356253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-c84e804a-5128-4346-addc-17d596acd0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-6919a959-2bd9-4399-a52d-7dae33f0a948,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-2b112a71-8b1d-40f1-98be-f9b667e750c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-1b80972b-4b8d-4c84-b82b-fdfc5fa147d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-66cb2533-7bbb-4aa5-8303-2c30c0da6044,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-56694257-ef58-4e3f-9abf-2cff4cb04537,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-14af258d-363c-4e1c-a4da-cb2aab165f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-6446ff2c-2323-4b92-9bb5-7d2839aa3aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780431997-172.17.0.7-1597141467949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36073,DS-f0c4c558-1c33-488a-9a27-f9bd068072f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-876ecb6e-9593-4fcb-a26c-581faf7bb821,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-5032f03d-ef19-4c68-abaa-d4a016008cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-7157edb1-ef84-4e30-8488-2edbd966ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-c8db0fbb-6728-4cbf-aff7-194aa8a73963,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-ce9a7330-95e2-46d4-b27e-739c5adefe28,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-c8b5850a-e878-45ae-bb22-4f7f4a91c81c,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-1fac04aa-6b74-4f48-a48e-405eb6daa766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780431997-172.17.0.7-1597141467949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36073,DS-f0c4c558-1c33-488a-9a27-f9bd068072f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-876ecb6e-9593-4fcb-a26c-581faf7bb821,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-5032f03d-ef19-4c68-abaa-d4a016008cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-7157edb1-ef84-4e30-8488-2edbd966ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-c8db0fbb-6728-4cbf-aff7-194aa8a73963,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-ce9a7330-95e2-46d4-b27e-739c5adefe28,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-c8b5850a-e878-45ae-bb22-4f7f4a91c81c,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-1fac04aa-6b74-4f48-a48e-405eb6daa766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703334897-172.17.0.7-1597141944613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34481,DS-2561d18b-8ec2-4799-b459-3b83233e345c,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-17f59d19-b1e4-4710-b32c-701653872cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-9bba215d-5198-48cc-965d-d9895241d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-53bf86be-e4fc-4161-b0e5-b05a138f7a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-4f85b42f-1f2c-4717-91bb-2ec106026610,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-e2c88f50-6b30-4e9c-b5c0-fe1fe8f82965,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-a728ba47-4348-4e73-9b94-b340779ecbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c2c3d61b-caf1-4299-a6f7-a584556fbbb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703334897-172.17.0.7-1597141944613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34481,DS-2561d18b-8ec2-4799-b459-3b83233e345c,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-17f59d19-b1e4-4710-b32c-701653872cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-9bba215d-5198-48cc-965d-d9895241d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-53bf86be-e4fc-4161-b0e5-b05a138f7a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-4f85b42f-1f2c-4717-91bb-2ec106026610,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-e2c88f50-6b30-4e9c-b5c0-fe1fe8f82965,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-a728ba47-4348-4e73-9b94-b340779ecbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c2c3d61b-caf1-4299-a6f7-a584556fbbb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478044168-172.17.0.7-1597142205855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44037,DS-69e8f175-847a-4777-bb85-609404b69b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-00180ebf-4fa6-49fb-b06b-b652233b7fff,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-e2fb460c-7893-4098-950f-a302f1d17a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-59bde7a8-308c-4bad-b65b-6f4fd0abf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-dff2e3db-07a6-448a-a1d8-fd3562c2821f,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-b798d210-58b0-463a-ad70-c991b850b588,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-5ee7a624-ad9e-44a7-932b-ff6426c42de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-fc452935-8da6-45bc-b50d-1c0efc99fd7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478044168-172.17.0.7-1597142205855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44037,DS-69e8f175-847a-4777-bb85-609404b69b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-00180ebf-4fa6-49fb-b06b-b652233b7fff,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-e2fb460c-7893-4098-950f-a302f1d17a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-59bde7a8-308c-4bad-b65b-6f4fd0abf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-dff2e3db-07a6-448a-a1d8-fd3562c2821f,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-b798d210-58b0-463a-ad70-c991b850b588,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-5ee7a624-ad9e-44a7-932b-ff6426c42de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-fc452935-8da6-45bc-b50d-1c0efc99fd7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382945495-172.17.0.7-1597142236165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33291,DS-2a687f10-e5a6-4d39-a1e7-76daa22dd267,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-9e663e35-a5ca-432a-820c-f96197a14b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-835c068f-9265-4a24-91f6-cede136991d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-75187b2d-3ae2-4290-8cfd-b8132cfa09e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-79e92c33-f1de-4c50-a7b9-379d9cf58bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-55f5dd20-0ded-4447-ac39-b48fa3fcd23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-c3204d70-8718-4b07-9f56-a04710e8d2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-7268f5bb-f633-4cc0-8f87-5a19229cf3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382945495-172.17.0.7-1597142236165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33291,DS-2a687f10-e5a6-4d39-a1e7-76daa22dd267,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-9e663e35-a5ca-432a-820c-f96197a14b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-835c068f-9265-4a24-91f6-cede136991d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-75187b2d-3ae2-4290-8cfd-b8132cfa09e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-79e92c33-f1de-4c50-a7b9-379d9cf58bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-55f5dd20-0ded-4447-ac39-b48fa3fcd23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-c3204d70-8718-4b07-9f56-a04710e8d2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-7268f5bb-f633-4cc0-8f87-5a19229cf3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5163
