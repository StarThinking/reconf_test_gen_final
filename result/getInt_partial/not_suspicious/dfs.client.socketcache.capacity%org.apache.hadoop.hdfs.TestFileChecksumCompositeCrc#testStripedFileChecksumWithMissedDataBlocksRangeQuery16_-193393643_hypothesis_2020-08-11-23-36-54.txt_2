reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101365505-172.17.0.10-1597189209009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38207,DS-e87b062b-9339-4715-8ad8-5c6e7e417c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-171e3c9d-0e71-4bed-9291-a401dcba4d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-7c2c2b71-1c46-47d0-baa9-b1ade0b7aa44,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-a2672062-6eb8-4e72-9d88-12a2021d07ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-e04ae0bd-740c-410a-a009-c042a56484ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-7ce4703c-8781-4ba1-b792-be9a34e09aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-d78b965d-8d06-453c-a31a-ebff86a61907,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-ec31573b-ae7f-4dbb-b455-2aaa7598f3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101365505-172.17.0.10-1597189209009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38207,DS-e87b062b-9339-4715-8ad8-5c6e7e417c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-171e3c9d-0e71-4bed-9291-a401dcba4d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-7c2c2b71-1c46-47d0-baa9-b1ade0b7aa44,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-a2672062-6eb8-4e72-9d88-12a2021d07ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-e04ae0bd-740c-410a-a009-c042a56484ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-7ce4703c-8781-4ba1-b792-be9a34e09aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-d78b965d-8d06-453c-a31a-ebff86a61907,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-ec31573b-ae7f-4dbb-b455-2aaa7598f3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634668882-172.17.0.10-1597189348972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-a8c35735-c09a-41d9-acbc-832d33b7f872,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-46b438bc-9575-4ec1-9d78-ada8088f617c,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-1cbb1332-cced-4364-963b-d634b69318aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-0db3249b-a0db-4e8b-befd-d0df7544fd81,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-12112948-eb11-4eb5-a7a5-ad079279cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-333654c3-c552-43c5-a7ea-14d96e943d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-7e3c0894-d77a-4ddb-a869-4ba34f7a400b,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-6bf4aa9f-cc87-4bd2-b60d-542dea943d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634668882-172.17.0.10-1597189348972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-a8c35735-c09a-41d9-acbc-832d33b7f872,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-46b438bc-9575-4ec1-9d78-ada8088f617c,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-1cbb1332-cced-4364-963b-d634b69318aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-0db3249b-a0db-4e8b-befd-d0df7544fd81,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-12112948-eb11-4eb5-a7a5-ad079279cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-333654c3-c552-43c5-a7ea-14d96e943d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-7e3c0894-d77a-4ddb-a869-4ba34f7a400b,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-6bf4aa9f-cc87-4bd2-b60d-542dea943d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765090690-172.17.0.10-1597189664342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-06c3d4f9-ee72-4a5e-9ce3-db20ed21c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-d9017bb5-4203-48c6-ad4e-5704b1a823ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-b7ff3fdb-49b0-4044-8031-f62063560e73,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-02e2ae95-a98f-459e-874e-808fbba4a45c,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-edb5f678-ba51-4f5c-9c43-f049dd6259d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-eae73784-5b5c-4c1b-b742-161b044e6895,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-c941ce0a-d597-4c68-9617-668c18515033,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-4c63c54a-9e20-4eea-bd2b-341553075c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765090690-172.17.0.10-1597189664342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-06c3d4f9-ee72-4a5e-9ce3-db20ed21c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-d9017bb5-4203-48c6-ad4e-5704b1a823ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-b7ff3fdb-49b0-4044-8031-f62063560e73,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-02e2ae95-a98f-459e-874e-808fbba4a45c,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-edb5f678-ba51-4f5c-9c43-f049dd6259d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-eae73784-5b5c-4c1b-b742-161b044e6895,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-c941ce0a-d597-4c68-9617-668c18515033,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-4c63c54a-9e20-4eea-bd2b-341553075c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404828682-172.17.0.10-1597189872862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46331,DS-8528d3b6-c08a-41e1-851c-63c93c7eeebd,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-29230658-4c4b-4210-aab0-bfa2eeaf52bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-e5988046-d284-42c3-8a35-47fd4ff4cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-aa3144f7-ec7d-4a42-b1ed-b8c7ed8d7e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-6f4c7e9a-828c-422e-b0b5-4956d674659e,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-b8d2f549-7cf7-46b5-a57b-c7bd6205bf51,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-803fd7bb-43d7-4c69-9e4c-4fcc759eb7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-c43b7dbd-8151-4905-a153-b7b6d6988408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404828682-172.17.0.10-1597189872862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46331,DS-8528d3b6-c08a-41e1-851c-63c93c7eeebd,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-29230658-4c4b-4210-aab0-bfa2eeaf52bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-e5988046-d284-42c3-8a35-47fd4ff4cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-aa3144f7-ec7d-4a42-b1ed-b8c7ed8d7e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-6f4c7e9a-828c-422e-b0b5-4956d674659e,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-b8d2f549-7cf7-46b5-a57b-c7bd6205bf51,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-803fd7bb-43d7-4c69-9e4c-4fcc759eb7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-c43b7dbd-8151-4905-a153-b7b6d6988408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174263409-172.17.0.10-1597190159165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43126,DS-0d6f6185-8983-4658-a514-22c68784a0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-7aa63bb7-9260-4e6b-87ef-17d32a180d93,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-c40da38f-d608-4d7e-8240-b0488d2f6aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-adbf92d3-4c5d-45e3-b653-f3bb5000ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-f09b014c-3535-42be-a040-84d9fe331436,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-08faaac0-4632-4528-b5ef-2b3f158d4af3,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-147469a3-c164-41e0-950d-28cd7493fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-7ad287fe-9bf3-4b0b-b5c0-f65f5563e4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174263409-172.17.0.10-1597190159165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43126,DS-0d6f6185-8983-4658-a514-22c68784a0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-7aa63bb7-9260-4e6b-87ef-17d32a180d93,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-c40da38f-d608-4d7e-8240-b0488d2f6aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-adbf92d3-4c5d-45e3-b653-f3bb5000ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-f09b014c-3535-42be-a040-84d9fe331436,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-08faaac0-4632-4528-b5ef-2b3f158d4af3,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-147469a3-c164-41e0-950d-28cd7493fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-7ad287fe-9bf3-4b0b-b5c0-f65f5563e4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895729163-172.17.0.10-1597190518685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-2de6a708-7abf-48b6-a680-0b8e7e426f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-326ae2bc-0f29-4aac-be35-e185b9dfe280,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-e5b77db7-00d8-439c-82e0-48c173b1be9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-3136937c-9b03-4222-9af2-4408a9db991a,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-f0cbd85a-e3fe-43b5-9dce-7b3e1c6a377b,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-4e858920-297a-4106-8167-ae9242e1c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-f5ace16e-3379-4e47-9883-85afbaaf8235,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-de0b82a9-040c-4814-a6fe-5b86eb5d2a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895729163-172.17.0.10-1597190518685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-2de6a708-7abf-48b6-a680-0b8e7e426f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-326ae2bc-0f29-4aac-be35-e185b9dfe280,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-e5b77db7-00d8-439c-82e0-48c173b1be9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-3136937c-9b03-4222-9af2-4408a9db991a,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-f0cbd85a-e3fe-43b5-9dce-7b3e1c6a377b,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-4e858920-297a-4106-8167-ae9242e1c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-f5ace16e-3379-4e47-9883-85afbaaf8235,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-de0b82a9-040c-4814-a6fe-5b86eb5d2a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28670690-172.17.0.10-1597191448705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-c0f29f14-5666-4304-b705-04c8ce1a9df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-8b05845f-1175-4fe0-bd36-ec5db91cb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-8a8ab9d2-8fe5-407d-b644-7cfda86311d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-39240c4e-3bde-4f7f-93a6-b1803e173d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-acd28500-6cf1-4fcf-a48c-63e72b977f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-5872b21b-05dc-49b7-a623-6e9f437cc84a,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-727b9748-da5c-4077-b7f4-c347ba375cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-4e0dd928-5e0e-4593-b925-e528a2373bed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28670690-172.17.0.10-1597191448705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-c0f29f14-5666-4304-b705-04c8ce1a9df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-8b05845f-1175-4fe0-bd36-ec5db91cb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-8a8ab9d2-8fe5-407d-b644-7cfda86311d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-39240c4e-3bde-4f7f-93a6-b1803e173d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-acd28500-6cf1-4fcf-a48c-63e72b977f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-5872b21b-05dc-49b7-a623-6e9f437cc84a,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-727b9748-da5c-4077-b7f4-c347ba375cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-4e0dd928-5e0e-4593-b925-e528a2373bed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546601923-172.17.0.10-1597191872489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-61ae8cb3-d014-4314-9428-593d939e6c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-169fc98d-f9f3-4c82-ac3d-10a68639aab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-1269870a-99e3-4ec1-adf9-0051571f4285,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-e59f96a4-9cfd-436d-b699-d3d68f428875,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-66cab65c-449c-481b-90f6-21df09187952,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-cd424aa9-ae26-4320-ae5e-02245521e060,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-df615c58-0adb-4a3c-9879-337a79413113,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-2bae1314-c284-480d-a2be-699dddc4257a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546601923-172.17.0.10-1597191872489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-61ae8cb3-d014-4314-9428-593d939e6c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-169fc98d-f9f3-4c82-ac3d-10a68639aab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-1269870a-99e3-4ec1-adf9-0051571f4285,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-e59f96a4-9cfd-436d-b699-d3d68f428875,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-66cab65c-449c-481b-90f6-21df09187952,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-cd424aa9-ae26-4320-ae5e-02245521e060,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-df615c58-0adb-4a3c-9879-337a79413113,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-2bae1314-c284-480d-a2be-699dddc4257a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037312416-172.17.0.10-1597191914050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38411,DS-a49b9a33-1f0b-415e-9064-e6e1af4d897d,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-ab8c773e-e665-4686-b1b2-7ff4d7bd2806,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-a665ad52-71c7-48c6-8067-799385e07694,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-5fff631f-dcb1-4d32-8e86-3d19b18b08ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-5f85114d-ccb9-4bca-a364-3031789ccaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-804d3563-f38d-4939-ab36-f66f1d01ef10,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-9a0444cf-f7a5-4ebc-b9e3-0f18129e964a,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-f27c40da-a991-4d54-9795-11e843c1477e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037312416-172.17.0.10-1597191914050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38411,DS-a49b9a33-1f0b-415e-9064-e6e1af4d897d,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-ab8c773e-e665-4686-b1b2-7ff4d7bd2806,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-a665ad52-71c7-48c6-8067-799385e07694,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-5fff631f-dcb1-4d32-8e86-3d19b18b08ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-5f85114d-ccb9-4bca-a364-3031789ccaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-804d3563-f38d-4939-ab36-f66f1d01ef10,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-9a0444cf-f7a5-4ebc-b9e3-0f18129e964a,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-f27c40da-a991-4d54-9795-11e843c1477e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592668580-172.17.0.10-1597192061605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-0729fe0c-4adc-4d45-b751-e5d170b72653,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-85de160d-24a0-4da9-a7a8-9bdf5859ac90,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-aa8b1972-c8a1-486b-96ee-e74b4c67a029,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-56264431-4aef-48f1-add6-b03d50b0b592,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-38be0795-66e6-4010-be76-5a8bc5fbea89,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-6999b525-7385-41ba-ba2b-877e928e1430,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-41e84eb7-6a9f-41ca-8e5f-def7dcb89fad,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-76b701b0-a0d6-4704-8fe8-ad54960b2bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592668580-172.17.0.10-1597192061605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-0729fe0c-4adc-4d45-b751-e5d170b72653,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-85de160d-24a0-4da9-a7a8-9bdf5859ac90,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-aa8b1972-c8a1-486b-96ee-e74b4c67a029,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-56264431-4aef-48f1-add6-b03d50b0b592,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-38be0795-66e6-4010-be76-5a8bc5fbea89,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-6999b525-7385-41ba-ba2b-877e928e1430,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-41e84eb7-6a9f-41ca-8e5f-def7dcb89fad,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-76b701b0-a0d6-4704-8fe8-ad54960b2bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572146508-172.17.0.10-1597192282807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38370,DS-06d08063-990b-4024-a3a4-b9f02aca36a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-1035c6af-61cd-454d-a33c-0661e5509978,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-e583d83a-0757-4a8d-95b1-58f8b029a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-04e2e72e-f52b-4acd-81c9-968563af61f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-e098b93a-3570-47bf-b749-55cada32c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-fb6ea946-9ec1-45d3-b1b0-fb534b69c32c,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-f3c23f86-4d9d-43b9-a548-550b269468b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-ae94e01f-4b71-46b5-80b0-0516f964b09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572146508-172.17.0.10-1597192282807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38370,DS-06d08063-990b-4024-a3a4-b9f02aca36a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-1035c6af-61cd-454d-a33c-0661e5509978,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-e583d83a-0757-4a8d-95b1-58f8b029a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-04e2e72e-f52b-4acd-81c9-968563af61f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-e098b93a-3570-47bf-b749-55cada32c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-fb6ea946-9ec1-45d3-b1b0-fb534b69c32c,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-f3c23f86-4d9d-43b9-a548-550b269468b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-ae94e01f-4b71-46b5-80b0-0516f964b09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906019217-172.17.0.10-1597193067900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-c35ad4f1-bd97-4311-ab73-37de6f513d67,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-048d1772-1f4b-4c0c-a18c-1550baa1a796,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-a6600729-dd45-490e-b33f-e5b4e3ab0e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-d07bc46d-9782-4299-9e7f-b09aba4675cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-23badc72-f65a-4090-9b7d-b8dfcfbe3a79,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-2aa87ddc-5e05-4457-9097-c565070c13c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-df0b5df6-754c-4fd3-9211-758df39821f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-e22911ea-cd5b-4b5a-8a61-2dfbffa55ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906019217-172.17.0.10-1597193067900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-c35ad4f1-bd97-4311-ab73-37de6f513d67,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-048d1772-1f4b-4c0c-a18c-1550baa1a796,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-a6600729-dd45-490e-b33f-e5b4e3ab0e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-d07bc46d-9782-4299-9e7f-b09aba4675cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-23badc72-f65a-4090-9b7d-b8dfcfbe3a79,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-2aa87ddc-5e05-4457-9097-c565070c13c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-df0b5df6-754c-4fd3-9211-758df39821f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-e22911ea-cd5b-4b5a-8a61-2dfbffa55ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162599377-172.17.0.10-1597193140184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-0365f731-fa1f-4b4f-a166-f80e367c25fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-b84c7a7a-d560-4ecf-830a-0002f7ff5432,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-eeda6a71-9287-401e-b823-1fae75541ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-12e6bbaf-782f-4edb-a2c5-6115c96aad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-d5099672-412e-4686-8d93-92950d5207af,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-d484d571-7650-4541-a069-5edee63a276d,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-11c4199a-8ca7-4fdd-be1b-1df19fa9b6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-f207e437-9682-4b41-b684-949daffa0ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162599377-172.17.0.10-1597193140184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-0365f731-fa1f-4b4f-a166-f80e367c25fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-b84c7a7a-d560-4ecf-830a-0002f7ff5432,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-eeda6a71-9287-401e-b823-1fae75541ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-12e6bbaf-782f-4edb-a2c5-6115c96aad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-d5099672-412e-4686-8d93-92950d5207af,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-d484d571-7650-4541-a069-5edee63a276d,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-11c4199a-8ca7-4fdd-be1b-1df19fa9b6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-f207e437-9682-4b41-b684-949daffa0ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625040094-172.17.0.10-1597193251121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-d2321427-afc4-48b8-894e-ff0a43654e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-c935f2ae-727c-4ecd-aca9-15d6b7e17242,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-8026db0a-5e21-4364-bc50-31a71e89e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-6b664fa5-ab56-4e9e-8fbe-2e68a2ac11aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-07ace711-3927-4e33-b881-122b3fdfc768,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-8f54891a-cc18-4175-a534-5d4221648a76,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-8cffa328-5d3e-4d4a-827d-61a511266964,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-448d5bbc-587d-4fb1-ba6e-227c9e09ef84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625040094-172.17.0.10-1597193251121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-d2321427-afc4-48b8-894e-ff0a43654e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-c935f2ae-727c-4ecd-aca9-15d6b7e17242,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-8026db0a-5e21-4364-bc50-31a71e89e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-6b664fa5-ab56-4e9e-8fbe-2e68a2ac11aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-07ace711-3927-4e33-b881-122b3fdfc768,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-8f54891a-cc18-4175-a534-5d4221648a76,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-8cffa328-5d3e-4d4a-827d-61a511266964,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-448d5bbc-587d-4fb1-ba6e-227c9e09ef84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624742875-172.17.0.10-1597193517996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44296,DS-837e4fee-2c4b-4aa1-a713-d866ff61768f,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-bafb0f80-5ffc-4b7f-be9b-b45ed7136a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-e0104e78-79f7-495a-b33f-93362e051878,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-5407fd6c-bb3a-4c40-b8fd-f7e50e5fa2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-bf1add02-f012-4623-b5aa-9d0d301b37c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-b4c38653-df47-4b61-af3b-3b45738f8bba,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-0304c946-da72-4b50-99c3-c78b0c3956a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-394e5d75-9866-474a-8ede-1c76e18f5194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624742875-172.17.0.10-1597193517996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44296,DS-837e4fee-2c4b-4aa1-a713-d866ff61768f,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-bafb0f80-5ffc-4b7f-be9b-b45ed7136a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-e0104e78-79f7-495a-b33f-93362e051878,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-5407fd6c-bb3a-4c40-b8fd-f7e50e5fa2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-bf1add02-f012-4623-b5aa-9d0d301b37c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-b4c38653-df47-4b61-af3b-3b45738f8bba,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-0304c946-da72-4b50-99c3-c78b0c3956a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-394e5d75-9866-474a-8ede-1c76e18f5194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517379561-172.17.0.10-1597193797153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-be1b0d03-24de-458a-84cd-bdf8d45855f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-3948a8dc-be03-4d6b-90dd-7f2110ba24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-6416a94d-5023-49f7-bd69-ed9351bd2ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-1a301d43-3583-4b06-be0c-fdc0b0f33994,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-43a7833f-2385-4750-83e8-da1ead08dec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-c572fc91-9fa7-45fd-b766-323b0ef93c42,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-dc681fbd-4f76-4938-af88-488abab53e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-51801eb5-71f6-46a7-adc7-50a171999c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517379561-172.17.0.10-1597193797153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-be1b0d03-24de-458a-84cd-bdf8d45855f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-3948a8dc-be03-4d6b-90dd-7f2110ba24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-6416a94d-5023-49f7-bd69-ed9351bd2ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-1a301d43-3583-4b06-be0c-fdc0b0f33994,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-43a7833f-2385-4750-83e8-da1ead08dec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-c572fc91-9fa7-45fd-b766-323b0ef93c42,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-dc681fbd-4f76-4938-af88-488abab53e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-51801eb5-71f6-46a7-adc7-50a171999c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628825870-172.17.0.10-1597194137548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-c32827f1-e07d-4fdc-a285-29fbd8491274,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-9018bf43-05c8-4f6e-853b-cb4dc4d3153c,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-02d2f5d3-54c7-411c-9ba1-6638a08970dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-e44c6fec-5802-4b24-9a27-91e19870e958,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-a0741b3f-396c-499e-9a62-f1520d91dec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-074a1dc9-442a-42bf-bb5d-ef54134f28f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-51d80344-0af4-4835-849e-33f5fa977949,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-eae175f5-ff57-4884-ae6f-fd48664ca711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628825870-172.17.0.10-1597194137548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-c32827f1-e07d-4fdc-a285-29fbd8491274,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-9018bf43-05c8-4f6e-853b-cb4dc4d3153c,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-02d2f5d3-54c7-411c-9ba1-6638a08970dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-e44c6fec-5802-4b24-9a27-91e19870e958,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-a0741b3f-396c-499e-9a62-f1520d91dec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-074a1dc9-442a-42bf-bb5d-ef54134f28f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-51d80344-0af4-4835-849e-33f5fa977949,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-eae175f5-ff57-4884-ae6f-fd48664ca711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953759926-172.17.0.10-1597194167544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36132,DS-5069ed32-c9b9-44da-845c-273bf97f2aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-f9831fbe-6136-4ce1-a126-ca60c6cb9a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-e34c4548-f874-4a2c-ba07-88b6baccf709,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-c9dd7e07-d622-42b4-9af5-9b2be4fcd2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-bc8e17e2-3017-4200-92f3-5a5d974ca133,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-ec71a366-b45e-492e-81b6-76c9524529ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-ed8c6f55-445e-46c8-8b2b-dfd1b3d5ff43,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-624a1176-c8a3-4349-914c-a51ac9ca53f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953759926-172.17.0.10-1597194167544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36132,DS-5069ed32-c9b9-44da-845c-273bf97f2aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-f9831fbe-6136-4ce1-a126-ca60c6cb9a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-e34c4548-f874-4a2c-ba07-88b6baccf709,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-c9dd7e07-d622-42b4-9af5-9b2be4fcd2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-bc8e17e2-3017-4200-92f3-5a5d974ca133,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-ec71a366-b45e-492e-81b6-76c9524529ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-ed8c6f55-445e-46c8-8b2b-dfd1b3d5ff43,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-624a1176-c8a3-4349-914c-a51ac9ca53f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5498
