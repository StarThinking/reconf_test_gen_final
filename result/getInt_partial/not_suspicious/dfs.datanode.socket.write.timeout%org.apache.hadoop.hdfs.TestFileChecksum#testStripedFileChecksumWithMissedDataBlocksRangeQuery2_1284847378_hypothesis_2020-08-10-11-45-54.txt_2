reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560584115-172.17.0.8-1597061373344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-88a1ce91-042a-4f27-b032-420370b2a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-aabe20ea-bbf3-4de1-a1b5-898881fc718d,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-4337a52e-58aa-4e18-a236-ef099c5b4a84,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-ddd3d661-9fba-4c6b-abd5-2f9ecf089c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-f35a72fb-5fb9-4222-a37f-4cb7fab583b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-1bd0d3e2-9a71-4445-8cf2-0e246c001ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-65b4fed1-9bde-49ef-98f8-6d2fc8d3f2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-956e1934-64d1-4a87-acc8-860d5cdaa3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560584115-172.17.0.8-1597061373344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-88a1ce91-042a-4f27-b032-420370b2a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-aabe20ea-bbf3-4de1-a1b5-898881fc718d,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-4337a52e-58aa-4e18-a236-ef099c5b4a84,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-ddd3d661-9fba-4c6b-abd5-2f9ecf089c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-f35a72fb-5fb9-4222-a37f-4cb7fab583b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-1bd0d3e2-9a71-4445-8cf2-0e246c001ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-65b4fed1-9bde-49ef-98f8-6d2fc8d3f2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-956e1934-64d1-4a87-acc8-860d5cdaa3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543562135-172.17.0.8-1597061605369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35430,DS-926a5829-519d-4f7b-9448-7fad5a70a058,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-c70df25b-622d-4ab2-a7ca-ad130ae6ebf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-2ea8676c-e279-4a98-8fba-91a4581a0b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-c1469a3b-0f53-4096-b0ff-5e98abf75c01,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-033c8ac3-587c-4f70-a20c-e79e007f1869,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-abdda686-57ae-4384-8929-19e7cf9891b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-097be919-93d3-4188-95ef-e683acff29cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-fe6af22f-d378-478c-9fda-43dca2844d9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543562135-172.17.0.8-1597061605369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35430,DS-926a5829-519d-4f7b-9448-7fad5a70a058,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-c70df25b-622d-4ab2-a7ca-ad130ae6ebf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-2ea8676c-e279-4a98-8fba-91a4581a0b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-c1469a3b-0f53-4096-b0ff-5e98abf75c01,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-033c8ac3-587c-4f70-a20c-e79e007f1869,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-abdda686-57ae-4384-8929-19e7cf9891b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-097be919-93d3-4188-95ef-e683acff29cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-fe6af22f-d378-478c-9fda-43dca2844d9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121208638-172.17.0.8-1597061795916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46237,DS-64deb8a9-2107-459c-9ffb-cd63d05dc700,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-54782ec5-55ab-4b2a-a28f-c2dc7817bd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-ee860edc-d416-460b-96cd-081f6ddf9dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-651c517c-ca80-42d4-bcea-2fcb0eb471f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-deb7820f-f070-4bde-b3e7-9d053e6c6673,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-ced2e243-5bd2-4b51-9d30-ac3d7832c787,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-be687d78-6e51-4c88-ba06-dde9e6b89878,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-112aaad7-f2bd-4875-969d-b9acd6c5b1e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121208638-172.17.0.8-1597061795916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46237,DS-64deb8a9-2107-459c-9ffb-cd63d05dc700,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-54782ec5-55ab-4b2a-a28f-c2dc7817bd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-ee860edc-d416-460b-96cd-081f6ddf9dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-651c517c-ca80-42d4-bcea-2fcb0eb471f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-deb7820f-f070-4bde-b3e7-9d053e6c6673,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-ced2e243-5bd2-4b51-9d30-ac3d7832c787,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-be687d78-6e51-4c88-ba06-dde9e6b89878,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-112aaad7-f2bd-4875-969d-b9acd6c5b1e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559182101-172.17.0.8-1597061874352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32857,DS-6ec4e785-b27d-4a06-ae0d-3dd3e8cee5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-6bf104ad-498d-4c57-9544-697704b67754,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-0c447057-e9b0-4179-af30-2551ea64b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-a86ba663-0012-4cfa-973b-fc1c034a17ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-e3b0285f-dae3-4709-86c7-9ff3d18fe8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-bad8ab80-c2ff-4288-a19d-732c7f3335cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-f939a5e2-56da-4d5d-a6d7-758d658b03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-74d37599-ea9e-4b01-b20d-950f5fd2731e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559182101-172.17.0.8-1597061874352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32857,DS-6ec4e785-b27d-4a06-ae0d-3dd3e8cee5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-6bf104ad-498d-4c57-9544-697704b67754,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-0c447057-e9b0-4179-af30-2551ea64b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-a86ba663-0012-4cfa-973b-fc1c034a17ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-e3b0285f-dae3-4709-86c7-9ff3d18fe8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-bad8ab80-c2ff-4288-a19d-732c7f3335cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-f939a5e2-56da-4d5d-a6d7-758d658b03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-74d37599-ea9e-4b01-b20d-950f5fd2731e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071679684-172.17.0.8-1597062160109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-6305d489-9b23-4c32-8933-c9ac6cf61cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-7897c12d-eb68-489d-a567-adaca21901e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-8b95e9d3-9605-4b8e-bb12-32794cc7a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-342873de-63d4-4129-8072-9ca3ee61e10c,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-03369203-5581-4246-b211-3b4624e155a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-3e94377b-a8c8-4348-9c2a-3da04e86b248,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-68818e1a-3a11-4e3e-9a94-b4ca6572f3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-be9fa1ad-8f64-417e-aed5-d7fd43780171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071679684-172.17.0.8-1597062160109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-6305d489-9b23-4c32-8933-c9ac6cf61cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-7897c12d-eb68-489d-a567-adaca21901e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-8b95e9d3-9605-4b8e-bb12-32794cc7a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-342873de-63d4-4129-8072-9ca3ee61e10c,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-03369203-5581-4246-b211-3b4624e155a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-3e94377b-a8c8-4348-9c2a-3da04e86b248,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-68818e1a-3a11-4e3e-9a94-b4ca6572f3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-be9fa1ad-8f64-417e-aed5-d7fd43780171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714395402-172.17.0.8-1597062283534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46786,DS-41a560f9-ee0a-4956-9006-74977e79c679,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-62d704e9-a783-4969-b299-18b6eb6ac5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-a78364d3-f799-4d9e-8f6c-2ced03ad53c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-741fe5df-594f-4e25-865b-4109ef906828,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-dca8c677-5c40-4e60-b64c-c003f59a49b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-3b796bf9-118f-4dcb-af98-c768a3ab01b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-bc43ef9e-6362-4688-9b96-3e1f7d55b11f,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-c0c68cea-823f-44ec-9aea-ae77f9b421e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714395402-172.17.0.8-1597062283534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46786,DS-41a560f9-ee0a-4956-9006-74977e79c679,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-62d704e9-a783-4969-b299-18b6eb6ac5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-a78364d3-f799-4d9e-8f6c-2ced03ad53c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-741fe5df-594f-4e25-865b-4109ef906828,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-dca8c677-5c40-4e60-b64c-c003f59a49b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-3b796bf9-118f-4dcb-af98-c768a3ab01b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-bc43ef9e-6362-4688-9b96-3e1f7d55b11f,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-c0c68cea-823f-44ec-9aea-ae77f9b421e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255882863-172.17.0.8-1597062832134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40016,DS-40f19cf3-2c48-4ec0-bce7-a25625ce3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-f24354e7-3b99-45fb-aeb3-33b5b5ff2fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-897fbbde-f7ea-4eb2-a1f7-74aab5c60cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-a57fcc4d-392d-4c27-8b8e-43c49b214825,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-1d7e286a-62cb-4f14-afb2-0dda06f3e111,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-f1f2c8ae-5d15-4d47-beac-87be797a6983,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-00b8a536-07e8-40ae-9e55-901e79736d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-80432942-4988-429a-b0cc-56a3b2108a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255882863-172.17.0.8-1597062832134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40016,DS-40f19cf3-2c48-4ec0-bce7-a25625ce3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-f24354e7-3b99-45fb-aeb3-33b5b5ff2fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-897fbbde-f7ea-4eb2-a1f7-74aab5c60cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-a57fcc4d-392d-4c27-8b8e-43c49b214825,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-1d7e286a-62cb-4f14-afb2-0dda06f3e111,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-f1f2c8ae-5d15-4d47-beac-87be797a6983,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-00b8a536-07e8-40ae-9e55-901e79736d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-80432942-4988-429a-b0cc-56a3b2108a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202201008-172.17.0.8-1597063074266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-694d38b5-1de7-4917-94e2-eb9f0e7194e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-05174233-1f47-4a3a-9ccc-4bb7983f9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-337e7042-27bd-43c8-8f11-948c43135eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-d597ac0d-7bbf-482f-bcc1-38ac8b3b53c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-212333ab-afc1-4d73-9d08-270f09fb8d24,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-d98a4d6c-545d-4c73-9d0d-34a303355da7,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-476b50fd-6741-4563-8a5d-2c9978a8543c,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-be744c5c-bf71-4275-9209-9d92204f0ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202201008-172.17.0.8-1597063074266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-694d38b5-1de7-4917-94e2-eb9f0e7194e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-05174233-1f47-4a3a-9ccc-4bb7983f9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-337e7042-27bd-43c8-8f11-948c43135eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-d597ac0d-7bbf-482f-bcc1-38ac8b3b53c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-212333ab-afc1-4d73-9d08-270f09fb8d24,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-d98a4d6c-545d-4c73-9d0d-34a303355da7,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-476b50fd-6741-4563-8a5d-2c9978a8543c,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-be744c5c-bf71-4275-9209-9d92204f0ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023992511-172.17.0.8-1597063260160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40668,DS-f0304736-fabf-4eec-a83c-12687e742abf,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-6d37f60c-865c-4af3-9ec8-d508c99609a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-fecd89e3-c3dd-4c12-89e6-5d53c62ee9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-c825c39e-80f0-4899-ae72-641e90619ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-de4f5fc1-3aff-484e-9cdb-23bfa83a407a,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-5aef2f2d-e3f9-4da4-a446-629da7f2648a,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-5a2a33b5-a155-459c-a4cf-516f5dc4b0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-bb89b028-6c14-4a39-a94d-e3f50b673f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023992511-172.17.0.8-1597063260160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40668,DS-f0304736-fabf-4eec-a83c-12687e742abf,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-6d37f60c-865c-4af3-9ec8-d508c99609a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-fecd89e3-c3dd-4c12-89e6-5d53c62ee9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-c825c39e-80f0-4899-ae72-641e90619ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-de4f5fc1-3aff-484e-9cdb-23bfa83a407a,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-5aef2f2d-e3f9-4da4-a446-629da7f2648a,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-5a2a33b5-a155-459c-a4cf-516f5dc4b0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-bb89b028-6c14-4a39-a94d-e3f50b673f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710598958-172.17.0.8-1597063294240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44787,DS-29d646a6-c755-4b79-bd71-1510b5e298fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-ad306a75-773f-4d4d-9a13-0df9077dbba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-d2eafead-e25f-4475-8910-cd4c177726ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-e2af8f5b-8970-452f-bdd1-4f64ec7bc67a,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-2ebd0a66-5620-4c9a-8c81-cc4a7a6b95b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-d9975d93-0366-4d5b-b3ae-a890f00af878,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-87b80d17-042f-4c9b-9de6-ae8a43ff3141,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-b2a43403-19cf-4c65-969b-6765d9e93c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710598958-172.17.0.8-1597063294240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44787,DS-29d646a6-c755-4b79-bd71-1510b5e298fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-ad306a75-773f-4d4d-9a13-0df9077dbba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-d2eafead-e25f-4475-8910-cd4c177726ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-e2af8f5b-8970-452f-bdd1-4f64ec7bc67a,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-2ebd0a66-5620-4c9a-8c81-cc4a7a6b95b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-d9975d93-0366-4d5b-b3ae-a890f00af878,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-87b80d17-042f-4c9b-9de6-ae8a43ff3141,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-b2a43403-19cf-4c65-969b-6765d9e93c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511637087-172.17.0.8-1597063533434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-4730995c-9487-4434-b661-0fa2ca635dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-66173430-d81a-4125-bef7-2993e75af387,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-54be8a01-868b-4737-bb5b-3dce6931379c,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-f16588bd-e866-48f9-adb9-6784b05397f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-7fd55963-e30f-425a-9906-0e39a74b6dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-232b4005-51f3-47d0-bf67-dbbda9de4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-9efc205b-d787-428a-9e6f-f36c5f51d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-0e25a625-3329-4148-a843-e39aee4840f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511637087-172.17.0.8-1597063533434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-4730995c-9487-4434-b661-0fa2ca635dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-66173430-d81a-4125-bef7-2993e75af387,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-54be8a01-868b-4737-bb5b-3dce6931379c,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-f16588bd-e866-48f9-adb9-6784b05397f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-7fd55963-e30f-425a-9906-0e39a74b6dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-232b4005-51f3-47d0-bf67-dbbda9de4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-9efc205b-d787-428a-9e6f-f36c5f51d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-0e25a625-3329-4148-a843-e39aee4840f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874875759-172.17.0.8-1597063734594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-633023b3-bb55-4b17-9672-07e7865c61df,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-94684e84-7a06-4420-983d-ba1113718370,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-e7598ee4-7b83-4a14-a131-94b5614e0c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-8231168a-0b45-418b-b7cb-dd042155b27e,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-3b957128-7699-469c-b90b-bf570515314b,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-6355fd2f-815c-46a6-9636-0cf19704221a,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-80c0fc50-cc48-4ce6-b3f3-152a0dfc0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-46c6c087-f501-4792-9a5b-054b8ae2491a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874875759-172.17.0.8-1597063734594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-633023b3-bb55-4b17-9672-07e7865c61df,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-94684e84-7a06-4420-983d-ba1113718370,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-e7598ee4-7b83-4a14-a131-94b5614e0c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-8231168a-0b45-418b-b7cb-dd042155b27e,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-3b957128-7699-469c-b90b-bf570515314b,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-6355fd2f-815c-46a6-9636-0cf19704221a,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-80c0fc50-cc48-4ce6-b3f3-152a0dfc0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-46c6c087-f501-4792-9a5b-054b8ae2491a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399598886-172.17.0.8-1597064104183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-f5930203-d6c2-44e0-860f-fa1e6692b81d,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-76a7c653-aebe-41b7-90f6-b7122db9d937,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-754ece37-4047-4280-8fae-02d5da13a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-f3ef207b-4737-45bb-ae0c-f68b794c4290,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-bc40a0f6-7fbb-488d-a96d-bf873a78b44f,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-49704995-67fa-4781-94b3-7ca6866a3069,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-f5c6987c-38e5-4723-a6f1-80cd7a7ab19f,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-aa41a33d-6d07-4968-baf3-9807286bd1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399598886-172.17.0.8-1597064104183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-f5930203-d6c2-44e0-860f-fa1e6692b81d,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-76a7c653-aebe-41b7-90f6-b7122db9d937,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-754ece37-4047-4280-8fae-02d5da13a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-f3ef207b-4737-45bb-ae0c-f68b794c4290,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-bc40a0f6-7fbb-488d-a96d-bf873a78b44f,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-49704995-67fa-4781-94b3-7ca6866a3069,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-f5c6987c-38e5-4723-a6f1-80cd7a7ab19f,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-aa41a33d-6d07-4968-baf3-9807286bd1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215433199-172.17.0.8-1597064345792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45739,DS-0c59a805-8387-42af-8c07-f1aaad0da5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-c65557bd-3ed7-4f7a-bed2-a76b33e3e1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-cc3bea52-0598-4e07-8d70-44870d1d6006,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-8bfcdd5c-0ce6-4e0c-bdbc-9bce5513e306,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-7f292b70-a93f-4ab4-a2dd-7bdd112544c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-4697b845-4afb-48d9-a06d-e7e313859f66,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-8a40fcda-c41f-47da-a2a1-6f6d8d8d6794,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-9f84e54e-f8cf-4be9-bb25-157767729ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215433199-172.17.0.8-1597064345792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45739,DS-0c59a805-8387-42af-8c07-f1aaad0da5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-c65557bd-3ed7-4f7a-bed2-a76b33e3e1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-cc3bea52-0598-4e07-8d70-44870d1d6006,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-8bfcdd5c-0ce6-4e0c-bdbc-9bce5513e306,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-7f292b70-a93f-4ab4-a2dd-7bdd112544c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-4697b845-4afb-48d9-a06d-e7e313859f66,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-8a40fcda-c41f-47da-a2a1-6f6d8d8d6794,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-9f84e54e-f8cf-4be9-bb25-157767729ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492287434-172.17.0.8-1597064462160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45742,DS-8f4c30ad-437e-4b32-80de-833fcdb62726,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-48be28b6-9f4d-49e1-b04a-7161d9e798c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-9ab5098a-68ba-4860-91ce-4bdce3d250ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-d5167e0d-3880-4d58-afb0-51a96da353e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-09ce2c60-05bd-4a2a-a6a7-db6eca37d5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-2512da8e-6f72-4966-a230-2227ce8d05d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-3b12e8dc-2ee8-4254-8afb-97b5fba5febf,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-a23ec877-bd3e-412f-b2a1-f476370f8b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492287434-172.17.0.8-1597064462160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45742,DS-8f4c30ad-437e-4b32-80de-833fcdb62726,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-48be28b6-9f4d-49e1-b04a-7161d9e798c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-9ab5098a-68ba-4860-91ce-4bdce3d250ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-d5167e0d-3880-4d58-afb0-51a96da353e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-09ce2c60-05bd-4a2a-a6a7-db6eca37d5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-2512da8e-6f72-4966-a230-2227ce8d05d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-3b12e8dc-2ee8-4254-8afb-97b5fba5febf,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-a23ec877-bd3e-412f-b2a1-f476370f8b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912435909-172.17.0.8-1597064693546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-e3bf23df-3174-41c7-a7f3-303190423f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-a66f6829-4822-48fd-ae01-6c0f6dbee614,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-dcb90ecf-5537-4bfd-a5f0-cc2eb9edc58c,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-9adf3386-afb8-4157-9fe9-0ac601e956f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-f94af76c-eda4-413d-9bde-2a87f9707375,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-efdce39f-701c-493b-a67a-bf4c8ca0c765,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-b23cb5c6-dcdc-4ab3-86ac-e616ffb9c5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-7bf055b9-11bb-4755-accc-c21f582258b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912435909-172.17.0.8-1597064693546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-e3bf23df-3174-41c7-a7f3-303190423f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-a66f6829-4822-48fd-ae01-6c0f6dbee614,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-dcb90ecf-5537-4bfd-a5f0-cc2eb9edc58c,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-9adf3386-afb8-4157-9fe9-0ac601e956f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-f94af76c-eda4-413d-9bde-2a87f9707375,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-efdce39f-701c-493b-a67a-bf4c8ca0c765,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-b23cb5c6-dcdc-4ab3-86ac-e616ffb9c5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-7bf055b9-11bb-4755-accc-c21f582258b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101436530-172.17.0.8-1597064855896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-2be487b3-ccd9-45e0-8863-1d523cb3f215,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-805f004c-7162-4b91-93f1-b909c100ddff,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-f098a87f-bde7-4482-9ba1-73664650319b,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-2410a3f1-716a-403d-859d-eb86500bf213,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-540117c7-2348-4741-b0d4-ce858a2e5590,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-eb6b68b6-a4cc-4830-b1e5-0b62012ee67a,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-2b83c05d-5bbf-4565-9d9a-02ebe64fe324,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-b6ed8105-da8a-411d-9faa-3cb2ca902c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101436530-172.17.0.8-1597064855896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-2be487b3-ccd9-45e0-8863-1d523cb3f215,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-805f004c-7162-4b91-93f1-b909c100ddff,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-f098a87f-bde7-4482-9ba1-73664650319b,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-2410a3f1-716a-403d-859d-eb86500bf213,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-540117c7-2348-4741-b0d4-ce858a2e5590,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-eb6b68b6-a4cc-4830-b1e5-0b62012ee67a,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-2b83c05d-5bbf-4565-9d9a-02ebe64fe324,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-b6ed8105-da8a-411d-9faa-3cb2ca902c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817221020-172.17.0.8-1597064984858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-9d0b798f-52b9-4dfb-9a1f-63d76bf5834f,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-15a0c9c1-6ec9-4700-b68f-ef07c3502363,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-2b8da9ac-bb6c-48af-81a3-f5a97507c539,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-77364d14-9ac3-4acc-a09f-b62f4e2cdf40,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-5cbaf515-1afe-4526-a71c-98a38810a248,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-60d13c7c-2a97-45bd-a1b3-4f45f4f522b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-0bad5a5e-31bd-4012-baea-41ea9cbdc25b,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-0d88a52b-9d82-4f58-8e01-b573ec7a2988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817221020-172.17.0.8-1597064984858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-9d0b798f-52b9-4dfb-9a1f-63d76bf5834f,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-15a0c9c1-6ec9-4700-b68f-ef07c3502363,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-2b8da9ac-bb6c-48af-81a3-f5a97507c539,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-77364d14-9ac3-4acc-a09f-b62f4e2cdf40,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-5cbaf515-1afe-4526-a71c-98a38810a248,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-60d13c7c-2a97-45bd-a1b3-4f45f4f522b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-0bad5a5e-31bd-4012-baea-41ea9cbdc25b,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-0d88a52b-9d82-4f58-8e01-b573ec7a2988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609438674-172.17.0.8-1597065222078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-ddaf6d26-cf28-4fcc-8257-c82b5f553086,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-021e0242-f982-41d1-902e-9a83eee85567,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-e68683c9-7689-4895-8b43-364468f23e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-4edca163-a424-42f7-9bed-139da2152331,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-21f4706e-2d88-465b-abba-2d93b4f5fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-5db7f782-b484-4d34-a862-91f687b56da5,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-1f4cd58a-7da6-40ba-8869-b838d3a94cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-1f121d42-d13f-4220-ae3a-78d22d4881e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609438674-172.17.0.8-1597065222078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-ddaf6d26-cf28-4fcc-8257-c82b5f553086,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-021e0242-f982-41d1-902e-9a83eee85567,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-e68683c9-7689-4895-8b43-364468f23e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-4edca163-a424-42f7-9bed-139da2152331,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-21f4706e-2d88-465b-abba-2d93b4f5fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-5db7f782-b484-4d34-a862-91f687b56da5,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-1f4cd58a-7da6-40ba-8869-b838d3a94cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-1f121d42-d13f-4220-ae3a-78d22d4881e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014563505-172.17.0.8-1597065649298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-c8ab9f2a-d54d-4aa8-8b87-d2ac29ce25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-58db6b35-7e02-4cd0-9e82-4936504cf988,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-a62cc457-08e3-4fca-af74-40c9d812208d,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-cb64e42c-09fe-4fe9-8095-87057e864206,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-8b819aa9-848e-478a-bf09-31224573b9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-1b4bbecf-a960-4a72-91c8-bc2958a1571a,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-ce6b7acd-165d-4a1d-af78-38e2b5d5d7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-17c049ee-2740-4277-9e89-3b18d173fe27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014563505-172.17.0.8-1597065649298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-c8ab9f2a-d54d-4aa8-8b87-d2ac29ce25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-58db6b35-7e02-4cd0-9e82-4936504cf988,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-a62cc457-08e3-4fca-af74-40c9d812208d,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-cb64e42c-09fe-4fe9-8095-87057e864206,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-8b819aa9-848e-478a-bf09-31224573b9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-1b4bbecf-a960-4a72-91c8-bc2958a1571a,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-ce6b7acd-165d-4a1d-af78-38e2b5d5d7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-17c049ee-2740-4277-9e89-3b18d173fe27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5721
