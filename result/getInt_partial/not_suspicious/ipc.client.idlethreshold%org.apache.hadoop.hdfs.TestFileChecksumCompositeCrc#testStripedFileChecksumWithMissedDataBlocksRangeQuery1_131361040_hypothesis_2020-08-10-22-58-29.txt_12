reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928283759-172.17.0.16-1597100370917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35559,DS-77556f7e-7c6a-4c25-b304-183e57b8695f,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-7fa87e90-127d-485d-b748-73ed5f30708b,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-77714a1a-bd7e-4aca-964b-43a26266f8af,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-77e002d0-00a4-4a47-bfc6-1e0016ba6290,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-67eb7bff-0dc4-4944-956c-b4561f974873,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-304123c6-787c-4f2b-9a31-7b9483b16cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-4bf59934-0d19-4f46-a38c-7e83fcd93432,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-d46ccbb0-5c2b-4e4e-86af-0fc324b4062f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928283759-172.17.0.16-1597100370917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35559,DS-77556f7e-7c6a-4c25-b304-183e57b8695f,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-7fa87e90-127d-485d-b748-73ed5f30708b,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-77714a1a-bd7e-4aca-964b-43a26266f8af,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-77e002d0-00a4-4a47-bfc6-1e0016ba6290,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-67eb7bff-0dc4-4944-956c-b4561f974873,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-304123c6-787c-4f2b-9a31-7b9483b16cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-4bf59934-0d19-4f46-a38c-7e83fcd93432,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-d46ccbb0-5c2b-4e4e-86af-0fc324b4062f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009931523-172.17.0.16-1597100942809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45521,DS-1e78e54a-7eff-4189-ba9b-53bdcbf24b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-bb36c0c8-6dca-4224-add8-4f3cc35ae2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-e7003601-b49c-40cb-bcf4-877f4cf1a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-6f040c87-1126-4165-85cd-afdcd47d112e,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-dd8da28b-467f-4af9-bab8-3ebd3bc1f5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-874a422c-1fb7-4866-808f-59bc2995b61d,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-2c237594-cf78-44b8-a8a1-04a86d485a28,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-acc54b2f-0bc4-40e3-a2f4-342cd20dc9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009931523-172.17.0.16-1597100942809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45521,DS-1e78e54a-7eff-4189-ba9b-53bdcbf24b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-bb36c0c8-6dca-4224-add8-4f3cc35ae2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-e7003601-b49c-40cb-bcf4-877f4cf1a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-6f040c87-1126-4165-85cd-afdcd47d112e,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-dd8da28b-467f-4af9-bab8-3ebd3bc1f5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-874a422c-1fb7-4866-808f-59bc2995b61d,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-2c237594-cf78-44b8-a8a1-04a86d485a28,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-acc54b2f-0bc4-40e3-a2f4-342cd20dc9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215554334-172.17.0.16-1597101444396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38609,DS-4e29036b-baa4-4623-bd9f-40f762b3a781,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-4188f112-0a8b-4887-99aa-75d211053401,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-95b7644e-00d6-4f39-abe5-7457b4d33804,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-e2bbe2e1-b5cd-4336-b169-7414b97b5fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-0f3eae0c-8947-4b8b-9aa9-20acef0aa80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-f19c8f0a-a132-4fa2-a2b3-1db7267c194e,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-86a301a0-b5f2-4a3a-8e56-4a89fc32a61c,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-a47c4679-87d0-4397-ba7f-5433ae7ef4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215554334-172.17.0.16-1597101444396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38609,DS-4e29036b-baa4-4623-bd9f-40f762b3a781,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-4188f112-0a8b-4887-99aa-75d211053401,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-95b7644e-00d6-4f39-abe5-7457b4d33804,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-e2bbe2e1-b5cd-4336-b169-7414b97b5fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-0f3eae0c-8947-4b8b-9aa9-20acef0aa80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-f19c8f0a-a132-4fa2-a2b3-1db7267c194e,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-86a301a0-b5f2-4a3a-8e56-4a89fc32a61c,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-a47c4679-87d0-4397-ba7f-5433ae7ef4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876479671-172.17.0.16-1597101662288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45005,DS-5332d740-9a30-4206-8769-127f24c55090,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-b6192963-c91a-4faf-adf4-1cc0ff46a204,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-f1354bb0-10f7-4d1b-8858-2766418ea834,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-dfc9323d-13c8-439c-b42a-cf2773156147,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-26cb28e5-2140-432d-85df-43f9258c52aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-7b484de4-26ba-4a8c-b344-249178a7b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-cc912ce9-6015-4f50-9178-1aef5f4ecece,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-c92eadd8-2b61-4dc6-a327-aa1a2a8dc556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876479671-172.17.0.16-1597101662288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45005,DS-5332d740-9a30-4206-8769-127f24c55090,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-b6192963-c91a-4faf-adf4-1cc0ff46a204,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-f1354bb0-10f7-4d1b-8858-2766418ea834,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-dfc9323d-13c8-439c-b42a-cf2773156147,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-26cb28e5-2140-432d-85df-43f9258c52aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-7b484de4-26ba-4a8c-b344-249178a7b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-cc912ce9-6015-4f50-9178-1aef5f4ecece,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-c92eadd8-2b61-4dc6-a327-aa1a2a8dc556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015560627-172.17.0.16-1597101768870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39341,DS-69fe246b-c3a9-4983-b79e-3930a9085e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-81159a52-887a-4876-9feb-e200b0688373,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-a1c8c9f3-dc7a-41bf-af8c-b0296559827d,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-0fa0240c-d846-402a-83cc-b8017ff2ce51,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-0d2f66fc-df33-4ed1-af4e-dc5f5c5e1d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-66228666-001a-40e9-a2fc-a73bbc0c7616,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-b723b592-aab0-4c30-bfb6-7d449e0172fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-c5c73413-26c4-4912-bdb1-b1b1e2efd1ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015560627-172.17.0.16-1597101768870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39341,DS-69fe246b-c3a9-4983-b79e-3930a9085e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-81159a52-887a-4876-9feb-e200b0688373,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-a1c8c9f3-dc7a-41bf-af8c-b0296559827d,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-0fa0240c-d846-402a-83cc-b8017ff2ce51,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-0d2f66fc-df33-4ed1-af4e-dc5f5c5e1d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-66228666-001a-40e9-a2fc-a73bbc0c7616,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-b723b592-aab0-4c30-bfb6-7d449e0172fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-c5c73413-26c4-4912-bdb1-b1b1e2efd1ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426874447-172.17.0.16-1597101946684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-708c1a3c-f6ad-4f81-b34a-41a33adf3bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-29ee9423-a4df-4c14-af62-204db7f8c037,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-12b3c751-cb44-4dad-a027-5303b90fbb60,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-b4c92a47-f3ac-4b85-9997-9f6c8826d0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-dc7e4159-6880-4646-a9c7-653f803463fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-2c351d4f-cbf4-4557-9a83-03e1028986db,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-07af73ca-88cb-4be6-a93b-d73221fd8893,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-bd60b407-f5fc-444c-a2de-8fbe891dce22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426874447-172.17.0.16-1597101946684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-708c1a3c-f6ad-4f81-b34a-41a33adf3bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-29ee9423-a4df-4c14-af62-204db7f8c037,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-12b3c751-cb44-4dad-a027-5303b90fbb60,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-b4c92a47-f3ac-4b85-9997-9f6c8826d0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-dc7e4159-6880-4646-a9c7-653f803463fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-2c351d4f-cbf4-4557-9a83-03e1028986db,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-07af73ca-88cb-4be6-a93b-d73221fd8893,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-bd60b407-f5fc-444c-a2de-8fbe891dce22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280366218-172.17.0.16-1597102976235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34262,DS-8192f6a3-835b-474d-a3de-9974974c1373,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-72660afe-9c2e-4688-95b4-0c20d2336a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-45d21867-a9b0-4215-a611-e685b7920321,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-bc2e4541-7827-41fa-91bd-935c9efe65fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-442467e5-d3f7-4b3b-b5ec-5afdb1008162,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-f79ba09b-45e9-4bf7-9a1b-187b9cb16db0,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-0e7ec5e3-aa03-43f3-bb5a-e57c83c9fdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-68c01447-c0cc-473e-ad47-8578df793591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280366218-172.17.0.16-1597102976235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34262,DS-8192f6a3-835b-474d-a3de-9974974c1373,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-72660afe-9c2e-4688-95b4-0c20d2336a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-45d21867-a9b0-4215-a611-e685b7920321,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-bc2e4541-7827-41fa-91bd-935c9efe65fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-442467e5-d3f7-4b3b-b5ec-5afdb1008162,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-f79ba09b-45e9-4bf7-9a1b-187b9cb16db0,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-0e7ec5e3-aa03-43f3-bb5a-e57c83c9fdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-68c01447-c0cc-473e-ad47-8578df793591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811300424-172.17.0.16-1597103007738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-18ba48b2-7a09-4733-b7e9-2cefa245efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0bdce359-0e6f-420f-90fa-4f3e44b6df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-fab97bae-709d-4ab5-b142-56ea4198c174,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-cebcc28a-cb5e-4fde-9f72-ecd458b4ca11,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-4453d689-5a8e-4b6f-9bf0-8824e2a8205e,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-6970e028-074f-4314-8a94-2bca676beffb,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-a72f2f4f-4340-4c70-b0e2-250dc8a511b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-bec3973e-7c12-4a0a-a5d3-8b8e94facdce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811300424-172.17.0.16-1597103007738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-18ba48b2-7a09-4733-b7e9-2cefa245efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0bdce359-0e6f-420f-90fa-4f3e44b6df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-fab97bae-709d-4ab5-b142-56ea4198c174,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-cebcc28a-cb5e-4fde-9f72-ecd458b4ca11,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-4453d689-5a8e-4b6f-9bf0-8824e2a8205e,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-6970e028-074f-4314-8a94-2bca676beffb,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-a72f2f4f-4340-4c70-b0e2-250dc8a511b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-bec3973e-7c12-4a0a-a5d3-8b8e94facdce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100682437-172.17.0.16-1597103121489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-7716cb47-c4f5-4a2a-a8fd-2821d8c9edc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-8e94a11a-3b6a-4998-b64e-8758807c0b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-d492e194-bacc-4281-94fe-f1ef8773fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-14aa4f58-f938-4d63-a3d7-b02216742792,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-9dd82a51-8c55-442e-be31-5f6a4a2811e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-843d7103-7704-41e3-8f7b-ccf107d3f2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-b3c57bb0-d7f9-4a97-abc4-12e83a6a9081,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-69944abf-5093-41f4-b3ba-9cba5b1d1b1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100682437-172.17.0.16-1597103121489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-7716cb47-c4f5-4a2a-a8fd-2821d8c9edc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-8e94a11a-3b6a-4998-b64e-8758807c0b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-d492e194-bacc-4281-94fe-f1ef8773fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-14aa4f58-f938-4d63-a3d7-b02216742792,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-9dd82a51-8c55-442e-be31-5f6a4a2811e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-843d7103-7704-41e3-8f7b-ccf107d3f2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-b3c57bb0-d7f9-4a97-abc4-12e83a6a9081,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-69944abf-5093-41f4-b3ba-9cba5b1d1b1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941926645-172.17.0.16-1597103194962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-0767b87e-b4be-40e3-82c2-7afad1999fca,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-523e1053-bcc6-4cdc-9acb-760f75cdce17,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-67744ab8-e9ff-4396-9840-5f44cca27e03,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-abdc4c7c-5fa7-4b98-8625-a623405a55bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-3bd34a69-219d-4345-9ad4-11f4f445dae4,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-61e2693b-c430-4a17-83ee-3d1ebf4c4857,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-1739f15c-25db-4275-bff2-6e40b7722675,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-32c21100-cb20-4402-af13-1fe50257c66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941926645-172.17.0.16-1597103194962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-0767b87e-b4be-40e3-82c2-7afad1999fca,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-523e1053-bcc6-4cdc-9acb-760f75cdce17,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-67744ab8-e9ff-4396-9840-5f44cca27e03,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-abdc4c7c-5fa7-4b98-8625-a623405a55bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-3bd34a69-219d-4345-9ad4-11f4f445dae4,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-61e2693b-c430-4a17-83ee-3d1ebf4c4857,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-1739f15c-25db-4275-bff2-6e40b7722675,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-32c21100-cb20-4402-af13-1fe50257c66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588944281-172.17.0.16-1597103679498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-5b81ec8d-8a45-46bc-b33f-02d18d7c8d57,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-61064ce0-cc54-4ff5-b20f-cec9ae19f2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-a87c1015-c1db-43fd-9f47-a59f7e23d449,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-543d2a76-68e0-4189-be3c-00809b3f3361,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-7abf88df-3413-43b9-b194-b527ebe3379b,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-a45f7122-41d4-4fb8-bc65-80b08b4b19ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-271bb5f2-3ebd-44b0-bddd-bc55ffbedb33,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-3f7b45ed-6492-4ae8-95e7-32389314acb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588944281-172.17.0.16-1597103679498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-5b81ec8d-8a45-46bc-b33f-02d18d7c8d57,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-61064ce0-cc54-4ff5-b20f-cec9ae19f2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-a87c1015-c1db-43fd-9f47-a59f7e23d449,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-543d2a76-68e0-4189-be3c-00809b3f3361,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-7abf88df-3413-43b9-b194-b527ebe3379b,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-a45f7122-41d4-4fb8-bc65-80b08b4b19ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-271bb5f2-3ebd-44b0-bddd-bc55ffbedb33,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-3f7b45ed-6492-4ae8-95e7-32389314acb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10944620-172.17.0.16-1597103919687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-b8aeca13-f28e-4277-b74c-a7480fc9497d,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-89767e00-fa9a-41f6-8507-b4bd928c044e,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-5cc09944-4081-476f-afff-5bd842d99c38,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-fdae5f9b-80df-4857-ba4e-5adc20c74828,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-bbae82b8-8230-4d98-aa43-3b7895be927d,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-6b49121f-add2-47b7-b488-5866d1e1c2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-7aa98f0f-00db-401e-9993-462aeb1865d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-cc75866c-8de0-4ff6-b203-b6a202926002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10944620-172.17.0.16-1597103919687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-b8aeca13-f28e-4277-b74c-a7480fc9497d,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-89767e00-fa9a-41f6-8507-b4bd928c044e,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-5cc09944-4081-476f-afff-5bd842d99c38,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-fdae5f9b-80df-4857-ba4e-5adc20c74828,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-bbae82b8-8230-4d98-aa43-3b7895be927d,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-6b49121f-add2-47b7-b488-5866d1e1c2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-7aa98f0f-00db-401e-9993-462aeb1865d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-cc75866c-8de0-4ff6-b203-b6a202926002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311906194-172.17.0.16-1597104101803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37619,DS-518d088f-4528-49e8-a226-07404214663c,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-e1539a63-f5dd-41dc-bc8a-93c67cdf528a,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-9b3337f2-0fe1-4069-bf53-3d7002fc96ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-324e6275-dcff-4578-b6a5-088fcc39aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-7b65bc35-e094-413a-ac0f-83cfa9a803f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-08cfd1e2-3559-42f1-b066-3443a31cb6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-b1e93276-078d-40ac-b22a-4e58c2b627fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-39ea3395-0f16-4efc-ae42-d285d50605ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311906194-172.17.0.16-1597104101803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37619,DS-518d088f-4528-49e8-a226-07404214663c,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-e1539a63-f5dd-41dc-bc8a-93c67cdf528a,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-9b3337f2-0fe1-4069-bf53-3d7002fc96ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-324e6275-dcff-4578-b6a5-088fcc39aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-7b65bc35-e094-413a-ac0f-83cfa9a803f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-08cfd1e2-3559-42f1-b066-3443a31cb6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-b1e93276-078d-40ac-b22a-4e58c2b627fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-39ea3395-0f16-4efc-ae42-d285d50605ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822749676-172.17.0.16-1597104672979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-06bc066d-8a2b-40e7-b1b0-ed91e854fe70,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-f1c39481-a09a-4cbc-b2ab-a71e5daf36a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-e5514fe0-d540-444e-81cc-289b7408c62f,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-68a09829-5828-4a5d-ad10-28122ab8077f,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-33b21f21-e0e6-4b0b-a364-20ebba7a212b,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-7f496ef2-7427-4501-8373-3302c0ee0f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-2e8ceaac-25c0-4173-903b-188cab04012b,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-f1cd4e24-bc5d-40b0-9b08-35171025e3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822749676-172.17.0.16-1597104672979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-06bc066d-8a2b-40e7-b1b0-ed91e854fe70,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-f1c39481-a09a-4cbc-b2ab-a71e5daf36a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-e5514fe0-d540-444e-81cc-289b7408c62f,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-68a09829-5828-4a5d-ad10-28122ab8077f,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-33b21f21-e0e6-4b0b-a364-20ebba7a212b,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-7f496ef2-7427-4501-8373-3302c0ee0f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-2e8ceaac-25c0-4173-903b-188cab04012b,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-f1cd4e24-bc5d-40b0-9b08-35171025e3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793896956-172.17.0.16-1597104983074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44633,DS-4bf95512-535c-4132-9326-f4f724b6e1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-45e75c47-cb40-4fdf-a5b2-9a78ccea4d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-727efb3d-5655-4d5b-b667-c4575e1795f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-1940b9c7-f1f3-4968-9392-16c3145477df,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-56c29a98-b0d8-46bc-8100-6814ee4ff583,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-9129c863-9b3b-40ea-b12c-a5fb3fd62584,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-f670354d-3e98-48c2-8305-b350c5834832,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-cae34e06-9214-47cc-af84-a3ecf1a5dd0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793896956-172.17.0.16-1597104983074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44633,DS-4bf95512-535c-4132-9326-f4f724b6e1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-45e75c47-cb40-4fdf-a5b2-9a78ccea4d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-727efb3d-5655-4d5b-b667-c4575e1795f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-1940b9c7-f1f3-4968-9392-16c3145477df,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-56c29a98-b0d8-46bc-8100-6814ee4ff583,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-9129c863-9b3b-40ea-b12c-a5fb3fd62584,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-f670354d-3e98-48c2-8305-b350c5834832,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-cae34e06-9214-47cc-af84-a3ecf1a5dd0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632471452-172.17.0.16-1597105017735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-9ee2fd32-26f8-48d5-8a61-234cdce4e9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-40445d30-1504-4aa2-bff4-e013e0bfa5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-2dd30004-0fd5-40fc-bbea-393d047f3210,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-ef5cf1be-3e9f-4ceb-bf35-2dcd34c3ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-a60cc7fb-289e-4d95-a17a-573badca3bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-3e605724-15df-4772-95df-f1806d1dd11e,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-17c48119-aa95-47d3-a3c4-5b9c70acc2da,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-f3d06c25-74ce-4c2e-853f-d2a20c77e702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632471452-172.17.0.16-1597105017735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-9ee2fd32-26f8-48d5-8a61-234cdce4e9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-40445d30-1504-4aa2-bff4-e013e0bfa5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-2dd30004-0fd5-40fc-bbea-393d047f3210,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-ef5cf1be-3e9f-4ceb-bf35-2dcd34c3ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-a60cc7fb-289e-4d95-a17a-573badca3bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-3e605724-15df-4772-95df-f1806d1dd11e,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-17c48119-aa95-47d3-a3c4-5b9c70acc2da,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-f3d06c25-74ce-4c2e-853f-d2a20c77e702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649139596-172.17.0.16-1597105791754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39741,DS-35fa1193-e1b0-4b1a-b359-f2b23e12ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-173cfe01-4310-4f7a-bdbc-d4ec0036f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-a7eecc5a-d878-41e2-b716-ac87ae623304,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-56152dec-79b6-48fd-a7cb-60a1f0011050,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-4a27d424-ae7d-4996-8aad-e724da42fd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-7fda2956-70db-4220-9b9f-9ff84270947f,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-ad579f7a-b926-4164-812e-72a363daa112,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-d4da35c1-7b95-41b1-a694-ffa161d19dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649139596-172.17.0.16-1597105791754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39741,DS-35fa1193-e1b0-4b1a-b359-f2b23e12ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-173cfe01-4310-4f7a-bdbc-d4ec0036f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-a7eecc5a-d878-41e2-b716-ac87ae623304,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-56152dec-79b6-48fd-a7cb-60a1f0011050,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-4a27d424-ae7d-4996-8aad-e724da42fd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-7fda2956-70db-4220-9b9f-9ff84270947f,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-ad579f7a-b926-4164-812e-72a363daa112,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-d4da35c1-7b95-41b1-a694-ffa161d19dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5544
