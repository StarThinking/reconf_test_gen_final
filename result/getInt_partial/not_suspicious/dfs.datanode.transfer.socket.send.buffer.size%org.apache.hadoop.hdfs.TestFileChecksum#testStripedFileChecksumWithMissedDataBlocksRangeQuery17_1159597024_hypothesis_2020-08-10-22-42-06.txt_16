reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129139177-172.17.0.16-1597099394271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34469,DS-96ee7ded-ffea-4c40-8c5b-ab5b99bf0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-77d09f87-52ba-4c82-9409-4152020e55f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-8393525e-228c-4588-99e4-cd701f36afa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-710ea170-3591-42f8-9d87-5b43dabd936c,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-1bd299aa-bdd7-495e-a05c-f3f61b5e5611,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-e9619e53-588a-4663-9d52-1ebaab5c5808,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-a332837e-1e4a-4675-977a-d09a54456a78,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-e1715236-dae7-43a3-b169-b8e3ac8ca526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129139177-172.17.0.16-1597099394271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34469,DS-96ee7ded-ffea-4c40-8c5b-ab5b99bf0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-77d09f87-52ba-4c82-9409-4152020e55f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-8393525e-228c-4588-99e4-cd701f36afa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-710ea170-3591-42f8-9d87-5b43dabd936c,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-1bd299aa-bdd7-495e-a05c-f3f61b5e5611,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-e9619e53-588a-4663-9d52-1ebaab5c5808,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-a332837e-1e4a-4675-977a-d09a54456a78,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-e1715236-dae7-43a3-b169-b8e3ac8ca526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328080153-172.17.0.16-1597100198263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39995,DS-276f6b4e-4af8-4cc3-907c-f0df906c376c,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-33d48383-0352-4066-928b-5e76bc49cec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-a119d585-8248-41dd-840e-94fc55faf1db,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-fc80cf17-e342-46dc-a69b-16cc38004d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-8b1fd729-f05e-4d0b-a887-7235c67c8b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-7c40570e-df86-43bd-a300-079ac875006e,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-918a85a3-9ac0-4262-91a2-250868aeccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-f331a9fc-c60f-4837-91ee-1234560ac260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328080153-172.17.0.16-1597100198263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39995,DS-276f6b4e-4af8-4cc3-907c-f0df906c376c,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-33d48383-0352-4066-928b-5e76bc49cec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-a119d585-8248-41dd-840e-94fc55faf1db,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-fc80cf17-e342-46dc-a69b-16cc38004d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-8b1fd729-f05e-4d0b-a887-7235c67c8b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-7c40570e-df86-43bd-a300-079ac875006e,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-918a85a3-9ac0-4262-91a2-250868aeccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-f331a9fc-c60f-4837-91ee-1234560ac260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531865889-172.17.0.16-1597100604357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-7a7af718-4c52-4172-8a7c-a8dab5cfcbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-b848a816-f3b0-457b-81c6-a085a8c43847,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-488259f5-5f78-4b07-9d6e-f2f7784451d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-934287be-bfec-448a-ab9c-e1342d776485,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-9fb112b3-c3c6-4ae5-8f06-65a868c401dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-92c1eda7-7bd5-44dc-a869-7e545668545c,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-e0262ba2-8b68-4121-b778-f26b0a36d5db,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-07eb1c28-3453-4690-9b41-b96840c8f316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531865889-172.17.0.16-1597100604357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-7a7af718-4c52-4172-8a7c-a8dab5cfcbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-b848a816-f3b0-457b-81c6-a085a8c43847,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-488259f5-5f78-4b07-9d6e-f2f7784451d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-934287be-bfec-448a-ab9c-e1342d776485,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-9fb112b3-c3c6-4ae5-8f06-65a868c401dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-92c1eda7-7bd5-44dc-a869-7e545668545c,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-e0262ba2-8b68-4121-b778-f26b0a36d5db,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-07eb1c28-3453-4690-9b41-b96840c8f316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016747175-172.17.0.16-1597100694216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41855,DS-979f23b7-8e48-4aad-8ec2-5071ae922e49,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-bd867abc-6781-4cce-8ab9-f24b39459eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-cadbe0ce-835f-4cc2-9e30-3960f43952aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-af5a3c08-db83-4b34-9b77-94d043a3cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-cac1c768-d9bb-4eb6-9cd0-fe9fc69093dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-cf56e431-1d9a-48f1-a543-af75c1ebd277,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-78d75e56-9af8-4dea-912d-51affaa38ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-af821c4c-4493-41a7-bec2-c95fa2f59451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016747175-172.17.0.16-1597100694216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41855,DS-979f23b7-8e48-4aad-8ec2-5071ae922e49,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-bd867abc-6781-4cce-8ab9-f24b39459eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-cadbe0ce-835f-4cc2-9e30-3960f43952aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-af5a3c08-db83-4b34-9b77-94d043a3cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-cac1c768-d9bb-4eb6-9cd0-fe9fc69093dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-cf56e431-1d9a-48f1-a543-af75c1ebd277,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-78d75e56-9af8-4dea-912d-51affaa38ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-af821c4c-4493-41a7-bec2-c95fa2f59451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169114543-172.17.0.16-1597100921156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-c517bb7f-431a-4b27-a139-759d5f4ec5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-52f3eb88-76d2-45a9-9d8a-9b80075c0855,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-60d3368e-f234-48a8-b0c7-0a79bc154fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-5e2c1b79-8143-47e1-b813-81bbf8fd2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-7e08b1a1-218c-4394-a2af-4e17bc7c6a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-00275c96-1e5b-425d-b49d-3363dbdd3309,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-03eb9a39-5ba9-43c0-8671-24d8d7a171eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-d59e7f9b-dea7-4566-b572-99a71b4dd0e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169114543-172.17.0.16-1597100921156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-c517bb7f-431a-4b27-a139-759d5f4ec5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-52f3eb88-76d2-45a9-9d8a-9b80075c0855,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-60d3368e-f234-48a8-b0c7-0a79bc154fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-5e2c1b79-8143-47e1-b813-81bbf8fd2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-7e08b1a1-218c-4394-a2af-4e17bc7c6a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-00275c96-1e5b-425d-b49d-3363dbdd3309,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-03eb9a39-5ba9-43c0-8671-24d8d7a171eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-d59e7f9b-dea7-4566-b572-99a71b4dd0e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734364082-172.17.0.16-1597101009775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-1ad27d28-c4ae-4800-8a3c-d6fa3f9630bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-4b26589d-edef-4ac5-adf1-2ca20b2de743,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-f9c14146-2d1b-49ec-93fb-66a5d085924f,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-b1f7ed0e-e3d8-472d-9197-4878fd3690b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-ef2e99c9-0497-4834-be5e-97407130baa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-ffddd05b-b6be-447f-81c9-838d10db5051,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-50234195-7fee-404a-892e-9cd30d9c801e,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-6438eec5-9e8c-4333-93d2-b79705e926e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734364082-172.17.0.16-1597101009775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-1ad27d28-c4ae-4800-8a3c-d6fa3f9630bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-4b26589d-edef-4ac5-adf1-2ca20b2de743,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-f9c14146-2d1b-49ec-93fb-66a5d085924f,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-b1f7ed0e-e3d8-472d-9197-4878fd3690b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-ef2e99c9-0497-4834-be5e-97407130baa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-ffddd05b-b6be-447f-81c9-838d10db5051,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-50234195-7fee-404a-892e-9cd30d9c801e,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-6438eec5-9e8c-4333-93d2-b79705e926e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243292482-172.17.0.16-1597101307389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-f643340c-6c18-4b62-b69b-64d12d39ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-bc6be16c-a790-474a-ba2c-22567998a7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-33d7baa0-a421-431e-9b08-5a5b9dd6d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-fbf05251-888d-4a5d-9e8b-b839db21a235,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-b017b701-df4e-4c65-b40c-dda77f4e7e13,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-883b707c-42ba-45ab-b737-7b69943169c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-f6c8a8ca-61a9-411a-92e9-7cff46ca864f,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-447f4e57-1680-4943-87e7-f3ee1cd1b647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243292482-172.17.0.16-1597101307389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-f643340c-6c18-4b62-b69b-64d12d39ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-bc6be16c-a790-474a-ba2c-22567998a7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-33d7baa0-a421-431e-9b08-5a5b9dd6d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-fbf05251-888d-4a5d-9e8b-b839db21a235,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-b017b701-df4e-4c65-b40c-dda77f4e7e13,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-883b707c-42ba-45ab-b737-7b69943169c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-f6c8a8ca-61a9-411a-92e9-7cff46ca864f,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-447f4e57-1680-4943-87e7-f3ee1cd1b647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924493139-172.17.0.16-1597102332737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35565,DS-9093e4d5-a03c-4446-8b07-15bcf1c35843,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-158562f0-7176-4c76-ba8e-d42a60d80106,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-9200c06e-17f7-4be0-a29e-40fef2ae94b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-cd3b1561-1fe3-4d6a-b514-08fa52ec7eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-bf8a2031-c271-4bca-a530-086b87f37b87,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-66cd1fef-daa8-4fa4-9984-0c2bda9a8173,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-a21b2dcf-eb9f-4525-8ee0-760447312def,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-f473ddea-639a-4667-a6ed-5b4cdfa6518f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924493139-172.17.0.16-1597102332737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35565,DS-9093e4d5-a03c-4446-8b07-15bcf1c35843,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-158562f0-7176-4c76-ba8e-d42a60d80106,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-9200c06e-17f7-4be0-a29e-40fef2ae94b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-cd3b1561-1fe3-4d6a-b514-08fa52ec7eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-bf8a2031-c271-4bca-a530-086b87f37b87,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-66cd1fef-daa8-4fa4-9984-0c2bda9a8173,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-a21b2dcf-eb9f-4525-8ee0-760447312def,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-f473ddea-639a-4667-a6ed-5b4cdfa6518f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860336337-172.17.0.16-1597102872859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-8a83880f-32f2-4378-bee6-2a2de5872f66,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-f51c7134-7707-4db4-b2b3-9ef497c6eb52,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-56648305-a9fe-49eb-aae6-b82bbb6eb213,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-5e0ec405-9f37-4f7b-a4c0-665bdd374840,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-d3b8869d-a74f-4c16-a56b-d047ebd90799,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-09ce2f01-13fa-4f7f-aa19-81672f826b88,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-a215414b-cc49-4473-9332-b568cec84b46,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-562d8f04-92c7-44e8-a144-271088c54c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860336337-172.17.0.16-1597102872859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-8a83880f-32f2-4378-bee6-2a2de5872f66,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-f51c7134-7707-4db4-b2b3-9ef497c6eb52,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-56648305-a9fe-49eb-aae6-b82bbb6eb213,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-5e0ec405-9f37-4f7b-a4c0-665bdd374840,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-d3b8869d-a74f-4c16-a56b-d047ebd90799,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-09ce2f01-13fa-4f7f-aa19-81672f826b88,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-a215414b-cc49-4473-9332-b568cec84b46,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-562d8f04-92c7-44e8-a144-271088c54c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142560926-172.17.0.16-1597103654764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-28eab206-deaa-4366-a519-869fc6b90c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-a81e02be-bcdb-4fe2-80c9-43fd709a4cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-d67016b4-647e-4fd7-87d6-24e8b5183e09,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-ec32ffbc-bfe6-492d-9d29-08dd8a70c4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-d4a805f0-fdbd-48d5-85cd-de782ac99266,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-c784a236-7def-49f5-951c-f52ff534bfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-ac90f9d5-2eab-4a99-888d-8febce4a2045,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-adc88bf3-df32-4104-8fd7-21b38f022aa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142560926-172.17.0.16-1597103654764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-28eab206-deaa-4366-a519-869fc6b90c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-a81e02be-bcdb-4fe2-80c9-43fd709a4cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-d67016b4-647e-4fd7-87d6-24e8b5183e09,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-ec32ffbc-bfe6-492d-9d29-08dd8a70c4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-d4a805f0-fdbd-48d5-85cd-de782ac99266,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-c784a236-7def-49f5-951c-f52ff534bfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-ac90f9d5-2eab-4a99-888d-8febce4a2045,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-adc88bf3-df32-4104-8fd7-21b38f022aa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058762741-172.17.0.16-1597104611581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-d5300be1-92e3-4846-ad13-280530c4ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-b5457c1a-855a-42f2-819c-15143b7950c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-a980dc8d-a186-465f-8966-97c5848792ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-69118263-75bc-42fe-b7b6-2c92bf4245ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-3903b5df-cfd6-4d1d-baf8-5b07339a26c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-a66c4d04-e8e8-4d83-82db-439fe8be7d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-3fcb81bb-321b-4b4b-a9f3-8c7de73c4db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-039c6e04-01f7-4599-adae-093b669254df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058762741-172.17.0.16-1597104611581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-d5300be1-92e3-4846-ad13-280530c4ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-b5457c1a-855a-42f2-819c-15143b7950c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-a980dc8d-a186-465f-8966-97c5848792ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-69118263-75bc-42fe-b7b6-2c92bf4245ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-3903b5df-cfd6-4d1d-baf8-5b07339a26c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-a66c4d04-e8e8-4d83-82db-439fe8be7d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-3fcb81bb-321b-4b4b-a9f3-8c7de73c4db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-039c6e04-01f7-4599-adae-093b669254df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950025001-172.17.0.16-1597105103192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37534,DS-a366b826-ff4a-4940-a558-4ddf5a8c19ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-4ae1beac-5fd3-4403-b1cd-9c13cdf0701c,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-89d34588-1e01-4fa9-b441-17f7a9a196d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-b774e8fe-fdb1-412d-b6bc-46bd4a7ce4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-269fe05d-4df3-4b8b-ad64-cebda2aaaccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-f1af6eb1-ce5f-4d6f-87d2-bcd0eb4e09f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-1f1a9e9e-a7d7-4116-a036-1d0ae150d5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-1a7fdd75-38b2-4b07-af6a-a8fef250ee3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950025001-172.17.0.16-1597105103192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37534,DS-a366b826-ff4a-4940-a558-4ddf5a8c19ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-4ae1beac-5fd3-4403-b1cd-9c13cdf0701c,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-89d34588-1e01-4fa9-b441-17f7a9a196d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-b774e8fe-fdb1-412d-b6bc-46bd4a7ce4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-269fe05d-4df3-4b8b-ad64-cebda2aaaccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-f1af6eb1-ce5f-4d6f-87d2-bcd0eb4e09f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-1f1a9e9e-a7d7-4116-a036-1d0ae150d5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-1a7fdd75-38b2-4b07-af6a-a8fef250ee3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18299551-172.17.0.16-1597105431660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40670,DS-812351d2-0758-401e-a348-9479d5aa05fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-c79472c6-f5db-413b-9a62-51c16cb7c6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-dea139b0-62d4-4e24-9fe9-91eea3e5b94c,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-df970fba-a90c-46ad-b4db-4c90af5edbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-1630824d-f20c-4446-ab3e-fe594eeb7bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-a02e1399-6f74-4cc9-9645-9fd5e87348f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-acf77baf-d0b5-436c-a93f-dea3d75ca8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-53691cb6-bc0b-4465-ba25-c08f6bf38941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18299551-172.17.0.16-1597105431660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40670,DS-812351d2-0758-401e-a348-9479d5aa05fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-c79472c6-f5db-413b-9a62-51c16cb7c6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-dea139b0-62d4-4e24-9fe9-91eea3e5b94c,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-df970fba-a90c-46ad-b4db-4c90af5edbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-1630824d-f20c-4446-ab3e-fe594eeb7bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-a02e1399-6f74-4cc9-9645-9fd5e87348f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-acf77baf-d0b5-436c-a93f-dea3d75ca8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-53691cb6-bc0b-4465-ba25-c08f6bf38941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323017274-172.17.0.16-1597105774660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-3d19529a-01c5-48db-b7be-2222ebd5b4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-c04266fb-bc34-4a9f-8456-3780db332289,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-1ebae7ce-61dd-4080-a808-5cb82a32d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-fc359d77-ddcb-4c9a-b035-033937e3ec90,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-d8e62b26-2fd0-4608-b027-f3a32eb49ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-fa219eec-4c83-475b-a4bf-119d7f98474a,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-47f677fb-2c5f-4d92-ad4b-89b676631032,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-3a922e5d-57f5-4a3b-8b65-4e9f9a02af4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323017274-172.17.0.16-1597105774660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-3d19529a-01c5-48db-b7be-2222ebd5b4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-c04266fb-bc34-4a9f-8456-3780db332289,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-1ebae7ce-61dd-4080-a808-5cb82a32d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-fc359d77-ddcb-4c9a-b035-033937e3ec90,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-d8e62b26-2fd0-4608-b027-f3a32eb49ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-fa219eec-4c83-475b-a4bf-119d7f98474a,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-47f677fb-2c5f-4d92-ad4b-89b676631032,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-3a922e5d-57f5-4a3b-8b65-4e9f9a02af4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6602
