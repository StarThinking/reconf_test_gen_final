reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520996359-172.17.0.11-1597058741415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-1b69a0b1-27a0-4f36-b589-d81222f0a952,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-97a84386-685f-4446-8c19-44ea68bfe165,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-d6cb7096-bd95-4649-9ef5-49a657d89ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-1c59d434-cb32-4a53-82bf-2cc914b81afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-83fa0696-5a7b-4e5c-a0e7-9ed22df9b152,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-016943e1-ca3e-4875-a0fc-660152cb929b,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ad36142f-4434-4ff3-ba2a-9a60f650b2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-ae633573-6863-41cb-8fd2-015a97e25559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520996359-172.17.0.11-1597058741415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-1b69a0b1-27a0-4f36-b589-d81222f0a952,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-97a84386-685f-4446-8c19-44ea68bfe165,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-d6cb7096-bd95-4649-9ef5-49a657d89ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-1c59d434-cb32-4a53-82bf-2cc914b81afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-83fa0696-5a7b-4e5c-a0e7-9ed22df9b152,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-016943e1-ca3e-4875-a0fc-660152cb929b,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ad36142f-4434-4ff3-ba2a-9a60f650b2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-ae633573-6863-41cb-8fd2-015a97e25559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682912092-172.17.0.11-1597059000315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-4b7910d4-e295-4755-b0d4-e25ce1c7ab35,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-f7680f1c-95c0-424a-b539-ba8d24bd5661,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-9f1d9fed-291b-423e-b3a0-36d7fe503e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-96e38701-3315-4f4e-b490-3da863cd1006,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-c78f489a-9834-4f21-9def-e4ad2b4b7d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-418ac82a-0101-477b-bf3b-85b4f722783a,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-4e988713-b4b4-443b-a209-bfb19b6cf218,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-f3f70944-cedb-4860-a540-48fee5245741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682912092-172.17.0.11-1597059000315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-4b7910d4-e295-4755-b0d4-e25ce1c7ab35,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-f7680f1c-95c0-424a-b539-ba8d24bd5661,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-9f1d9fed-291b-423e-b3a0-36d7fe503e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-96e38701-3315-4f4e-b490-3da863cd1006,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-c78f489a-9834-4f21-9def-e4ad2b4b7d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-418ac82a-0101-477b-bf3b-85b4f722783a,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-4e988713-b4b4-443b-a209-bfb19b6cf218,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-f3f70944-cedb-4860-a540-48fee5245741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058688654-172.17.0.11-1597059031381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34882,DS-5831bad8-a556-460d-9523-1dc46a8d41f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-3b2885f7-1d0f-47de-9d93-2efce44b4bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-09407f62-173f-4dab-bcb3-043bbc17fd68,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-03fe59d6-d670-4b42-a043-717a80c0e065,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-12c9f5d6-5acb-4728-9461-1048a469070f,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-31cf7a54-36a4-49ea-b8b3-a8e1a52cdd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-6052932b-c907-4baa-bc32-8895772a2352,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-573e236d-28e3-4622-8623-aa09d74b9f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058688654-172.17.0.11-1597059031381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34882,DS-5831bad8-a556-460d-9523-1dc46a8d41f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-3b2885f7-1d0f-47de-9d93-2efce44b4bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-09407f62-173f-4dab-bcb3-043bbc17fd68,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-03fe59d6-d670-4b42-a043-717a80c0e065,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-12c9f5d6-5acb-4728-9461-1048a469070f,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-31cf7a54-36a4-49ea-b8b3-a8e1a52cdd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-6052932b-c907-4baa-bc32-8895772a2352,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-573e236d-28e3-4622-8623-aa09d74b9f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818258200-172.17.0.11-1597059302323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44851,DS-eb81fdfb-c34d-4bf1-a181-714c1405c836,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-184e2751-ba77-46c7-bc73-b7b23c12cd81,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-cab79873-c017-4461-9fd5-f55f2d5f2edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-522ddc69-636f-4e36-ad4c-8fe57c33807e,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-9ac80f61-c796-45e7-a723-fda9a4415f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-55343d20-0b18-4587-b6fa-90338ffa4b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-4ec37e20-fe8b-42ad-a333-8803d4e8a925,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-fdcb3595-87e8-437b-b02c-ce99a99f1536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818258200-172.17.0.11-1597059302323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44851,DS-eb81fdfb-c34d-4bf1-a181-714c1405c836,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-184e2751-ba77-46c7-bc73-b7b23c12cd81,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-cab79873-c017-4461-9fd5-f55f2d5f2edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-522ddc69-636f-4e36-ad4c-8fe57c33807e,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-9ac80f61-c796-45e7-a723-fda9a4415f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-55343d20-0b18-4587-b6fa-90338ffa4b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-4ec37e20-fe8b-42ad-a333-8803d4e8a925,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-fdcb3595-87e8-437b-b02c-ce99a99f1536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595967486-172.17.0.11-1597059597695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-e5621113-13d4-488a-98a0-ac133eec5b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-1e286829-595b-4c45-b6f3-f38299c0749b,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-db16c830-1053-4367-8b48-42cda439960a,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-df74384f-9d99-4da9-9ab2-3deb12c612b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-cb40dfb5-5747-4f11-93a1-7f89699a9c58,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-e167cbbf-3210-4f21-9388-a6dd0ffd4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-153a46be-1f8c-4466-8d7b-4f18a0691614,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-5c65d1b4-2d0e-41c2-8574-1f0291159d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595967486-172.17.0.11-1597059597695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-e5621113-13d4-488a-98a0-ac133eec5b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-1e286829-595b-4c45-b6f3-f38299c0749b,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-db16c830-1053-4367-8b48-42cda439960a,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-df74384f-9d99-4da9-9ab2-3deb12c612b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-cb40dfb5-5747-4f11-93a1-7f89699a9c58,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-e167cbbf-3210-4f21-9388-a6dd0ffd4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-153a46be-1f8c-4466-8d7b-4f18a0691614,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-5c65d1b4-2d0e-41c2-8574-1f0291159d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28323734-172.17.0.11-1597059731738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45978,DS-5d43a4eb-c5a0-4b29-b411-695f678a88fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-8561d3fa-2878-40a3-a1b7-b8732cba84a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-83104a5c-d0a7-44e6-a65c-e7d46d2f8daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4d6c38a8-a985-41c8-800a-8574ba5bb318,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-6ab52017-6da5-479c-8221-546baaa8a304,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-81d59a96-3135-48d8-82f4-e12f07860c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-61dc32b8-d114-4633-a30a-cc289a453939,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-0703f40f-9c49-42b8-be1f-10302e19831d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28323734-172.17.0.11-1597059731738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45978,DS-5d43a4eb-c5a0-4b29-b411-695f678a88fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-8561d3fa-2878-40a3-a1b7-b8732cba84a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-83104a5c-d0a7-44e6-a65c-e7d46d2f8daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4d6c38a8-a985-41c8-800a-8574ba5bb318,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-6ab52017-6da5-479c-8221-546baaa8a304,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-81d59a96-3135-48d8-82f4-e12f07860c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-61dc32b8-d114-4633-a30a-cc289a453939,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-0703f40f-9c49-42b8-be1f-10302e19831d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643684800-172.17.0.11-1597060208096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38776,DS-01e3fd0e-d039-46d3-b146-9bdedde25071,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-c17e26df-421e-483e-9968-2ce672251b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-667ae957-74fa-4bcc-bb55-3292832c4b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-b27fd765-c16d-4fdc-b450-4611365883b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-68206570-1c85-4893-9b76-2487408a6fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-037114f8-b30f-4d15-9086-c0f2c3c80be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-79daff75-10bf-457b-8e48-b51e5bce10dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-0638dc14-2524-4f0c-977d-61b3c2e11ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643684800-172.17.0.11-1597060208096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38776,DS-01e3fd0e-d039-46d3-b146-9bdedde25071,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-c17e26df-421e-483e-9968-2ce672251b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-667ae957-74fa-4bcc-bb55-3292832c4b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-b27fd765-c16d-4fdc-b450-4611365883b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-68206570-1c85-4893-9b76-2487408a6fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-037114f8-b30f-4d15-9086-c0f2c3c80be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-79daff75-10bf-457b-8e48-b51e5bce10dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-0638dc14-2524-4f0c-977d-61b3c2e11ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303925446-172.17.0.11-1597061353370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33619,DS-e21f2870-79e7-4345-aa12-de33b4b431a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-467a9a6c-2eed-4faf-8025-d30ec91bb50f,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-72ee9528-df24-4f01-b2fb-92fcca37552d,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-20d4a503-ca53-4fce-a6b7-6d3537ef266c,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-2ee87a75-5beb-48b8-ace9-f2d75b73391d,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-adb09251-696e-4752-baab-0b3262470bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-87c70d80-d2ec-4618-98ee-175a07eb5e87,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-cc76233e-b31f-46a5-9466-e197fbc4174b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303925446-172.17.0.11-1597061353370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33619,DS-e21f2870-79e7-4345-aa12-de33b4b431a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-467a9a6c-2eed-4faf-8025-d30ec91bb50f,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-72ee9528-df24-4f01-b2fb-92fcca37552d,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-20d4a503-ca53-4fce-a6b7-6d3537ef266c,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-2ee87a75-5beb-48b8-ace9-f2d75b73391d,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-adb09251-696e-4752-baab-0b3262470bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-87c70d80-d2ec-4618-98ee-175a07eb5e87,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-cc76233e-b31f-46a5-9466-e197fbc4174b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808421335-172.17.0.11-1597061782206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40820,DS-3bec644d-8d76-4872-b0b1-60bfbd1efbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-4b669e25-b0f0-4bed-83c4-d424a1127f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-506e8b2d-4d3e-46de-9d73-2f20f804688e,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-942fbef0-8b86-482d-84f1-8322f36f33cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-5776ab2a-1bd1-4c9e-9faf-ab7ac3fb34fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-f34dc458-047e-4b8c-b443-a84cff902dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-2add74be-a324-407b-bbba-7bdebf5a8c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-10ffa5c3-e6aa-4afa-a961-bebba896e9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808421335-172.17.0.11-1597061782206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40820,DS-3bec644d-8d76-4872-b0b1-60bfbd1efbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-4b669e25-b0f0-4bed-83c4-d424a1127f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-506e8b2d-4d3e-46de-9d73-2f20f804688e,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-942fbef0-8b86-482d-84f1-8322f36f33cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-5776ab2a-1bd1-4c9e-9faf-ab7ac3fb34fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-f34dc458-047e-4b8c-b443-a84cff902dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-2add74be-a324-407b-bbba-7bdebf5a8c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-10ffa5c3-e6aa-4afa-a961-bebba896e9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108070668-172.17.0.11-1597062013562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45434,DS-947c627e-7f97-4163-aabb-103139ad7014,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-a190debe-92e0-47e0-8bf6-8c6de764b97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-146da166-1eb0-4c4e-9323-6b358bb71e25,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-90d63cb7-7318-49f4-b9b0-d30f54c46f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-06c27537-7a4f-438d-9e27-c9ae425dc53b,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-cc5039aa-0bf0-43d6-a539-103dc73537ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-40a8f80b-8a49-493d-9319-2a096f787fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-23cc3899-634b-4495-8af1-d667256aae33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108070668-172.17.0.11-1597062013562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45434,DS-947c627e-7f97-4163-aabb-103139ad7014,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-a190debe-92e0-47e0-8bf6-8c6de764b97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-146da166-1eb0-4c4e-9323-6b358bb71e25,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-90d63cb7-7318-49f4-b9b0-d30f54c46f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-06c27537-7a4f-438d-9e27-c9ae425dc53b,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-cc5039aa-0bf0-43d6-a539-103dc73537ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-40a8f80b-8a49-493d-9319-2a096f787fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-23cc3899-634b-4495-8af1-d667256aae33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581413870-172.17.0.11-1597062298213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35163,DS-3caec21b-7b8b-41f7-b1a4-36030e8873c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-258580f1-9cc8-43db-8c02-bc0471fc19a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-0498948f-b524-4fef-81ab-603e46810e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-c9a9f4a2-050e-4d94-919e-c38478f9af64,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-e77f9353-1dcf-4aa0-9238-4e178afac278,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-0a74b642-85ed-4d02-a55c-5c695f87ef7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-e172e941-015d-4ae5-b18b-398d2f11ffba,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-7607e619-efaf-4336-b9ae-f5cd427060e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581413870-172.17.0.11-1597062298213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35163,DS-3caec21b-7b8b-41f7-b1a4-36030e8873c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-258580f1-9cc8-43db-8c02-bc0471fc19a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-0498948f-b524-4fef-81ab-603e46810e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-c9a9f4a2-050e-4d94-919e-c38478f9af64,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-e77f9353-1dcf-4aa0-9238-4e178afac278,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-0a74b642-85ed-4d02-a55c-5c695f87ef7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-e172e941-015d-4ae5-b18b-398d2f11ffba,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-7607e619-efaf-4336-b9ae-f5cd427060e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925317193-172.17.0.11-1597063087112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38918,DS-4ed5c892-8937-4290-b32c-ecf9b1a5be20,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-dcee75ab-b470-4df5-b15c-a28be78ad16a,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-d300ef5a-ef5c-4db6-9902-10c0b5f7ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-e88cebb7-7d0a-42be-b16b-0a60d4fa8522,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-b5076f38-3f97-40ed-a240-62d57f13cec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-f48bf412-51da-4554-bca7-8f5a7a0f7ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-41fba3f3-b8fe-4558-b755-a1052f2d4f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-548873ca-bb51-44be-9be9-2ec9479d0b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925317193-172.17.0.11-1597063087112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38918,DS-4ed5c892-8937-4290-b32c-ecf9b1a5be20,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-dcee75ab-b470-4df5-b15c-a28be78ad16a,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-d300ef5a-ef5c-4db6-9902-10c0b5f7ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-e88cebb7-7d0a-42be-b16b-0a60d4fa8522,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-b5076f38-3f97-40ed-a240-62d57f13cec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-f48bf412-51da-4554-bca7-8f5a7a0f7ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-41fba3f3-b8fe-4558-b755-a1052f2d4f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-548873ca-bb51-44be-9be9-2ec9479d0b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069580607-172.17.0.11-1597063361350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-8a01e1e5-9156-4db2-94d1-62e6052e0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-19db2696-7d35-482d-b01c-8cada4156394,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-f56724e7-fd98-451e-868b-1ea3012942d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-96804c2a-786f-42c3-85d6-7058989b1529,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-f4160b97-6706-4c74-8789-763f9f05e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-36de9964-8197-4166-a11b-9d17521f1788,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-8aa46ca6-dcd4-4eed-a551-b6ba86c54efe,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-1a4a3b51-f57c-4fcf-a052-f9f774f89b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069580607-172.17.0.11-1597063361350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-8a01e1e5-9156-4db2-94d1-62e6052e0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-19db2696-7d35-482d-b01c-8cada4156394,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-f56724e7-fd98-451e-868b-1ea3012942d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-96804c2a-786f-42c3-85d6-7058989b1529,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-f4160b97-6706-4c74-8789-763f9f05e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-36de9964-8197-4166-a11b-9d17521f1788,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-8aa46ca6-dcd4-4eed-a551-b6ba86c54efe,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-1a4a3b51-f57c-4fcf-a052-f9f774f89b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592736903-172.17.0.11-1597063567111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-23d1ef4a-cf00-4058-a67c-0ec1c4c70d05,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-e797088c-c296-4b68-93f3-cd16cc2822a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-eeaaf27a-9150-4a89-b732-33e5d2623866,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-4555bd69-01a3-44d4-960e-04ac5f917595,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-f1eb0b8a-84ed-4d6c-8177-ca24560ec8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-6712c7d8-13d3-4b9f-ae8f-75ef4ed3beef,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-80b69f33-7db9-419a-8758-15bc69d8f60e,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-8cc90eaa-7ed9-4886-a7f7-cb41363700fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592736903-172.17.0.11-1597063567111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-23d1ef4a-cf00-4058-a67c-0ec1c4c70d05,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-e797088c-c296-4b68-93f3-cd16cc2822a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-eeaaf27a-9150-4a89-b732-33e5d2623866,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-4555bd69-01a3-44d4-960e-04ac5f917595,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-f1eb0b8a-84ed-4d6c-8177-ca24560ec8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-6712c7d8-13d3-4b9f-ae8f-75ef4ed3beef,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-80b69f33-7db9-419a-8758-15bc69d8f60e,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-8cc90eaa-7ed9-4886-a7f7-cb41363700fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481022378-172.17.0.11-1597063632503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-87d0a9fa-9a32-4de6-b6ae-a9766fd92aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-9c0da00a-a082-42cb-a4aa-011a064b25ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-34a109fb-f4ad-449e-b153-753bcef9a443,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-62d2ac41-6b17-4f20-aae7-d5b0a15d7ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-aa6b994e-d1b3-4622-9c09-082b629334f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-5ddb821e-d100-438c-aa51-b31912f417bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-dc50f47c-a100-48ea-9064-843ea72d4a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-b5c12752-7900-4618-a49d-f5b6866632f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481022378-172.17.0.11-1597063632503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-87d0a9fa-9a32-4de6-b6ae-a9766fd92aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-9c0da00a-a082-42cb-a4aa-011a064b25ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-34a109fb-f4ad-449e-b153-753bcef9a443,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-62d2ac41-6b17-4f20-aae7-d5b0a15d7ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-aa6b994e-d1b3-4622-9c09-082b629334f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-5ddb821e-d100-438c-aa51-b31912f417bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-dc50f47c-a100-48ea-9064-843ea72d4a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-b5c12752-7900-4618-a49d-f5b6866632f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366147998-172.17.0.11-1597063735729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-24c0f1c8-dd0a-4f8f-ad03-82137e791539,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-8192c39b-b420-4345-be9e-58c378d5bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-f83fffb0-068a-4663-a99a-355673e82595,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-dcde72ef-2700-4bc1-b763-c5795f059700,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-fb11d4d1-90cb-48f8-82e2-d1ab9829c0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-14532f26-6f7d-41a7-8a53-6f14257ea114,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-32076dbd-7abf-4a1b-9003-19ada33d8d61,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-f983bb25-9d63-4148-8a0a-f091739665a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366147998-172.17.0.11-1597063735729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-24c0f1c8-dd0a-4f8f-ad03-82137e791539,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-8192c39b-b420-4345-be9e-58c378d5bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-f83fffb0-068a-4663-a99a-355673e82595,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-dcde72ef-2700-4bc1-b763-c5795f059700,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-fb11d4d1-90cb-48f8-82e2-d1ab9829c0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-14532f26-6f7d-41a7-8a53-6f14257ea114,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-32076dbd-7abf-4a1b-9003-19ada33d8d61,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-f983bb25-9d63-4148-8a0a-f091739665a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748798015-172.17.0.11-1597063806160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-9d6f09e7-53e8-4764-bf03-a417d9628648,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-f13d2d38-b33a-45c1-a21a-bd2665d79d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-72206535-ea13-4c6e-89e5-7b1df092b672,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-2dd5a89b-828c-4283-b4e8-f02fd13a6da9,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-c6909340-5fc3-498e-a813-c394d1ea4121,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-18464f49-3851-4b0c-af70-b478862dfbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-81881e2c-1504-416b-a58a-204440195c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-f6e73f80-2af1-4482-a5cf-7ea09462d1c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748798015-172.17.0.11-1597063806160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-9d6f09e7-53e8-4764-bf03-a417d9628648,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-f13d2d38-b33a-45c1-a21a-bd2665d79d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-72206535-ea13-4c6e-89e5-7b1df092b672,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-2dd5a89b-828c-4283-b4e8-f02fd13a6da9,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-c6909340-5fc3-498e-a813-c394d1ea4121,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-18464f49-3851-4b0c-af70-b478862dfbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-81881e2c-1504-416b-a58a-204440195c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-f6e73f80-2af1-4482-a5cf-7ea09462d1c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5259
