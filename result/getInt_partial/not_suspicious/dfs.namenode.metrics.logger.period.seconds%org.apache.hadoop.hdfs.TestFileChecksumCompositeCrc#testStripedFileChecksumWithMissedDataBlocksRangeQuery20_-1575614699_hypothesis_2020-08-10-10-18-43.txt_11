reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388116909-172.17.0.12-1597054911379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-36af164f-29d1-4228-8421-92f81d0d753f,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-2e2ed8f6-3c15-42b4-bc99-15e3c354da21,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-7e5d207f-0761-43f2-9999-ca5d50f5a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-6218f0a6-21ac-4ddd-9ad6-c94d18291252,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-f663f30c-7d7f-427d-ab32-4b86ec5ce0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-9dc88fb2-0998-4af9-8a33-d87f11c31dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-d9c359e4-3edb-487c-aca6-ea0c6eb7c598,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-3ce12cc5-3228-4393-9fbd-c7c7f90128ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388116909-172.17.0.12-1597054911379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-36af164f-29d1-4228-8421-92f81d0d753f,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-2e2ed8f6-3c15-42b4-bc99-15e3c354da21,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-7e5d207f-0761-43f2-9999-ca5d50f5a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-6218f0a6-21ac-4ddd-9ad6-c94d18291252,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-f663f30c-7d7f-427d-ab32-4b86ec5ce0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-9dc88fb2-0998-4af9-8a33-d87f11c31dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-d9c359e4-3edb-487c-aca6-ea0c6eb7c598,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-3ce12cc5-3228-4393-9fbd-c7c7f90128ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959848289-172.17.0.12-1597055024266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-beec6dbf-6f2d-4624-a59f-0bf90d6cce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-9de4ca72-c984-4554-9f95-99d7306ac65b,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-8c04d93e-d261-417b-bab3-8ac77332553b,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-1e72aaa1-3c1d-4175-89cc-bf330acba6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-ba6492b1-9a40-4f21-b791-fefa35bf48c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-d4a57b0a-4f60-45cf-b040-137dcabdb77f,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-53f7e7d0-3e2f-4bf2-b50f-55d2a4c5e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-ad90d0a6-5f57-4ffb-8792-79789ae37deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959848289-172.17.0.12-1597055024266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-beec6dbf-6f2d-4624-a59f-0bf90d6cce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-9de4ca72-c984-4554-9f95-99d7306ac65b,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-8c04d93e-d261-417b-bab3-8ac77332553b,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-1e72aaa1-3c1d-4175-89cc-bf330acba6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-ba6492b1-9a40-4f21-b791-fefa35bf48c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-d4a57b0a-4f60-45cf-b040-137dcabdb77f,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-53f7e7d0-3e2f-4bf2-b50f-55d2a4c5e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-ad90d0a6-5f57-4ffb-8792-79789ae37deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474753111-172.17.0.12-1597055533025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-62173f19-f276-4fed-a9d3-3a99b4dadc02,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-16d8bbb2-3ba7-4228-98b4-7777c6b48bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-71e4a904-1c6e-4eff-992e-94eb4bdbdd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-bff2a1bd-a35a-4126-b6a6-ac51f55df603,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-7facb149-4c7f-418f-bc51-88081fc4be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-b4793be7-2890-41f9-97ad-eac4d0ec4a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-477a8cd9-0f26-4a46-8fcf-5dcfb2fd125c,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-405442e7-a064-41fe-9aaf-5551d4d0b823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474753111-172.17.0.12-1597055533025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-62173f19-f276-4fed-a9d3-3a99b4dadc02,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-16d8bbb2-3ba7-4228-98b4-7777c6b48bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-71e4a904-1c6e-4eff-992e-94eb4bdbdd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-bff2a1bd-a35a-4126-b6a6-ac51f55df603,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-7facb149-4c7f-418f-bc51-88081fc4be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-b4793be7-2890-41f9-97ad-eac4d0ec4a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-477a8cd9-0f26-4a46-8fcf-5dcfb2fd125c,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-405442e7-a064-41fe-9aaf-5551d4d0b823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164632677-172.17.0.12-1597055754345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-bf14a36e-0f86-483f-ba10-0c0d3517d4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-d6c13bd7-de69-4342-957b-22343ccb8eff,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-2500836c-849c-43d5-960b-67811a0d1ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-458fe72e-31d1-4020-bb92-54bf1031647b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-30dd7f51-50ef-4156-8f37-c275d2d8e9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-ea2acf6e-f440-487e-aa8f-1cda9dc1e537,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-d087d184-03f9-44f8-a242-6b6823ebef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-7b972e77-414e-4c3b-8df4-7640133fc594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164632677-172.17.0.12-1597055754345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-bf14a36e-0f86-483f-ba10-0c0d3517d4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-d6c13bd7-de69-4342-957b-22343ccb8eff,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-2500836c-849c-43d5-960b-67811a0d1ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-458fe72e-31d1-4020-bb92-54bf1031647b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-30dd7f51-50ef-4156-8f37-c275d2d8e9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-ea2acf6e-f440-487e-aa8f-1cda9dc1e537,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-d087d184-03f9-44f8-a242-6b6823ebef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-7b972e77-414e-4c3b-8df4-7640133fc594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279549498-172.17.0.12-1597056095630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37474,DS-661363ae-15f3-4e3e-ad4f-1c842d53084d,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-8ce79fb9-5a49-462a-9a47-7d1ced7a3c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-e2de2cf8-6f8b-4134-8429-aab99ab1361e,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-d6749d7d-28c2-4245-a85a-034cc58204d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-83b2304a-eb75-4106-8f69-a3ef077f0ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-d5225613-cfc8-49f4-807a-88e3e9d9ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-763a9d86-5bf5-4b78-af5f-98da92d1e5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-29d14ae2-8494-4751-af49-37df60173442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279549498-172.17.0.12-1597056095630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37474,DS-661363ae-15f3-4e3e-ad4f-1c842d53084d,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-8ce79fb9-5a49-462a-9a47-7d1ced7a3c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-e2de2cf8-6f8b-4134-8429-aab99ab1361e,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-d6749d7d-28c2-4245-a85a-034cc58204d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-83b2304a-eb75-4106-8f69-a3ef077f0ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-d5225613-cfc8-49f4-807a-88e3e9d9ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-763a9d86-5bf5-4b78-af5f-98da92d1e5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-29d14ae2-8494-4751-af49-37df60173442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760091535-172.17.0.12-1597056203652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34971,DS-7f566908-e25d-44c8-8f1c-fe18f0c605ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-f9f40d18-e98c-4fd1-9492-77981d35caa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-d77ef411-ea34-48f0-a8d7-e7bf4873f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-c44f040d-776a-4470-a95a-9ca01cc08325,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-f461ab14-0537-4ca3-8b9a-2ec6be0a35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-6dbca597-f260-4e77-8110-d2e59f71aaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-0ce66e53-9143-4976-8c13-c900f9a94d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-e8900481-bbbe-44a6-9fc7-318fe491666c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760091535-172.17.0.12-1597056203652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34971,DS-7f566908-e25d-44c8-8f1c-fe18f0c605ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-f9f40d18-e98c-4fd1-9492-77981d35caa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-d77ef411-ea34-48f0-a8d7-e7bf4873f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-c44f040d-776a-4470-a95a-9ca01cc08325,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-f461ab14-0537-4ca3-8b9a-2ec6be0a35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-6dbca597-f260-4e77-8110-d2e59f71aaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-0ce66e53-9143-4976-8c13-c900f9a94d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-e8900481-bbbe-44a6-9fc7-318fe491666c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255284265-172.17.0.12-1597056668554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35845,DS-8a77b943-fcc5-4e3a-b063-b68ebdf06fba,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-16873a97-9dad-4785-8f91-b91c335b1aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-4dac045a-2541-42dc-a02b-2c9e9c480dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e568407c-0507-44ef-9db0-71e4d2b079f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-e42385a7-3cc2-4f0d-acf3-b82be7d06b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-5165a195-ddcf-4361-b584-b9ede641f469,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-ea9654b4-dd08-4066-adcd-c068e7cda369,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-12900fab-ac4c-4dc0-8ce9-ba68f568fc40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255284265-172.17.0.12-1597056668554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35845,DS-8a77b943-fcc5-4e3a-b063-b68ebdf06fba,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-16873a97-9dad-4785-8f91-b91c335b1aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-4dac045a-2541-42dc-a02b-2c9e9c480dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e568407c-0507-44ef-9db0-71e4d2b079f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-e42385a7-3cc2-4f0d-acf3-b82be7d06b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-5165a195-ddcf-4361-b584-b9ede641f469,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-ea9654b4-dd08-4066-adcd-c068e7cda369,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-12900fab-ac4c-4dc0-8ce9-ba68f568fc40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695081520-172.17.0.12-1597056741264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46134,DS-1080cff5-ca01-416f-8be0-9aa71f2d4139,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-a3fbe68f-2c78-419b-ad13-2eca4504bc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-e2898de0-cacc-44e3-bcd0-18e214918b59,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-32984374-8881-4d7d-8359-dc4a284dca71,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-184c449e-ca9e-4c5d-b7d0-77a8c1dded29,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-3c0c60bb-fb60-46f1-833b-be293d724c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-6d4f222c-7f37-4e8e-b5c5-ab26a665a2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-4115a26c-0854-4fe4-acd5-04d1c63b520d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695081520-172.17.0.12-1597056741264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46134,DS-1080cff5-ca01-416f-8be0-9aa71f2d4139,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-a3fbe68f-2c78-419b-ad13-2eca4504bc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-e2898de0-cacc-44e3-bcd0-18e214918b59,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-32984374-8881-4d7d-8359-dc4a284dca71,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-184c449e-ca9e-4c5d-b7d0-77a8c1dded29,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-3c0c60bb-fb60-46f1-833b-be293d724c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-6d4f222c-7f37-4e8e-b5c5-ab26a665a2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-4115a26c-0854-4fe4-acd5-04d1c63b520d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18566349-172.17.0.12-1597056818237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-f1a13dc6-ff58-422f-91ad-28d853c0deca,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-d0018831-c5a1-4873-94db-d715dab89ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-77c56d94-2d21-4599-b5a2-d962e5a47af1,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-8764b6b8-1a9d-435f-bcbe-1b11d8d4258c,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-efea16d9-9847-4180-8b31-19c413f9a191,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-17fa1544-ccaa-41b1-98af-06a1da5a614e,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-f6658ec6-93a7-4896-89af-60680ee81afb,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-19ff3833-6a58-4cfe-be85-08e8624832a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18566349-172.17.0.12-1597056818237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-f1a13dc6-ff58-422f-91ad-28d853c0deca,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-d0018831-c5a1-4873-94db-d715dab89ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-77c56d94-2d21-4599-b5a2-d962e5a47af1,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-8764b6b8-1a9d-435f-bcbe-1b11d8d4258c,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-efea16d9-9847-4180-8b31-19c413f9a191,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-17fa1544-ccaa-41b1-98af-06a1da5a614e,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-f6658ec6-93a7-4896-89af-60680ee81afb,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-19ff3833-6a58-4cfe-be85-08e8624832a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518907809-172.17.0.12-1597057568806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37889,DS-04a3a1f0-8de6-4e8d-9722-8c83a4b95b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-1fc13d3f-d756-4241-912d-65bda0231e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-85cae47c-5ebe-4d3e-bbaf-4c7b4c39140b,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-771eb5c6-626c-4b54-8ac7-cb3a3ef3a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-5cf0ffec-ec64-4474-b5e0-09f93ff548b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-c01ce958-d528-4158-9958-1d60154b4ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-e632c5bf-78fd-4912-8008-8e1050de8c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-4ec5b23f-7ec0-4edd-95ee-132f7137d7f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518907809-172.17.0.12-1597057568806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37889,DS-04a3a1f0-8de6-4e8d-9722-8c83a4b95b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-1fc13d3f-d756-4241-912d-65bda0231e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-85cae47c-5ebe-4d3e-bbaf-4c7b4c39140b,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-771eb5c6-626c-4b54-8ac7-cb3a3ef3a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-5cf0ffec-ec64-4474-b5e0-09f93ff548b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-c01ce958-d528-4158-9958-1d60154b4ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-e632c5bf-78fd-4912-8008-8e1050de8c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-4ec5b23f-7ec0-4edd-95ee-132f7137d7f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743464242-172.17.0.12-1597057797829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44466,DS-92cb2b21-fd7c-480b-bbe2-a3bdb5860325,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-b01ccd87-20e9-4f30-8c9c-6fc6ffe989ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-bf1a4fb1-3471-4139-be7c-906bb7f2ce30,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-96dd1d4e-0544-48dc-a627-c091963b91d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-1d8967eb-b85c-4955-aacf-89959bc77758,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-59be25b2-9342-428a-bef3-010c6095156d,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-c5e5b6c3-0266-42a0-9b13-e3d14d32a001,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-7a4bb40b-9294-4a30-9d65-21adec129a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743464242-172.17.0.12-1597057797829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44466,DS-92cb2b21-fd7c-480b-bbe2-a3bdb5860325,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-b01ccd87-20e9-4f30-8c9c-6fc6ffe989ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-bf1a4fb1-3471-4139-be7c-906bb7f2ce30,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-96dd1d4e-0544-48dc-a627-c091963b91d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-1d8967eb-b85c-4955-aacf-89959bc77758,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-59be25b2-9342-428a-bef3-010c6095156d,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-c5e5b6c3-0266-42a0-9b13-e3d14d32a001,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-7a4bb40b-9294-4a30-9d65-21adec129a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058654180-172.17.0.12-1597058308741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37256,DS-50a0cab7-cc96-4a67-9231-bd39621f8ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-316de02c-42b9-4380-962c-de673db9e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-964e3588-ec47-4f07-9000-e9da43b51ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-a2e657b0-5383-42ee-8102-8ab0375d98c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2ca1bf3f-e77c-4ed2-b8bd-d1a2981d168b,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-eaf77a72-18c1-45e9-a02f-598b8966a3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-01b1f690-f97d-4566-81b9-ade8c3e71d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-6f62d1a4-6164-4a4c-be52-9b56cf22386e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058654180-172.17.0.12-1597058308741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37256,DS-50a0cab7-cc96-4a67-9231-bd39621f8ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-316de02c-42b9-4380-962c-de673db9e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-964e3588-ec47-4f07-9000-e9da43b51ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-a2e657b0-5383-42ee-8102-8ab0375d98c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2ca1bf3f-e77c-4ed2-b8bd-d1a2981d168b,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-eaf77a72-18c1-45e9-a02f-598b8966a3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-01b1f690-f97d-4566-81b9-ade8c3e71d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-6f62d1a4-6164-4a4c-be52-9b56cf22386e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807577429-172.17.0.12-1597058383764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40819,DS-8fd20228-7cd0-4328-9ed8-958142266fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-a9c23ed2-10e2-434c-a9bd-f82f3e982065,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-a44c9209-6110-43cb-ad63-688c75881150,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-7b94a264-001b-406d-b429-6a46ef2d68f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-d6744793-70be-44ec-b62c-336a874b292c,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-4b05769e-e6ee-483e-92a1-284e75972952,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-71382875-dcea-40ec-ac26-5ad0f96dc97b,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-367a8761-eef2-441d-8702-7f8cd417f3ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807577429-172.17.0.12-1597058383764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40819,DS-8fd20228-7cd0-4328-9ed8-958142266fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-a9c23ed2-10e2-434c-a9bd-f82f3e982065,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-a44c9209-6110-43cb-ad63-688c75881150,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-7b94a264-001b-406d-b429-6a46ef2d68f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-d6744793-70be-44ec-b62c-336a874b292c,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-4b05769e-e6ee-483e-92a1-284e75972952,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-71382875-dcea-40ec-ac26-5ad0f96dc97b,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-367a8761-eef2-441d-8702-7f8cd417f3ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126788651-172.17.0.12-1597058499493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-9d066df1-7728-435e-9fa0-363be71c5cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-84ce9b8f-31e4-436e-87ab-a3595fce7cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-bbb63e92-6723-4d84-b8ec-585f6e608fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-bef61e6d-f3c8-4bb3-885d-ff68bde1cbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-8b490caf-6b0f-46ac-8d98-c8d0bc907fda,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-89fc425e-7a5b-48fc-ac13-b5080b5cabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-5d03e4f4-30d7-42bf-86f1-0069b427bd33,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-3cd8ad3c-e2c8-4e21-989b-81334d6aca19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126788651-172.17.0.12-1597058499493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-9d066df1-7728-435e-9fa0-363be71c5cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-84ce9b8f-31e4-436e-87ab-a3595fce7cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-bbb63e92-6723-4d84-b8ec-585f6e608fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-bef61e6d-f3c8-4bb3-885d-ff68bde1cbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-8b490caf-6b0f-46ac-8d98-c8d0bc907fda,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-89fc425e-7a5b-48fc-ac13-b5080b5cabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-5d03e4f4-30d7-42bf-86f1-0069b427bd33,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-3cd8ad3c-e2c8-4e21-989b-81334d6aca19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764791923-172.17.0.12-1597058802346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35305,DS-781613d2-e9a3-4f56-852f-2b59312167bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-5b82ba0f-b66d-4b31-aabb-2c9eebe1019c,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-94c715f1-6ae2-404c-b83a-d2b755f3efe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-c0fa7d9f-4f5d-4694-87f2-e2a56422159d,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-eb44210a-ff69-493c-af69-07e90f348784,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-af4b5c5d-0149-49fe-81a4-17b0262424e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-086dec86-a3c0-4f0e-844c-4c78586701cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-86f154c0-c664-4ff8-8065-f60883b91eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764791923-172.17.0.12-1597058802346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35305,DS-781613d2-e9a3-4f56-852f-2b59312167bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-5b82ba0f-b66d-4b31-aabb-2c9eebe1019c,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-94c715f1-6ae2-404c-b83a-d2b755f3efe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-c0fa7d9f-4f5d-4694-87f2-e2a56422159d,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-eb44210a-ff69-493c-af69-07e90f348784,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-af4b5c5d-0149-49fe-81a4-17b0262424e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-086dec86-a3c0-4f0e-844c-4c78586701cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-86f154c0-c664-4ff8-8065-f60883b91eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783880870-172.17.0.12-1597058845721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45738,DS-6d4bae81-4808-4273-b248-8858339d9a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-14980998-01d3-41c1-9249-4d8202ba074a,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-15d86c59-7839-4e52-9e34-f6f1865362c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-90f5c444-aefd-4f3c-89a5-5933b7a15526,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-5584ac02-d894-49df-9648-ee60a3ae8d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-6663ede1-de65-4c94-b432-8a494f5288d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-a992f3aa-d661-4aeb-a92d-6d7bce7b34e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-ea10c311-0174-4c7c-8127-71fc41343d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783880870-172.17.0.12-1597058845721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45738,DS-6d4bae81-4808-4273-b248-8858339d9a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-14980998-01d3-41c1-9249-4d8202ba074a,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-15d86c59-7839-4e52-9e34-f6f1865362c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-90f5c444-aefd-4f3c-89a5-5933b7a15526,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-5584ac02-d894-49df-9648-ee60a3ae8d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-6663ede1-de65-4c94-b432-8a494f5288d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-a992f3aa-d661-4aeb-a92d-6d7bce7b34e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-ea10c311-0174-4c7c-8127-71fc41343d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529391488-172.17.0.12-1597059099329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44455,DS-f49e6258-e3de-4ace-b0a5-ea591b3fc66d,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-222f408a-2e20-4878-8fa3-79568ac4fc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-0bda6072-200e-4eae-a4ac-9c673c7c6720,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-1e5ee49e-0c47-45af-a33e-e19e4c368800,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-d8ce6b55-1926-4151-b70f-ec4fe6d6da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-3b8af577-9e83-42c1-9ee9-991dbf5547a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-060bd9b6-b7a7-452c-a43f-efe589dc664d,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-a7a66f22-31e7-49db-97b0-bf60f767458a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529391488-172.17.0.12-1597059099329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44455,DS-f49e6258-e3de-4ace-b0a5-ea591b3fc66d,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-222f408a-2e20-4878-8fa3-79568ac4fc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-0bda6072-200e-4eae-a4ac-9c673c7c6720,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-1e5ee49e-0c47-45af-a33e-e19e4c368800,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-d8ce6b55-1926-4151-b70f-ec4fe6d6da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-3b8af577-9e83-42c1-9ee9-991dbf5547a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-060bd9b6-b7a7-452c-a43f-efe589dc664d,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-a7a66f22-31e7-49db-97b0-bf60f767458a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148366094-172.17.0.12-1597059179849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42653,DS-4835c92e-2512-4ce3-99fc-da4067bbc332,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-a8028484-00a1-4994-b876-9e34c3b3f178,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-0a0cbae3-078b-40b0-9d76-6d3410ee724d,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-ac768652-b3e1-4037-82da-283d9f1e365b,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-211f4237-ce63-41e4-8116-fc019731bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-fe43a900-d415-4d92-84ad-c2c44bacea74,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-92cefec2-fecc-46cd-acf6-5255f96f6947,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a6ea65fa-26c2-4501-b20b-b34f46590d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148366094-172.17.0.12-1597059179849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42653,DS-4835c92e-2512-4ce3-99fc-da4067bbc332,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-a8028484-00a1-4994-b876-9e34c3b3f178,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-0a0cbae3-078b-40b0-9d76-6d3410ee724d,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-ac768652-b3e1-4037-82da-283d9f1e365b,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-211f4237-ce63-41e4-8116-fc019731bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-fe43a900-d415-4d92-84ad-c2c44bacea74,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-92cefec2-fecc-46cd-acf6-5255f96f6947,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a6ea65fa-26c2-4501-b20b-b34f46590d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732207741-172.17.0.12-1597059299404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35262,DS-fb4805a1-8743-4dad-a859-5355f4e14740,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-c297901d-09b6-449c-8d87-2a56dc0a17d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-aa080077-a891-463b-9ad2-f79d0041fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-922caeac-bb74-4e55-ac8e-174940e85c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-ab7bd887-2b11-4e2c-987f-8e14c79524b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-f891cd54-4405-46f8-9f4e-c8e195b71e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-c8bc90ae-0605-4692-bcf7-256ba1ccc4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-92ca001e-b2fd-48c3-9b72-8b86dabf6775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732207741-172.17.0.12-1597059299404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35262,DS-fb4805a1-8743-4dad-a859-5355f4e14740,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-c297901d-09b6-449c-8d87-2a56dc0a17d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-aa080077-a891-463b-9ad2-f79d0041fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-922caeac-bb74-4e55-ac8e-174940e85c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-ab7bd887-2b11-4e2c-987f-8e14c79524b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-f891cd54-4405-46f8-9f4e-c8e195b71e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-c8bc90ae-0605-4692-bcf7-256ba1ccc4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-92ca001e-b2fd-48c3-9b72-8b86dabf6775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5620
