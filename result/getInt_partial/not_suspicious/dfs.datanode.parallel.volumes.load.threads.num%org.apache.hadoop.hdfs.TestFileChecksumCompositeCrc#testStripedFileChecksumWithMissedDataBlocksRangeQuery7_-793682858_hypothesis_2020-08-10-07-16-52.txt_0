reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134804597-172.17.0.3-1597043866396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35942,DS-fa73bf48-c049-412b-be45-ec54499fa2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-e094e9b5-6f65-414e-a448-ed6b30327706,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-0263566e-6346-4493-b607-56bf02c03565,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-65fb8a7d-1195-44a8-94ba-6be6e2ba9589,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-abae38d4-684e-4f5f-860f-834dcf8af818,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-f8952f65-8f35-4c24-b344-95ded9236e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-507c4529-7d46-4293-a0bc-3e70c2645faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-b4608f4f-7fa4-4a53-bc3d-465a66af65be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134804597-172.17.0.3-1597043866396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35942,DS-fa73bf48-c049-412b-be45-ec54499fa2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-e094e9b5-6f65-414e-a448-ed6b30327706,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-0263566e-6346-4493-b607-56bf02c03565,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-65fb8a7d-1195-44a8-94ba-6be6e2ba9589,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-abae38d4-684e-4f5f-860f-834dcf8af818,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-f8952f65-8f35-4c24-b344-95ded9236e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-507c4529-7d46-4293-a0bc-3e70c2645faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-b4608f4f-7fa4-4a53-bc3d-465a66af65be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065830939-172.17.0.3-1597044017782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-e2fd9310-9544-45d7-a806-a86c8f0d7bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-290ba22e-5f16-4d96-a6bd-555c5534943f,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-2108c737-c879-408d-97a2-b79174a739e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-75b03acb-a1cb-435f-a8bf-2fa225665187,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-17d3cfcb-cd51-44a8-84cb-56988e7a4be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-b99794c3-8b87-41a1-9214-d59db2ba2353,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-70a274dd-5c3a-4915-b5c6-f6f37a0aa3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-c6b9e556-5b6d-4ce1-a3f2-ee39862f1f52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065830939-172.17.0.3-1597044017782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-e2fd9310-9544-45d7-a806-a86c8f0d7bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-290ba22e-5f16-4d96-a6bd-555c5534943f,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-2108c737-c879-408d-97a2-b79174a739e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-75b03acb-a1cb-435f-a8bf-2fa225665187,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-17d3cfcb-cd51-44a8-84cb-56988e7a4be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-b99794c3-8b87-41a1-9214-d59db2ba2353,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-70a274dd-5c3a-4915-b5c6-f6f37a0aa3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-c6b9e556-5b6d-4ce1-a3f2-ee39862f1f52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600007692-172.17.0.3-1597044054762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39095,DS-dca5bb49-cb94-40ae-a94a-ee792490bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-8b8e0852-5153-41f6-b85a-246750e00217,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-1d0117b5-2795-4c47-b81f-a0cc3d3b5c18,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-e54c9267-1651-42ba-8346-9a6d885a50f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-129cbb12-be8a-46a4-a2cb-7a52f7734272,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-78afe2a6-6bf4-4455-9bab-1bf1baa4ce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-7654d0c1-57dc-413d-aedb-1b686e9ab18e,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-8044510e-fcf0-4501-aa58-3ddcffa392b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600007692-172.17.0.3-1597044054762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39095,DS-dca5bb49-cb94-40ae-a94a-ee792490bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-8b8e0852-5153-41f6-b85a-246750e00217,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-1d0117b5-2795-4c47-b81f-a0cc3d3b5c18,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-e54c9267-1651-42ba-8346-9a6d885a50f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-129cbb12-be8a-46a4-a2cb-7a52f7734272,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-78afe2a6-6bf4-4455-9bab-1bf1baa4ce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-7654d0c1-57dc-413d-aedb-1b686e9ab18e,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-8044510e-fcf0-4501-aa58-3ddcffa392b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34246230-172.17.0.3-1597044374079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-9c164fac-bc7b-441d-9f42-4959be4912be,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-3521fc44-8a41-4b31-abfe-1ee5defee127,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-bc95b2a6-b236-42ff-b9c6-13005aadf5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-c1a2d774-1afa-4743-912c-bcebb6859e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-9850e251-038f-467f-b8e0-0dc96c6974a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-b3a59fa8-f933-48a4-a8eb-e566309f6996,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-c478e036-cde9-40bb-af6f-f3751920069d,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-3a3c94b8-746f-4315-91b1-f0ba735c3f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34246230-172.17.0.3-1597044374079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-9c164fac-bc7b-441d-9f42-4959be4912be,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-3521fc44-8a41-4b31-abfe-1ee5defee127,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-bc95b2a6-b236-42ff-b9c6-13005aadf5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-c1a2d774-1afa-4743-912c-bcebb6859e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-9850e251-038f-467f-b8e0-0dc96c6974a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-b3a59fa8-f933-48a4-a8eb-e566309f6996,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-c478e036-cde9-40bb-af6f-f3751920069d,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-3a3c94b8-746f-4315-91b1-f0ba735c3f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490075874-172.17.0.3-1597044584306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-bdea5e45-6f56-47a2-a4d7-6d669a583ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-21ce4516-a54a-4a68-acf3-8381176bc8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-4c1557d2-b42d-4c9b-a682-b85ea1cfca04,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-1e5a93a2-835d-4018-a35e-8d030b6046ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-be8f26cd-caa2-4f51-b336-f34d58034482,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-8ca06d05-f38c-4188-80da-0c001af6527a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-e9f46b9c-c17c-4bb7-9be1-47d2bf7e4dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-ec7b4266-d9aa-4222-b08d-54936df7aaf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490075874-172.17.0.3-1597044584306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-bdea5e45-6f56-47a2-a4d7-6d669a583ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-21ce4516-a54a-4a68-acf3-8381176bc8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-4c1557d2-b42d-4c9b-a682-b85ea1cfca04,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-1e5a93a2-835d-4018-a35e-8d030b6046ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-be8f26cd-caa2-4f51-b336-f34d58034482,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-8ca06d05-f38c-4188-80da-0c001af6527a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-e9f46b9c-c17c-4bb7-9be1-47d2bf7e4dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-ec7b4266-d9aa-4222-b08d-54936df7aaf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722737123-172.17.0.3-1597044686731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-fabe65ef-e8f0-416e-8ab5-60970ae32e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-47c78ddc-c8c6-482f-b34c-033cc594e5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-974fc922-55b4-4040-a2ff-bac02f5eebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-0b57fd03-d531-4a6b-ad9c-7af889fb3514,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-8de3b0a0-f232-4632-92c1-5278997ef78c,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-193375fe-a2ba-41e1-8881-d6d056a643ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-8f31da16-34fa-4190-992e-5638a1a80b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-d9d869e3-7b48-48cd-ae28-4cb146dfe9f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722737123-172.17.0.3-1597044686731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-fabe65ef-e8f0-416e-8ab5-60970ae32e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-47c78ddc-c8c6-482f-b34c-033cc594e5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-974fc922-55b4-4040-a2ff-bac02f5eebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-0b57fd03-d531-4a6b-ad9c-7af889fb3514,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-8de3b0a0-f232-4632-92c1-5278997ef78c,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-193375fe-a2ba-41e1-8881-d6d056a643ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-8f31da16-34fa-4190-992e-5638a1a80b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-d9d869e3-7b48-48cd-ae28-4cb146dfe9f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260252235-172.17.0.3-1597044911978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-bfa15b86-f6d1-444a-9da0-9f0df53fe643,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-0c19a131-cfe0-41cb-aa74-8c185f38123e,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-fe70d3cd-8fbd-4248-aef6-50ef2e7660f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-a7e17f5a-fd83-418c-8ff8-19d6ea508824,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-bdadce3e-e932-4c5a-ba3f-82ea2bbd49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-f8f1178a-47ec-41b1-9487-5ba02d625d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-bd848e0c-8428-41a5-a8cc-b6e1d0fa7fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-7e4bbe36-9944-45ad-886d-4984344e9eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260252235-172.17.0.3-1597044911978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-bfa15b86-f6d1-444a-9da0-9f0df53fe643,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-0c19a131-cfe0-41cb-aa74-8c185f38123e,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-fe70d3cd-8fbd-4248-aef6-50ef2e7660f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-a7e17f5a-fd83-418c-8ff8-19d6ea508824,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-bdadce3e-e932-4c5a-ba3f-82ea2bbd49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-f8f1178a-47ec-41b1-9487-5ba02d625d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-bd848e0c-8428-41a5-a8cc-b6e1d0fa7fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-7e4bbe36-9944-45ad-886d-4984344e9eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596948461-172.17.0.3-1597045148802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43924,DS-572c0048-6ee6-45c8-916f-b48fdd349310,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-2eae8cc4-c361-4ed5-849f-9cebbe8e9659,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-1f5ea706-da94-4b19-b92f-7a5365032653,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-f94623f0-bd64-4047-b091-4a87c137ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-5ffa34e7-0f5e-4df8-9c7e-b036df36553c,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-b7f9182a-5650-4692-a48f-ef1c50bcc300,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-712f7383-e172-43ce-b9f6-e810c79f3e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-fae874d7-bb80-4242-8be7-5e879575df5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596948461-172.17.0.3-1597045148802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43924,DS-572c0048-6ee6-45c8-916f-b48fdd349310,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-2eae8cc4-c361-4ed5-849f-9cebbe8e9659,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-1f5ea706-da94-4b19-b92f-7a5365032653,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-f94623f0-bd64-4047-b091-4a87c137ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-5ffa34e7-0f5e-4df8-9c7e-b036df36553c,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-b7f9182a-5650-4692-a48f-ef1c50bcc300,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-712f7383-e172-43ce-b9f6-e810c79f3e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-fae874d7-bb80-4242-8be7-5e879575df5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856580453-172.17.0.3-1597045329737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-63498b3f-8d85-48bc-a256-34a63c13b271,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-f45afa2b-e6fa-44d4-b1a8-c019d96b57ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-b2687a99-de92-4fc6-a89f-cfe070cf4c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-8353f90a-a951-41c0-8b4d-96565c1a2308,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-46a2f976-9060-45d9-96fd-ab95d8976255,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-1d77844c-5e13-4ca1-b748-70a3b73b163c,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-11d181bc-0801-4943-9a87-9f13c064e80f,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-c831bf58-b951-466f-b6ae-6f84591ad88b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856580453-172.17.0.3-1597045329737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-63498b3f-8d85-48bc-a256-34a63c13b271,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-f45afa2b-e6fa-44d4-b1a8-c019d96b57ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-b2687a99-de92-4fc6-a89f-cfe070cf4c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-8353f90a-a951-41c0-8b4d-96565c1a2308,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-46a2f976-9060-45d9-96fd-ab95d8976255,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-1d77844c-5e13-4ca1-b748-70a3b73b163c,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-11d181bc-0801-4943-9a87-9f13c064e80f,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-c831bf58-b951-466f-b6ae-6f84591ad88b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766907400-172.17.0.3-1597045356677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-1c588792-5b81-4ff6-953b-7f6a8f2c5eae,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-61427cfa-9fb4-4d52-9601-1f0dfea5cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-bdea3617-a36f-4655-8fd3-8d7e118dd6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-e4eae78d-022f-4e83-a3fd-8546cee72125,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-6ef5869b-a9a4-40d3-b622-c00a1c191cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-0a80cd21-4a8a-4d46-9a39-30b03b2cdc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-9df3bd29-5966-4482-b6be-bf85e215691a,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-11426565-551e-4f98-baae-34e56c069f51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766907400-172.17.0.3-1597045356677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-1c588792-5b81-4ff6-953b-7f6a8f2c5eae,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-61427cfa-9fb4-4d52-9601-1f0dfea5cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-bdea3617-a36f-4655-8fd3-8d7e118dd6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-e4eae78d-022f-4e83-a3fd-8546cee72125,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-6ef5869b-a9a4-40d3-b622-c00a1c191cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-0a80cd21-4a8a-4d46-9a39-30b03b2cdc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-9df3bd29-5966-4482-b6be-bf85e215691a,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-11426565-551e-4f98-baae-34e56c069f51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826316749-172.17.0.3-1597045391944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40625,DS-5109ae9c-d94f-46b3-bbae-7e634c87a1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-60cdeb75-d1eb-4440-b074-305c15c55d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ff39acb0-2523-4b04-aeba-4112a3c85e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-1e086037-6d9b-4d86-8f84-ff5a7215ce2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-5e94da46-668d-47d8-b7a0-e686278eecde,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-be918892-4dac-4ec4-a8a4-f04eadc53d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-cb161303-f60e-4862-9a32-069d27b7a42c,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-b8c9ad6e-50dd-4435-bd78-8ecbe01da609,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826316749-172.17.0.3-1597045391944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40625,DS-5109ae9c-d94f-46b3-bbae-7e634c87a1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-60cdeb75-d1eb-4440-b074-305c15c55d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ff39acb0-2523-4b04-aeba-4112a3c85e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-1e086037-6d9b-4d86-8f84-ff5a7215ce2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-5e94da46-668d-47d8-b7a0-e686278eecde,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-be918892-4dac-4ec4-a8a4-f04eadc53d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-cb161303-f60e-4862-9a32-069d27b7a42c,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-b8c9ad6e-50dd-4435-bd78-8ecbe01da609,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401955385-172.17.0.3-1597045645184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33155,DS-8d23bfd4-79ec-4fc4-bf43-88c11e3d5636,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-e466b1b4-6b6d-482d-bbba-5cae2c352489,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-373b01c0-8845-4962-91ac-0748c95edd12,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-86e4e403-0e28-496e-8e15-7689bdfa28cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-0774f7ec-1014-4e8e-a9b0-388e69824db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-55e3e4af-29c2-4bdf-a825-eeab072a61e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-0e80711d-0f3b-4a95-8d99-752b1c129f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-6c8da4c9-1379-408c-8eac-20d36afd0ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401955385-172.17.0.3-1597045645184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33155,DS-8d23bfd4-79ec-4fc4-bf43-88c11e3d5636,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-e466b1b4-6b6d-482d-bbba-5cae2c352489,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-373b01c0-8845-4962-91ac-0748c95edd12,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-86e4e403-0e28-496e-8e15-7689bdfa28cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-0774f7ec-1014-4e8e-a9b0-388e69824db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-55e3e4af-29c2-4bdf-a825-eeab072a61e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-0e80711d-0f3b-4a95-8d99-752b1c129f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-6c8da4c9-1379-408c-8eac-20d36afd0ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668972129-172.17.0.3-1597045715305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35231,DS-cc7b88cc-121e-4972-8d5f-eb8be88c2f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-4ae9c6c1-e7eb-456f-b055-94fd5ece0e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-db3d7a43-8b6a-4d6d-8851-16118d602b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-8d8e4397-f092-4d34-bc6d-7a3525cf6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-1e0bcb2c-d7ed-4611-a966-4eee08262761,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-c3b8df4b-626b-4da7-bd8d-e603c3c22595,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-f0410c0b-c0bc-4988-893a-b4bf33ff5b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-0d393282-683f-4da4-8345-9257389b6102,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668972129-172.17.0.3-1597045715305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35231,DS-cc7b88cc-121e-4972-8d5f-eb8be88c2f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-4ae9c6c1-e7eb-456f-b055-94fd5ece0e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-db3d7a43-8b6a-4d6d-8851-16118d602b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-8d8e4397-f092-4d34-bc6d-7a3525cf6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-1e0bcb2c-d7ed-4611-a966-4eee08262761,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-c3b8df4b-626b-4da7-bd8d-e603c3c22595,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-f0410c0b-c0bc-4988-893a-b4bf33ff5b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-0d393282-683f-4da4-8345-9257389b6102,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903025274-172.17.0.3-1597045812586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37686,DS-5c39ab10-cadb-4aab-8bed-6798ae2d77d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-0120c706-c3ea-466a-a164-fe0d12b152ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-12f65d90-909b-4eb5-be2e-6e7da9697116,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-f869988d-d1f7-468a-9baf-e04a94dfdd48,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-7a401677-66aa-4363-962c-91711967c710,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-ed03b74d-8fcf-4755-8f33-415f6ecc417c,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-e46ece61-2424-409b-8a65-2e593b3433bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-60a891dd-24d4-4be2-b7d3-2cee85abeb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903025274-172.17.0.3-1597045812586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37686,DS-5c39ab10-cadb-4aab-8bed-6798ae2d77d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-0120c706-c3ea-466a-a164-fe0d12b152ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-12f65d90-909b-4eb5-be2e-6e7da9697116,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-f869988d-d1f7-468a-9baf-e04a94dfdd48,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-7a401677-66aa-4363-962c-91711967c710,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-ed03b74d-8fcf-4755-8f33-415f6ecc417c,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-e46ece61-2424-409b-8a65-2e593b3433bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-60a891dd-24d4-4be2-b7d3-2cee85abeb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040844966-172.17.0.3-1597045886905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38479,DS-f96137d0-3cc3-40c7-af32-4f808305c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-152421d5-08a4-4372-a15d-72a9aebcbdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-30fad084-e21c-44a1-bfef-8414c92b59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-2b63bd4e-cf68-41c1-a9a3-cb9549b8c5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-9ad267cf-7c87-4294-9d22-5700c295f176,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-1fc05132-2c28-48e9-a49d-3ce93d53b741,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-5b6a4fe0-dc60-4ea3-b819-eef1f8c99ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-687ed055-83c5-4da3-a580-982cb516f3d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040844966-172.17.0.3-1597045886905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38479,DS-f96137d0-3cc3-40c7-af32-4f808305c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-152421d5-08a4-4372-a15d-72a9aebcbdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-30fad084-e21c-44a1-bfef-8414c92b59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-2b63bd4e-cf68-41c1-a9a3-cb9549b8c5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-9ad267cf-7c87-4294-9d22-5700c295f176,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-1fc05132-2c28-48e9-a49d-3ce93d53b741,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-5b6a4fe0-dc60-4ea3-b819-eef1f8c99ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-687ed055-83c5-4da3-a580-982cb516f3d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795798230-172.17.0.3-1597045927437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-1140cb91-2154-4d6b-ab0f-23e6b9e52ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-264f870c-92a5-4788-aa2d-0d4ad897b544,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-354f17ac-cbf8-4f87-8595-0f6f005a86b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-802a7bde-84fc-409f-9483-89ccdd15d6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-7904702e-ae7f-42e4-b39b-01a00ac34e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-e21b9388-7342-469e-bd46-6e30f3782742,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-87e2f124-a3b4-4df5-9efb-18637f99b145,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-d01900c7-65f5-4f6e-8089-826aae809980,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795798230-172.17.0.3-1597045927437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-1140cb91-2154-4d6b-ab0f-23e6b9e52ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-264f870c-92a5-4788-aa2d-0d4ad897b544,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-354f17ac-cbf8-4f87-8595-0f6f005a86b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-802a7bde-84fc-409f-9483-89ccdd15d6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-7904702e-ae7f-42e4-b39b-01a00ac34e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-e21b9388-7342-469e-bd46-6e30f3782742,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-87e2f124-a3b4-4df5-9efb-18637f99b145,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-d01900c7-65f5-4f6e-8089-826aae809980,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129083815-172.17.0.3-1597045993808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40435,DS-2034a613-0efd-481b-844b-e69145f1ea43,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-127004a6-2cea-4fc8-9efd-0376b3cf3cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-e5535083-e3ec-40f3-9873-55e3b61bd22a,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-411ddb29-b4b7-4549-b88e-1459ee437d37,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-5c776032-fc11-4769-a77b-c6c62ec6d4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-98883f46-64f2-488f-a3f8-912f9d6e2116,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-af659704-922a-4299-a1a8-afc12b6e5d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-372b6b67-2e62-42a6-9cb8-04f1696be2ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129083815-172.17.0.3-1597045993808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40435,DS-2034a613-0efd-481b-844b-e69145f1ea43,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-127004a6-2cea-4fc8-9efd-0376b3cf3cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-e5535083-e3ec-40f3-9873-55e3b61bd22a,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-411ddb29-b4b7-4549-b88e-1459ee437d37,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-5c776032-fc11-4769-a77b-c6c62ec6d4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-98883f46-64f2-488f-a3f8-912f9d6e2116,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-af659704-922a-4299-a1a8-afc12b6e5d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-372b6b67-2e62-42a6-9cb8-04f1696be2ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787113820-172.17.0.3-1597046214714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35253,DS-6445bbb6-4785-4a3d-8e6f-522474207781,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-b435e5c4-8f04-41f9-a09a-c396b785a432,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-3164984b-7583-4c26-983b-a83288a06767,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-12fd06d1-d9b5-45c4-a1e7-8237d11d4c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-d67b4af8-8580-4623-bbfb-a67bb51f6520,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-761c2ec8-f9aa-4f97-9da8-54a6c26f03ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-3b7d5248-43ed-4f0d-ab2d-645a326b191c,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-0594c62d-b18a-4d91-a8de-48a44eae589b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787113820-172.17.0.3-1597046214714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35253,DS-6445bbb6-4785-4a3d-8e6f-522474207781,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-b435e5c4-8f04-41f9-a09a-c396b785a432,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-3164984b-7583-4c26-983b-a83288a06767,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-12fd06d1-d9b5-45c4-a1e7-8237d11d4c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-d67b4af8-8580-4623-bbfb-a67bb51f6520,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-761c2ec8-f9aa-4f97-9da8-54a6c26f03ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-3b7d5248-43ed-4f0d-ab2d-645a326b191c,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-0594c62d-b18a-4d91-a8de-48a44eae589b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362664081-172.17.0.3-1597046388743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33756,DS-4275f3b4-6da3-4aba-967c-c01a8097a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-8fe897ae-edca-4879-b65b-ebd786eb6da8,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-34d7ccee-5b36-453b-8b90-241f8cbba78d,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-96d437a9-3130-469f-8a46-5456bc39fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-be3fc7d6-fe0a-4291-b2ef-397a83fa23e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-8c54ba76-ac2b-411e-acf1-320726b71d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-7fea7af1-aaf1-487c-ba7b-6f2348bf98ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-2d0326ef-8b9a-440c-994f-54c7157f1946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362664081-172.17.0.3-1597046388743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33756,DS-4275f3b4-6da3-4aba-967c-c01a8097a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-8fe897ae-edca-4879-b65b-ebd786eb6da8,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-34d7ccee-5b36-453b-8b90-241f8cbba78d,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-96d437a9-3130-469f-8a46-5456bc39fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-be3fc7d6-fe0a-4291-b2ef-397a83fa23e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-8c54ba76-ac2b-411e-acf1-320726b71d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-7fea7af1-aaf1-487c-ba7b-6f2348bf98ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-2d0326ef-8b9a-440c-994f-54c7157f1946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930033487-172.17.0.3-1597046607545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36563,DS-d5c09172-c7bf-4d96-b483-762922864c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-99169899-985d-401a-9407-931fefa171d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-9473ff5f-10fc-4203-b06d-98d2e1f3fdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-ea5d02d0-1dcd-493b-ae0d-69ef57a8d149,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-9802edef-11eb-47b5-b721-fd7ee0eec998,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-37841236-22bd-4bf9-b47a-679831790636,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-e5c32d9f-9d3d-4fca-9037-d7f5f0414ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-88aaa172-e651-4678-885e-863dac82a6c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930033487-172.17.0.3-1597046607545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36563,DS-d5c09172-c7bf-4d96-b483-762922864c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-99169899-985d-401a-9407-931fefa171d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-9473ff5f-10fc-4203-b06d-98d2e1f3fdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-ea5d02d0-1dcd-493b-ae0d-69ef57a8d149,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-9802edef-11eb-47b5-b721-fd7ee0eec998,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-37841236-22bd-4bf9-b47a-679831790636,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-e5c32d9f-9d3d-4fca-9037-d7f5f0414ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-88aaa172-e651-4678-885e-863dac82a6c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487302433-172.17.0.3-1597046684044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42341,DS-e7498455-d43c-4ae5-9ab7-6c6da3b26f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-91211cea-2df0-47ba-8f74-3c0f5b9b7339,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-dc18a4e7-06d6-4974-912d-71b075e1b892,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-222448dd-0d52-4898-911e-a63adc926d15,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-97e064f4-757f-40d6-845f-f8b42237767e,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-1cb694cc-20c1-4aef-9098-5c9d2830d631,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-6fbe5593-8bbe-4c2a-8355-a58f76278f49,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-ed317bad-7548-4a86-be22-63bb9d76dc9b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487302433-172.17.0.3-1597046684044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42341,DS-e7498455-d43c-4ae5-9ab7-6c6da3b26f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-91211cea-2df0-47ba-8f74-3c0f5b9b7339,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-dc18a4e7-06d6-4974-912d-71b075e1b892,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-222448dd-0d52-4898-911e-a63adc926d15,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-97e064f4-757f-40d6-845f-f8b42237767e,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-1cb694cc-20c1-4aef-9098-5c9d2830d631,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-6fbe5593-8bbe-4c2a-8355-a58f76278f49,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-ed317bad-7548-4a86-be22-63bb9d76dc9b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745873295-172.17.0.3-1597046955064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33992,DS-dce3767f-2a7d-47ba-a672-0f877f162c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-0cbbe149-9cea-4a52-b311-b5e68acf14ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-3b481f35-a9c8-4f90-840b-d0f3ad2f037d,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-f8e58318-8e4c-48f7-9691-bcae23be5878,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-3f77a4aa-5a78-4091-aa09-8da67b3e9e09,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-4cca0d7e-16d5-4421-98a7-835c0379f5be,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-e98c24c2-a3cd-42bb-b8a6-8fbca250a595,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-3834e3a6-3969-4c50-9626-82d78c18f1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745873295-172.17.0.3-1597046955064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33992,DS-dce3767f-2a7d-47ba-a672-0f877f162c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-0cbbe149-9cea-4a52-b311-b5e68acf14ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-3b481f35-a9c8-4f90-840b-d0f3ad2f037d,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-f8e58318-8e4c-48f7-9691-bcae23be5878,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-3f77a4aa-5a78-4091-aa09-8da67b3e9e09,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-4cca0d7e-16d5-4421-98a7-835c0379f5be,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-e98c24c2-a3cd-42bb-b8a6-8fbca250a595,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-3834e3a6-3969-4c50-9626-82d78c18f1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19786875-172.17.0.3-1597047147771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-4c553c7a-dfd0-4bc3-afe7-f4ef50806258,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-498167d0-8236-4b73-afc1-e2e23b710fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-0e5963da-b72b-40c0-9a1e-d38e211f3864,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-f31859e2-c215-4cca-a7b0-c176d83998d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-43136dbc-7380-4f0e-ab4e-d22f1b1a3174,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-49bec6b9-f0c4-409c-bcf7-70bba1a85fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-ebc28dac-508b-416c-a245-37524ac66edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-29715a0e-d00c-4fa3-bb71-2dff0e20d571,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19786875-172.17.0.3-1597047147771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-4c553c7a-dfd0-4bc3-afe7-f4ef50806258,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-498167d0-8236-4b73-afc1-e2e23b710fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-0e5963da-b72b-40c0-9a1e-d38e211f3864,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-f31859e2-c215-4cca-a7b0-c176d83998d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-43136dbc-7380-4f0e-ab4e-d22f1b1a3174,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-49bec6b9-f0c4-409c-bcf7-70bba1a85fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-ebc28dac-508b-416c-a245-37524ac66edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-29715a0e-d00c-4fa3-bb71-2dff0e20d571,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112015053-172.17.0.3-1597047300261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46032,DS-4655c196-0a94-401e-9c25-b50c17b2bf69,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-3f797c84-a264-4b6b-862c-cb2b1d42d102,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-23de0906-e556-491d-8bf0-87cb01c6432b,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-c55e1f8c-5647-40ab-a829-a86effd00ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-ea8d44cf-2f39-4d90-8325-3ed1fd3433a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-2a648bd8-f20d-40eb-bcae-5f2421e2d7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-01f850b0-385c-4783-aa1c-279072806cab,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-f5f97487-191f-4d41-bc88-fe6154102ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112015053-172.17.0.3-1597047300261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46032,DS-4655c196-0a94-401e-9c25-b50c17b2bf69,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-3f797c84-a264-4b6b-862c-cb2b1d42d102,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-23de0906-e556-491d-8bf0-87cb01c6432b,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-c55e1f8c-5647-40ab-a829-a86effd00ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-ea8d44cf-2f39-4d90-8325-3ed1fd3433a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-2a648bd8-f20d-40eb-bcae-5f2421e2d7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-01f850b0-385c-4783-aa1c-279072806cab,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-f5f97487-191f-4d41-bc88-fe6154102ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517639340-172.17.0.3-1597047555220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36570,DS-cfe6c948-5b27-49f9-9345-7192f7f71109,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-9204e008-0ca1-435a-8074-685d76535a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-b421068d-588b-4b77-b3c0-c15cdddb7997,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-4ac2726f-6bf1-483e-b1e4-8f78bd35ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-f00d1f14-a611-4950-8b10-e6af533eeaae,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-605b3435-b3d4-472d-8722-dc1f74d41747,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-69f033a7-a45f-4cb3-92f1-f72912914104,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-26573a1e-ba9e-43e8-85a2-e33c26ec9ab9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517639340-172.17.0.3-1597047555220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36570,DS-cfe6c948-5b27-49f9-9345-7192f7f71109,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-9204e008-0ca1-435a-8074-685d76535a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-b421068d-588b-4b77-b3c0-c15cdddb7997,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-4ac2726f-6bf1-483e-b1e4-8f78bd35ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-f00d1f14-a611-4950-8b10-e6af533eeaae,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-605b3435-b3d4-472d-8722-dc1f74d41747,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-69f033a7-a45f-4cb3-92f1-f72912914104,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-26573a1e-ba9e-43e8-85a2-e33c26ec9ab9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860248326-172.17.0.3-1597047590617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34001,DS-c7fa52ba-225a-4e73-8650-0f2a136cc684,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-6ef690b3-3bcf-4b65-9289-598e00d1b218,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-8540a874-6aeb-4ced-bbc8-a09a58664de0,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-be7c468f-ccf0-47b9-ac92-c48039509e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-665ecd57-1fc1-4a22-a784-1dfe3330c015,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-b60ff7ed-e601-4300-93a1-cb04685ca533,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-1279b161-f9cc-4911-a427-28f02be1a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-46a9b671-9ec4-46e2-919c-febb222877e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860248326-172.17.0.3-1597047590617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34001,DS-c7fa52ba-225a-4e73-8650-0f2a136cc684,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-6ef690b3-3bcf-4b65-9289-598e00d1b218,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-8540a874-6aeb-4ced-bbc8-a09a58664de0,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-be7c468f-ccf0-47b9-ac92-c48039509e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-665ecd57-1fc1-4a22-a784-1dfe3330c015,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-b60ff7ed-e601-4300-93a1-cb04685ca533,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-1279b161-f9cc-4911-a427-28f02be1a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-46a9b671-9ec4-46e2-919c-febb222877e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092570102-172.17.0.3-1597047630493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44914,DS-b3830bda-b785-4b0b-8282-28209b301676,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-fb27dc51-cff9-4a98-a4d4-80b0fc3c03f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-28a018cd-88c6-4428-b73d-7ece33a09fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-36c6fde5-685d-4527-83b9-87f9ea418995,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-e83a7011-c2ef-45f1-9a6e-cc49aa4d0b09,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-97f65513-7c54-442c-8602-f0cbeb262fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-12552ca4-a6b6-480e-8aa7-09b2c75d9588,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-2a343b5c-f2d3-4599-83b3-c074b88c7084,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092570102-172.17.0.3-1597047630493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44914,DS-b3830bda-b785-4b0b-8282-28209b301676,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-fb27dc51-cff9-4a98-a4d4-80b0fc3c03f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-28a018cd-88c6-4428-b73d-7ece33a09fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-36c6fde5-685d-4527-83b9-87f9ea418995,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-e83a7011-c2ef-45f1-9a6e-cc49aa4d0b09,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-97f65513-7c54-442c-8602-f0cbeb262fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-12552ca4-a6b6-480e-8aa7-09b2c75d9588,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-2a343b5c-f2d3-4599-83b3-c074b88c7084,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011671605-172.17.0.3-1597047824553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-87258799-55ba-47b2-b319-d85aed9fda79,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-55abebb5-d500-442c-9352-d35a609eb5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-e773213f-01d4-4871-a5cb-1f0ef6387594,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-198f6bf5-38d6-46c6-af66-17eae79077dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-7b1181b1-025c-40ce-bcd4-1ad1355f8d70,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-e951dffa-3f63-41aa-bf2d-d086cccf4c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-ddd21481-9f3b-4fb1-adaf-d836f04b960a,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-8ef42cbd-03c1-42fc-9507-6af3eda473b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011671605-172.17.0.3-1597047824553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-87258799-55ba-47b2-b319-d85aed9fda79,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-55abebb5-d500-442c-9352-d35a609eb5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-e773213f-01d4-4871-a5cb-1f0ef6387594,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-198f6bf5-38d6-46c6-af66-17eae79077dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-7b1181b1-025c-40ce-bcd4-1ad1355f8d70,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-e951dffa-3f63-41aa-bf2d-d086cccf4c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-ddd21481-9f3b-4fb1-adaf-d836f04b960a,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-8ef42cbd-03c1-42fc-9507-6af3eda473b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899370205-172.17.0.3-1597047892729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41810,DS-21253cc7-437c-475c-8305-3161a915299e,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-e78d1e4d-87f2-4526-8779-0ed5e6c2975a,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-afcfc4d0-2f50-45c2-8e96-3745788e5a51,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-67d2907a-6649-468e-bfe6-3a5104f486cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-8d7c56c0-ea94-421d-acd4-ac8b4dab9922,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-dc1a1a20-a2ec-4bd1-aeee-b7d18dcc5b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-aee0d3e9-d400-4e46-b326-e5feaee38dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-9eab1dcf-ab51-4831-a30e-c484de9d7511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899370205-172.17.0.3-1597047892729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41810,DS-21253cc7-437c-475c-8305-3161a915299e,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-e78d1e4d-87f2-4526-8779-0ed5e6c2975a,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-afcfc4d0-2f50-45c2-8e96-3745788e5a51,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-67d2907a-6649-468e-bfe6-3a5104f486cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-8d7c56c0-ea94-421d-acd4-ac8b4dab9922,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-dc1a1a20-a2ec-4bd1-aeee-b7d18dcc5b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-aee0d3e9-d400-4e46-b326-e5feaee38dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-9eab1dcf-ab51-4831-a30e-c484de9d7511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370096380-172.17.0.3-1597047989096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-6b037b1f-8bb3-432b-9d13-3220b5f74a84,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-404333c5-4ce3-4a68-aecd-c0ec84ce1e11,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-4b415315-6733-4c42-a5ba-26477bf0c034,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-322392ae-6b73-4d93-8a58-3a11ccf62099,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-937f5d48-efa0-4bee-8f44-5b3d5ad58ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-0e5b4aa2-9c59-4a78-b0b3-2aa22cef73df,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-24aa1ed7-dba2-4d48-932a-126c530741b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-060163d9-233c-4f91-9358-66735d498035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370096380-172.17.0.3-1597047989096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-6b037b1f-8bb3-432b-9d13-3220b5f74a84,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-404333c5-4ce3-4a68-aecd-c0ec84ce1e11,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-4b415315-6733-4c42-a5ba-26477bf0c034,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-322392ae-6b73-4d93-8a58-3a11ccf62099,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-937f5d48-efa0-4bee-8f44-5b3d5ad58ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-0e5b4aa2-9c59-4a78-b0b3-2aa22cef73df,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-24aa1ed7-dba2-4d48-932a-126c530741b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-060163d9-233c-4f91-9358-66735d498035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284029960-172.17.0.3-1597048252054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39860,DS-263f3520-953b-4a86-b4ae-30e1f15cd8de,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-388ab7a6-36fd-42a2-92f6-20785af6308d,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-cbe5e281-622f-4679-ac34-5d65bf3044aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-2a709b2b-ca5c-44ec-8dbc-74be4faf7325,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-87384a2f-bc68-4f3a-b527-bf2bd3d9f140,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-ea0ebf02-926d-485a-b3b7-438f3ec84d20,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-171df886-c9bf-430d-88a4-b7d32f06bfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-f580cfee-d60b-401a-96f7-e4d23de963ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284029960-172.17.0.3-1597048252054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39860,DS-263f3520-953b-4a86-b4ae-30e1f15cd8de,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-388ab7a6-36fd-42a2-92f6-20785af6308d,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-cbe5e281-622f-4679-ac34-5d65bf3044aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-2a709b2b-ca5c-44ec-8dbc-74be4faf7325,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-87384a2f-bc68-4f3a-b527-bf2bd3d9f140,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-ea0ebf02-926d-485a-b3b7-438f3ec84d20,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-171df886-c9bf-430d-88a4-b7d32f06bfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-f580cfee-d60b-401a-96f7-e4d23de963ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066278095-172.17.0.3-1597048556704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-4eb85ace-ad84-40df-ab4c-27f62a5c3108,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-8faa9562-e6e1-4186-8823-888e1d7b5150,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-c9be53fa-f64c-47bf-a8fc-db6cf7790bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-6f1a4606-863e-4cef-bb6e-0bebc5605672,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-8ad7d744-60e2-4cce-999d-373235c4c6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-cfd4a57c-3412-4d11-8a95-bbb059584bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-336b433d-ce47-41b6-b0bc-432c30083db8,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-4afd53e9-cb60-4c38-a4f9-ef34187f250b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066278095-172.17.0.3-1597048556704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-4eb85ace-ad84-40df-ab4c-27f62a5c3108,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-8faa9562-e6e1-4186-8823-888e1d7b5150,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-c9be53fa-f64c-47bf-a8fc-db6cf7790bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-6f1a4606-863e-4cef-bb6e-0bebc5605672,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-8ad7d744-60e2-4cce-999d-373235c4c6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-cfd4a57c-3412-4d11-8a95-bbb059584bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-336b433d-ce47-41b6-b0bc-432c30083db8,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-4afd53e9-cb60-4c38-a4f9-ef34187f250b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698895554-172.17.0.3-1597048692881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41671,DS-9c161734-7059-449f-8c6a-512ec40cdde7,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-46abacbd-3f20-4665-9553-3c36ea29a33c,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-d1fd6706-2271-46a7-a670-846808983951,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b6ca3d55-52d1-49f5-bc5d-ab7511a91664,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-3683901b-94c4-4f39-a0f8-b5f14204228f,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-dfb50fd6-97a2-4fcb-89fd-8ee42aab6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-f3255965-ab0f-4875-9152-c491985b51e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-dd89b3e2-3f78-4d9f-9e2f-6f45a91acd40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698895554-172.17.0.3-1597048692881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41671,DS-9c161734-7059-449f-8c6a-512ec40cdde7,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-46abacbd-3f20-4665-9553-3c36ea29a33c,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-d1fd6706-2271-46a7-a670-846808983951,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b6ca3d55-52d1-49f5-bc5d-ab7511a91664,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-3683901b-94c4-4f39-a0f8-b5f14204228f,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-dfb50fd6-97a2-4fcb-89fd-8ee42aab6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-f3255965-ab0f-4875-9152-c491985b51e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-dd89b3e2-3f78-4d9f-9e2f-6f45a91acd40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689920393-172.17.0.3-1597048805307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34006,DS-82efcb2f-fb81-4ded-ac13-03340ad5f7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-12dff50c-2753-44d2-a7f8-b971bad4c934,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-5752a2bd-616d-4bfb-9278-dc3c07e1ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-5a98ce85-e0c1-40cd-9347-725ed17f1a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-f6183cf7-5e63-42f7-902b-a57c5cd083ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-f8e6cdae-db60-4403-98ce-8cc5219e7ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-346a8c75-c9be-4f13-b079-98ddd3c5f9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-5fc33f1a-ebcc-4f2c-be3e-c9ce01f0535c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689920393-172.17.0.3-1597048805307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34006,DS-82efcb2f-fb81-4ded-ac13-03340ad5f7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-12dff50c-2753-44d2-a7f8-b971bad4c934,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-5752a2bd-616d-4bfb-9278-dc3c07e1ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-5a98ce85-e0c1-40cd-9347-725ed17f1a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-f6183cf7-5e63-42f7-902b-a57c5cd083ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-f8e6cdae-db60-4403-98ce-8cc5219e7ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-346a8c75-c9be-4f13-b079-98ddd3c5f9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-5fc33f1a-ebcc-4f2c-be3e-c9ce01f0535c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47583276-172.17.0.3-1597048840862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37761,DS-48f158bc-5f66-47af-842e-c64e34ba038a,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-f04f8b56-fe58-49b6-b866-7f23209d98dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-16bfdfb3-27f5-4ea5-8280-8f5b5d2bb43e,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-57bbcfda-fff2-4473-a239-d98e796cdf05,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-3ed22d95-5895-47de-8d3b-fd68ad9cb4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-69ad9232-4c8e-404e-9ca3-6df7945f962d,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-d1c4d771-594e-4dc2-8117-74ef42ecc69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-a57b87b4-6453-4450-a186-1e3e87d9c534,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47583276-172.17.0.3-1597048840862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37761,DS-48f158bc-5f66-47af-842e-c64e34ba038a,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-f04f8b56-fe58-49b6-b866-7f23209d98dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-16bfdfb3-27f5-4ea5-8280-8f5b5d2bb43e,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-57bbcfda-fff2-4473-a239-d98e796cdf05,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-3ed22d95-5895-47de-8d3b-fd68ad9cb4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-69ad9232-4c8e-404e-9ca3-6df7945f962d,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-d1c4d771-594e-4dc2-8117-74ef42ecc69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-a57b87b4-6453-4450-a186-1e3e87d9c534,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497443193-172.17.0.3-1597049018961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-1c0ceb04-d54b-482e-839f-157f9f577fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-780e8476-82fa-487a-8ea2-ab79d24473e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-39498d28-0f74-4809-8bba-3b4f4012753e,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-939977b9-e837-465a-9db6-3e7749e20fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-778b231b-0d13-4582-b4fa-7e3ec20fd309,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-7a89d775-eff0-4687-87e7-a9ebb7c7b70c,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-85ad9465-9d66-47a0-a0b1-3bf148d2d0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-78e6c8ae-666d-4fbe-84e6-75f7662a8d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497443193-172.17.0.3-1597049018961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-1c0ceb04-d54b-482e-839f-157f9f577fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-780e8476-82fa-487a-8ea2-ab79d24473e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-39498d28-0f74-4809-8bba-3b4f4012753e,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-939977b9-e837-465a-9db6-3e7749e20fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-778b231b-0d13-4582-b4fa-7e3ec20fd309,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-7a89d775-eff0-4687-87e7-a9ebb7c7b70c,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-85ad9465-9d66-47a0-a0b1-3bf148d2d0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-78e6c8ae-666d-4fbe-84e6-75f7662a8d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268779960-172.17.0.3-1597049132501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43990,DS-4b1a1c26-ec65-451f-9085-17b9f18c2097,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-600a451f-20b3-4e4f-b2ab-19dfc6818f89,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-7b9f8dc9-896a-4aa7-bce2-581544bc496f,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-b75ad2c8-ec9a-40b6-a29a-7ee10799c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-a48c1320-2108-47ff-8b8c-43dfd54a19b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-c59f4753-c95c-49ac-8535-593516c23822,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-cc3adcbf-2b22-499b-9c8d-5058c05a90d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-42988639-a207-4884-a36e-5651ba1ab2fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268779960-172.17.0.3-1597049132501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43990,DS-4b1a1c26-ec65-451f-9085-17b9f18c2097,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-600a451f-20b3-4e4f-b2ab-19dfc6818f89,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-7b9f8dc9-896a-4aa7-bce2-581544bc496f,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-b75ad2c8-ec9a-40b6-a29a-7ee10799c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-a48c1320-2108-47ff-8b8c-43dfd54a19b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-c59f4753-c95c-49ac-8535-593516c23822,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-cc3adcbf-2b22-499b-9c8d-5058c05a90d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-42988639-a207-4884-a36e-5651ba1ab2fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5379
