reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248886452-172.17.0.5-1597073787580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40742,DS-ac3ddcaa-cd0c-4aae-bc88-b9376da2a193,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-d6c81281-c88a-4eed-acbd-a0498bc46d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-dc8ca7f3-aad6-4348-bebf-dcbecc45a14d,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-2170c972-7fbc-4906-a3bd-e801833c300e,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-bfcae265-5b36-4d20-a79e-b79f4758995a,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-fb3acfd8-23ab-4643-bb7e-8d1e989fb684,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-5f4ffb35-c294-464b-89db-fd39f38c0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-2fbfd573-4e7f-41e8-bc4a-312f550593eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248886452-172.17.0.5-1597073787580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40742,DS-ac3ddcaa-cd0c-4aae-bc88-b9376da2a193,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-d6c81281-c88a-4eed-acbd-a0498bc46d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-dc8ca7f3-aad6-4348-bebf-dcbecc45a14d,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-2170c972-7fbc-4906-a3bd-e801833c300e,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-bfcae265-5b36-4d20-a79e-b79f4758995a,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-fb3acfd8-23ab-4643-bb7e-8d1e989fb684,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-5f4ffb35-c294-464b-89db-fd39f38c0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-2fbfd573-4e7f-41e8-bc4a-312f550593eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218716248-172.17.0.5-1597074091295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45545,DS-a82cd45f-bfd3-47ba-b10e-76b1f08ec851,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-c7a2f7f9-20d7-49c7-be47-e96e7ee35080,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-36c2d00f-e099-4c94-9c8f-f79b018ba9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-2e873881-9ed8-4445-bf20-684fd7c39202,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-dac5b912-5f15-4cc9-a40c-9e7a71a34cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-bfb48dbf-3c77-4d58-80bf-c70e894ed3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-10c2e46a-cff1-44e5-ab96-b220bdcbba18,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-cb88174f-2d19-4d09-b5df-fb9ce426215b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218716248-172.17.0.5-1597074091295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45545,DS-a82cd45f-bfd3-47ba-b10e-76b1f08ec851,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-c7a2f7f9-20d7-49c7-be47-e96e7ee35080,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-36c2d00f-e099-4c94-9c8f-f79b018ba9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-2e873881-9ed8-4445-bf20-684fd7c39202,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-dac5b912-5f15-4cc9-a40c-9e7a71a34cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-bfb48dbf-3c77-4d58-80bf-c70e894ed3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-10c2e46a-cff1-44e5-ab96-b220bdcbba18,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-cb88174f-2d19-4d09-b5df-fb9ce426215b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246821239-172.17.0.5-1597074126084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40330,DS-d16b8e81-4eda-451c-b9f0-90f6c12ddd22,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-6abc6d59-d4d2-4d62-babe-17ad11aa647f,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-44af061d-0b4e-4611-b071-dfe6f8422ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-ec96d526-99ea-422b-8405-19194b2d1d85,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-f86fdce9-c509-45de-aeb8-65db89db5138,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-e4b785cd-10ca-4960-8b40-53740fa33775,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-b504e147-4524-463f-83ca-5e498e3343df,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-0b645763-e022-45c4-b763-7f9eb458ece9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246821239-172.17.0.5-1597074126084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40330,DS-d16b8e81-4eda-451c-b9f0-90f6c12ddd22,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-6abc6d59-d4d2-4d62-babe-17ad11aa647f,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-44af061d-0b4e-4611-b071-dfe6f8422ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-ec96d526-99ea-422b-8405-19194b2d1d85,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-f86fdce9-c509-45de-aeb8-65db89db5138,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-e4b785cd-10ca-4960-8b40-53740fa33775,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-b504e147-4524-463f-83ca-5e498e3343df,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-0b645763-e022-45c4-b763-7f9eb458ece9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108861351-172.17.0.5-1597074646149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39854,DS-f295bc97-5aab-454a-98de-3d30ab4c6973,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-53dc1c6f-7c89-47c6-8c6f-08ad4e39c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-00610409-9d5f-40ac-a4fd-7ba01832f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-3a3f4981-288c-48ca-ac42-527af324d132,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-f9388bdc-666c-43a4-931a-25ea3a963c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-5a7be482-c328-4d2b-88a1-df8af94781ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-93c81169-d909-4591-9ba8-4a86df2ea8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-1a13e15a-c874-4e41-9bb7-be2f2d26f8fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108861351-172.17.0.5-1597074646149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39854,DS-f295bc97-5aab-454a-98de-3d30ab4c6973,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-53dc1c6f-7c89-47c6-8c6f-08ad4e39c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-00610409-9d5f-40ac-a4fd-7ba01832f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-3a3f4981-288c-48ca-ac42-527af324d132,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-f9388bdc-666c-43a4-931a-25ea3a963c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-5a7be482-c328-4d2b-88a1-df8af94781ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-93c81169-d909-4591-9ba8-4a86df2ea8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-1a13e15a-c874-4e41-9bb7-be2f2d26f8fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396093621-172.17.0.5-1597074996021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38650,DS-83725892-1b8c-4003-a6a4-7f13ebf01467,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-1b5d2e71-3733-4a9b-a526-104e60bca671,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-fa4d9949-3dae-4b3b-b4c4-b4a02ad1511b,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-f7230539-7b83-4cde-ac3b-9117d3dad960,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-1c1e6b23-e136-47d3-8f10-21558f5f5969,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-868ff7d4-53fc-4891-9b2a-57799e58baff,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-73aa5bf1-49da-49e3-adec-33cacf521bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-4b641e5a-0b65-41f4-bc12-2af1d866ba1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396093621-172.17.0.5-1597074996021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38650,DS-83725892-1b8c-4003-a6a4-7f13ebf01467,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-1b5d2e71-3733-4a9b-a526-104e60bca671,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-fa4d9949-3dae-4b3b-b4c4-b4a02ad1511b,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-f7230539-7b83-4cde-ac3b-9117d3dad960,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-1c1e6b23-e136-47d3-8f10-21558f5f5969,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-868ff7d4-53fc-4891-9b2a-57799e58baff,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-73aa5bf1-49da-49e3-adec-33cacf521bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-4b641e5a-0b65-41f4-bc12-2af1d866ba1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948160078-172.17.0.5-1597075713410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-ca4cfa87-050c-4341-aa7e-c8fcf4be4c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-d902f8a8-9bbb-4ead-ae12-02260762e699,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-aca0c63e-6a8b-41eb-a0f6-61ab384a674f,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-53ed87de-34a9-4eeb-99b9-1a1d48dc4382,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-73254b72-1c9b-464e-ad49-5fa13169aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-54ca7697-9308-4889-a6d7-c6f67f295c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-0ef9379f-bf74-49e6-b183-0efb54378284,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-59372cf4-03d6-4ad9-be28-184da5ef4dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948160078-172.17.0.5-1597075713410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-ca4cfa87-050c-4341-aa7e-c8fcf4be4c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-d902f8a8-9bbb-4ead-ae12-02260762e699,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-aca0c63e-6a8b-41eb-a0f6-61ab384a674f,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-53ed87de-34a9-4eeb-99b9-1a1d48dc4382,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-73254b72-1c9b-464e-ad49-5fa13169aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-54ca7697-9308-4889-a6d7-c6f67f295c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-0ef9379f-bf74-49e6-b183-0efb54378284,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-59372cf4-03d6-4ad9-be28-184da5ef4dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589606620-172.17.0.5-1597076358217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44237,DS-dd8eb0e1-44e0-4ba0-86f5-9748fdd3801d,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-d5c5775d-8fec-48b3-834e-e4048bbc7459,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-0f826be9-067f-47d6-abf5-e0951dd6dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-8248a5e1-0925-4e60-a2ff-2aa0a50e2cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-c7d2e298-3eb8-489f-8d56-777b6e4d4087,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-caf6f840-6454-44a5-85b6-ef9b492b6f29,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-3051d15b-537d-4f17-b136-9ee15f6d8401,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-bdf86cf1-9432-4e1e-8d7c-991dddf47b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589606620-172.17.0.5-1597076358217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44237,DS-dd8eb0e1-44e0-4ba0-86f5-9748fdd3801d,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-d5c5775d-8fec-48b3-834e-e4048bbc7459,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-0f826be9-067f-47d6-abf5-e0951dd6dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-8248a5e1-0925-4e60-a2ff-2aa0a50e2cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-c7d2e298-3eb8-489f-8d56-777b6e4d4087,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-caf6f840-6454-44a5-85b6-ef9b492b6f29,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-3051d15b-537d-4f17-b136-9ee15f6d8401,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-bdf86cf1-9432-4e1e-8d7c-991dddf47b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012595606-172.17.0.5-1597076529618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37053,DS-70e17ea7-4873-48a9-9f09-704d085a03a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-8b522167-8b11-44a8-a5f6-4c0375a7605b,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-24b84058-79f8-4b1d-9478-f9a5841e34da,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-ec65e4b1-85c8-4c8e-8b3f-c34b54ee7eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-c10a3417-72c2-4be4-a471-98c181c4db7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-c835d0f7-afca-4169-8af0-dfd40d10855c,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c3fea4dc-ee6d-4ce7-b28a-996aa0bb989d,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-2bc0be80-401c-449e-82f1-1ab676308dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012595606-172.17.0.5-1597076529618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37053,DS-70e17ea7-4873-48a9-9f09-704d085a03a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-8b522167-8b11-44a8-a5f6-4c0375a7605b,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-24b84058-79f8-4b1d-9478-f9a5841e34da,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-ec65e4b1-85c8-4c8e-8b3f-c34b54ee7eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-c10a3417-72c2-4be4-a471-98c181c4db7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-c835d0f7-afca-4169-8af0-dfd40d10855c,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c3fea4dc-ee6d-4ce7-b28a-996aa0bb989d,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-2bc0be80-401c-449e-82f1-1ab676308dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186086950-172.17.0.5-1597076822708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37231,DS-cb33ce3a-830d-47a3-a38e-10fa9e24e1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-ec34da33-b563-45a0-99c1-b026cac60dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-67d38559-890c-4b25-89dd-2afc99fd3043,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-31baba80-dbaa-4a5d-9634-ee60c54e7b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-cd931dc0-7f51-4c4e-9ca2-38a332b90664,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-0dcdbd0c-4578-4077-b4f9-379898523c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-181be388-1802-4b25-ace7-6b168e504ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-36aad97b-9798-4c1c-ae02-d5bee4ea8d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186086950-172.17.0.5-1597076822708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37231,DS-cb33ce3a-830d-47a3-a38e-10fa9e24e1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-ec34da33-b563-45a0-99c1-b026cac60dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-67d38559-890c-4b25-89dd-2afc99fd3043,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-31baba80-dbaa-4a5d-9634-ee60c54e7b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-cd931dc0-7f51-4c4e-9ca2-38a332b90664,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-0dcdbd0c-4578-4077-b4f9-379898523c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-181be388-1802-4b25-ace7-6b168e504ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-36aad97b-9798-4c1c-ae02-d5bee4ea8d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282530650-172.17.0.5-1597077269814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44338,DS-d04c0974-4602-42c6-afe9-69931627eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-bd7ddbe9-ad89-4d23-9e35-0814de62738d,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-b7eace69-512e-4d15-9051-61ff6eae2919,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-1f7cc681-c268-4937-a001-8ff71bf46727,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-2c861503-af61-415d-b97e-3f89813e07c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-d5d3959f-8378-40b0-ab5c-1b2e36638859,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-55f980a0-10f4-4792-ab31-43ccaba48877,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-a5695d8d-5dbf-4697-878c-0666f3384458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282530650-172.17.0.5-1597077269814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44338,DS-d04c0974-4602-42c6-afe9-69931627eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-bd7ddbe9-ad89-4d23-9e35-0814de62738d,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-b7eace69-512e-4d15-9051-61ff6eae2919,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-1f7cc681-c268-4937-a001-8ff71bf46727,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-2c861503-af61-415d-b97e-3f89813e07c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-d5d3959f-8378-40b0-ab5c-1b2e36638859,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-55f980a0-10f4-4792-ab31-43ccaba48877,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-a5695d8d-5dbf-4697-878c-0666f3384458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347493866-172.17.0.5-1597078401926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-b5c5f25c-9343-4198-baf9-4a400ea3963a,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-fdfcc6ed-0852-4450-a64a-70f8b9136203,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-73a6b1cd-9a2c-496b-ac1e-e30ce031237f,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-bed53721-8237-44bd-931b-2a0da2f94025,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-de4fa4b1-3d7e-4735-a64d-c6b746fb4357,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-d1ff2798-c66e-4cb2-8d2e-758390c11ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-30fd1c20-1d30-4265-97b6-250c0d5aa6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-255c1f4d-f69c-4e50-9fb0-e50a5202f36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347493866-172.17.0.5-1597078401926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-b5c5f25c-9343-4198-baf9-4a400ea3963a,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-fdfcc6ed-0852-4450-a64a-70f8b9136203,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-73a6b1cd-9a2c-496b-ac1e-e30ce031237f,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-bed53721-8237-44bd-931b-2a0da2f94025,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-de4fa4b1-3d7e-4735-a64d-c6b746fb4357,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-d1ff2798-c66e-4cb2-8d2e-758390c11ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-30fd1c20-1d30-4265-97b6-250c0d5aa6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-255c1f4d-f69c-4e50-9fb0-e50a5202f36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139931202-172.17.0.5-1597078439573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32781,DS-1794c80c-140d-4089-8018-b1faa3ede8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-6b3526d5-bc34-46d8-8ee9-19283b74adc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-fb46d835-5467-4002-8614-939a7e49db7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-7d93107b-538a-40ef-b70e-87a85232aaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-cad58307-8929-49a0-b728-d4f99a74aef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-b3ff4959-c600-4b91-bb65-ed649146fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-950646be-ef94-4922-9063-582e1baba660,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-9e835677-b721-499a-a960-e591551ce90f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139931202-172.17.0.5-1597078439573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32781,DS-1794c80c-140d-4089-8018-b1faa3ede8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-6b3526d5-bc34-46d8-8ee9-19283b74adc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-fb46d835-5467-4002-8614-939a7e49db7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-7d93107b-538a-40ef-b70e-87a85232aaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-cad58307-8929-49a0-b728-d4f99a74aef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-b3ff4959-c600-4b91-bb65-ed649146fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-950646be-ef94-4922-9063-582e1baba660,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-9e835677-b721-499a-a960-e591551ce90f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876787702-172.17.0.5-1597078480643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-81b69a08-5260-4593-aa49-66a777261f30,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-91375d35-2acd-4457-a172-09b9ed6e5232,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-dcc97f4f-5063-4786-ba7f-0d9993985c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-87c337f3-838f-4616-88cf-2afd66580fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-2764ebfb-d119-4c7c-8023-cf86595b2318,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-24b4e59f-2f51-42fa-baf3-2261c1070213,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-2f480c3b-3dd0-4425-b0f9-612e9f3ad502,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-7578ecc8-62b1-4564-b519-41fca82abaa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876787702-172.17.0.5-1597078480643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-81b69a08-5260-4593-aa49-66a777261f30,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-91375d35-2acd-4457-a172-09b9ed6e5232,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-dcc97f4f-5063-4786-ba7f-0d9993985c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-87c337f3-838f-4616-88cf-2afd66580fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-2764ebfb-d119-4c7c-8023-cf86595b2318,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-24b4e59f-2f51-42fa-baf3-2261c1070213,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-2f480c3b-3dd0-4425-b0f9-612e9f3ad502,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-7578ecc8-62b1-4564-b519-41fca82abaa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239987625-172.17.0.5-1597078587026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43234,DS-3b6dad27-63a6-4928-8175-d6bee52f1f74,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-8070d5cc-bd2e-4126-84c5-4bcc7c294ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-dfd54791-a41a-4db6-a887-fa4eb67c8dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-1a03379c-d2b3-494f-96fd-e8c3ad7c2778,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-26b50f32-0aef-4d51-b4dc-7d277fc4894d,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-045425dc-66ac-4604-a2fa-efa01b949c77,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-65de0224-4718-4c26-a5ce-5bca6756ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-18125929-43c4-4961-b210-5c9fed0e2a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239987625-172.17.0.5-1597078587026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43234,DS-3b6dad27-63a6-4928-8175-d6bee52f1f74,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-8070d5cc-bd2e-4126-84c5-4bcc7c294ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-dfd54791-a41a-4db6-a887-fa4eb67c8dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-1a03379c-d2b3-494f-96fd-e8c3ad7c2778,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-26b50f32-0aef-4d51-b4dc-7d277fc4894d,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-045425dc-66ac-4604-a2fa-efa01b949c77,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-65de0224-4718-4c26-a5ce-5bca6756ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-18125929-43c4-4961-b210-5c9fed0e2a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5537
