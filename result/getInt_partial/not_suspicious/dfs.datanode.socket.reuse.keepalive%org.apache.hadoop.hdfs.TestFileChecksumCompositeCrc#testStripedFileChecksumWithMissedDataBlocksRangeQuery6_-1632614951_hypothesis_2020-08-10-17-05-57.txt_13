reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33226916-172.17.0.18-1597079286696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43412,DS-609df3b9-6bb6-407c-b968-6baa11d8b242,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-0c767034-ce3c-47e3-ad04-212efb7b8678,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-a271d9b7-10cf-48a2-a32a-7692dc1c8c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-cea1adc8-e356-46c0-bd12-af2d83c109a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-3e1b5169-4428-4b2f-9851-ae717e7962e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-2f974218-0068-435a-88a1-707cf72df84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-6692cb22-3747-4f59-8f4f-66cd3db6a29a,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-ea26c1fe-c0c1-4851-969b-441548e6a6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33226916-172.17.0.18-1597079286696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43412,DS-609df3b9-6bb6-407c-b968-6baa11d8b242,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-0c767034-ce3c-47e3-ad04-212efb7b8678,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-a271d9b7-10cf-48a2-a32a-7692dc1c8c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-cea1adc8-e356-46c0-bd12-af2d83c109a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-3e1b5169-4428-4b2f-9851-ae717e7962e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-2f974218-0068-435a-88a1-707cf72df84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-6692cb22-3747-4f59-8f4f-66cd3db6a29a,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-ea26c1fe-c0c1-4851-969b-441548e6a6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4610722-172.17.0.18-1597079353909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-aaf73ff9-e545-43a8-bf44-656a6cae7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-c8bd12e5-ed7a-4f17-8280-bb21f6fdcb83,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-a652041a-7687-4f97-98dd-4a8db9e0adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-16ffe867-f8a5-4452-a87c-6e2bce7ae795,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-115b57f3-a79e-45c0-88c1-dc0e416b9eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-38b4bcc9-406f-40e2-80c7-6e84969426e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-ba971343-be6d-422a-a8ce-5eb0be2b44d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-de2e9873-8006-4f28-b835-b5527244a439,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4610722-172.17.0.18-1597079353909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-aaf73ff9-e545-43a8-bf44-656a6cae7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-c8bd12e5-ed7a-4f17-8280-bb21f6fdcb83,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-a652041a-7687-4f97-98dd-4a8db9e0adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-16ffe867-f8a5-4452-a87c-6e2bce7ae795,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-115b57f3-a79e-45c0-88c1-dc0e416b9eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-38b4bcc9-406f-40e2-80c7-6e84969426e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-ba971343-be6d-422a-a8ce-5eb0be2b44d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-de2e9873-8006-4f28-b835-b5527244a439,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157440236-172.17.0.18-1597079617065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39815,DS-3f9d1fd6-db53-4ae4-91a3-1c3365c8ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-92473002-70f8-4484-86a7-ed85dba149bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-67ef7ab8-1f48-4fc3-9ce5-6cc8d16d8bff,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-668f3333-d330-4196-a04a-7f798edb5430,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-72cf0dc2-9214-4e1c-8035-0f82184a9782,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-9c5dfd88-1eeb-484b-a114-c3017248eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-45e47d7e-af4f-428d-aaeb-01fc45b82fae,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-e8e31a7c-0340-461d-aec1-69fa332b7a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157440236-172.17.0.18-1597079617065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39815,DS-3f9d1fd6-db53-4ae4-91a3-1c3365c8ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-92473002-70f8-4484-86a7-ed85dba149bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-67ef7ab8-1f48-4fc3-9ce5-6cc8d16d8bff,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-668f3333-d330-4196-a04a-7f798edb5430,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-72cf0dc2-9214-4e1c-8035-0f82184a9782,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-9c5dfd88-1eeb-484b-a114-c3017248eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-45e47d7e-af4f-428d-aaeb-01fc45b82fae,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-e8e31a7c-0340-461d-aec1-69fa332b7a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380347149-172.17.0.18-1597079764308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34302,DS-24f138cb-573e-4a3f-bcc7-f6e22d8e54a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-6df83d78-106e-4524-af91-dfba8b194956,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-966873de-8edc-4f32-b275-496d220fac73,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-760c2635-8ce6-4557-a95b-a48e8da4ce7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-50487e68-47ee-4e5a-a675-99eb0a036d59,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-c6ef5561-17ee-4a99-81b7-0223dabe16fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-c5cb65d0-1c51-426a-8221-7b3a4e74913c,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-8efa4854-b45a-465e-90dc-a13aabe83a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380347149-172.17.0.18-1597079764308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34302,DS-24f138cb-573e-4a3f-bcc7-f6e22d8e54a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-6df83d78-106e-4524-af91-dfba8b194956,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-966873de-8edc-4f32-b275-496d220fac73,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-760c2635-8ce6-4557-a95b-a48e8da4ce7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-50487e68-47ee-4e5a-a675-99eb0a036d59,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-c6ef5561-17ee-4a99-81b7-0223dabe16fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-c5cb65d0-1c51-426a-8221-7b3a4e74913c,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-8efa4854-b45a-465e-90dc-a13aabe83a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319658511-172.17.0.18-1597080342401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-d05d54b9-5854-41aa-9b66-32703724d8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-fd4f2ef5-61dd-49c3-baa8-41e205b01554,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-f903dcfc-7e90-4c62-a485-39bae67fae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-95bf3844-dc3b-47ba-9aa9-5142fd81c046,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-b032fe4c-f1fe-4d6d-8062-d17f4b7ae6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-67358447-f2e4-4241-896e-f33ca4a185d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-2035959c-4a55-42aa-8998-d26761686a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-4ab7e6f9-7113-4541-b8e8-7e2c913fe354,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319658511-172.17.0.18-1597080342401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-d05d54b9-5854-41aa-9b66-32703724d8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-fd4f2ef5-61dd-49c3-baa8-41e205b01554,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-f903dcfc-7e90-4c62-a485-39bae67fae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-95bf3844-dc3b-47ba-9aa9-5142fd81c046,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-b032fe4c-f1fe-4d6d-8062-d17f4b7ae6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-67358447-f2e4-4241-896e-f33ca4a185d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-2035959c-4a55-42aa-8998-d26761686a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-4ab7e6f9-7113-4541-b8e8-7e2c913fe354,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347308494-172.17.0.18-1597080485718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37433,DS-6f4c9268-1618-4d4e-8ced-e952272d272d,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-c444bd79-716b-40fa-80dc-6d119bd242b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-07c87723-6955-4416-9ad4-a541a1e2bd36,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-ba33d8ca-c9f1-46fd-971c-a84a81170e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-4e46d27d-f6d6-4aca-a7d7-259085804e85,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-af12901e-2340-4f4d-8727-699e40c16649,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-18de37cc-9bf1-48c7-bb85-26dbcb5536b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-88e00ae0-d03a-4196-8e43-5b08f232cde6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347308494-172.17.0.18-1597080485718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37433,DS-6f4c9268-1618-4d4e-8ced-e952272d272d,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-c444bd79-716b-40fa-80dc-6d119bd242b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-07c87723-6955-4416-9ad4-a541a1e2bd36,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-ba33d8ca-c9f1-46fd-971c-a84a81170e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-4e46d27d-f6d6-4aca-a7d7-259085804e85,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-af12901e-2340-4f4d-8727-699e40c16649,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-18de37cc-9bf1-48c7-bb85-26dbcb5536b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-88e00ae0-d03a-4196-8e43-5b08f232cde6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647282808-172.17.0.18-1597080519902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-073a16fb-f2bc-4718-b6d6-c7fecc5869ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-f0702404-807c-4194-bc45-8099c9a57ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-57713a1f-6238-437b-9051-6f61dc58f490,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-aa20400e-34c2-4d42-9397-641f5f320525,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-4d5073a4-12dc-46f9-a4f7-38531493fff2,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-cd81f8c8-7fcb-4afe-90ab-8ee7782bc3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-4e070027-b58d-4ded-bba2-63dda45a24bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-bd67d8bc-708e-41b2-9592-dd119ec1bfce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647282808-172.17.0.18-1597080519902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-073a16fb-f2bc-4718-b6d6-c7fecc5869ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-f0702404-807c-4194-bc45-8099c9a57ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-57713a1f-6238-437b-9051-6f61dc58f490,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-aa20400e-34c2-4d42-9397-641f5f320525,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-4d5073a4-12dc-46f9-a4f7-38531493fff2,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-cd81f8c8-7fcb-4afe-90ab-8ee7782bc3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-4e070027-b58d-4ded-bba2-63dda45a24bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-bd67d8bc-708e-41b2-9592-dd119ec1bfce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757210734-172.17.0.18-1597080636987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38912,DS-fa3072d2-c5f6-4259-9b6c-fd65ea0e8137,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-7e787880-99b2-4adf-bee9-7ef1d3d1367d,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-5eaa23c8-2329-4c6b-b4df-1d4ae007650e,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-b6cf0f4b-b5ed-4224-afd0-3b0be5017738,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-f21da247-18e0-4b8e-9d38-4b56a43cdbec,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-7794b503-81c5-43a1-933d-21687892a074,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-b5f822d3-8473-4e41-8aa6-dd46811a3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-b42c3e20-7cf3-4de2-9aeb-8feefcdefc5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757210734-172.17.0.18-1597080636987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38912,DS-fa3072d2-c5f6-4259-9b6c-fd65ea0e8137,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-7e787880-99b2-4adf-bee9-7ef1d3d1367d,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-5eaa23c8-2329-4c6b-b4df-1d4ae007650e,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-b6cf0f4b-b5ed-4224-afd0-3b0be5017738,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-f21da247-18e0-4b8e-9d38-4b56a43cdbec,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-7794b503-81c5-43a1-933d-21687892a074,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-b5f822d3-8473-4e41-8aa6-dd46811a3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-b42c3e20-7cf3-4de2-9aeb-8feefcdefc5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490955125-172.17.0.18-1597080723753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-abf694d9-5e9e-4fc5-a529-b8a91f8f300d,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-8de7b76d-ebe8-4e7d-a1cf-b61c417f112e,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-5a3c14f0-4430-49eb-8521-46de868ac8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-78a9ecce-bc08-4e3e-b3fe-99663a7c54ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-f0a9e195-8e49-4c31-9dae-143f578a06a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-a43db766-ea25-449b-ad1a-8d478275c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-302e5116-ff7e-411e-ae7f-311927beb38e,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-a0b917b3-96bc-438e-a268-8da24ba6d70e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490955125-172.17.0.18-1597080723753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-abf694d9-5e9e-4fc5-a529-b8a91f8f300d,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-8de7b76d-ebe8-4e7d-a1cf-b61c417f112e,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-5a3c14f0-4430-49eb-8521-46de868ac8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-78a9ecce-bc08-4e3e-b3fe-99663a7c54ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-f0a9e195-8e49-4c31-9dae-143f578a06a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-a43db766-ea25-449b-ad1a-8d478275c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-302e5116-ff7e-411e-ae7f-311927beb38e,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-a0b917b3-96bc-438e-a268-8da24ba6d70e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959171215-172.17.0.18-1597081093332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46596,DS-a54b2b03-3391-4688-9765-af91cedabe02,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-67124230-2c1d-49da-b049-bb12bc48b465,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-a4456693-6f2f-45bd-a884-9d3df50fbd70,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-5f2a5caf-4a87-40ed-aa4f-ff1518b8e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-5b2797ed-619d-48b6-bc01-801ff739d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-0ee7536b-9499-4c30-b5c6-1f6eb4c57867,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-f36d79a3-5c04-4708-8269-05450325b183,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-15b5dd4b-3ca7-450e-8737-da44bfb194db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959171215-172.17.0.18-1597081093332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46596,DS-a54b2b03-3391-4688-9765-af91cedabe02,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-67124230-2c1d-49da-b049-bb12bc48b465,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-a4456693-6f2f-45bd-a884-9d3df50fbd70,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-5f2a5caf-4a87-40ed-aa4f-ff1518b8e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-5b2797ed-619d-48b6-bc01-801ff739d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-0ee7536b-9499-4c30-b5c6-1f6eb4c57867,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-f36d79a3-5c04-4708-8269-05450325b183,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-15b5dd4b-3ca7-450e-8737-da44bfb194db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784028192-172.17.0.18-1597081346567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-367216cb-d0c5-4947-8091-8d83d501f8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-67f7b9f2-c247-4df3-ac0b-6d4b07046472,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-f066e5a7-7e95-4d2e-b181-32b77aa4fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-cd057332-1a0d-42c2-8489-1d03ab64c834,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-732855f6-7c91-4b69-85db-2a8a28d63b80,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-1d21b634-ba3a-408c-9259-8e5cb2dda97c,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-e159fe76-1134-4904-9b30-5279dc2c549c,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-78fcc7fc-2178-4886-88f0-dff56f76bb4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784028192-172.17.0.18-1597081346567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-367216cb-d0c5-4947-8091-8d83d501f8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-67f7b9f2-c247-4df3-ac0b-6d4b07046472,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-f066e5a7-7e95-4d2e-b181-32b77aa4fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-cd057332-1a0d-42c2-8489-1d03ab64c834,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-732855f6-7c91-4b69-85db-2a8a28d63b80,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-1d21b634-ba3a-408c-9259-8e5cb2dda97c,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-e159fe76-1134-4904-9b30-5279dc2c549c,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-78fcc7fc-2178-4886-88f0-dff56f76bb4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331461242-172.17.0.18-1597081463211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42053,DS-f104ec04-85b2-4dbe-91f6-ded0ff8aea55,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-601daa32-4e24-43c5-bd77-e9ba652a8f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-4b619fa9-849c-4bd8-a83d-b45dd31a16f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-eb05bf3f-5c61-4c99-b92d-5a0f9ad2d42a,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-d944cd88-daee-4fa4-b4e8-346c8cfcc8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-bbb825ba-585c-4867-91f8-a8387e3f7f98,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-0aee04dc-f228-461b-9af1-81be3e067d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-3205b0e8-cc5c-4ba5-9401-c003e80ba684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331461242-172.17.0.18-1597081463211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42053,DS-f104ec04-85b2-4dbe-91f6-ded0ff8aea55,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-601daa32-4e24-43c5-bd77-e9ba652a8f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-4b619fa9-849c-4bd8-a83d-b45dd31a16f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-eb05bf3f-5c61-4c99-b92d-5a0f9ad2d42a,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-d944cd88-daee-4fa4-b4e8-346c8cfcc8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-bbb825ba-585c-4867-91f8-a8387e3f7f98,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-0aee04dc-f228-461b-9af1-81be3e067d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-3205b0e8-cc5c-4ba5-9401-c003e80ba684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970873006-172.17.0.18-1597081887489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-d68932ef-c1f0-46cb-b09d-0e4d47386d13,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-ee1d5371-06a3-4a94-97bb-f385da6c9095,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-a133dec4-dc07-4e6c-9599-5cb40e990b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-d2f2c16e-a716-4630-820d-f6f7b261a167,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-eb09c909-606a-48c8-a115-4ec0428ec15b,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-9f58ab2c-a030-4ff9-8aef-b312b38dbbef,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-cbcc1c00-c6d4-4678-bf75-558b670c78af,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-1f42657a-90db-45cc-9b63-262e5855e6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970873006-172.17.0.18-1597081887489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-d68932ef-c1f0-46cb-b09d-0e4d47386d13,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-ee1d5371-06a3-4a94-97bb-f385da6c9095,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-a133dec4-dc07-4e6c-9599-5cb40e990b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-d2f2c16e-a716-4630-820d-f6f7b261a167,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-eb09c909-606a-48c8-a115-4ec0428ec15b,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-9f58ab2c-a030-4ff9-8aef-b312b38dbbef,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-cbcc1c00-c6d4-4678-bf75-558b670c78af,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-1f42657a-90db-45cc-9b63-262e5855e6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248784571-172.17.0.18-1597081955722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-74b0118f-103d-4e8e-9784-cdfca6fe4a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-257addb6-a537-4819-ba84-93fcbbefa9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-f4196961-b314-4984-b8e7-1469fce2a8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-9220c42d-466d-4f72-9e82-9ecc65b8c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-7517e0f7-331d-4c0d-b3e0-7ff71a423533,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-6d60b656-e787-44be-bc3c-8a709fbac227,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-c14f66ee-9c8c-4cb0-beeb-ae03b8343be4,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-299f7435-4ad4-4521-ab0f-f231a118b9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248784571-172.17.0.18-1597081955722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-74b0118f-103d-4e8e-9784-cdfca6fe4a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-257addb6-a537-4819-ba84-93fcbbefa9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-f4196961-b314-4984-b8e7-1469fce2a8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-9220c42d-466d-4f72-9e82-9ecc65b8c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-7517e0f7-331d-4c0d-b3e0-7ff71a423533,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-6d60b656-e787-44be-bc3c-8a709fbac227,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-c14f66ee-9c8c-4cb0-beeb-ae03b8343be4,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-299f7435-4ad4-4521-ab0f-f231a118b9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745386389-172.17.0.18-1597082115568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-0fd1209c-8ec8-4dfe-bd30-54a0258242df,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-f6d8f82a-eecf-4539-9323-e465a0441a85,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-255b679a-f71f-46d4-b103-e81528142204,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-b90f002f-50e4-4dd5-b432-5d2adc362f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-7ec60030-b25e-49b4-9d15-b566c589da6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-d007251f-dbfd-43c7-ac5a-ce52bba1da15,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-ce152fee-5a16-4f0c-ba99-11f0d4c05fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-f4230750-3cf5-43c7-9d22-807bf8630cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745386389-172.17.0.18-1597082115568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-0fd1209c-8ec8-4dfe-bd30-54a0258242df,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-f6d8f82a-eecf-4539-9323-e465a0441a85,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-255b679a-f71f-46d4-b103-e81528142204,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-b90f002f-50e4-4dd5-b432-5d2adc362f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-7ec60030-b25e-49b4-9d15-b566c589da6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-d007251f-dbfd-43c7-ac5a-ce52bba1da15,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-ce152fee-5a16-4f0c-ba99-11f0d4c05fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-f4230750-3cf5-43c7-9d22-807bf8630cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564372957-172.17.0.18-1597082450608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33243,DS-8613e3cf-c3c4-4ac9-84ac-20b8accf64b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-4c5ef819-2590-45e8-99e6-72f2f6aca649,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-18a9956f-7c7a-44e7-a188-277827712202,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-582d1693-11ce-4a0f-ad34-38ec3ebe871d,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-59205e91-e0f7-4ae3-a4f6-6a8f1bdbb18f,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-a02787b1-7093-4752-9f1a-5a55c3054164,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-ae8b555b-8985-45dc-9b38-f847c78f2877,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-6710b731-9925-4325-9979-7e07f2083c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564372957-172.17.0.18-1597082450608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33243,DS-8613e3cf-c3c4-4ac9-84ac-20b8accf64b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-4c5ef819-2590-45e8-99e6-72f2f6aca649,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-18a9956f-7c7a-44e7-a188-277827712202,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-582d1693-11ce-4a0f-ad34-38ec3ebe871d,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-59205e91-e0f7-4ae3-a4f6-6a8f1bdbb18f,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-a02787b1-7093-4752-9f1a-5a55c3054164,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-ae8b555b-8985-45dc-9b38-f847c78f2877,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-6710b731-9925-4325-9979-7e07f2083c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687812597-172.17.0.18-1597082493817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-28a7753f-7c15-416e-abfb-64ba4d7caa56,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-4d7b800d-6861-49d4-8b56-a636748170e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-e353f4e7-c2e9-4e9f-adc1-7e73b565f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-0c7ea9c7-cb67-42d9-a061-d9010c4c4138,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-983c1578-342a-4807-87fd-5fc05b4cc646,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-4d457f9e-a859-4d9b-b2ca-e67c4f6f71df,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-62b1c031-1cf4-4363-bc4e-0711385b2e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-0d2f1125-0345-4a5f-bdd5-5ae7c041c106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687812597-172.17.0.18-1597082493817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-28a7753f-7c15-416e-abfb-64ba4d7caa56,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-4d7b800d-6861-49d4-8b56-a636748170e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-e353f4e7-c2e9-4e9f-adc1-7e73b565f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-0c7ea9c7-cb67-42d9-a061-d9010c4c4138,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-983c1578-342a-4807-87fd-5fc05b4cc646,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-4d457f9e-a859-4d9b-b2ca-e67c4f6f71df,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-62b1c031-1cf4-4363-bc4e-0711385b2e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-0d2f1125-0345-4a5f-bdd5-5ae7c041c106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455126344-172.17.0.18-1597082642660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41440,DS-a8465828-d8bf-4f95-a303-b237ef847af2,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-89e5bbe2-0ef2-4762-8892-23819a4de46f,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-e0484129-707b-4f37-8c20-7cc0e6c6a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-10729f8c-7b18-4f4b-845e-e9b94c979bab,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-26d86584-fe6c-4e07-9483-42f9d6af912d,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-f4c3e249-feec-42cd-8da0-be780fdeb793,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-18d4b182-c19e-472e-9020-4f234338d606,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-bacde118-39d6-442d-b163-1f5f00e74b0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455126344-172.17.0.18-1597082642660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41440,DS-a8465828-d8bf-4f95-a303-b237ef847af2,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-89e5bbe2-0ef2-4762-8892-23819a4de46f,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-e0484129-707b-4f37-8c20-7cc0e6c6a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-10729f8c-7b18-4f4b-845e-e9b94c979bab,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-26d86584-fe6c-4e07-9483-42f9d6af912d,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-f4c3e249-feec-42cd-8da0-be780fdeb793,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-18d4b182-c19e-472e-9020-4f234338d606,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-bacde118-39d6-442d-b163-1f5f00e74b0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003655675-172.17.0.18-1597082832718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-25a538f1-9b27-48db-a66b-36ff33fb2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-d9fbc61b-d636-4ba2-bd4a-89539b4cec40,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-f32c16e1-d967-45c2-8f69-2acc4140b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-b660ed2c-d3d9-43bc-965d-ce9e5f92afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-32b5c1a3-a91e-408b-84e6-74c9681a385b,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e6b9b416-8a30-497e-8dbf-2aab32b1182d,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-6a974f47-12a9-4f4a-9f8d-9756e11f7416,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-4bb5c990-0ec7-41c6-ab73-d67b92c8612a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003655675-172.17.0.18-1597082832718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-25a538f1-9b27-48db-a66b-36ff33fb2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-d9fbc61b-d636-4ba2-bd4a-89539b4cec40,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-f32c16e1-d967-45c2-8f69-2acc4140b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-b660ed2c-d3d9-43bc-965d-ce9e5f92afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-32b5c1a3-a91e-408b-84e6-74c9681a385b,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e6b9b416-8a30-497e-8dbf-2aab32b1182d,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-6a974f47-12a9-4f4a-9f8d-9756e11f7416,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-4bb5c990-0ec7-41c6-ab73-d67b92c8612a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498267415-172.17.0.18-1597082876948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-6cd7a42d-b2d2-4579-9ccb-1a7df656bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-32cdd209-9b03-431e-b7a0-345aca3d4c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-289db8fb-09b0-4cce-9a15-b354787b4671,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-d2bdcb85-bfb3-4a76-b1d2-84ee9f119374,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-b76fc93a-82b1-4b66-b8f8-d16e205f48b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-ce8b0495-91dc-4b46-9dc2-6c40c49514e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-2d813830-e97d-4300-a93c-e44e9dfcb074,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-9d4812fb-f817-4442-a6e4-321b34fbb49e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498267415-172.17.0.18-1597082876948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-6cd7a42d-b2d2-4579-9ccb-1a7df656bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-32cdd209-9b03-431e-b7a0-345aca3d4c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-289db8fb-09b0-4cce-9a15-b354787b4671,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-d2bdcb85-bfb3-4a76-b1d2-84ee9f119374,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-b76fc93a-82b1-4b66-b8f8-d16e205f48b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-ce8b0495-91dc-4b46-9dc2-6c40c49514e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-2d813830-e97d-4300-a93c-e44e9dfcb074,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-9d4812fb-f817-4442-a6e4-321b34fbb49e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340556641-172.17.0.18-1597083056054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-f2febac7-de3b-4ae5-b4a3-d7102bae25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-334d3a74-c0a9-4302-9288-ac393bb7737e,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-2fadabd9-32bc-4195-aaf4-9fa3bc815706,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-8dc21be6-e87d-4bfa-8f3b-35a94da9dcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-a367ad77-df52-4fb0-8c25-26cfd49c5b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-ac636455-8a13-48a2-9ccf-7a4e5dc16913,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-afaa026e-afa5-493a-ab59-63f55b131a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-18bb3683-fe38-4ec4-a6c5-eab773b5402e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340556641-172.17.0.18-1597083056054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-f2febac7-de3b-4ae5-b4a3-d7102bae25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-334d3a74-c0a9-4302-9288-ac393bb7737e,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-2fadabd9-32bc-4195-aaf4-9fa3bc815706,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-8dc21be6-e87d-4bfa-8f3b-35a94da9dcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-a367ad77-df52-4fb0-8c25-26cfd49c5b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-ac636455-8a13-48a2-9ccf-7a4e5dc16913,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-afaa026e-afa5-493a-ab59-63f55b131a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-18bb3683-fe38-4ec4-a6c5-eab773b5402e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562408322-172.17.0.18-1597083314232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-fc6d1cc0-523d-4a5f-97c8-3f8c322211c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c4156ff6-aad5-46d9-af53-275443612f50,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-c1bddfcf-0130-49e5-b88b-6a4724b102af,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-4300fb6b-aac9-4e64-b559-d7b047970cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-b46ed84b-7c14-4490-966e-a74f7022bcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-1a22fa71-580f-468a-a9bb-9a54c8d43681,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-bcd4bec7-8678-408c-861e-2a7d4ee9dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-d77e331e-3936-469b-9bd2-369afdba37fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562408322-172.17.0.18-1597083314232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-fc6d1cc0-523d-4a5f-97c8-3f8c322211c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c4156ff6-aad5-46d9-af53-275443612f50,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-c1bddfcf-0130-49e5-b88b-6a4724b102af,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-4300fb6b-aac9-4e64-b559-d7b047970cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-b46ed84b-7c14-4490-966e-a74f7022bcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-1a22fa71-580f-468a-a9bb-9a54c8d43681,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-bcd4bec7-8678-408c-861e-2a7d4ee9dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-d77e331e-3936-469b-9bd2-369afdba37fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246608531-172.17.0.18-1597083424508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37896,DS-073ffccb-2d1c-4697-856d-1d9bd2410dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-5f7c7632-73ff-496c-a834-5dcb6b745ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-0402e7bd-e4b7-4ba9-8cc8-5d5363457c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-d701f6cb-f018-4b43-9e74-ae9ce7676ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-ebb3be1b-b68c-4bb7-b59c-af25e1a22741,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-27dee5aa-a8a0-4e38-bcaf-0e750900be49,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-99eada00-e27a-4e38-aa3b-be5df2fb3283,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-c82a162f-1b7d-4f77-86a9-dc97cae53461,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246608531-172.17.0.18-1597083424508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37896,DS-073ffccb-2d1c-4697-856d-1d9bd2410dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-5f7c7632-73ff-496c-a834-5dcb6b745ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-0402e7bd-e4b7-4ba9-8cc8-5d5363457c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-d701f6cb-f018-4b43-9e74-ae9ce7676ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-ebb3be1b-b68c-4bb7-b59c-af25e1a22741,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-27dee5aa-a8a0-4e38-bcaf-0e750900be49,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-99eada00-e27a-4e38-aa3b-be5df2fb3283,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-c82a162f-1b7d-4f77-86a9-dc97cae53461,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266376291-172.17.0.18-1597083458556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-884fab41-ecd8-4c0c-b9a3-f8b08abfcd02,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-56b09f9c-3b1a-4c6d-bf1b-1d5adbd9cc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-17dfa5f9-634b-420c-a785-d713064a594f,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-40655593-6991-4b1c-a130-bcefd37b2c96,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-7b232512-ad13-4ea9-af3d-20e278e369db,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-56ce349b-989a-487c-b458-ef8bc149687b,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-c07205c6-9624-4979-aec9-0333d00ea2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-21b2fc85-945d-488f-9efe-097e049cb325,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266376291-172.17.0.18-1597083458556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-884fab41-ecd8-4c0c-b9a3-f8b08abfcd02,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-56b09f9c-3b1a-4c6d-bf1b-1d5adbd9cc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-17dfa5f9-634b-420c-a785-d713064a594f,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-40655593-6991-4b1c-a130-bcefd37b2c96,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-7b232512-ad13-4ea9-af3d-20e278e369db,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-56ce349b-989a-487c-b458-ef8bc149687b,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-c07205c6-9624-4979-aec9-0333d00ea2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-21b2fc85-945d-488f-9efe-097e049cb325,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979242729-172.17.0.18-1597083673257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-270dfce3-9aba-41c0-9946-aad4c880b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-7a2315eb-97d8-4647-ab3c-47bd31421210,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-3c7c6fad-eb1d-494c-a046-1adcc054f8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-045a4ee7-4db8-4b3a-842a-256458d97ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-e57bd365-dcab-449a-8fa1-7be3adfab204,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-0a11500d-39eb-4f87-8a1a-ce191bb652bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-2d050af4-2c69-4d6f-b2cd-ad6404af37cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-42098b05-30c6-46a1-a2e0-93285fb9201a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979242729-172.17.0.18-1597083673257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-270dfce3-9aba-41c0-9946-aad4c880b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-7a2315eb-97d8-4647-ab3c-47bd31421210,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-3c7c6fad-eb1d-494c-a046-1adcc054f8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-045a4ee7-4db8-4b3a-842a-256458d97ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-e57bd365-dcab-449a-8fa1-7be3adfab204,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-0a11500d-39eb-4f87-8a1a-ce191bb652bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-2d050af4-2c69-4d6f-b2cd-ad6404af37cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-42098b05-30c6-46a1-a2e0-93285fb9201a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222842215-172.17.0.18-1597083792040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-4e2abb30-8fad-4f3e-85fe-92489a137689,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-287d7e9d-2818-462c-a20d-78d290ede125,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-15e76da2-314e-4191-9a3c-7b9133e4ab18,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-8348df12-842f-479c-bfe3-ff6a50202011,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-15026574-3f08-418d-85ea-53e2aeb951ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-50bd0c2d-4d03-4bbd-a5a2-8916ef7eebd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-1e34dc02-09a6-4679-9604-8cf5eaed307c,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-a8557d9e-9ea0-4862-a106-93e87d913b1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222842215-172.17.0.18-1597083792040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-4e2abb30-8fad-4f3e-85fe-92489a137689,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-287d7e9d-2818-462c-a20d-78d290ede125,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-15e76da2-314e-4191-9a3c-7b9133e4ab18,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-8348df12-842f-479c-bfe3-ff6a50202011,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-15026574-3f08-418d-85ea-53e2aeb951ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-50bd0c2d-4d03-4bbd-a5a2-8916ef7eebd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-1e34dc02-09a6-4679-9604-8cf5eaed307c,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-a8557d9e-9ea0-4862-a106-93e87d913b1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447404461-172.17.0.18-1597083864343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35340,DS-c6defe63-967d-452c-b57f-3f05aa942b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-2666df58-45b7-420c-bfb9-6366dc9c6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-83cc058a-c17b-4755-8c2d-0bd1173f7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-df760c13-7144-4408-b34d-7ac59e7e7e73,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-c86591ab-83e9-4622-8e59-51c61a872f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-ad7db27d-137e-4246-9d61-1aec7b9c3221,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-cba9d27d-875c-481d-9f8b-36003bdac4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-b3cbf12e-f7e3-4a8f-81c2-55cb29f56ab9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447404461-172.17.0.18-1597083864343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35340,DS-c6defe63-967d-452c-b57f-3f05aa942b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-2666df58-45b7-420c-bfb9-6366dc9c6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-83cc058a-c17b-4755-8c2d-0bd1173f7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-df760c13-7144-4408-b34d-7ac59e7e7e73,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-c86591ab-83e9-4622-8e59-51c61a872f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-ad7db27d-137e-4246-9d61-1aec7b9c3221,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-cba9d27d-875c-481d-9f8b-36003bdac4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-b3cbf12e-f7e3-4a8f-81c2-55cb29f56ab9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380318161-172.17.0.18-1597083899159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-496fb022-54b3-4883-a23f-41fdae71ef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-2d4194a6-c6f9-4b12-84d7-97c8a05b604c,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-bb67174e-3d02-4f66-8616-ee106a037c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-2ef66007-c3bd-4373-bde2-1a7e6adab29a,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-8be12c00-c3e2-4a55-9891-224a425adf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-c5fa56b4-9f89-4205-bbcc-04ea40afac52,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-dfe8669a-9b4b-4975-a830-547b152129e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-1e9ff213-28d6-42ab-ba7b-48c75e34dc57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380318161-172.17.0.18-1597083899159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-496fb022-54b3-4883-a23f-41fdae71ef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-2d4194a6-c6f9-4b12-84d7-97c8a05b604c,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-bb67174e-3d02-4f66-8616-ee106a037c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-2ef66007-c3bd-4373-bde2-1a7e6adab29a,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-8be12c00-c3e2-4a55-9891-224a425adf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-c5fa56b4-9f89-4205-bbcc-04ea40afac52,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-dfe8669a-9b4b-4975-a830-547b152129e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-1e9ff213-28d6-42ab-ba7b-48c75e34dc57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657672994-172.17.0.18-1597083937007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-ee36225b-7151-4d8a-96ba-0110c00a2d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-52c6b676-f179-4c63-9fe6-5b88dc7dae58,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-d8fc1b0c-a79e-430d-ae4a-d6e3d2d5a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-45038266-ae3f-4a4f-9ebe-9ba46729433a,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-b17c4769-76d7-46f5-bc71-2b2bc35fcf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-478533e7-a8dd-4869-b3c8-05f0e33f95da,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-1f2cc635-0f81-4504-b251-9b5d11b76dab,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-80d48f86-2aa8-4559-896c-2f341748c1c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657672994-172.17.0.18-1597083937007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-ee36225b-7151-4d8a-96ba-0110c00a2d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-52c6b676-f179-4c63-9fe6-5b88dc7dae58,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-d8fc1b0c-a79e-430d-ae4a-d6e3d2d5a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-45038266-ae3f-4a4f-9ebe-9ba46729433a,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-b17c4769-76d7-46f5-bc71-2b2bc35fcf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-478533e7-a8dd-4869-b3c8-05f0e33f95da,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-1f2cc635-0f81-4504-b251-9b5d11b76dab,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-80d48f86-2aa8-4559-896c-2f341748c1c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016806412-172.17.0.18-1597084266910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40485,DS-a2813f27-9a29-4cef-938b-27069f3aa83a,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-0a896b6c-fb28-4393-b503-075cb38e90f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-b723920c-3809-42b5-bc28-eba7cdbf7a38,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-50625d11-291e-4712-bd7e-a22e41fdd007,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-90cc3d59-0a75-4830-87b8-21be737764fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-c4565203-d77f-465a-8d98-b015a096e186,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-f4ec7e05-2c40-47a9-9e65-2b32574f344e,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-61d322ec-3b5a-4658-a176-ea1723e3c405,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016806412-172.17.0.18-1597084266910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40485,DS-a2813f27-9a29-4cef-938b-27069f3aa83a,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-0a896b6c-fb28-4393-b503-075cb38e90f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-b723920c-3809-42b5-bc28-eba7cdbf7a38,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-50625d11-291e-4712-bd7e-a22e41fdd007,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-90cc3d59-0a75-4830-87b8-21be737764fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-c4565203-d77f-465a-8d98-b015a096e186,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-f4ec7e05-2c40-47a9-9e65-2b32574f344e,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-61d322ec-3b5a-4658-a176-ea1723e3c405,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647412831-172.17.0.18-1597084306422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-4c11069a-2de1-4e29-8c30-74cabd45a3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-8c908129-2e71-40be-a89d-b2db6e4bdc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-46992612-631d-48e6-891b-5bf53890a03e,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-eee98cb9-d316-4ec7-857b-d3b414cad46a,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-56eaa416-ff33-4200-82bf-d6e76cd76068,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-de763f69-03ba-4981-b1d3-942dadf3480b,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-59da9c30-794c-4b5c-94fb-a539aac3e8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-28b45944-db80-4b1b-b733-0abe954488da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647412831-172.17.0.18-1597084306422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-4c11069a-2de1-4e29-8c30-74cabd45a3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-8c908129-2e71-40be-a89d-b2db6e4bdc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-46992612-631d-48e6-891b-5bf53890a03e,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-eee98cb9-d316-4ec7-857b-d3b414cad46a,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-56eaa416-ff33-4200-82bf-d6e76cd76068,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-de763f69-03ba-4981-b1d3-942dadf3480b,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-59da9c30-794c-4b5c-94fb-a539aac3e8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-28b45944-db80-4b1b-b733-0abe954488da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64479935-172.17.0.18-1597084337059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-f93e7e37-6bbb-41ae-8195-94517e3a4956,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-2e5d42a8-e0b6-4f6d-bd2b-e98faa9e25b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-539440b9-62cb-48df-a20c-bb371ccc3d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-d088af87-0a5a-423b-84c9-00f388fc43e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-685f059d-ce72-4396-9737-4a8c068e0c80,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-b1ad883a-aafc-4beb-bcfe-dd29e39209e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-28bd1aae-2073-47d3-9a63-c677db3b9d73,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-8f7faef6-9f34-49cb-b8d2-e22330ff3e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64479935-172.17.0.18-1597084337059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-f93e7e37-6bbb-41ae-8195-94517e3a4956,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-2e5d42a8-e0b6-4f6d-bd2b-e98faa9e25b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-539440b9-62cb-48df-a20c-bb371ccc3d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-d088af87-0a5a-423b-84c9-00f388fc43e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-685f059d-ce72-4396-9737-4a8c068e0c80,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-b1ad883a-aafc-4beb-bcfe-dd29e39209e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-28bd1aae-2073-47d3-9a63-c677db3b9d73,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-8f7faef6-9f34-49cb-b8d2-e22330ff3e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270250848-172.17.0.18-1597084372175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-6055c756-5d81-4e10-b924-13fd34b58e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-716dc914-ad3c-4c12-99c0-f3446c982342,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-5833e5b5-5877-45fd-a9ce-34a8e527c4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-0f04f9c1-286c-4e08-8ff1-5e2d02a939f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-274e6414-5a28-4049-88c2-85aeab0e06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-d76d1eb7-d09c-4064-8d07-980560633b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-38a18ee8-b2a7-4291-b2f1-158b8ca09788,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-74ec36bd-0d73-4518-a5b6-33a22e35cd39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270250848-172.17.0.18-1597084372175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-6055c756-5d81-4e10-b924-13fd34b58e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-716dc914-ad3c-4c12-99c0-f3446c982342,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-5833e5b5-5877-45fd-a9ce-34a8e527c4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-0f04f9c1-286c-4e08-8ff1-5e2d02a939f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-274e6414-5a28-4049-88c2-85aeab0e06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-d76d1eb7-d09c-4064-8d07-980560633b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-38a18ee8-b2a7-4291-b2f1-158b8ca09788,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-74ec36bd-0d73-4518-a5b6-33a22e35cd39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112021583-172.17.0.18-1597084441745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45389,DS-4b3b1fbc-0e28-446e-a76e-c95c69d0fce6,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-901002b9-67fe-4523-9931-4c5df65094b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-fd16e22c-f0e7-48d3-a76f-5dd44e05a693,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-80dd7586-4d28-402a-ac14-a1bc3db3c21a,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-c9dc4b93-01dd-4713-a876-528bd4e68f52,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-5b70fc11-587a-43fe-9454-c0521fcecd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-aae08a40-a828-49e3-9190-1f5453573c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-8ddacfe9-affa-4333-a7d5-81f600bac439,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112021583-172.17.0.18-1597084441745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45389,DS-4b3b1fbc-0e28-446e-a76e-c95c69d0fce6,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-901002b9-67fe-4523-9931-4c5df65094b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-fd16e22c-f0e7-48d3-a76f-5dd44e05a693,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-80dd7586-4d28-402a-ac14-a1bc3db3c21a,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-c9dc4b93-01dd-4713-a876-528bd4e68f52,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-5b70fc11-587a-43fe-9454-c0521fcecd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-aae08a40-a828-49e3-9190-1f5453573c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-8ddacfe9-affa-4333-a7d5-81f600bac439,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047731811-172.17.0.18-1597084475736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39547,DS-a2f67ca4-90f1-4cd6-8c28-cd6612d86210,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-5699c7a5-05ed-4a63-8bff-b12a2fd0d6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-85fe230d-f214-4d65-a756-eaa2c85f7080,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-29415174-b3ba-47c3-ac8e-abcbbf870b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-014d1add-4ce9-44a8-8737-6db9840c7811,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-30383334-50a9-4478-958d-db355df8eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-10e15c2e-cae8-4706-b2f9-b61e64509e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-d5da06fc-80ca-403a-8f17-f165683c7a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047731811-172.17.0.18-1597084475736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39547,DS-a2f67ca4-90f1-4cd6-8c28-cd6612d86210,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-5699c7a5-05ed-4a63-8bff-b12a2fd0d6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-85fe230d-f214-4d65-a756-eaa2c85f7080,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-29415174-b3ba-47c3-ac8e-abcbbf870b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-014d1add-4ce9-44a8-8737-6db9840c7811,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-30383334-50a9-4478-958d-db355df8eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-10e15c2e-cae8-4706-b2f9-b61e64509e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-d5da06fc-80ca-403a-8f17-f165683c7a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671862758-172.17.0.18-1597084555972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36479,DS-b92c569c-eff5-428d-b65e-801a19d48385,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-78ca1f90-11e0-4b82-882e-d8327c4c011d,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-5cbbb008-a9de-4d95-914c-a0349c77fab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-b937d551-47ae-476a-a0ae-645621d71fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-f5df267d-a315-4347-8630-ead6491dd9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-0bf40150-5aab-41e9-8822-df1113099317,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-b2c3242e-7123-4aa8-8f16-23574d53b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-6990543b-9064-49bb-b3b5-d6da1a5a21c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671862758-172.17.0.18-1597084555972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36479,DS-b92c569c-eff5-428d-b65e-801a19d48385,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-78ca1f90-11e0-4b82-882e-d8327c4c011d,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-5cbbb008-a9de-4d95-914c-a0349c77fab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-b937d551-47ae-476a-a0ae-645621d71fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-f5df267d-a315-4347-8630-ead6491dd9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-0bf40150-5aab-41e9-8822-df1113099317,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-b2c3242e-7123-4aa8-8f16-23574d53b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-6990543b-9064-49bb-b3b5-d6da1a5a21c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5467
