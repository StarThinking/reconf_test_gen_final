reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32762200-172.17.0.18-1597072116643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-d3e0007e-c8d2-426f-8116-8e039b4784ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-5ac4933d-e61b-475d-8698-daf9b97824a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-1f60572a-6331-443b-a4dc-523194ff54ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-145a1eda-f829-414f-a6cc-15da5cec7846,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-23eaba50-ecc7-4bb8-ae38-36c7558caab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-23970b50-28da-4eb0-ae65-2bc9b96d6ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-8509177b-e461-401b-bb02-519e2c9fa63e,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-b1ccda75-6c0d-40f9-9188-13d0ca63f4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32762200-172.17.0.18-1597072116643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-d3e0007e-c8d2-426f-8116-8e039b4784ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-5ac4933d-e61b-475d-8698-daf9b97824a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-1f60572a-6331-443b-a4dc-523194ff54ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-145a1eda-f829-414f-a6cc-15da5cec7846,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-23eaba50-ecc7-4bb8-ae38-36c7558caab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-23970b50-28da-4eb0-ae65-2bc9b96d6ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-8509177b-e461-401b-bb02-519e2c9fa63e,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-b1ccda75-6c0d-40f9-9188-13d0ca63f4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388784132-172.17.0.18-1597072743825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46237,DS-23d9af2a-7380-4394-ac5a-611fd30b622c,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-6dcedee8-63e2-441c-8198-fac4e062caaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-37d652b0-99d6-4e87-8092-f58fcee3bf82,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-e4e91270-214b-40de-8fe7-551fce750ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-440c6750-b617-4606-a4e6-b7a80003636e,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-65cdc538-1d3a-4541-98ac-c083d5e14b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-a3c9797d-edce-42f9-a784-1abc0b95ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-d4a85849-83de-480c-b4df-a1e104a85e7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388784132-172.17.0.18-1597072743825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46237,DS-23d9af2a-7380-4394-ac5a-611fd30b622c,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-6dcedee8-63e2-441c-8198-fac4e062caaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-37d652b0-99d6-4e87-8092-f58fcee3bf82,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-e4e91270-214b-40de-8fe7-551fce750ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-440c6750-b617-4606-a4e6-b7a80003636e,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-65cdc538-1d3a-4541-98ac-c083d5e14b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-a3c9797d-edce-42f9-a784-1abc0b95ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-d4a85849-83de-480c-b4df-a1e104a85e7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805163157-172.17.0.18-1597073925761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37619,DS-9f56d495-1f7d-4af8-8ac1-362a78779a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-f60533a1-ef28-409f-83f6-814e466e7560,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-2e2f2c77-6730-4e17-a9da-e5ba14b94842,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-f6e0dd8a-701c-474e-8eb8-bb4247c2f554,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-b9f4894d-5cb8-42af-bb7c-8e666b02ebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-015fe7d0-d96e-4816-a74f-d4788fbdec60,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-806f1432-f7b5-4767-8d0b-da4cb6c76a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-567d70e4-344a-41a8-9413-68590dcf0494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805163157-172.17.0.18-1597073925761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37619,DS-9f56d495-1f7d-4af8-8ac1-362a78779a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-f60533a1-ef28-409f-83f6-814e466e7560,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-2e2f2c77-6730-4e17-a9da-e5ba14b94842,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-f6e0dd8a-701c-474e-8eb8-bb4247c2f554,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-b9f4894d-5cb8-42af-bb7c-8e666b02ebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-015fe7d0-d96e-4816-a74f-d4788fbdec60,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-806f1432-f7b5-4767-8d0b-da4cb6c76a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-567d70e4-344a-41a8-9413-68590dcf0494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191612200-172.17.0.18-1597073960957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44407,DS-747f8664-dddd-499e-bb79-69f4c98e3527,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-d5c3638e-f71e-4597-9fda-3daa1bc2c808,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-d21f3310-8331-40c0-9c05-a69e0a706142,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-5821bb29-8dd0-4c2b-9540-35b10437cc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-46b82ecd-4c37-4a97-916d-e2f8d907a3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-8f37ad44-ff28-4434-aaf5-94c9cf04ee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-4206fc8d-894a-4b41-9e1c-24ffaef43480,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-f14b0d33-eb39-41af-8869-ade92ac6f6ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191612200-172.17.0.18-1597073960957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44407,DS-747f8664-dddd-499e-bb79-69f4c98e3527,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-d5c3638e-f71e-4597-9fda-3daa1bc2c808,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-d21f3310-8331-40c0-9c05-a69e0a706142,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-5821bb29-8dd0-4c2b-9540-35b10437cc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-46b82ecd-4c37-4a97-916d-e2f8d907a3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-8f37ad44-ff28-4434-aaf5-94c9cf04ee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-4206fc8d-894a-4b41-9e1c-24ffaef43480,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-f14b0d33-eb39-41af-8869-ade92ac6f6ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457986178-172.17.0.18-1597074101799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40819,DS-d9e977cc-4cd8-4236-810f-9763b12dfffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-ec259353-4b94-47b4-84a7-a4835f32712d,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-f7d13653-1e33-4f8f-9dc1-b0445f39ee6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-79ad9178-a71d-4d03-9948-47ac434d5709,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-84d7bf07-521f-4d7a-a52f-f19acfac061d,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-c27de27d-e8f2-43b7-a99f-4c0a61caa20d,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-43481f55-58c0-41ab-939e-059e333c7289,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-1a533864-194e-457b-9029-5521b1e73b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457986178-172.17.0.18-1597074101799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40819,DS-d9e977cc-4cd8-4236-810f-9763b12dfffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-ec259353-4b94-47b4-84a7-a4835f32712d,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-f7d13653-1e33-4f8f-9dc1-b0445f39ee6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-79ad9178-a71d-4d03-9948-47ac434d5709,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-84d7bf07-521f-4d7a-a52f-f19acfac061d,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-c27de27d-e8f2-43b7-a99f-4c0a61caa20d,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-43481f55-58c0-41ab-939e-059e333c7289,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-1a533864-194e-457b-9029-5521b1e73b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174556721-172.17.0.18-1597074577863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-7828a46e-4136-4985-8ef1-ab6a3ff609da,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-82dda302-7bb0-45b0-905c-f07fc4d2c5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-d6ffbfe1-6df3-47bc-974d-c05fd9bf8502,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-62e11f03-aa96-40c9-ab85-932a35355fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-b745d000-1200-4b14-ab11-965a61af46c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-a8131693-64de-44ba-954a-2b19d52bb715,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-185dd141-198b-4342-a43f-bc1563a9e5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-488dd08c-d449-40ec-bb19-4b819f652ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174556721-172.17.0.18-1597074577863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-7828a46e-4136-4985-8ef1-ab6a3ff609da,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-82dda302-7bb0-45b0-905c-f07fc4d2c5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-d6ffbfe1-6df3-47bc-974d-c05fd9bf8502,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-62e11f03-aa96-40c9-ab85-932a35355fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-b745d000-1200-4b14-ab11-965a61af46c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-a8131693-64de-44ba-954a-2b19d52bb715,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-185dd141-198b-4342-a43f-bc1563a9e5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-488dd08c-d449-40ec-bb19-4b819f652ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807387605-172.17.0.18-1597074652537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43690,DS-43c4976b-953f-450d-aa47-162109ccfc67,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-cb8e6008-003a-48dc-b593-5d483deefac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-d1ccd26b-7bbb-4ccc-97d6-0062ffc435a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-9a6efba0-ca2b-43af-a426-5908e012a217,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-0954b796-cbbd-492d-95b9-2cb784c985c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-cba21fce-5aff-4068-8177-a00d5b59c790,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-b17fa8a0-5aa8-465a-a789-d40ade840144,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-621ff6ce-b051-4107-8a5b-fa67e893617b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807387605-172.17.0.18-1597074652537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43690,DS-43c4976b-953f-450d-aa47-162109ccfc67,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-cb8e6008-003a-48dc-b593-5d483deefac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-d1ccd26b-7bbb-4ccc-97d6-0062ffc435a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-9a6efba0-ca2b-43af-a426-5908e012a217,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-0954b796-cbbd-492d-95b9-2cb784c985c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-cba21fce-5aff-4068-8177-a00d5b59c790,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-b17fa8a0-5aa8-465a-a789-d40ade840144,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-621ff6ce-b051-4107-8a5b-fa67e893617b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689857698-172.17.0.18-1597076922911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35611,DS-f067dbe5-ad40-496b-a794-4040b9d71b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-ec69c48b-3998-4ba6-9fe0-ca8f5e455328,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-662e1df7-fb86-40d1-8743-2127d898d440,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-6743597a-ba17-463b-b8d1-171e85cbf07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-b0447955-12af-4eb1-97ee-0c505b7db2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-93e8ef04-a11d-4ba7-9a92-a07f20bee3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-48bb5012-0059-4504-8e49-573139a08f81,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-c962de5f-bdca-4031-8069-91a1b425d962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689857698-172.17.0.18-1597076922911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35611,DS-f067dbe5-ad40-496b-a794-4040b9d71b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-ec69c48b-3998-4ba6-9fe0-ca8f5e455328,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-662e1df7-fb86-40d1-8743-2127d898d440,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-6743597a-ba17-463b-b8d1-171e85cbf07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-b0447955-12af-4eb1-97ee-0c505b7db2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-93e8ef04-a11d-4ba7-9a92-a07f20bee3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-48bb5012-0059-4504-8e49-573139a08f81,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-c962de5f-bdca-4031-8069-91a1b425d962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494060645-172.17.0.18-1597077008495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-6643913b-36f7-446d-b8dc-ffcee0966631,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-cced5f2d-62dd-48d9-a883-d586886e2676,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-9a442441-b377-4203-ae0d-d0759ec67ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-507454bd-7cec-4059-9eab-27147f4f6ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-751cd19d-79c6-459e-b28e-e8627f7d9d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-16528953-d2d1-49e3-883e-eff1ca71507a,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-ff1430a1-844c-4d25-99a7-4049eea7da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-7cdd2c9d-4397-4d68-b746-22bb216f95f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494060645-172.17.0.18-1597077008495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-6643913b-36f7-446d-b8dc-ffcee0966631,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-cced5f2d-62dd-48d9-a883-d586886e2676,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-9a442441-b377-4203-ae0d-d0759ec67ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-507454bd-7cec-4059-9eab-27147f4f6ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-751cd19d-79c6-459e-b28e-e8627f7d9d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-16528953-d2d1-49e3-883e-eff1ca71507a,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-ff1430a1-844c-4d25-99a7-4049eea7da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-7cdd2c9d-4397-4d68-b746-22bb216f95f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5226
