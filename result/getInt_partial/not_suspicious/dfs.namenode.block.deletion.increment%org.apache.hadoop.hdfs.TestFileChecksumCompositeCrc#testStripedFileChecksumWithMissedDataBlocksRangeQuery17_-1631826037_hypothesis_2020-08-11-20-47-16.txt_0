reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747905003-172.17.0.11-1597179099474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41821,DS-33df4102-494e-47f4-ae39-b03c9c328440,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-9e032ebb-9b38-46fe-a3d8-b522d8c17432,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-4eee598e-4484-4cc4-a05c-ee26a2a9509c,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-f3f1d3e2-8bc4-4cff-8a48-d1ceefee4aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-ded35d0f-407a-458e-9d95-eefb83704df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-67fe5fe6-a561-4140-bfef-8cd547fc6048,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-e94fb1da-5f5a-471f-ab35-1f86026d167c,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-136586b3-f8e1-4035-8e11-3f6aab306f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747905003-172.17.0.11-1597179099474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41821,DS-33df4102-494e-47f4-ae39-b03c9c328440,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-9e032ebb-9b38-46fe-a3d8-b522d8c17432,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-4eee598e-4484-4cc4-a05c-ee26a2a9509c,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-f3f1d3e2-8bc4-4cff-8a48-d1ceefee4aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-ded35d0f-407a-458e-9d95-eefb83704df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-67fe5fe6-a561-4140-bfef-8cd547fc6048,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-e94fb1da-5f5a-471f-ab35-1f86026d167c,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-136586b3-f8e1-4035-8e11-3f6aab306f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123904177-172.17.0.11-1597179204042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44960,DS-cfe9b6f0-293a-4639-acd9-91f9f4fd3a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-63138df1-491d-4fee-a917-6f41551fa683,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-177d97be-ecfb-4357-914e-3190777f8676,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-6af9f682-9cf0-4eed-ad7e-f38fa7aa80de,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-8563f5a6-b464-4d74-853a-87c5712069c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-12f135db-6a33-409a-a582-fb94e767d953,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-a58d37cf-425f-4b37-8183-120e0da779a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-be1bc637-9fd4-4749-8dfa-063a2da64fe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123904177-172.17.0.11-1597179204042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44960,DS-cfe9b6f0-293a-4639-acd9-91f9f4fd3a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-63138df1-491d-4fee-a917-6f41551fa683,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-177d97be-ecfb-4357-914e-3190777f8676,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-6af9f682-9cf0-4eed-ad7e-f38fa7aa80de,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-8563f5a6-b464-4d74-853a-87c5712069c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-12f135db-6a33-409a-a582-fb94e767d953,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-a58d37cf-425f-4b37-8183-120e0da779a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-be1bc637-9fd4-4749-8dfa-063a2da64fe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102318614-172.17.0.11-1597179309758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-a2f66685-e065-4913-a064-47f0a3793ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-b37acb0c-1fca-45af-90bb-e5660950e0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-6e741b48-9a8c-42a8-a6d8-04cfcaf88e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-c5121ef5-3fe5-4d02-92ad-5bdb1082587c,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-5155f51c-5329-47bc-9fda-51aaefb79c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-379ed161-d285-4521-99d2-6799f6d31610,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-31cf8983-a41e-4aa5-9762-7641a3d7ac8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-4aa6cf6e-af81-48df-a927-d008b43afce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102318614-172.17.0.11-1597179309758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-a2f66685-e065-4913-a064-47f0a3793ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-b37acb0c-1fca-45af-90bb-e5660950e0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-6e741b48-9a8c-42a8-a6d8-04cfcaf88e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-c5121ef5-3fe5-4d02-92ad-5bdb1082587c,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-5155f51c-5329-47bc-9fda-51aaefb79c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-379ed161-d285-4521-99d2-6799f6d31610,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-31cf8983-a41e-4aa5-9762-7641a3d7ac8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-4aa6cf6e-af81-48df-a927-d008b43afce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202004604-172.17.0.11-1597179491639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42000,DS-2b6804ae-9cc6-4e76-a813-e6d97c7e737e,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-6cac1e89-6178-4044-bdda-c6a95ed37e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-403412cd-0f6a-4735-862c-3503fc17ce0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-2f9f8658-d762-422e-85a2-8241ad0997ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-ea56daab-93fd-4548-a054-d19b2a7631a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-e55ac0be-feec-4e3a-ba98-6a57d6e4e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-94901d7f-6497-468b-9d6e-43fa98dd044d,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-6099f96a-ca0a-4b92-9278-f823f2a9663e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202004604-172.17.0.11-1597179491639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42000,DS-2b6804ae-9cc6-4e76-a813-e6d97c7e737e,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-6cac1e89-6178-4044-bdda-c6a95ed37e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-403412cd-0f6a-4735-862c-3503fc17ce0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-2f9f8658-d762-422e-85a2-8241ad0997ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-ea56daab-93fd-4548-a054-d19b2a7631a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-e55ac0be-feec-4e3a-ba98-6a57d6e4e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-94901d7f-6497-468b-9d6e-43fa98dd044d,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-6099f96a-ca0a-4b92-9278-f823f2a9663e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288076536-172.17.0.11-1597179644198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-1c922bc7-39ec-4e20-953c-cc20752fdaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-cc617efb-06d1-42c0-bdab-e8a4f21e72fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-c4cb8b4b-814c-4740-87b3-50e3e7c9c0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-d2a40250-6234-4f1a-8004-c9523d2f9408,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-935f7825-7188-4094-a11e-db5a05af51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-5f3daa68-646e-4e04-bf5b-ce0109fb712c,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-41542bed-5009-4c79-ad24-44858f0342c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-69bf2788-ed81-4899-986f-86e6abfb8419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288076536-172.17.0.11-1597179644198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-1c922bc7-39ec-4e20-953c-cc20752fdaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-cc617efb-06d1-42c0-bdab-e8a4f21e72fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-c4cb8b4b-814c-4740-87b3-50e3e7c9c0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-d2a40250-6234-4f1a-8004-c9523d2f9408,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-935f7825-7188-4094-a11e-db5a05af51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-5f3daa68-646e-4e04-bf5b-ce0109fb712c,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-41542bed-5009-4c79-ad24-44858f0342c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-69bf2788-ed81-4899-986f-86e6abfb8419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073284257-172.17.0.11-1597179904640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34926,DS-7bddb836-4aa7-41ae-8209-a5011fa0073b,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-4f48df96-2aa2-437b-a4aa-40a725d49295,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-d81e5eff-e15a-407b-a58f-22258b3d2f69,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-18483d71-2670-4f90-aaa8-c4e277e68de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-93df6813-3aea-452d-a980-6b335f00b3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-03b1971d-fa17-4808-9b3d-ebd5cd2b4905,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-cbe46fc3-3dc7-427a-9803-b2758aaebb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-e83fd5bb-9246-4083-b3cd-435f371685b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073284257-172.17.0.11-1597179904640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34926,DS-7bddb836-4aa7-41ae-8209-a5011fa0073b,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-4f48df96-2aa2-437b-a4aa-40a725d49295,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-d81e5eff-e15a-407b-a58f-22258b3d2f69,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-18483d71-2670-4f90-aaa8-c4e277e68de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-93df6813-3aea-452d-a980-6b335f00b3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-03b1971d-fa17-4808-9b3d-ebd5cd2b4905,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-cbe46fc3-3dc7-427a-9803-b2758aaebb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-e83fd5bb-9246-4083-b3cd-435f371685b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648945890-172.17.0.11-1597180141059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40058,DS-5d8daee6-cb19-4352-a516-70c3aabdab88,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-882cbd8a-202c-414a-9748-574ace0f2c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-b5b1006b-dbd9-4031-8ad3-5ec9b90d6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-25179a0c-bfa4-4d45-88bd-10bdc919d409,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-c84e4ba7-2ab5-43ff-a8aa-9455a88a577b,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-af55ea73-62a5-42d4-abeb-cbf1c2890f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-86e99c5e-96fb-498a-82ad-aa0fa11a28af,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-bd682074-f20e-4243-8437-fa853c3937b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648945890-172.17.0.11-1597180141059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40058,DS-5d8daee6-cb19-4352-a516-70c3aabdab88,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-882cbd8a-202c-414a-9748-574ace0f2c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-b5b1006b-dbd9-4031-8ad3-5ec9b90d6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-25179a0c-bfa4-4d45-88bd-10bdc919d409,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-c84e4ba7-2ab5-43ff-a8aa-9455a88a577b,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-af55ea73-62a5-42d4-abeb-cbf1c2890f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-86e99c5e-96fb-498a-82ad-aa0fa11a28af,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-bd682074-f20e-4243-8437-fa853c3937b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1075806246-172.17.0.11-1597180210893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-0f93e667-0c8d-4d47-b5c0-41f088e75225,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-df51ff3a-2e52-4d56-b279-26b2dc8e1a16,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-ca8a151c-2b78-48da-8220-7c2466a34d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-ac45c83b-7427-4a43-aa55-d1fe696ae863,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-d6482be5-83c8-44da-a041-5c2671a493e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-d6432f9f-7f1f-448e-bda4-6d214606ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-178430d3-7795-4bf9-9693-31aa5d7740ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-b1965c3b-0dd5-4511-a3af-1118ea007002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1075806246-172.17.0.11-1597180210893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-0f93e667-0c8d-4d47-b5c0-41f088e75225,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-df51ff3a-2e52-4d56-b279-26b2dc8e1a16,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-ca8a151c-2b78-48da-8220-7c2466a34d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-ac45c83b-7427-4a43-aa55-d1fe696ae863,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-d6482be5-83c8-44da-a041-5c2671a493e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-d6432f9f-7f1f-448e-bda4-6d214606ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-178430d3-7795-4bf9-9693-31aa5d7740ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-b1965c3b-0dd5-4511-a3af-1118ea007002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444987233-172.17.0.11-1597180822668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-a6e1dc52-c215-47ad-b63d-881e560c04da,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-abc4c7f1-8042-4b70-9a18-3337bdb6aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-536418e2-c4e8-46c0-8d15-7f4cabb6c6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-46fd8ffa-092d-4f8e-b41a-8e8969c5e7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-f7d506d7-e77b-4024-ae8e-1a57139e3394,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-acde80fb-071b-4ec9-a1d3-5e99fe933714,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-3c533fa5-d9d5-4939-b10d-dafe59eff18f,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-b388f84b-ca0a-4faf-af01-2e8b9d2e35ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444987233-172.17.0.11-1597180822668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-a6e1dc52-c215-47ad-b63d-881e560c04da,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-abc4c7f1-8042-4b70-9a18-3337bdb6aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-536418e2-c4e8-46c0-8d15-7f4cabb6c6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-46fd8ffa-092d-4f8e-b41a-8e8969c5e7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-f7d506d7-e77b-4024-ae8e-1a57139e3394,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-acde80fb-071b-4ec9-a1d3-5e99fe933714,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-3c533fa5-d9d5-4939-b10d-dafe59eff18f,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-b388f84b-ca0a-4faf-af01-2e8b9d2e35ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052471906-172.17.0.11-1597180998059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-521fd32d-8db4-486a-8477-2143df78afec,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-033fb3ca-ebb1-4d47-9998-b19f2e11d232,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-a323d396-b4a8-4e0e-a480-14fc1841b614,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-e302e02f-f088-44e6-bd1c-46fa52d96280,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-5000612f-ed2d-4971-ba3b-522039f63584,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-555b81d2-9c30-4cd9-98f1-070e1b1a8cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-849e8b02-03ed-4dd7-9d4a-20e5ea2b1ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-bc9fffa7-ed65-4077-9e45-e9ef5e6fbd68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052471906-172.17.0.11-1597180998059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-521fd32d-8db4-486a-8477-2143df78afec,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-033fb3ca-ebb1-4d47-9998-b19f2e11d232,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-a323d396-b4a8-4e0e-a480-14fc1841b614,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-e302e02f-f088-44e6-bd1c-46fa52d96280,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-5000612f-ed2d-4971-ba3b-522039f63584,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-555b81d2-9c30-4cd9-98f1-070e1b1a8cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-849e8b02-03ed-4dd7-9d4a-20e5ea2b1ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-bc9fffa7-ed65-4077-9e45-e9ef5e6fbd68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588192684-172.17.0.11-1597181029211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42113,DS-8a8b3fd3-9524-4d57-96ec-07b85e20cd42,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-4b309ac3-4545-4ece-8e49-4ad2387d762f,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-69af737a-f70d-4660-bbfd-f825a7b77237,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-a72cef44-b69d-485b-ad81-b819102b54cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-b980ef6e-6c91-4630-bc00-e94056908697,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-b816fcf6-86e0-49bf-ae3f-2f948f704fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-f39fdb17-8354-4ca8-9551-66d3204ac036,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-46a9d7ac-86d3-4259-b558-9113619cc7ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588192684-172.17.0.11-1597181029211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42113,DS-8a8b3fd3-9524-4d57-96ec-07b85e20cd42,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-4b309ac3-4545-4ece-8e49-4ad2387d762f,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-69af737a-f70d-4660-bbfd-f825a7b77237,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-a72cef44-b69d-485b-ad81-b819102b54cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-b980ef6e-6c91-4630-bc00-e94056908697,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-b816fcf6-86e0-49bf-ae3f-2f948f704fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-f39fdb17-8354-4ca8-9551-66d3204ac036,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-46a9d7ac-86d3-4259-b558-9113619cc7ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709953595-172.17.0.11-1597181057084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36779,DS-3c8f3739-3feb-42ab-9e6e-8aaedfe890ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-258eac64-ae8e-47e4-bba2-9ce90d94642c,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-779d1650-6fd6-406e-909a-a4ab4de3c853,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-694f4115-f199-40e4-b954-2c733f83314d,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-f76526f4-11d6-4f6d-9097-e2c55d88c44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-f9347f52-e162-4317-a3fb-dca356a87fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-abf232fe-11b5-4f91-bdca-05b4478ad40c,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-706d0bf4-4985-4a63-9f81-0abbbf02cd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709953595-172.17.0.11-1597181057084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36779,DS-3c8f3739-3feb-42ab-9e6e-8aaedfe890ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-258eac64-ae8e-47e4-bba2-9ce90d94642c,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-779d1650-6fd6-406e-909a-a4ab4de3c853,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-694f4115-f199-40e4-b954-2c733f83314d,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-f76526f4-11d6-4f6d-9097-e2c55d88c44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-f9347f52-e162-4317-a3fb-dca356a87fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-abf232fe-11b5-4f91-bdca-05b4478ad40c,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-706d0bf4-4985-4a63-9f81-0abbbf02cd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671456537-172.17.0.11-1597181319505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-3096eb8c-9cd3-4516-bcd0-7037d7a6272c,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-61535e26-4634-402b-b58a-86fd3a34f792,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-6a468d3d-9aa3-4ec7-bd4d-b5c66d4763c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-4ea90fcf-8d55-47c2-8854-a04ef1ce3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-8147e553-f3c0-49fb-b527-554f11e08aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-11d03273-456c-4c96-8aec-68245e4add68,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-9331c215-5667-4c8e-802d-74a1e89da7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-3ea3ce08-5088-4fe7-9c86-1cfeb0f9b478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671456537-172.17.0.11-1597181319505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-3096eb8c-9cd3-4516-bcd0-7037d7a6272c,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-61535e26-4634-402b-b58a-86fd3a34f792,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-6a468d3d-9aa3-4ec7-bd4d-b5c66d4763c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-4ea90fcf-8d55-47c2-8854-a04ef1ce3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-8147e553-f3c0-49fb-b527-554f11e08aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-11d03273-456c-4c96-8aec-68245e4add68,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-9331c215-5667-4c8e-802d-74a1e89da7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-3ea3ce08-5088-4fe7-9c86-1cfeb0f9b478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642562900-172.17.0.11-1597181355143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-59485f18-b130-4335-99f1-3e10434570a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-0b2affb9-bff1-40f4-8e13-4a1c9c93f256,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-88ac16ac-3829-4e6c-881f-268bf852d30c,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-3dcda363-adff-4e2e-bda4-f9e6c7866146,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-2c80e115-e9ec-489c-a9b7-e947ae7113d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-4df22f47-ff5f-4370-a8ff-41dab4bfb883,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-dcd24be7-88a4-4ef9-8d70-c91492a10352,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-4e6853d4-1859-4ace-ad18-74e64b7f1bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642562900-172.17.0.11-1597181355143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-59485f18-b130-4335-99f1-3e10434570a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-0b2affb9-bff1-40f4-8e13-4a1c9c93f256,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-88ac16ac-3829-4e6c-881f-268bf852d30c,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-3dcda363-adff-4e2e-bda4-f9e6c7866146,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-2c80e115-e9ec-489c-a9b7-e947ae7113d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-4df22f47-ff5f-4370-a8ff-41dab4bfb883,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-dcd24be7-88a4-4ef9-8d70-c91492a10352,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-4e6853d4-1859-4ace-ad18-74e64b7f1bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850857349-172.17.0.11-1597181386422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-ff242c3a-fbd6-41ec-a1ca-4639726e9ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-3ec348f9-bd88-41ae-bc86-a25474fd3949,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-c6cbf802-7af7-446a-96b8-197cfa48d53f,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-9179c9dc-e174-4f84-a3fb-89840c0ea159,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-33170cd8-67d1-4363-abb0-7a0ab341a901,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-8192c3d7-6c5e-4a81-a7f8-aad8fac846f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-61c9a9d4-5fba-4ba7-b384-39deab50d4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-b6b82ae4-bf6d-49a6-93c6-db1535725b17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850857349-172.17.0.11-1597181386422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-ff242c3a-fbd6-41ec-a1ca-4639726e9ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-3ec348f9-bd88-41ae-bc86-a25474fd3949,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-c6cbf802-7af7-446a-96b8-197cfa48d53f,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-9179c9dc-e174-4f84-a3fb-89840c0ea159,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-33170cd8-67d1-4363-abb0-7a0ab341a901,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-8192c3d7-6c5e-4a81-a7f8-aad8fac846f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-61c9a9d4-5fba-4ba7-b384-39deab50d4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-b6b82ae4-bf6d-49a6-93c6-db1535725b17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829338169-172.17.0.11-1597181667714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41211,DS-f69ab9f2-8b13-42d8-becd-3311d55cbc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-509f5dd7-a129-47ef-985e-0524abe1d740,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-2fd4ead4-d91f-4ea7-8259-9a66658ff746,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-50cf1a51-3b26-4c34-9cd5-6aff7d336cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-3caecaaf-7aed-42a4-921d-ca31919f855d,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-29e31447-fadd-474d-aded-7e949fddce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-30a9b9ec-d048-4468-b5c0-bcf8c11775ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-93945754-5d49-476f-8c70-466345edf8a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829338169-172.17.0.11-1597181667714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41211,DS-f69ab9f2-8b13-42d8-becd-3311d55cbc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-509f5dd7-a129-47ef-985e-0524abe1d740,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-2fd4ead4-d91f-4ea7-8259-9a66658ff746,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-50cf1a51-3b26-4c34-9cd5-6aff7d336cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-3caecaaf-7aed-42a4-921d-ca31919f855d,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-29e31447-fadd-474d-aded-7e949fddce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-30a9b9ec-d048-4468-b5c0-bcf8c11775ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-93945754-5d49-476f-8c70-466345edf8a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719115054-172.17.0.11-1597182020751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45953,DS-f73c294c-a20a-4296-9599-27e6a3af371b,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-9e6f31f4-9c2f-47cb-b9cf-a56d6409ab67,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-04def5a5-5f3d-41e9-99b9-5ea974a5f202,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-7f40abe0-93ba-4787-85e2-331c4b360973,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d45677c9-7726-4ad0-bdb8-921272545af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-4f070ec3-9fbd-497a-a0e9-bdd8d1628971,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-a5a13129-6a7c-4154-8065-e8dcee346782,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-4642ad24-ff22-4691-99df-97aef8f80b14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719115054-172.17.0.11-1597182020751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45953,DS-f73c294c-a20a-4296-9599-27e6a3af371b,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-9e6f31f4-9c2f-47cb-b9cf-a56d6409ab67,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-04def5a5-5f3d-41e9-99b9-5ea974a5f202,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-7f40abe0-93ba-4787-85e2-331c4b360973,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d45677c9-7726-4ad0-bdb8-921272545af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-4f070ec3-9fbd-497a-a0e9-bdd8d1628971,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-a5a13129-6a7c-4154-8065-e8dcee346782,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-4642ad24-ff22-4691-99df-97aef8f80b14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326072285-172.17.0.11-1597182959342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-bfbea080-426d-4397-a49e-1bd145e55c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-e182bb3c-1651-46ac-a8b7-f27b9f349532,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-5bc33b59-d9d7-45bd-b241-04ee711d5290,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-ee573a13-b551-45db-9c21-3722f0a8051a,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-58e568b8-b9e4-43c7-a4a8-bdd1e191f3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-af00c2d7-fe76-4f33-9833-82a0adcc058b,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-1f468717-7db0-4088-8217-3fb8d8546f80,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-4d879da2-65a3-4f86-988d-707534a0b596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326072285-172.17.0.11-1597182959342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-bfbea080-426d-4397-a49e-1bd145e55c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-e182bb3c-1651-46ac-a8b7-f27b9f349532,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-5bc33b59-d9d7-45bd-b241-04ee711d5290,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-ee573a13-b551-45db-9c21-3722f0a8051a,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-58e568b8-b9e4-43c7-a4a8-bdd1e191f3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-af00c2d7-fe76-4f33-9833-82a0adcc058b,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-1f468717-7db0-4088-8217-3fb8d8546f80,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-4d879da2-65a3-4f86-988d-707534a0b596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-856134519-172.17.0.11-1597183031558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-8c5f7cad-aad2-422b-b990-5c0635e874a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-d67dab41-29f0-479a-b18c-afcf8accc26e,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-54fbca2e-8121-457f-8975-39fe793f92f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-5de99358-5f03-43cf-831e-1d772e1e4050,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-27ca0fee-3503-4f7f-a643-1948e0fe9f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-7f6ef6a1-7009-4245-8434-395fe73ad072,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-9e89f320-ec3f-44dd-9345-8f516ffbe771,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-7ba76390-8698-442b-98ab-2f63471e6093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-856134519-172.17.0.11-1597183031558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-8c5f7cad-aad2-422b-b990-5c0635e874a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-d67dab41-29f0-479a-b18c-afcf8accc26e,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-54fbca2e-8121-457f-8975-39fe793f92f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-5de99358-5f03-43cf-831e-1d772e1e4050,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-27ca0fee-3503-4f7f-a643-1948e0fe9f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-7f6ef6a1-7009-4245-8434-395fe73ad072,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-9e89f320-ec3f-44dd-9345-8f516ffbe771,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-7ba76390-8698-442b-98ab-2f63471e6093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311687014-172.17.0.11-1597183678576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45967,DS-3d59e3c3-948c-437c-9f85-518270fe705b,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-8e41fc49-08f7-46a2-91d4-23ce5e1ddbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-506a87c2-347a-4349-b0dd-250153d1a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-df214e44-d5c3-4aa6-9371-2bc93c3472e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-2129f152-690f-4eb7-91f4-2f8e8af79975,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-1f61d3b0-4079-43a1-8ea2-bafed76cef19,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-7f0b4a77-98b4-483d-901a-66b22c310036,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-6adfa6be-711e-49d7-9739-56cbfa86b23b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311687014-172.17.0.11-1597183678576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45967,DS-3d59e3c3-948c-437c-9f85-518270fe705b,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-8e41fc49-08f7-46a2-91d4-23ce5e1ddbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-506a87c2-347a-4349-b0dd-250153d1a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-df214e44-d5c3-4aa6-9371-2bc93c3472e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-2129f152-690f-4eb7-91f4-2f8e8af79975,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-1f61d3b0-4079-43a1-8ea2-bafed76cef19,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-7f0b4a77-98b4-483d-901a-66b22c310036,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-6adfa6be-711e-49d7-9739-56cbfa86b23b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603435413-172.17.0.11-1597183748614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-7f7c79a3-9e00-4abc-8b8b-851abe5150a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-a8db4524-8b80-47cf-8a8c-b1ca59370926,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-1cf7de41-4e00-4dfd-9eed-6de73e273e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-293cbe21-6218-4733-83ba-37b0b938d9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-45a19992-7150-4382-a515-1ac44983ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-14d9c056-f74f-4a93-8498-c1b926084981,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-ba9a9847-7980-43fd-b3e5-5be7b39f94b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-7790946e-0b8f-45ea-8f08-ee8a25ba422c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603435413-172.17.0.11-1597183748614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-7f7c79a3-9e00-4abc-8b8b-851abe5150a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-a8db4524-8b80-47cf-8a8c-b1ca59370926,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-1cf7de41-4e00-4dfd-9eed-6de73e273e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-293cbe21-6218-4733-83ba-37b0b938d9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-45a19992-7150-4382-a515-1ac44983ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-14d9c056-f74f-4a93-8498-c1b926084981,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-ba9a9847-7980-43fd-b3e5-5be7b39f94b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-7790946e-0b8f-45ea-8f08-ee8a25ba422c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5059
