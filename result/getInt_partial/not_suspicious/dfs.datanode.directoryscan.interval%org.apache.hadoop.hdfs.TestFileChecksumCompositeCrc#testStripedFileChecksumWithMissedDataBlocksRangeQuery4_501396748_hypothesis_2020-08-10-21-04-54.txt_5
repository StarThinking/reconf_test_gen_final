reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045665067-172.17.0.13-1597093504581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46098,DS-b201e62a-63c4-4302-b96b-4968c6b8615b,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-649cdd99-a142-4e9e-abeb-722978622d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-08e8ac9e-64d7-4ede-9954-ceed2a7cc5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-a25ce6b1-7e8e-4e68-99ba-62bae4d36f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-4decf0c3-fbfd-4ba5-8451-c857f9118fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-7067544b-5a21-4046-bf07-3deb07ab1e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-8b3d8be6-5706-46ae-8f9e-a440cb7b59dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-1dfe2079-a926-42ec-ad1f-edabf1ccdff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045665067-172.17.0.13-1597093504581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46098,DS-b201e62a-63c4-4302-b96b-4968c6b8615b,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-649cdd99-a142-4e9e-abeb-722978622d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-08e8ac9e-64d7-4ede-9954-ceed2a7cc5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-a25ce6b1-7e8e-4e68-99ba-62bae4d36f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-4decf0c3-fbfd-4ba5-8451-c857f9118fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-7067544b-5a21-4046-bf07-3deb07ab1e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-8b3d8be6-5706-46ae-8f9e-a440cb7b59dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-1dfe2079-a926-42ec-ad1f-edabf1ccdff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210728491-172.17.0.13-1597093580168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-9dfb0aed-6b4b-4c2b-9605-ff4545e7cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-62126cbb-b0c8-4509-8ad8-28e3cd65e650,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-9635f547-dd19-4712-bee8-4a0f5d32ca68,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-f01ca419-cb4a-486c-9817-24cb5ace0b62,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-edad6490-ac86-41ed-b217-35f5abe6c4de,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-e76e636e-3e95-4fd6-b119-31e2fc07c92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-9677dd08-7db3-4387-a134-d44b972f1199,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-58b0093a-dce7-4512-aa77-a1c8ff96ba49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210728491-172.17.0.13-1597093580168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-9dfb0aed-6b4b-4c2b-9605-ff4545e7cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-62126cbb-b0c8-4509-8ad8-28e3cd65e650,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-9635f547-dd19-4712-bee8-4a0f5d32ca68,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-f01ca419-cb4a-486c-9817-24cb5ace0b62,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-edad6490-ac86-41ed-b217-35f5abe6c4de,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-e76e636e-3e95-4fd6-b119-31e2fc07c92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-9677dd08-7db3-4387-a134-d44b972f1199,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-58b0093a-dce7-4512-aa77-a1c8ff96ba49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732315874-172.17.0.13-1597093907935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34674,DS-4c9f6e06-bc96-4a74-93ee-2af83a3df816,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-ceeaa9b9-383a-4a52-8c52-b0ca8d399452,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-61ff1221-de20-4823-80a9-a4a2a89a2892,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-f88c9395-a5f1-4586-8711-7657ab2669b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-47193490-6e0d-4941-b1a7-6cb4d65184e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-5ca6f2d2-406a-4f5b-ae36-4c662df4b1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-98a947b9-c7d3-4214-a76f-df1911df5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-15035aa8-83bc-497c-a58d-a7fe4733eeec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732315874-172.17.0.13-1597093907935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34674,DS-4c9f6e06-bc96-4a74-93ee-2af83a3df816,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-ceeaa9b9-383a-4a52-8c52-b0ca8d399452,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-61ff1221-de20-4823-80a9-a4a2a89a2892,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-f88c9395-a5f1-4586-8711-7657ab2669b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-47193490-6e0d-4941-b1a7-6cb4d65184e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-5ca6f2d2-406a-4f5b-ae36-4c662df4b1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-98a947b9-c7d3-4214-a76f-df1911df5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-15035aa8-83bc-497c-a58d-a7fe4733eeec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615600110-172.17.0.13-1597094080310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39766,DS-63f3ca86-e72d-4180-bac8-cb5be83782d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-462f54b1-b840-4009-8378-26f5e1e9e3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-d60869b5-281e-485f-8217-f7275db38d12,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-60491f8a-14c6-4788-a10b-184b5349365a,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-ebd9272d-3b04-4912-9557-6e28cacbac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-02702f6e-5fcb-4316-820e-ee50fbf68874,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-24bdd2b6-29fd-478e-a8a6-fbb7851a8e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-06a50a26-7a96-43dd-93a9-781f7c3ee8e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615600110-172.17.0.13-1597094080310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39766,DS-63f3ca86-e72d-4180-bac8-cb5be83782d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-462f54b1-b840-4009-8378-26f5e1e9e3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-d60869b5-281e-485f-8217-f7275db38d12,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-60491f8a-14c6-4788-a10b-184b5349365a,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-ebd9272d-3b04-4912-9557-6e28cacbac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-02702f6e-5fcb-4316-820e-ee50fbf68874,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-24bdd2b6-29fd-478e-a8a6-fbb7851a8e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-06a50a26-7a96-43dd-93a9-781f7c3ee8e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714811878-172.17.0.13-1597094744675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46875,DS-4c072d32-6d37-49c5-85a3-62e68577e747,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-54350462-84a4-42fe-be5d-ef10b875f5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-864b5a73-21f7-4072-91cf-8d63d61096ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-5b76b113-2a2e-45be-9b7f-76290b2be9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-0c30b047-8c51-4943-8e14-4f3a4c97a299,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-636a5c6f-53a2-499c-90b5-1757f5f3c3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-5ef92408-972f-47ac-8333-f142bb46925c,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-5146116f-9b44-4859-8771-571966d600c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714811878-172.17.0.13-1597094744675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46875,DS-4c072d32-6d37-49c5-85a3-62e68577e747,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-54350462-84a4-42fe-be5d-ef10b875f5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-864b5a73-21f7-4072-91cf-8d63d61096ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-5b76b113-2a2e-45be-9b7f-76290b2be9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-0c30b047-8c51-4943-8e14-4f3a4c97a299,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-636a5c6f-53a2-499c-90b5-1757f5f3c3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-5ef92408-972f-47ac-8333-f142bb46925c,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-5146116f-9b44-4859-8771-571966d600c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607113181-172.17.0.13-1597094784400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-420e206c-6173-4df9-ac76-a7365231d065,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-9edc1f37-9a9b-417f-95b3-b711f1a8f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-7a4b9288-f3c0-496c-912a-13e11ce06809,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-4033f21b-a8b2-4c10-800b-623a7f38babb,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-26ebaa8d-d713-4cf7-80a9-9d389e031b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-85f7a6d4-c64f-4a87-9f5f-a17c2e80ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-5357a374-0fd4-4a54-bd89-2be2c98c71b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-77858cd7-236f-4171-9f50-459b6530cccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607113181-172.17.0.13-1597094784400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-420e206c-6173-4df9-ac76-a7365231d065,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-9edc1f37-9a9b-417f-95b3-b711f1a8f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-7a4b9288-f3c0-496c-912a-13e11ce06809,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-4033f21b-a8b2-4c10-800b-623a7f38babb,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-26ebaa8d-d713-4cf7-80a9-9d389e031b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-85f7a6d4-c64f-4a87-9f5f-a17c2e80ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-5357a374-0fd4-4a54-bd89-2be2c98c71b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-77858cd7-236f-4171-9f50-459b6530cccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261031508-172.17.0.13-1597094959408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35543,DS-8f2b9986-0754-496f-b0dc-881e3935854b,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-fe44948d-f832-4377-be13-aab0e1de9fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-7e0d0150-08e0-4d5e-9c0b-d17ba9a19935,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-5b87f375-6651-4f56-8a7f-45e4b2ccfd06,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-0fed28da-744f-499c-b48d-af9520c652e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-7defd4cc-c891-4c5c-8d44-d6bc6b3c3c27,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-f5114813-e9f7-4615-91c1-152d7d69d535,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-94970465-0f5b-40b4-acec-16bfb127537b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261031508-172.17.0.13-1597094959408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35543,DS-8f2b9986-0754-496f-b0dc-881e3935854b,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-fe44948d-f832-4377-be13-aab0e1de9fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-7e0d0150-08e0-4d5e-9c0b-d17ba9a19935,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-5b87f375-6651-4f56-8a7f-45e4b2ccfd06,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-0fed28da-744f-499c-b48d-af9520c652e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-7defd4cc-c891-4c5c-8d44-d6bc6b3c3c27,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-f5114813-e9f7-4615-91c1-152d7d69d535,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-94970465-0f5b-40b4-acec-16bfb127537b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87447163-172.17.0.13-1597095067354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-c7bb1c77-3d69-4d4d-b05b-14a80cf9970a,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-fe530ba8-3c4e-429f-a58f-764b944b39a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-fcab4484-5ad1-4b3e-9964-c62b61622281,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-d7fc326f-fbcd-45d1-92d8-d80b6aa79cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-253b874b-0279-4f8a-90a4-f388f446dd29,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-4fb30b09-5a89-4b64-a68b-9c370dbcdb18,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-de05e5f9-ac05-4a88-9902-7d19d46a585f,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-8c1b0833-4424-4382-b09d-44e515ce257d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87447163-172.17.0.13-1597095067354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-c7bb1c77-3d69-4d4d-b05b-14a80cf9970a,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-fe530ba8-3c4e-429f-a58f-764b944b39a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-fcab4484-5ad1-4b3e-9964-c62b61622281,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-d7fc326f-fbcd-45d1-92d8-d80b6aa79cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-253b874b-0279-4f8a-90a4-f388f446dd29,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-4fb30b09-5a89-4b64-a68b-9c370dbcdb18,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-de05e5f9-ac05-4a88-9902-7d19d46a585f,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-8c1b0833-4424-4382-b09d-44e515ce257d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121825652-172.17.0.13-1597095331677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38720,DS-64dc79e6-e8c4-4103-9fc0-0aac8cf8a907,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-b149bef9-17ab-4515-a1cc-c1636d265831,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-6af3138c-47cd-45a5-a625-88beaf6101a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-484190e8-a781-4849-b81a-c30f89e9808f,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-611b78f6-794a-4cf9-b9cb-2d07f6329f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-ba4a9ff4-da32-43fd-a3d3-94821908d15e,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-080760b7-5358-4c8d-866c-4fde51aa5d30,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-499515bf-5ec5-4e79-8c6d-d35e97c64686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121825652-172.17.0.13-1597095331677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38720,DS-64dc79e6-e8c4-4103-9fc0-0aac8cf8a907,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-b149bef9-17ab-4515-a1cc-c1636d265831,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-6af3138c-47cd-45a5-a625-88beaf6101a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-484190e8-a781-4849-b81a-c30f89e9808f,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-611b78f6-794a-4cf9-b9cb-2d07f6329f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-ba4a9ff4-da32-43fd-a3d3-94821908d15e,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-080760b7-5358-4c8d-866c-4fde51aa5d30,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-499515bf-5ec5-4e79-8c6d-d35e97c64686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48088646-172.17.0.13-1597095440184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40696,DS-ef7b4c14-6fa1-4c7c-87a2-e453deaeba33,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-32b35329-5afa-41b2-9cda-197a0aa543a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-8302ddec-ab1d-42f0-8d62-adb2d29f32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-a602b78f-a5e9-468a-8435-93147e70b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-7ed557ed-991b-4290-916f-936e458575e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-26886354-aea8-4a41-b172-1c16b969b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-8cb28655-41da-4c19-998e-342b3c7250ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-970ff182-6214-4571-81e2-31cdfb5d61d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48088646-172.17.0.13-1597095440184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40696,DS-ef7b4c14-6fa1-4c7c-87a2-e453deaeba33,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-32b35329-5afa-41b2-9cda-197a0aa543a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-8302ddec-ab1d-42f0-8d62-adb2d29f32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-a602b78f-a5e9-468a-8435-93147e70b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-7ed557ed-991b-4290-916f-936e458575e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-26886354-aea8-4a41-b172-1c16b969b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-8cb28655-41da-4c19-998e-342b3c7250ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-970ff182-6214-4571-81e2-31cdfb5d61d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778103143-172.17.0.13-1597095968076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33393,DS-0376ce5f-0cc6-4ea9-ab04-b679ced9692b,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-51f0d1a9-9ecb-483e-b6e2-9fe18fdb95fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-65f0b6fb-3cd1-4ae4-b2a6-f4a3d716ef3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-948189e8-bbe7-4341-aa66-7ce40ee47300,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-8a79c8c1-7747-46ab-8bcf-dc41ea1a4661,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-1cd003a5-d52f-4520-9f88-470c50251b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-ce037efb-b417-4d4f-9f4b-b19432fde6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-956ad2ef-299e-442f-aa64-f7eab2f2a606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778103143-172.17.0.13-1597095968076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33393,DS-0376ce5f-0cc6-4ea9-ab04-b679ced9692b,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-51f0d1a9-9ecb-483e-b6e2-9fe18fdb95fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-65f0b6fb-3cd1-4ae4-b2a6-f4a3d716ef3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-948189e8-bbe7-4341-aa66-7ce40ee47300,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-8a79c8c1-7747-46ab-8bcf-dc41ea1a4661,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-1cd003a5-d52f-4520-9f88-470c50251b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-ce037efb-b417-4d4f-9f4b-b19432fde6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-956ad2ef-299e-442f-aa64-f7eab2f2a606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165930707-172.17.0.13-1597096511355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43738,DS-fdb6dfe8-ed0a-49a8-9ad1-303ca1287bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-4a1bd88a-4cdd-4d7f-b9db-da08d667c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-331ef3fa-6e96-451b-8c0b-685823b89760,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-30465397-17ed-4f34-8854-66e7fa62dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-f0dbcf27-4a05-4058-9814-abcc2f7529df,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-3808ac81-aa85-4b95-97b0-2cf0c8602f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-ec759f68-b5c4-42a9-935e-d625b360e73e,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-de9a2fd1-db6f-40ec-bb9a-1ae826b74350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165930707-172.17.0.13-1597096511355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43738,DS-fdb6dfe8-ed0a-49a8-9ad1-303ca1287bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-4a1bd88a-4cdd-4d7f-b9db-da08d667c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-331ef3fa-6e96-451b-8c0b-685823b89760,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-30465397-17ed-4f34-8854-66e7fa62dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-f0dbcf27-4a05-4058-9814-abcc2f7529df,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-3808ac81-aa85-4b95-97b0-2cf0c8602f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-ec759f68-b5c4-42a9-935e-d625b360e73e,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-de9a2fd1-db6f-40ec-bb9a-1ae826b74350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924197543-172.17.0.13-1597096587611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44696,DS-9155a730-8dec-45e3-9a76-228d211c397d,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-5c02407f-0a24-4725-85f6-adfdae64b661,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-d5c63d01-250f-41bf-ad1c-96b7ac5a6ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-8f47d601-da15-41a7-aa57-d07681cbdd27,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-a56be5b0-fa49-4fc9-8df0-a168f3d20ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-26c2e558-13c7-408e-8731-316cc9a8593a,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-ccd8fb6d-f1c8-4ddd-800f-7506befcc578,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f159eb16-78a0-4d00-b35f-fc5e0e57ea06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924197543-172.17.0.13-1597096587611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44696,DS-9155a730-8dec-45e3-9a76-228d211c397d,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-5c02407f-0a24-4725-85f6-adfdae64b661,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-d5c63d01-250f-41bf-ad1c-96b7ac5a6ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-8f47d601-da15-41a7-aa57-d07681cbdd27,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-a56be5b0-fa49-4fc9-8df0-a168f3d20ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-26c2e558-13c7-408e-8731-316cc9a8593a,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-ccd8fb6d-f1c8-4ddd-800f-7506befcc578,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f159eb16-78a0-4d00-b35f-fc5e0e57ea06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283029654-172.17.0.13-1597096620637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-08ba1189-bb39-4aaa-85cb-0f531650f53e,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b2b442c7-48b4-4d28-acac-62ca120c316b,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-4eb608c1-9ea2-4a44-bad8-a1b5f598aff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-e2886653-18de-4980-bb25-68d44428e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-7ca9658b-7525-4da7-b177-c3bcaeeb6d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-d808a38a-dae0-4b3f-ae4c-4152230a3d54,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-03796c7b-36f6-48ae-a198-f60c9830a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-ca9238dd-7cb2-4f19-9d6e-04b827ce914a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283029654-172.17.0.13-1597096620637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-08ba1189-bb39-4aaa-85cb-0f531650f53e,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b2b442c7-48b4-4d28-acac-62ca120c316b,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-4eb608c1-9ea2-4a44-bad8-a1b5f598aff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-e2886653-18de-4980-bb25-68d44428e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-7ca9658b-7525-4da7-b177-c3bcaeeb6d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-d808a38a-dae0-4b3f-ae4c-4152230a3d54,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-03796c7b-36f6-48ae-a198-f60c9830a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-ca9238dd-7cb2-4f19-9d6e-04b827ce914a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858845949-172.17.0.13-1597096681944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41469,DS-32c986fe-b9fe-4bde-8e63-0f21e68e599d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-09bbdecc-2437-4fe6-be4e-3e8c95f04cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-54c1aa75-8c38-488f-8e23-40ca4fc3ee20,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-a28d4cb6-e936-4891-a0da-63cedfc239dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-dcdd7e8a-e255-45db-bc78-173b50bdef4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-03323142-cd23-4300-be04-d6cbd02581cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-1639a437-3836-4e77-a1b7-7508c596d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-9563d17b-bdf3-4925-ac29-69f4ed9fe293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858845949-172.17.0.13-1597096681944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41469,DS-32c986fe-b9fe-4bde-8e63-0f21e68e599d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-09bbdecc-2437-4fe6-be4e-3e8c95f04cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-54c1aa75-8c38-488f-8e23-40ca4fc3ee20,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-a28d4cb6-e936-4891-a0da-63cedfc239dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-dcdd7e8a-e255-45db-bc78-173b50bdef4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-03323142-cd23-4300-be04-d6cbd02581cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-1639a437-3836-4e77-a1b7-7508c596d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-9563d17b-bdf3-4925-ac29-69f4ed9fe293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745347204-172.17.0.13-1597096844087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39170,DS-99cf7b90-8b66-4a12-bdc7-357cc8c8e970,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-b391bf30-7476-40e1-b858-93f0dd9caf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-65aa1e80-15c8-4fad-9399-64d426d86a20,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-45833518-bb10-4238-ae85-6c6ed76ddebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-6ebf72c6-001f-4332-8662-9ad02a684d62,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-84630fdc-5302-466c-bdad-c1778b5ff8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-45757227-9684-4ce7-96c4-13f443413ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-3b324fc4-58ee-4db8-be18-8c1e73feb22a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745347204-172.17.0.13-1597096844087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39170,DS-99cf7b90-8b66-4a12-bdc7-357cc8c8e970,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-b391bf30-7476-40e1-b858-93f0dd9caf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-65aa1e80-15c8-4fad-9399-64d426d86a20,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-45833518-bb10-4238-ae85-6c6ed76ddebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-6ebf72c6-001f-4332-8662-9ad02a684d62,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-84630fdc-5302-466c-bdad-c1778b5ff8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-45757227-9684-4ce7-96c4-13f443413ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-3b324fc4-58ee-4db8-be18-8c1e73feb22a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975469982-172.17.0.13-1597097248220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40538,DS-cd7e9273-f5a7-45f5-b113-6d81612b2880,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-e8203aca-ba73-4752-8823-f7ee832b7736,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-f089c9a9-443b-4c9b-8ca5-701dea225a32,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-d7ce5a81-91d3-4bd9-9ad5-b14f07dade2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-dd231446-f18a-42f3-b671-bfcb617940a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-c20f8ffd-f3db-4a50-9954-8ef3b5cb6d83,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-e530d016-18f9-4d65-9f05-a104e5499a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-da94667a-e066-40f6-95f7-5cb2feb57e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975469982-172.17.0.13-1597097248220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40538,DS-cd7e9273-f5a7-45f5-b113-6d81612b2880,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-e8203aca-ba73-4752-8823-f7ee832b7736,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-f089c9a9-443b-4c9b-8ca5-701dea225a32,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-d7ce5a81-91d3-4bd9-9ad5-b14f07dade2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-dd231446-f18a-42f3-b671-bfcb617940a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-c20f8ffd-f3db-4a50-9954-8ef3b5cb6d83,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-e530d016-18f9-4d65-9f05-a104e5499a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-da94667a-e066-40f6-95f7-5cb2feb57e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316046922-172.17.0.13-1597097976424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-6385023e-3df8-418b-82d9-7993102e88c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-2c8fe3c1-40ec-4e50-9b33-e09014c68076,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-657878b1-85ad-46c2-acfa-e2f5bd00dddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-91f3b6d7-a4e3-4506-b591-035bbe86dc49,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-39dd2c0b-871d-434d-b6cb-5a477b6ffba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-59bef6de-eb0d-43cc-8152-44fc37885b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-db5375dc-56aa-4cfe-ac9c-aa3e4197230b,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-c7cf12eb-d6bb-4bff-b7ba-2f344edb928f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316046922-172.17.0.13-1597097976424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-6385023e-3df8-418b-82d9-7993102e88c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-2c8fe3c1-40ec-4e50-9b33-e09014c68076,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-657878b1-85ad-46c2-acfa-e2f5bd00dddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-91f3b6d7-a4e3-4506-b591-035bbe86dc49,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-39dd2c0b-871d-434d-b6cb-5a477b6ffba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-59bef6de-eb0d-43cc-8152-44fc37885b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-db5375dc-56aa-4cfe-ac9c-aa3e4197230b,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-c7cf12eb-d6bb-4bff-b7ba-2f344edb928f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943298482-172.17.0.13-1597098466150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44743,DS-354a5760-fb59-486f-8d43-4b27deedf4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-80c427df-5dcc-4e87-99c0-cc240e24b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-cb454696-8b4c-4dd5-bdae-9637c13ab374,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-145a7f49-ef0e-4c61-9371-321765342485,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-bcf544ab-ae51-40c9-b128-49b80f1c0377,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-98195523-c515-41c2-8e6f-55c99b303d62,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-de8340b6-04ee-4c2b-a085-cd9fd117a318,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-ff5c8372-5a84-40ca-9d67-065017e48e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943298482-172.17.0.13-1597098466150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44743,DS-354a5760-fb59-486f-8d43-4b27deedf4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-80c427df-5dcc-4e87-99c0-cc240e24b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-cb454696-8b4c-4dd5-bdae-9637c13ab374,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-145a7f49-ef0e-4c61-9371-321765342485,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-bcf544ab-ae51-40c9-b128-49b80f1c0377,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-98195523-c515-41c2-8e6f-55c99b303d62,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-de8340b6-04ee-4c2b-a085-cd9fd117a318,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-ff5c8372-5a84-40ca-9d67-065017e48e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5425
