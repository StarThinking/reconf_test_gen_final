reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645982607-172.17.0.6-1597142348431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-38e3254a-8ade-40bf-be49-1c28102c0568,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-25949271-052a-4afc-8439-540c6f5700e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-d18127cd-f4bd-45a5-8ad0-dc4945b99582,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-55335a73-c3b8-4a07-b409-1f622b69242e,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-b06460bb-f409-4fde-912d-d52c08e408f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-48ff4105-cb7d-45a2-bdf2-cbba657b481d,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-d4214a46-3564-4b51-a7f4-68c4497e6e63,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-902341a0-5faf-4332-9b36-49db0f1b4165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645982607-172.17.0.6-1597142348431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-38e3254a-8ade-40bf-be49-1c28102c0568,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-25949271-052a-4afc-8439-540c6f5700e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-d18127cd-f4bd-45a5-8ad0-dc4945b99582,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-55335a73-c3b8-4a07-b409-1f622b69242e,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-b06460bb-f409-4fde-912d-d52c08e408f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-48ff4105-cb7d-45a2-bdf2-cbba657b481d,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-d4214a46-3564-4b51-a7f4-68c4497e6e63,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-902341a0-5faf-4332-9b36-49db0f1b4165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103414470-172.17.0.6-1597142415987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42093,DS-942b7df0-b899-48cd-8348-b81c0d21f085,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-060b3b16-9d05-4de0-8268-623a28c04c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-4f2b2432-d7f2-4568-8af7-f02b8261372f,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-5b90285b-fb0f-4706-8628-5f5de08669ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-14b54279-a267-440e-9542-2688097457c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-d7df3305-8086-4537-bbd2-53181fc43429,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-64d0d60e-d818-4b5f-9f0e-1360e4299164,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-48123104-63ed-4175-985d-dd52ca971fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103414470-172.17.0.6-1597142415987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42093,DS-942b7df0-b899-48cd-8348-b81c0d21f085,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-060b3b16-9d05-4de0-8268-623a28c04c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-4f2b2432-d7f2-4568-8af7-f02b8261372f,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-5b90285b-fb0f-4706-8628-5f5de08669ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-14b54279-a267-440e-9542-2688097457c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-d7df3305-8086-4537-bbd2-53181fc43429,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-64d0d60e-d818-4b5f-9f0e-1360e4299164,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-48123104-63ed-4175-985d-dd52ca971fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530699222-172.17.0.6-1597142557943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-27874423-6a3d-4034-85a9-8222f2950a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-8b4a2b22-944b-43cd-9322-92ef6a99d592,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-0864ffb1-ded6-4d75-9211-500e7fdf0830,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-34b577ba-88d5-4857-940a-d2385e411d36,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1dd71df4-f9d3-4616-bb71-e0c2d06fa8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-1917d6ea-f5f9-434b-9935-537dfd6a3679,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-b39c72ea-139f-41bf-9980-b9b4122037a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-5c52999d-f308-44fa-8963-7fec2da2b32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530699222-172.17.0.6-1597142557943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-27874423-6a3d-4034-85a9-8222f2950a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-8b4a2b22-944b-43cd-9322-92ef6a99d592,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-0864ffb1-ded6-4d75-9211-500e7fdf0830,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-34b577ba-88d5-4857-940a-d2385e411d36,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1dd71df4-f9d3-4616-bb71-e0c2d06fa8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-1917d6ea-f5f9-434b-9935-537dfd6a3679,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-b39c72ea-139f-41bf-9980-b9b4122037a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-5c52999d-f308-44fa-8963-7fec2da2b32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202771918-172.17.0.6-1597142625576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44468,DS-6568b494-add9-442a-b0ce-a7dcd8c29a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-084229af-260d-4b29-b78c-8d4e288883fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-dd7169ec-1ff3-4d17-b1fc-0943a558171c,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-79e21898-5f9f-461a-b082-904bf2cb3f04,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-2dd44a19-1f26-40cb-a089-7f2b7d560c04,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-3e218d31-554b-460f-9483-1d1159a6db84,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-4e857cf3-1f5b-44bb-ba81-3f8ee3d5608b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-12d1b6ff-c291-4955-b561-4bf0c4481144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202771918-172.17.0.6-1597142625576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44468,DS-6568b494-add9-442a-b0ce-a7dcd8c29a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-084229af-260d-4b29-b78c-8d4e288883fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-dd7169ec-1ff3-4d17-b1fc-0943a558171c,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-79e21898-5f9f-461a-b082-904bf2cb3f04,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-2dd44a19-1f26-40cb-a089-7f2b7d560c04,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-3e218d31-554b-460f-9483-1d1159a6db84,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-4e857cf3-1f5b-44bb-ba81-3f8ee3d5608b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-12d1b6ff-c291-4955-b561-4bf0c4481144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604433125-172.17.0.6-1597142979587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46607,DS-a90b9f0a-6ba3-440e-aff0-0ffa36a9d0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-b0920f51-b460-445b-9024-f46462ace034,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-3cd30de5-87dd-4e32-9bd0-d663ec2c7db2,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-020cc0a5-8ab0-4848-984e-df38b656191d,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-d5237c7d-1815-4937-b3de-8196d0bf19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-124313bd-d158-43aa-86de-ea8e6eba8aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-1f3c09ba-57ea-465d-ab4a-52d1f21776bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-acad410f-4582-4fc3-b1c3-03e5f4c8143e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604433125-172.17.0.6-1597142979587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46607,DS-a90b9f0a-6ba3-440e-aff0-0ffa36a9d0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-b0920f51-b460-445b-9024-f46462ace034,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-3cd30de5-87dd-4e32-9bd0-d663ec2c7db2,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-020cc0a5-8ab0-4848-984e-df38b656191d,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-d5237c7d-1815-4937-b3de-8196d0bf19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-124313bd-d158-43aa-86de-ea8e6eba8aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-1f3c09ba-57ea-465d-ab4a-52d1f21776bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-acad410f-4582-4fc3-b1c3-03e5f4c8143e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170892576-172.17.0.6-1597143409986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40164,DS-a0fa6d11-7d92-4976-a775-4b499ff3212b,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-89373b4c-39df-4020-8938-c58d8e265e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-33a032b9-5c39-4c5e-bd8c-5d148cff7e06,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-38bd29d4-39fa-4498-8670-0dadaf6947c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-c1669726-cc27-4517-bcd6-8427d2b206e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-8a22977b-736a-4f0e-8a47-97d9ceb52840,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-e67de839-c342-4878-bbd3-ad81090b3746,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-13d0f1f3-652a-4c0e-8981-5232cc168ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170892576-172.17.0.6-1597143409986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40164,DS-a0fa6d11-7d92-4976-a775-4b499ff3212b,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-89373b4c-39df-4020-8938-c58d8e265e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-33a032b9-5c39-4c5e-bd8c-5d148cff7e06,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-38bd29d4-39fa-4498-8670-0dadaf6947c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-c1669726-cc27-4517-bcd6-8427d2b206e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-8a22977b-736a-4f0e-8a47-97d9ceb52840,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-e67de839-c342-4878-bbd3-ad81090b3746,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-13d0f1f3-652a-4c0e-8981-5232cc168ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083031058-172.17.0.6-1597143545096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-faefcee0-8bf9-453f-aeab-a78c002dc43e,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-e5387f4d-8465-4119-83df-6e4fdc22f757,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-081c7f8d-6413-44c1-82f1-cb90cdcbf477,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-b2584c23-1e8d-4544-969d-12dc5a6a9a51,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-0e24a9b9-5de0-47a0-9252-bc94d385f5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-888f3d6e-22eb-4ce3-b960-78b7933b1ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-97156625-689f-44e0-9c72-a6b05336a639,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-eb66d4fd-a9b8-4408-88a3-a0c455bc1c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083031058-172.17.0.6-1597143545096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-faefcee0-8bf9-453f-aeab-a78c002dc43e,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-e5387f4d-8465-4119-83df-6e4fdc22f757,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-081c7f8d-6413-44c1-82f1-cb90cdcbf477,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-b2584c23-1e8d-4544-969d-12dc5a6a9a51,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-0e24a9b9-5de0-47a0-9252-bc94d385f5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-888f3d6e-22eb-4ce3-b960-78b7933b1ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-97156625-689f-44e0-9c72-a6b05336a639,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-eb66d4fd-a9b8-4408-88a3-a0c455bc1c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067210831-172.17.0.6-1597143690252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-b4174990-1995-45d7-90f2-e078cb038b36,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-1c50a893-e7ed-44e8-a23d-adad919d2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-95810abe-5539-45f2-b0ed-1a9b57e661ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-72f4ba10-47f5-4700-b96e-8ce69bb22f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-f0863ce7-97b3-40f8-a629-af9edc2bb8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-0cc4be89-c9a4-4141-b203-fe12658c71e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-cd5df611-56d5-43f4-bb0c-89ae24339f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-8e5cd09b-2f06-4926-94a3-731199a2260c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067210831-172.17.0.6-1597143690252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-b4174990-1995-45d7-90f2-e078cb038b36,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-1c50a893-e7ed-44e8-a23d-adad919d2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-95810abe-5539-45f2-b0ed-1a9b57e661ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-72f4ba10-47f5-4700-b96e-8ce69bb22f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-f0863ce7-97b3-40f8-a629-af9edc2bb8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-0cc4be89-c9a4-4141-b203-fe12658c71e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-cd5df611-56d5-43f4-bb0c-89ae24339f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-8e5cd09b-2f06-4926-94a3-731199a2260c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379626076-172.17.0.6-1597143765311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46151,DS-897eb4a1-26c9-48c6-ab33-99e89f825aab,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-52600363-6af0-4f07-8b82-047d25f0b4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-13cc58ea-60fb-468b-8393-124eda23ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-7ebbb102-fc9b-4769-ab00-711372378eda,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-af4bf561-3c72-4d26-b384-60bc6556a215,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-4a28f981-058c-4553-8393-a7d0ec3d44e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-d6f0e597-2568-4a75-906a-87cd94933d11,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-602b4907-4b29-40e8-b9dd-f4bc59e09fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379626076-172.17.0.6-1597143765311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46151,DS-897eb4a1-26c9-48c6-ab33-99e89f825aab,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-52600363-6af0-4f07-8b82-047d25f0b4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-13cc58ea-60fb-468b-8393-124eda23ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-7ebbb102-fc9b-4769-ab00-711372378eda,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-af4bf561-3c72-4d26-b384-60bc6556a215,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-4a28f981-058c-4553-8393-a7d0ec3d44e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-d6f0e597-2568-4a75-906a-87cd94933d11,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-602b4907-4b29-40e8-b9dd-f4bc59e09fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501239346-172.17.0.6-1597144171388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35097,DS-9b5a7724-b609-4ed1-86ae-7364d18fad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-cc25afc0-b1f4-4073-8243-a77a041c9a06,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-4d0dd43e-5c3e-4641-a5bf-d77700f4b07a,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-a1aaf4b4-d83c-46fa-a9d0-689931eb3ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-c5613123-4a3b-481b-ad3e-b01305aa233f,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-f6b0c8ae-e319-4302-99b3-e4a983097149,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-2cc905b9-c4f2-4b4a-98dd-01dd5c0c7879,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-e57f5244-fe31-42cd-8418-32ed08a81fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501239346-172.17.0.6-1597144171388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35097,DS-9b5a7724-b609-4ed1-86ae-7364d18fad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-cc25afc0-b1f4-4073-8243-a77a041c9a06,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-4d0dd43e-5c3e-4641-a5bf-d77700f4b07a,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-a1aaf4b4-d83c-46fa-a9d0-689931eb3ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-c5613123-4a3b-481b-ad3e-b01305aa233f,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-f6b0c8ae-e319-4302-99b3-e4a983097149,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-2cc905b9-c4f2-4b4a-98dd-01dd5c0c7879,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-e57f5244-fe31-42cd-8418-32ed08a81fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043980934-172.17.0.6-1597144205491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-d602d2e0-74ad-4531-bbb0-480df6d9fa35,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-f1186902-9342-4211-a791-7723d50c8dca,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-d5d55785-b6ce-4d94-bf84-70ed6e64af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-adf67190-13c3-4412-85d9-9cf9270f2943,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-7a54086e-170b-428f-8464-dca51f694d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-b292d478-50dd-48e1-819f-aa8e66c2e179,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-5f29cda4-9d6b-45cd-bd78-77f238346cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-10c49c6b-9c7c-4570-bdc6-bf3cc8d98461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043980934-172.17.0.6-1597144205491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-d602d2e0-74ad-4531-bbb0-480df6d9fa35,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-f1186902-9342-4211-a791-7723d50c8dca,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-d5d55785-b6ce-4d94-bf84-70ed6e64af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-adf67190-13c3-4412-85d9-9cf9270f2943,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-7a54086e-170b-428f-8464-dca51f694d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-b292d478-50dd-48e1-819f-aa8e66c2e179,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-5f29cda4-9d6b-45cd-bd78-77f238346cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-10c49c6b-9c7c-4570-bdc6-bf3cc8d98461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184550239-172.17.0.6-1597144299212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39690,DS-1578a722-5dd9-4797-a1ea-1175aa1d15f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-cab2f7f1-cbd0-4c51-a265-489d20968cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-8fee3086-dff8-4f9d-9fad-734a25fe78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-9cc63943-eeca-47dc-a620-6f29ed804be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-90a47d3e-1763-409a-a44d-9ad063dbf5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-4cb819a0-5f66-4328-a49b-d6dee2b4b4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-f04d8eaa-9cd5-42b9-b702-b1f0a13e666f,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-30fdee2e-baa7-4aae-961b-b6639f9244aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184550239-172.17.0.6-1597144299212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39690,DS-1578a722-5dd9-4797-a1ea-1175aa1d15f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-cab2f7f1-cbd0-4c51-a265-489d20968cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-8fee3086-dff8-4f9d-9fad-734a25fe78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-9cc63943-eeca-47dc-a620-6f29ed804be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-90a47d3e-1763-409a-a44d-9ad063dbf5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-4cb819a0-5f66-4328-a49b-d6dee2b4b4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-f04d8eaa-9cd5-42b9-b702-b1f0a13e666f,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-30fdee2e-baa7-4aae-961b-b6639f9244aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655383066-172.17.0.6-1597144976350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-226d303e-4a1f-4600-8d49-5e89f1f1d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-93c59ead-b548-49e4-b204-9274ac387ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-1070f627-9a91-4766-bbb1-bae58aed8b59,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-f86400ac-e896-40c9-b065-c5f2707c49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-87387c6c-7e2d-41b7-b288-6050a704d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-3019b20f-f30b-4c19-9c00-c80648fcc249,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-4a8d9637-9914-443f-bf34-987a1fe09946,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-596f94e3-8212-4549-bb3b-2b46b77e870d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655383066-172.17.0.6-1597144976350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-226d303e-4a1f-4600-8d49-5e89f1f1d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-93c59ead-b548-49e4-b204-9274ac387ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-1070f627-9a91-4766-bbb1-bae58aed8b59,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-f86400ac-e896-40c9-b065-c5f2707c49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-87387c6c-7e2d-41b7-b288-6050a704d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-3019b20f-f30b-4c19-9c00-c80648fcc249,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-4a8d9637-9914-443f-bf34-987a1fe09946,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-596f94e3-8212-4549-bb3b-2b46b77e870d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711933070-172.17.0.6-1597145571146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-3cf9c1e5-b5b4-471f-ba65-e27a9dfc89f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-ce55b6ab-222a-457f-aa3e-9c3324074ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-a709b862-7b3d-436e-afd5-ea9d2ab87813,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-52d67582-f8ac-408e-99c5-0b883faf4be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-a35dc47d-b8c9-4a34-bfde-e38376b9c06e,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-cb475991-2d62-4bb8-a6a5-29ab5baa2805,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-88f84259-7055-4192-892e-b2bad3888350,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-711b3f98-4ba5-4aac-989d-3c93bf17a42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711933070-172.17.0.6-1597145571146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-3cf9c1e5-b5b4-471f-ba65-e27a9dfc89f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-ce55b6ab-222a-457f-aa3e-9c3324074ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-a709b862-7b3d-436e-afd5-ea9d2ab87813,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-52d67582-f8ac-408e-99c5-0b883faf4be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-a35dc47d-b8c9-4a34-bfde-e38376b9c06e,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-cb475991-2d62-4bb8-a6a5-29ab5baa2805,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-88f84259-7055-4192-892e-b2bad3888350,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-711b3f98-4ba5-4aac-989d-3c93bf17a42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871743866-172.17.0.6-1597145927004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-20ec4cd9-534a-4df0-b848-60d8064949ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-25155e93-c38d-4152-87c4-ba2909878a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-448d2453-e358-4d96-a721-e03a11874343,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-c8e00ee4-ff06-43ec-89b9-a263d009fd05,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-b4594e9c-6424-4cd6-b205-a78ebc99d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-2a8d8c66-d45d-4dd6-b60d-ab0697242817,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-857e4f8d-077c-4322-b245-4a02a350dae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-50ae5391-9101-43b3-a3f8-2bd95a337353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871743866-172.17.0.6-1597145927004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-20ec4cd9-534a-4df0-b848-60d8064949ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-25155e93-c38d-4152-87c4-ba2909878a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-448d2453-e358-4d96-a721-e03a11874343,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-c8e00ee4-ff06-43ec-89b9-a263d009fd05,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-b4594e9c-6424-4cd6-b205-a78ebc99d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-2a8d8c66-d45d-4dd6-b60d-ab0697242817,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-857e4f8d-077c-4322-b245-4a02a350dae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-50ae5391-9101-43b3-a3f8-2bd95a337353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369478425-172.17.0.6-1597146038102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-b47391ad-5af6-41a9-b7a1-1d15170ec6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-42abe888-94e8-48db-b730-0070c7d8483f,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-b15ff8f3-b47b-4502-b158-9ff820419ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-595e33f3-09d6-494b-bf0b-a6f4453681c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-18d2b5f8-9004-4761-9593-be4ff4e0d3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-9a266b4e-5d3a-443b-8b88-67835478b67e,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-ea6bf213-b943-4cc9-a1f8-00d2aaa23adb,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-a1252953-1c69-4d57-9cf6-0e074e89dfff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369478425-172.17.0.6-1597146038102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-b47391ad-5af6-41a9-b7a1-1d15170ec6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-42abe888-94e8-48db-b730-0070c7d8483f,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-b15ff8f3-b47b-4502-b158-9ff820419ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-595e33f3-09d6-494b-bf0b-a6f4453681c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-18d2b5f8-9004-4761-9593-be4ff4e0d3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-9a266b4e-5d3a-443b-8b88-67835478b67e,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-ea6bf213-b943-4cc9-a1f8-00d2aaa23adb,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-a1252953-1c69-4d57-9cf6-0e074e89dfff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503060969-172.17.0.6-1597146941280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43698,DS-1ace0317-207c-42dc-b48d-1ef821e2a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-5da22589-d7d1-431d-b152-801280a84317,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-d9bec678-798f-4df8-8e04-28fc2f63d9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-e31ee2bd-b57c-4eb0-89ff-91428a2f5171,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-dfc39da8-7cda-4467-a4a6-a7ae32342e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-75537d9a-7c74-4609-8bf8-3e82325e2372,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-cc2d3923-d961-4184-b511-8be525bb9bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-7d1007d4-6439-43a5-9c7e-6dc8eb15a5b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503060969-172.17.0.6-1597146941280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43698,DS-1ace0317-207c-42dc-b48d-1ef821e2a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-5da22589-d7d1-431d-b152-801280a84317,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-d9bec678-798f-4df8-8e04-28fc2f63d9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-e31ee2bd-b57c-4eb0-89ff-91428a2f5171,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-dfc39da8-7cda-4467-a4a6-a7ae32342e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-75537d9a-7c74-4609-8bf8-3e82325e2372,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-cc2d3923-d961-4184-b511-8be525bb9bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-7d1007d4-6439-43a5-9c7e-6dc8eb15a5b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934365423-172.17.0.6-1597147091815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46878,DS-5d1f40b1-ff9e-4199-b65c-7c131f8281ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-9bb1bf97-4f6c-4f74-af6d-a94bc1b2c64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d79e0586-bd50-4b0a-b3f6-2b476916d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-5ea2fbe2-30cb-4c8b-a027-e9a93b3bc4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-6a4af3e3-d087-41c8-949b-c3450d41c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-a6e79a31-0d10-4f7c-84fa-b5de9bad0eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-eff3a853-c2dc-45a6-8ede-39ed8b538ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-0e93ef44-6b66-44b9-bfb2-c532d17164be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934365423-172.17.0.6-1597147091815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46878,DS-5d1f40b1-ff9e-4199-b65c-7c131f8281ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-9bb1bf97-4f6c-4f74-af6d-a94bc1b2c64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d79e0586-bd50-4b0a-b3f6-2b476916d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-5ea2fbe2-30cb-4c8b-a027-e9a93b3bc4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-6a4af3e3-d087-41c8-949b-c3450d41c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-a6e79a31-0d10-4f7c-84fa-b5de9bad0eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-eff3a853-c2dc-45a6-8ede-39ed8b538ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-0e93ef44-6b66-44b9-bfb2-c532d17164be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5213
