reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030963798-172.17.0.6-1597053142422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-63a6b49d-6498-4784-8730-b869faca7473,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-6b6b3c35-984b-4151-80a4-399b7f65c411,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-272d3f3d-daa6-4287-a91d-bd03361c1fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-d84de14d-2493-4d77-907a-bf883a2b9a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-7eb8face-95be-48b5-96b4-c6aeac106091,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-53e316fa-40b7-417b-8307-46409b69e702,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-f48e48a0-f626-4be1-a868-6bdded89512a,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-0098c05a-752f-4ee6-a6d2-1b13cf9de3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030963798-172.17.0.6-1597053142422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-63a6b49d-6498-4784-8730-b869faca7473,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-6b6b3c35-984b-4151-80a4-399b7f65c411,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-272d3f3d-daa6-4287-a91d-bd03361c1fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-d84de14d-2493-4d77-907a-bf883a2b9a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-7eb8face-95be-48b5-96b4-c6aeac106091,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-53e316fa-40b7-417b-8307-46409b69e702,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-f48e48a0-f626-4be1-a868-6bdded89512a,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-0098c05a-752f-4ee6-a6d2-1b13cf9de3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57663936-172.17.0.6-1597053599840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-13f94ef2-4a1a-49f4-97d6-144bf61ef4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-66a66253-30ab-4ac1-82f7-d06a7182e8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-dbffa53b-773b-44be-b8d3-3001b8f2d8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-32176995-3401-4486-b601-ee742865ee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-5fee1281-1204-4458-a2f9-22da273962b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-e4d575d9-e63c-4cb0-ba4b-a91b0e36bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-4625a0f9-d70d-41df-916f-15abc6755c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-5c9a2ed4-5597-4268-bc5c-d82cdca1ad3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57663936-172.17.0.6-1597053599840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-13f94ef2-4a1a-49f4-97d6-144bf61ef4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-66a66253-30ab-4ac1-82f7-d06a7182e8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-dbffa53b-773b-44be-b8d3-3001b8f2d8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-32176995-3401-4486-b601-ee742865ee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-5fee1281-1204-4458-a2f9-22da273962b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-e4d575d9-e63c-4cb0-ba4b-a91b0e36bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-4625a0f9-d70d-41df-916f-15abc6755c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-5c9a2ed4-5597-4268-bc5c-d82cdca1ad3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327335908-172.17.0.6-1597053638168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46464,DS-f8ae4eff-5055-4657-847f-7ff6299fd0de,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-44d6db3d-3d2f-4c7f-8d8c-2bf9f2e4cc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-bc58e262-b96e-4b8e-ba14-92f5224ddb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-81582ae8-474f-4f1c-8d58-9176c01ea498,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-230e6802-ce60-4d72-86a3-a4dfe309690b,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-cfc1e87a-b1ce-4bb8-91eb-26524b4e5484,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-1ac8bb55-0fbe-4f6e-929f-3459dca3d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-df2c58a6-ae87-446e-a8af-9552419ee701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327335908-172.17.0.6-1597053638168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46464,DS-f8ae4eff-5055-4657-847f-7ff6299fd0de,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-44d6db3d-3d2f-4c7f-8d8c-2bf9f2e4cc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-bc58e262-b96e-4b8e-ba14-92f5224ddb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-81582ae8-474f-4f1c-8d58-9176c01ea498,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-230e6802-ce60-4d72-86a3-a4dfe309690b,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-cfc1e87a-b1ce-4bb8-91eb-26524b4e5484,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-1ac8bb55-0fbe-4f6e-929f-3459dca3d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-df2c58a6-ae87-446e-a8af-9552419ee701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920700716-172.17.0.6-1597053776922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38277,DS-ec895e6f-de23-44e9-b0a6-ef0b1772fa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-aeea75f6-f19d-4cbb-ba92-69c1598200b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-d8c5917e-18d3-4108-af4e-e44dc5c1272b,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-7335a13a-462b-4b20-9186-7ed8e387d9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-840b62d9-9111-40dd-bccd-8166166a365c,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-0dc24c79-94d8-4ea2-8044-21a2115ad336,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-9688bcc8-7d2c-491b-be17-8b2160ac8bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-1200297c-2251-42a4-8031-9748429a990a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920700716-172.17.0.6-1597053776922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38277,DS-ec895e6f-de23-44e9-b0a6-ef0b1772fa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-aeea75f6-f19d-4cbb-ba92-69c1598200b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-d8c5917e-18d3-4108-af4e-e44dc5c1272b,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-7335a13a-462b-4b20-9186-7ed8e387d9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-840b62d9-9111-40dd-bccd-8166166a365c,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-0dc24c79-94d8-4ea2-8044-21a2115ad336,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-9688bcc8-7d2c-491b-be17-8b2160ac8bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-1200297c-2251-42a4-8031-9748429a990a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889730224-172.17.0.6-1597053817120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-2ca45b32-bafe-4b41-b161-782440909ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-26d8f7fc-5f23-4397-aeef-cdb9e1f69d77,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-5f8a319e-7a84-4c1c-8d57-c10e52230cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-0d9bf448-3944-4ed9-8854-d63a37819f84,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-388d03af-861d-49ac-b61c-bdf6499b9bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-2c476e00-4323-44e9-8ae9-b4012306a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-ab3f5b34-73e4-45f2-89d6-ee25384a43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-72e3e136-06ff-4887-ab61-d865f9b11cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889730224-172.17.0.6-1597053817120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-2ca45b32-bafe-4b41-b161-782440909ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-26d8f7fc-5f23-4397-aeef-cdb9e1f69d77,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-5f8a319e-7a84-4c1c-8d57-c10e52230cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-0d9bf448-3944-4ed9-8854-d63a37819f84,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-388d03af-861d-49ac-b61c-bdf6499b9bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-2c476e00-4323-44e9-8ae9-b4012306a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-ab3f5b34-73e4-45f2-89d6-ee25384a43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-72e3e136-06ff-4887-ab61-d865f9b11cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784461424-172.17.0.6-1597054464696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-cdc6de12-b9d2-4adc-8d1a-7fb94e26c772,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-e914b3da-6baa-47f0-a7ff-fce9d48b34ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-b7612caa-6421-40af-be56-5b5309746f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-cf08168e-e523-4261-8b52-96a8e631e48e,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-7efa01df-a3d3-4b3f-9d7a-e27f3e194a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-49710776-f5ba-4908-bcbf-2d5e0e7aa531,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-f15a07b0-fd5a-4cd7-b605-99ff9808282a,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-a868ee6e-6a3a-4aa5-ad95-0af085e9c5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784461424-172.17.0.6-1597054464696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-cdc6de12-b9d2-4adc-8d1a-7fb94e26c772,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-e914b3da-6baa-47f0-a7ff-fce9d48b34ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-b7612caa-6421-40af-be56-5b5309746f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-cf08168e-e523-4261-8b52-96a8e631e48e,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-7efa01df-a3d3-4b3f-9d7a-e27f3e194a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-49710776-f5ba-4908-bcbf-2d5e0e7aa531,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-f15a07b0-fd5a-4cd7-b605-99ff9808282a,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-a868ee6e-6a3a-4aa5-ad95-0af085e9c5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953791506-172.17.0.6-1597055571529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37441,DS-2d953500-a5c9-40f1-ac45-aa9e9eb8ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-09d1c27f-72a6-4861-bd21-65a46f128118,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-528f25d1-5d08-4b04-adcc-9844c0327f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-9075f749-1a11-4dba-8a82-e02c3568324d,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-6fb8423a-6097-490d-b0a6-ac5f669916cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-764b5107-c972-4754-8c58-afaf3b8fcd87,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-e2688d1e-42ba-4898-8a7b-5dda903ccb32,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ed2c758b-dccc-410e-a411-8a54fabcab35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953791506-172.17.0.6-1597055571529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37441,DS-2d953500-a5c9-40f1-ac45-aa9e9eb8ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-09d1c27f-72a6-4861-bd21-65a46f128118,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-528f25d1-5d08-4b04-adcc-9844c0327f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-9075f749-1a11-4dba-8a82-e02c3568324d,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-6fb8423a-6097-490d-b0a6-ac5f669916cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-764b5107-c972-4754-8c58-afaf3b8fcd87,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-e2688d1e-42ba-4898-8a7b-5dda903ccb32,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ed2c758b-dccc-410e-a411-8a54fabcab35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348045465-172.17.0.6-1597055793460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-fc80ed1c-38b0-4bb0-9133-b7fe2dcb4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-fab1d210-3df6-435e-ba1c-2874a3147ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-0217fe53-bd64-48d8-8fee-90f9e4d002fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-a3672343-0cce-4936-bd7e-a2a55609c25b,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-78d2ab09-fb99-4937-a0c6-84cb3a22bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-1245e0b0-9227-4c78-85e2-efb67dd27b41,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-638ba7bc-91e9-4e55-b71d-78e63c7387cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-e19cd16c-6432-4985-9ef6-5208d3b7bff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348045465-172.17.0.6-1597055793460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-fc80ed1c-38b0-4bb0-9133-b7fe2dcb4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-fab1d210-3df6-435e-ba1c-2874a3147ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-0217fe53-bd64-48d8-8fee-90f9e4d002fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-a3672343-0cce-4936-bd7e-a2a55609c25b,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-78d2ab09-fb99-4937-a0c6-84cb3a22bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-1245e0b0-9227-4c78-85e2-efb67dd27b41,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-638ba7bc-91e9-4e55-b71d-78e63c7387cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-e19cd16c-6432-4985-9ef6-5208d3b7bff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906346856-172.17.0.6-1597055842419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-5d05e043-d22a-4923-b937-376b4a2fd81b,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-d881ac91-b80f-406c-950a-cc543fd35990,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-e906fe7b-8ea3-49c2-879b-909e7ec6a959,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-d8dea2d7-b27e-49e0-846d-083cb179d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-4b17e4bf-e806-4103-8db5-e5b096ebde47,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-35f02bce-f96c-4085-8f69-20a5adc651a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-b3c973c7-1d85-49b7-9214-4403a0cb912c,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-a6325aa3-09a4-4b2e-8598-2879375bd529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906346856-172.17.0.6-1597055842419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-5d05e043-d22a-4923-b937-376b4a2fd81b,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-d881ac91-b80f-406c-950a-cc543fd35990,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-e906fe7b-8ea3-49c2-879b-909e7ec6a959,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-d8dea2d7-b27e-49e0-846d-083cb179d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-4b17e4bf-e806-4103-8db5-e5b096ebde47,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-35f02bce-f96c-4085-8f69-20a5adc651a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-b3c973c7-1d85-49b7-9214-4403a0cb912c,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-a6325aa3-09a4-4b2e-8598-2879375bd529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623352771-172.17.0.6-1597055932091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43430,DS-10ad23b7-9674-45b1-9ab3-7067d9445248,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-593111ae-f205-4591-a569-7a71de47b655,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-ef2f38b7-6112-4950-939b-f17faa7573e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-18798ce2-e123-4bca-86e3-afe282010fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-67d63507-4325-4237-8f6e-4bebf6c9158d,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-9aec405f-d9a6-4f7d-99e6-f8114f9a7ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-51ae148d-9f88-4559-8d25-5b0ac4a38edf,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-132c303b-14c6-487d-b15d-612b920c8fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623352771-172.17.0.6-1597055932091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43430,DS-10ad23b7-9674-45b1-9ab3-7067d9445248,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-593111ae-f205-4591-a569-7a71de47b655,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-ef2f38b7-6112-4950-939b-f17faa7573e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-18798ce2-e123-4bca-86e3-afe282010fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-67d63507-4325-4237-8f6e-4bebf6c9158d,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-9aec405f-d9a6-4f7d-99e6-f8114f9a7ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-51ae148d-9f88-4559-8d25-5b0ac4a38edf,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-132c303b-14c6-487d-b15d-612b920c8fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686972275-172.17.0.6-1597056120682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44696,DS-66c77bfb-7808-493c-a0da-52c9ac366bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-5c9af7c3-13b6-4c23-8fc0-574c2be2d328,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-09bc6dcb-6489-49a0-a289-27b58047f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-8cc9dc1b-22a8-4be2-82e8-40a65dace7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-6dfff831-1e1b-467a-a753-4354003dda17,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-e3f78739-6707-47c2-a441-46bb74317664,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-6b8271fa-5867-42ad-b116-274827fd9ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-183d1a2f-aa0d-4665-85b3-82cd2d9022b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686972275-172.17.0.6-1597056120682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44696,DS-66c77bfb-7808-493c-a0da-52c9ac366bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-5c9af7c3-13b6-4c23-8fc0-574c2be2d328,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-09bc6dcb-6489-49a0-a289-27b58047f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-8cc9dc1b-22a8-4be2-82e8-40a65dace7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-6dfff831-1e1b-467a-a753-4354003dda17,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-e3f78739-6707-47c2-a441-46bb74317664,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-6b8271fa-5867-42ad-b116-274827fd9ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-183d1a2f-aa0d-4665-85b3-82cd2d9022b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81863561-172.17.0.6-1597056395074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-d3e0ff05-40f7-49bf-b966-f00ff2047f44,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-5957a074-d711-480a-bf6d-75e6378eaceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-1197f57f-cf3b-4109-b626-4398a564b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-383eb25e-d7ce-4f9e-8e2a-ff2d8550546e,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-db34ed2a-6e3c-4075-8edb-0d666664f41c,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-f742b951-ebd0-4ae6-8696-5c666da0f5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-a3a23263-2ba1-4784-8baa-b13898a22d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-deb8b1fb-d600-4495-a251-e518455204ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81863561-172.17.0.6-1597056395074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-d3e0ff05-40f7-49bf-b966-f00ff2047f44,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-5957a074-d711-480a-bf6d-75e6378eaceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-1197f57f-cf3b-4109-b626-4398a564b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-383eb25e-d7ce-4f9e-8e2a-ff2d8550546e,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-db34ed2a-6e3c-4075-8edb-0d666664f41c,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-f742b951-ebd0-4ae6-8696-5c666da0f5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-a3a23263-2ba1-4784-8baa-b13898a22d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-deb8b1fb-d600-4495-a251-e518455204ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897405919-172.17.0.6-1597056513356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-7d9a4642-e1c8-434b-a75f-f44042f59b38,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-30401565-6876-41ec-9f0d-e93770a7a146,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-eeef70a0-6476-4165-ac44-6ba4c382bee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-3044af76-a0ca-4fb6-9382-fdd86f816ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-2eb72d26-8257-49a0-ac66-df5e870cf8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-08fe9ab7-7b2b-4088-9189-871095db20eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-f4a01194-12f6-4a4e-9603-dd387b07a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-4ce3cd20-5c1f-426d-a2d1-92a4df8bb40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897405919-172.17.0.6-1597056513356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-7d9a4642-e1c8-434b-a75f-f44042f59b38,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-30401565-6876-41ec-9f0d-e93770a7a146,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-eeef70a0-6476-4165-ac44-6ba4c382bee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-3044af76-a0ca-4fb6-9382-fdd86f816ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-2eb72d26-8257-49a0-ac66-df5e870cf8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-08fe9ab7-7b2b-4088-9189-871095db20eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-f4a01194-12f6-4a4e-9603-dd387b07a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-4ce3cd20-5c1f-426d-a2d1-92a4df8bb40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967060629-172.17.0.6-1597056829794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-f2a1556d-d2f4-4a61-9418-6b5536088b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-6f617eae-54e0-40dc-9231-c0c8ee02efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-a945762f-3afd-4205-8ef6-df4d4046ccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-f00ac838-833e-45fd-9b6a-641a9ee8d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-59bd92d2-2bec-4cb8-ba57-649ec16e5488,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-bbfc6ac5-d9a7-42e2-972c-648d608698e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-ad84a830-2eaf-4c04-b43b-3c2d9d20465e,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-78fe8748-0dfb-4fba-a7e9-3d5b467db5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967060629-172.17.0.6-1597056829794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-f2a1556d-d2f4-4a61-9418-6b5536088b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-6f617eae-54e0-40dc-9231-c0c8ee02efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-a945762f-3afd-4205-8ef6-df4d4046ccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-f00ac838-833e-45fd-9b6a-641a9ee8d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-59bd92d2-2bec-4cb8-ba57-649ec16e5488,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-bbfc6ac5-d9a7-42e2-972c-648d608698e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-ad84a830-2eaf-4c04-b43b-3c2d9d20465e,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-78fe8748-0dfb-4fba-a7e9-3d5b467db5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233754547-172.17.0.6-1597057011698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39082,DS-ea3c72d5-fff1-4e46-921a-d8dcf6520646,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-08f8cd63-537f-4607-b35b-4264d67aa750,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-752acf74-244b-4c6d-bd83-12ddece1d93b,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-9b307fe1-ce5c-4dc6-ac88-894f7177f739,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-58a03af0-fcc5-4394-9b42-c07938c833a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-760e25aa-771c-4376-90ca-2c84d18a8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-c24aec09-70ef-4a8f-8dd3-80e5eaacc683,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-daf9f03c-e353-41eb-9e68-045edcad2264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233754547-172.17.0.6-1597057011698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39082,DS-ea3c72d5-fff1-4e46-921a-d8dcf6520646,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-08f8cd63-537f-4607-b35b-4264d67aa750,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-752acf74-244b-4c6d-bd83-12ddece1d93b,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-9b307fe1-ce5c-4dc6-ac88-894f7177f739,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-58a03af0-fcc5-4394-9b42-c07938c833a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-760e25aa-771c-4376-90ca-2c84d18a8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-c24aec09-70ef-4a8f-8dd3-80e5eaacc683,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-daf9f03c-e353-41eb-9e68-045edcad2264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262615391-172.17.0.6-1597057248415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32942,DS-488b25e4-4f82-467a-abbb-9a319fc466bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-425618de-4cf1-4e06-a639-48b1ba348fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-21df32d3-dd6f-4318-9fbe-2855a0a1d0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-a7c38cb8-13b3-4dde-84f4-c2ef3c009278,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-fe353a6f-dd4d-4a26-97af-0adbb9fb8ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-a4d42592-541d-4481-aeb9-3760e1e7f4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-d1d38ea2-79cd-49b7-a5fc-f94e4c5b990b,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-3032118f-44bd-4add-9078-00660a7d9e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262615391-172.17.0.6-1597057248415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32942,DS-488b25e4-4f82-467a-abbb-9a319fc466bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-425618de-4cf1-4e06-a639-48b1ba348fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-21df32d3-dd6f-4318-9fbe-2855a0a1d0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-a7c38cb8-13b3-4dde-84f4-c2ef3c009278,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-fe353a6f-dd4d-4a26-97af-0adbb9fb8ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-a4d42592-541d-4481-aeb9-3760e1e7f4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-d1d38ea2-79cd-49b7-a5fc-f94e4c5b990b,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-3032118f-44bd-4add-9078-00660a7d9e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198680484-172.17.0.6-1597057533100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-1fb6db2b-9165-4373-886f-c92f127b201c,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-e4e84e98-2e45-48c9-9a3b-f8c62a9bc7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-d820c268-23fa-4556-9af0-230f6015901c,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-a3f29a07-5753-4d4c-a02d-adc2e14ceb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-0ad71bb2-0e12-4ca6-a211-0bfab8e2a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-81ead001-580e-416b-94b1-3daf277852a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-a1c4dfc4-ad05-47f6-adfa-55db806d0990,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-8e13d30c-d3b7-45a9-8e7f-c15273c0ccce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198680484-172.17.0.6-1597057533100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-1fb6db2b-9165-4373-886f-c92f127b201c,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-e4e84e98-2e45-48c9-9a3b-f8c62a9bc7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-d820c268-23fa-4556-9af0-230f6015901c,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-a3f29a07-5753-4d4c-a02d-adc2e14ceb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-0ad71bb2-0e12-4ca6-a211-0bfab8e2a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-81ead001-580e-416b-94b1-3daf277852a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-a1c4dfc4-ad05-47f6-adfa-55db806d0990,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-8e13d30c-d3b7-45a9-8e7f-c15273c0ccce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969781931-172.17.0.6-1597057876674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35423,DS-78c9ce03-af19-4282-a928-fdc61d8224b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-aeddf1ad-c1c2-4c68-9775-ee17158a2351,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-659429ac-41b7-403b-889e-b530aaff8027,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-876a2a0c-3b46-40a5-8b40-eeb7d486775b,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-f1cb4ff1-066e-4505-add7-e75295c4d4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-c6546945-7362-4da7-b52e-eda84f474da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-f19f0012-a22a-4abc-a436-e3792d3eb0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-6b68e37b-8b1b-46b6-a8b3-ae63e60acf56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969781931-172.17.0.6-1597057876674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35423,DS-78c9ce03-af19-4282-a928-fdc61d8224b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-aeddf1ad-c1c2-4c68-9775-ee17158a2351,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-659429ac-41b7-403b-889e-b530aaff8027,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-876a2a0c-3b46-40a5-8b40-eeb7d486775b,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-f1cb4ff1-066e-4505-add7-e75295c4d4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-c6546945-7362-4da7-b52e-eda84f474da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-f19f0012-a22a-4abc-a436-e3792d3eb0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-6b68e37b-8b1b-46b6-a8b3-ae63e60acf56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224153921-172.17.0.6-1597058958605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-9fde0da6-500a-4a96-9d05-8d7bd11dbc54,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-3dca05d9-0717-4257-8f32-17d0f3deb86a,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-380a2132-13b2-4acb-90fe-c8bb5d50996b,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-f5e989f1-1369-495c-9e27-65aa794d2fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-e60ad472-5b58-4c75-be36-385232ca03e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-9f15c3ba-d9f2-4289-8aa1-1f7f43adb8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-efa07560-09b6-46b3-bff7-de74bbc63f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-ad761e00-bac8-4150-b844-9c178bfe989c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224153921-172.17.0.6-1597058958605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-9fde0da6-500a-4a96-9d05-8d7bd11dbc54,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-3dca05d9-0717-4257-8f32-17d0f3deb86a,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-380a2132-13b2-4acb-90fe-c8bb5d50996b,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-f5e989f1-1369-495c-9e27-65aa794d2fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-e60ad472-5b58-4c75-be36-385232ca03e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-9f15c3ba-d9f2-4289-8aa1-1f7f43adb8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-efa07560-09b6-46b3-bff7-de74bbc63f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-ad761e00-bac8-4150-b844-9c178bfe989c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6703
