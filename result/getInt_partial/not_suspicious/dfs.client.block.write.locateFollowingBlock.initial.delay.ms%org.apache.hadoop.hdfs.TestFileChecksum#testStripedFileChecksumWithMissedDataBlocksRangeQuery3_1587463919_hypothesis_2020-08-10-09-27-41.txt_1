reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410196806-172.17.0.14-1597052345458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-f3e7b3d2-be1e-42e4-bd93-df07e6052ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-41793bd0-0417-463d-8676-11c451afc365,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-fc96bbfb-35ee-41b6-ad3a-e307804a26e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-2e623cec-5bce-4385-8c92-98417e57df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-20950a1b-7bb5-4172-94c9-a3db9793f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-59e04ef2-ce09-4ba2-843b-9121be22bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-e4fc7dbe-960c-4ebb-83a1-bd10fb27ea58,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-08899994-63ee-4eb4-b261-4c042559576e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410196806-172.17.0.14-1597052345458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-f3e7b3d2-be1e-42e4-bd93-df07e6052ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-41793bd0-0417-463d-8676-11c451afc365,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-fc96bbfb-35ee-41b6-ad3a-e307804a26e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-2e623cec-5bce-4385-8c92-98417e57df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-20950a1b-7bb5-4172-94c9-a3db9793f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-59e04ef2-ce09-4ba2-843b-9121be22bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-e4fc7dbe-960c-4ebb-83a1-bd10fb27ea58,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-08899994-63ee-4eb4-b261-4c042559576e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721895263-172.17.0.14-1597052830711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-cdf123a5-5642-419f-aba4-29351c1ab690,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-a5811957-afa6-495b-820a-ac9d865374c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-6751d202-4b0c-4ee8-ab32-d47050ac4b67,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-a051ac8f-cf97-4be9-82bd-327543e783cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-0d9bfad6-006a-4445-92cd-34375ef316e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-39f2288d-c54b-4293-9a16-c1a234e48b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-16510b40-122b-4cb8-967c-d76bc41d729f,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-a711a1e3-8c33-438d-8e87-2de4ebdebba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721895263-172.17.0.14-1597052830711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-cdf123a5-5642-419f-aba4-29351c1ab690,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-a5811957-afa6-495b-820a-ac9d865374c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-6751d202-4b0c-4ee8-ab32-d47050ac4b67,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-a051ac8f-cf97-4be9-82bd-327543e783cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-0d9bfad6-006a-4445-92cd-34375ef316e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-39f2288d-c54b-4293-9a16-c1a234e48b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-16510b40-122b-4cb8-967c-d76bc41d729f,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-a711a1e3-8c33-438d-8e87-2de4ebdebba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289294756-172.17.0.14-1597052936871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-6e2c1e75-4e63-4981-a2a6-d44ae7d03573,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-c8246d26-cf56-4c6f-b929-9161ee582220,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-95443275-b6ed-4d40-b208-af7638304d53,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-e824bc90-e575-4799-a610-5d7f68dbc83e,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-503b3ef6-5e5b-4508-9900-9a2ff979eeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-26f2d3a8-16ab-4364-9eb6-90aa46be40d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-29c4b0fa-7a83-4f24-8ba4-cd8d63596119,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-10a96081-716d-4285-91be-2cec0d335c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289294756-172.17.0.14-1597052936871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-6e2c1e75-4e63-4981-a2a6-d44ae7d03573,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-c8246d26-cf56-4c6f-b929-9161ee582220,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-95443275-b6ed-4d40-b208-af7638304d53,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-e824bc90-e575-4799-a610-5d7f68dbc83e,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-503b3ef6-5e5b-4508-9900-9a2ff979eeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-26f2d3a8-16ab-4364-9eb6-90aa46be40d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-29c4b0fa-7a83-4f24-8ba4-cd8d63596119,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-10a96081-716d-4285-91be-2cec0d335c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566062091-172.17.0.14-1597053254398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35930,DS-efff7665-003a-4428-8039-a6826c243e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-083fe734-f74d-40e6-8377-4b512c4ea77f,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-9c1c5377-b3fe-45a5-9b4c-396566c351f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-3b4914fa-e6ca-4922-b670-8613d3b4283c,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-a9532404-7341-4583-b7ea-7a9fc8f7609e,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-ed96e873-bb20-4e16-86fc-6576cf41a738,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-47fb4c07-3edd-454a-919f-e426d730c945,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-52eeb26b-3be4-43f7-81b4-52f739179227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566062091-172.17.0.14-1597053254398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35930,DS-efff7665-003a-4428-8039-a6826c243e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-083fe734-f74d-40e6-8377-4b512c4ea77f,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-9c1c5377-b3fe-45a5-9b4c-396566c351f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-3b4914fa-e6ca-4922-b670-8613d3b4283c,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-a9532404-7341-4583-b7ea-7a9fc8f7609e,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-ed96e873-bb20-4e16-86fc-6576cf41a738,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-47fb4c07-3edd-454a-919f-e426d730c945,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-52eeb26b-3be4-43f7-81b4-52f739179227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482889582-172.17.0.14-1597053362772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39774,DS-4557240c-80f5-4272-83ab-bf6529750554,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-c190fc05-2836-4477-87fe-20b61ab5ebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-15c0ae45-42f0-407f-9b3e-22daa8acea93,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-4a4c2b3b-a6be-4480-9037-ba82db201c46,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-c56c8b5b-7223-459a-a6ba-7d99048b2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-c57c968a-e61e-47cc-ad8e-3e709080a820,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-37d45424-259c-4567-bbab-031cc789d267,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-0d00eef0-d6c4-49ad-8626-b55193788e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482889582-172.17.0.14-1597053362772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39774,DS-4557240c-80f5-4272-83ab-bf6529750554,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-c190fc05-2836-4477-87fe-20b61ab5ebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-15c0ae45-42f0-407f-9b3e-22daa8acea93,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-4a4c2b3b-a6be-4480-9037-ba82db201c46,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-c56c8b5b-7223-459a-a6ba-7d99048b2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-c57c968a-e61e-47cc-ad8e-3e709080a820,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-37d45424-259c-4567-bbab-031cc789d267,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-0d00eef0-d6c4-49ad-8626-b55193788e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910867000-172.17.0.14-1597053397139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40432,DS-47e176b9-3f01-4c2b-851f-d7aa568ec984,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-327483a4-fa78-411b-865c-d8ce0793e380,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-5c7d5a25-36ee-4684-b350-0baabfa94574,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-09053659-acec-40b3-b647-48bdadc3d8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-02106c8c-b81a-43f5-b8c3-13cee7232e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-822e9f1d-4487-4e30-924e-b85652be056c,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-f98b677f-4311-4c79-a748-b1301a369b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-e3a0e78f-9bb5-45a2-a345-57a99e7f0657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910867000-172.17.0.14-1597053397139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40432,DS-47e176b9-3f01-4c2b-851f-d7aa568ec984,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-327483a4-fa78-411b-865c-d8ce0793e380,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-5c7d5a25-36ee-4684-b350-0baabfa94574,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-09053659-acec-40b3-b647-48bdadc3d8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-02106c8c-b81a-43f5-b8c3-13cee7232e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-822e9f1d-4487-4e30-924e-b85652be056c,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-f98b677f-4311-4c79-a748-b1301a369b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-e3a0e78f-9bb5-45a2-a345-57a99e7f0657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882944386-172.17.0.14-1597054982747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34740,DS-34730e87-2106-4f78-8a01-0e428320e742,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-f1995518-0ea0-4a6c-b0b2-20e6c9cda941,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-369cd315-ed9b-4355-a5a0-8129a02341b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-ade8e94b-1c26-4709-a7c7-c2331253f360,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-11c62426-2fba-4f6f-8370-ab2aeca7e54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-6c46c9d0-f4f5-49d2-8468-19241f6db521,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-e4333880-2cc7-4360-a37f-22e938b45336,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-ef7c72f6-51b5-4e75-8579-5ddd17c9f831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882944386-172.17.0.14-1597054982747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34740,DS-34730e87-2106-4f78-8a01-0e428320e742,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-f1995518-0ea0-4a6c-b0b2-20e6c9cda941,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-369cd315-ed9b-4355-a5a0-8129a02341b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-ade8e94b-1c26-4709-a7c7-c2331253f360,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-11c62426-2fba-4f6f-8370-ab2aeca7e54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-6c46c9d0-f4f5-49d2-8468-19241f6db521,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-e4333880-2cc7-4360-a37f-22e938b45336,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-ef7c72f6-51b5-4e75-8579-5ddd17c9f831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892861297-172.17.0.14-1597055258068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-95fdbfa2-95d6-42ac-8b80-84c29a0c06cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-feaba61a-14d1-4791-a70e-af0dfb87c134,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-e0973f82-11ac-410a-8e46-b71c420fdbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-7455a147-9e47-4c8b-953c-e77d0c0de080,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-2396688c-fb11-4417-9358-3088f3cd797c,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-1d27f47d-1c6a-4e8b-ba53-d1a9e9137ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-a1f09ba2-1b30-4803-a5c8-3756814f1d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-d393dd67-0832-40ac-bc5b-9944b9c3601a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892861297-172.17.0.14-1597055258068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-95fdbfa2-95d6-42ac-8b80-84c29a0c06cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-feaba61a-14d1-4791-a70e-af0dfb87c134,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-e0973f82-11ac-410a-8e46-b71c420fdbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-7455a147-9e47-4c8b-953c-e77d0c0de080,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-2396688c-fb11-4417-9358-3088f3cd797c,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-1d27f47d-1c6a-4e8b-ba53-d1a9e9137ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-a1f09ba2-1b30-4803-a5c8-3756814f1d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-d393dd67-0832-40ac-bc5b-9944b9c3601a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133138943-172.17.0.14-1597055478165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45610,DS-b162fea3-b145-4fe0-864c-9001b2ec2706,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-c3823c33-4497-46c0-9755-dee03ababe25,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-8bcaee73-ba90-4e28-9fa3-2d0eff622cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-71e720b8-b3d1-484d-884f-c044294ac0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-1937a7d0-f0dd-4dfc-a9f6-ba051cc7ec46,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-63cf8b15-9216-40d3-aace-06c0a339426f,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-8a07e864-90d9-4344-bb09-bef9ff230482,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-02c43df6-84d8-44e1-bd5e-4775ae9ba383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133138943-172.17.0.14-1597055478165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45610,DS-b162fea3-b145-4fe0-864c-9001b2ec2706,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-c3823c33-4497-46c0-9755-dee03ababe25,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-8bcaee73-ba90-4e28-9fa3-2d0eff622cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-71e720b8-b3d1-484d-884f-c044294ac0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-1937a7d0-f0dd-4dfc-a9f6-ba051cc7ec46,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-63cf8b15-9216-40d3-aace-06c0a339426f,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-8a07e864-90d9-4344-bb09-bef9ff230482,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-02c43df6-84d8-44e1-bd5e-4775ae9ba383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358491743-172.17.0.14-1597056071724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-a1b5dbc7-9a9b-44d8-a1f7-d16b43cb40e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-2a7a4c46-04f0-4be3-9aa5-cb1e76828f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-a5cd6042-f825-421f-b707-20868bd3c079,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-ef4fe94a-c5d1-44f4-949d-725d4dcfc55e,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-8cbb7b88-7cb6-454a-8fa7-4a2eda0aeece,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-455cfa77-8e18-4db4-867c-29351747fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-1f63a06e-4bc0-463f-88a4-396c6c699d92,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-9036f6b0-817e-4fcc-bd81-3e8ae149b42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358491743-172.17.0.14-1597056071724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-a1b5dbc7-9a9b-44d8-a1f7-d16b43cb40e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-2a7a4c46-04f0-4be3-9aa5-cb1e76828f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-a5cd6042-f825-421f-b707-20868bd3c079,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-ef4fe94a-c5d1-44f4-949d-725d4dcfc55e,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-8cbb7b88-7cb6-454a-8fa7-4a2eda0aeece,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-455cfa77-8e18-4db4-867c-29351747fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-1f63a06e-4bc0-463f-88a4-396c6c699d92,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-9036f6b0-817e-4fcc-bd81-3e8ae149b42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107669542-172.17.0.14-1597056335344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-d2c686e7-a0cd-4054-915b-723f2665f066,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-6858ee0e-826d-4806-9cec-f992c116b33e,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-2a06876f-2002-4f00-8f88-9cef84a7c768,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-c3c76b40-ea33-4728-b728-1213fc290bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-a21807ea-86e3-46d2-8d69-ee171dffffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-0bf29bd7-89ae-4cc4-ae4c-5bb0f7c5773c,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-9268366f-0e72-4105-963c-9f9f07c93194,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-6cf392e1-eb48-48b2-9b2e-062d68a0c152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107669542-172.17.0.14-1597056335344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-d2c686e7-a0cd-4054-915b-723f2665f066,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-6858ee0e-826d-4806-9cec-f992c116b33e,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-2a06876f-2002-4f00-8f88-9cef84a7c768,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-c3c76b40-ea33-4728-b728-1213fc290bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-a21807ea-86e3-46d2-8d69-ee171dffffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-0bf29bd7-89ae-4cc4-ae4c-5bb0f7c5773c,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-9268366f-0e72-4105-963c-9f9f07c93194,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-6cf392e1-eb48-48b2-9b2e-062d68a0c152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657068647-172.17.0.14-1597056766134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45048,DS-7881bec9-2f8d-4da1-b78c-bfb8c9d35b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-9726183a-10d8-4e8e-9c18-cc06207d4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-47276088-0a09-43f0-8ac9-69a9beee672b,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-12003741-cb52-4cff-a7cb-3fe259ae7144,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-7ee99753-cabe-44f5-92d4-17fa5fe9fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-b739ded0-d7bf-44c5-9f4e-784420081201,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-3aa8579a-743c-4b20-aabd-def3007d81dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-f425aa24-9a7e-467b-851c-3b8fa0eba4a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657068647-172.17.0.14-1597056766134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45048,DS-7881bec9-2f8d-4da1-b78c-bfb8c9d35b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-9726183a-10d8-4e8e-9c18-cc06207d4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-47276088-0a09-43f0-8ac9-69a9beee672b,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-12003741-cb52-4cff-a7cb-3fe259ae7144,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-7ee99753-cabe-44f5-92d4-17fa5fe9fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-b739ded0-d7bf-44c5-9f4e-784420081201,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-3aa8579a-743c-4b20-aabd-def3007d81dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-f425aa24-9a7e-467b-851c-3b8fa0eba4a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5205
