reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187148113-172.17.0.17-1597113341560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45153,DS-b6eb95bd-770d-46ba-964d-1100c4c93563,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-9f8f8c27-f5bd-4ed4-bd14-4014312f2b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-8aada7a8-4d78-4b05-b69a-90bfab6eb294,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-dd1616eb-e8a4-4242-9c4b-6f242a0ddcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-1d514c96-27ac-4ab8-9d88-25be9b5a7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-560ab4d3-38b2-4547-b456-08098d578e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-3a35d4d6-5911-4be2-af05-d538583c1940,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-262e039c-c439-470d-b0fb-9e6451aae8a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187148113-172.17.0.17-1597113341560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45153,DS-b6eb95bd-770d-46ba-964d-1100c4c93563,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-9f8f8c27-f5bd-4ed4-bd14-4014312f2b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-8aada7a8-4d78-4b05-b69a-90bfab6eb294,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-dd1616eb-e8a4-4242-9c4b-6f242a0ddcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-1d514c96-27ac-4ab8-9d88-25be9b5a7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-560ab4d3-38b2-4547-b456-08098d578e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-3a35d4d6-5911-4be2-af05-d538583c1940,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-262e039c-c439-470d-b0fb-9e6451aae8a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777186963-172.17.0.17-1597113376458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-f04ac4f7-2bf6-4816-a1d5-b0d3aeceaed2,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-baf40860-a4b0-41a8-a6fc-a94dc5877f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-8306bdf1-49a8-4ccc-b3e1-b78cbcdbcb61,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-ccb0e0a9-8895-4c6a-8518-11bc47ad4e06,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-9b53c136-baff-471d-aa39-91082353c411,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-5f93bf07-be58-44c8-83bf-a12d1783fe24,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-1935da62-9d57-4805-8e35-2ac88fc9d1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-960aff15-0a7b-44ee-a90e-b81118820a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777186963-172.17.0.17-1597113376458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-f04ac4f7-2bf6-4816-a1d5-b0d3aeceaed2,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-baf40860-a4b0-41a8-a6fc-a94dc5877f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-8306bdf1-49a8-4ccc-b3e1-b78cbcdbcb61,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-ccb0e0a9-8895-4c6a-8518-11bc47ad4e06,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-9b53c136-baff-471d-aa39-91082353c411,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-5f93bf07-be58-44c8-83bf-a12d1783fe24,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-1935da62-9d57-4805-8e35-2ac88fc9d1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-960aff15-0a7b-44ee-a90e-b81118820a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669833096-172.17.0.17-1597113413214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37521,DS-e7f72a79-8bf2-4f42-9bd6-466d0370e44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-5f8747ce-6ec2-4ec7-a041-caa5ed26af8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-2abb4407-67f5-4fb3-b6a6-885d813bead9,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-a762a334-cd51-49c6-9ee3-d913e643442b,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-92734b35-c3f8-4d19-ae40-270e9b026733,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-8000313c-9a67-4cb3-9613-1228b40ac570,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-7f75e013-dcc9-4a39-9113-fb1afa88829c,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-3f24cc5b-078f-4c49-af90-7a5cef648ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669833096-172.17.0.17-1597113413214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37521,DS-e7f72a79-8bf2-4f42-9bd6-466d0370e44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-5f8747ce-6ec2-4ec7-a041-caa5ed26af8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-2abb4407-67f5-4fb3-b6a6-885d813bead9,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-a762a334-cd51-49c6-9ee3-d913e643442b,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-92734b35-c3f8-4d19-ae40-270e9b026733,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-8000313c-9a67-4cb3-9613-1228b40ac570,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-7f75e013-dcc9-4a39-9113-fb1afa88829c,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-3f24cc5b-078f-4c49-af90-7a5cef648ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358032514-172.17.0.17-1597113448916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-49d847f5-2ca8-4ccc-a0f4-486586ebe8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-e1dbb41e-2ee1-4c73-91e8-7993975d1cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-107d8617-3bc6-4ff7-938a-a15cf1e89967,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-5ba7930c-a135-444c-86cb-d8f92ea4ddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-1528af3e-74c1-470c-9ee3-28935c146aba,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-bbd6e5ff-ecc8-460b-8584-2dfaa589c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-562a741d-eb58-44cb-8deb-70aadd9ed7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-fb88c7dd-ca00-49dd-b412-57806c41d6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358032514-172.17.0.17-1597113448916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-49d847f5-2ca8-4ccc-a0f4-486586ebe8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-e1dbb41e-2ee1-4c73-91e8-7993975d1cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-107d8617-3bc6-4ff7-938a-a15cf1e89967,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-5ba7930c-a135-444c-86cb-d8f92ea4ddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-1528af3e-74c1-470c-9ee3-28935c146aba,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-bbd6e5ff-ecc8-460b-8584-2dfaa589c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-562a741d-eb58-44cb-8deb-70aadd9ed7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-fb88c7dd-ca00-49dd-b412-57806c41d6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430080743-172.17.0.17-1597113630794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42027,DS-038fccbf-2d7f-43db-b88c-30c32e4580d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-81e69a89-fbe3-4f4f-833f-d4d973173caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-6eab823d-871d-441a-8672-5279901ff59c,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-99bd607d-6f03-4d3b-983b-285f2ac5446c,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-3cd75ac2-7a50-4985-ab7b-145b1c26a387,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-8ac2c050-04e1-41e3-aac7-0499358227ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-13b3f14b-bcac-4802-909a-27308146cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-1979db3b-a27e-47c9-9a62-fd242dea9725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430080743-172.17.0.17-1597113630794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42027,DS-038fccbf-2d7f-43db-b88c-30c32e4580d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-81e69a89-fbe3-4f4f-833f-d4d973173caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-6eab823d-871d-441a-8672-5279901ff59c,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-99bd607d-6f03-4d3b-983b-285f2ac5446c,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-3cd75ac2-7a50-4985-ab7b-145b1c26a387,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-8ac2c050-04e1-41e3-aac7-0499358227ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-13b3f14b-bcac-4802-909a-27308146cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-1979db3b-a27e-47c9-9a62-fd242dea9725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187690685-172.17.0.17-1597113800299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-2912ea3d-99da-48e1-9805-2f751da8e721,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-74fb8cf5-2914-46b7-85fd-edf88668dd49,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-03268dec-9f2c-4786-9400-a8622ad404d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-eaff4385-4335-460a-9bf5-a8b7be126e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-6efea052-cdd9-433a-a3c5-ff2833845c60,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-b8311511-190e-444d-a6a5-9ad1f7f423a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-f13d738f-d401-4088-8563-350fb306fd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-34225b5b-b2da-4f0c-aa25-49a80f648785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187690685-172.17.0.17-1597113800299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-2912ea3d-99da-48e1-9805-2f751da8e721,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-74fb8cf5-2914-46b7-85fd-edf88668dd49,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-03268dec-9f2c-4786-9400-a8622ad404d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-eaff4385-4335-460a-9bf5-a8b7be126e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-6efea052-cdd9-433a-a3c5-ff2833845c60,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-b8311511-190e-444d-a6a5-9ad1f7f423a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-f13d738f-d401-4088-8563-350fb306fd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-34225b5b-b2da-4f0c-aa25-49a80f648785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521300751-172.17.0.17-1597114009750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-308fdce8-665c-4f7c-928f-98e490c9303d,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-1a05804c-8d20-4047-9d8b-63ee03869091,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-376ff4c3-78be-4cc1-8910-44263e14d0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-7f63ef30-a2ed-4a84-8ec3-ffa6b925b0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-624f59f4-e692-49ac-b6e2-4ca6ae71167a,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-ea620a99-0cca-45f4-bfdc-f1dd00a16a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-31c34fb5-7b59-4b76-9a34-3e4127a1057a,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-1a452fe3-065b-4815-8468-367024836b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521300751-172.17.0.17-1597114009750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-308fdce8-665c-4f7c-928f-98e490c9303d,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-1a05804c-8d20-4047-9d8b-63ee03869091,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-376ff4c3-78be-4cc1-8910-44263e14d0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-7f63ef30-a2ed-4a84-8ec3-ffa6b925b0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-624f59f4-e692-49ac-b6e2-4ca6ae71167a,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-ea620a99-0cca-45f4-bfdc-f1dd00a16a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-31c34fb5-7b59-4b76-9a34-3e4127a1057a,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-1a452fe3-065b-4815-8468-367024836b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310793026-172.17.0.17-1597114042994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44298,DS-94d1692f-0e0d-4df7-af5e-e47ca6ddceae,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-817213f5-7466-40d4-9b34-2d32cd2b7ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-618ac70a-10a5-4736-ac2c-58d3b376bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-0d5268bc-0c1f-440d-ba9b-c2bbc28f498b,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-3f497880-964f-49ca-a142-75cc9aca6b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-eb36d3ce-e9b8-4ffe-ae33-dcb75946ea6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-add54c17-0a02-4cf4-b698-bf4f7092334f,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-3ad4e1f7-e554-4f66-8221-656191958dce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310793026-172.17.0.17-1597114042994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44298,DS-94d1692f-0e0d-4df7-af5e-e47ca6ddceae,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-817213f5-7466-40d4-9b34-2d32cd2b7ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-618ac70a-10a5-4736-ac2c-58d3b376bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-0d5268bc-0c1f-440d-ba9b-c2bbc28f498b,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-3f497880-964f-49ca-a142-75cc9aca6b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-eb36d3ce-e9b8-4ffe-ae33-dcb75946ea6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-add54c17-0a02-4cf4-b698-bf4f7092334f,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-3ad4e1f7-e554-4f66-8221-656191958dce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767903199-172.17.0.17-1597114107192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-e672a936-36b8-4b47-98e5-c6c4c5c2a110,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-c469cca0-13c9-479f-ad47-6dc768612d62,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-901b0e77-3b2f-4cd5-a220-82c0a2e5e40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-51853f1f-748a-4741-8750-19c4a9973e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-2ee4a07d-fa0d-45e0-8902-6d0af62d5b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-c437a6f0-04af-44fa-be26-436600eb3db1,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-3fd58665-52b5-48a8-844b-73657a81d092,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-dd88f808-310b-4839-a905-bdd72a27174c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767903199-172.17.0.17-1597114107192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-e672a936-36b8-4b47-98e5-c6c4c5c2a110,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-c469cca0-13c9-479f-ad47-6dc768612d62,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-901b0e77-3b2f-4cd5-a220-82c0a2e5e40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-51853f1f-748a-4741-8750-19c4a9973e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-2ee4a07d-fa0d-45e0-8902-6d0af62d5b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-c437a6f0-04af-44fa-be26-436600eb3db1,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-3fd58665-52b5-48a8-844b-73657a81d092,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-dd88f808-310b-4839-a905-bdd72a27174c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905989839-172.17.0.17-1597114505126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-77e29026-c176-4669-8d7a-375218f740b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-a8118465-e20b-4c83-9af0-93c20b864110,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-2ec99122-1da4-46d7-80c4-6cb18dbfdd58,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-d3fef25e-79fd-4e38-8fa2-65b53a5fbfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-0b0c2037-6f8f-4212-9274-ed98f2f5b530,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-c9592f0e-7278-460d-b2af-db05d6b522a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-69d95a9e-4543-40c3-ab58-23720267ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-d228468c-0635-47d8-9ac9-0a2f516f8ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905989839-172.17.0.17-1597114505126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-77e29026-c176-4669-8d7a-375218f740b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-a8118465-e20b-4c83-9af0-93c20b864110,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-2ec99122-1da4-46d7-80c4-6cb18dbfdd58,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-d3fef25e-79fd-4e38-8fa2-65b53a5fbfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-0b0c2037-6f8f-4212-9274-ed98f2f5b530,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-c9592f0e-7278-460d-b2af-db05d6b522a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-69d95a9e-4543-40c3-ab58-23720267ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-d228468c-0635-47d8-9ac9-0a2f516f8ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258241600-172.17.0.17-1597114644828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35643,DS-e7305da2-4c2c-4116-bb5c-7f5357b8336c,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-947641bd-68e5-49f9-8556-6bc4d9d75bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-3d0ba3bc-2b88-4736-ae99-a2eda06bad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-b59df865-dcda-425b-bb04-4d4fb4f40ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-2d2a5302-e28e-401e-ab91-5ffb6f64a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-ef2615ef-39c8-48d1-887c-6d334e90e2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-3bd68a6a-a59d-4b35-b66e-cc28281ff2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-9313d5c2-c19e-4883-b8cc-fc73f79e9f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258241600-172.17.0.17-1597114644828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35643,DS-e7305da2-4c2c-4116-bb5c-7f5357b8336c,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-947641bd-68e5-49f9-8556-6bc4d9d75bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-3d0ba3bc-2b88-4736-ae99-a2eda06bad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-b59df865-dcda-425b-bb04-4d4fb4f40ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-2d2a5302-e28e-401e-ab91-5ffb6f64a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-ef2615ef-39c8-48d1-887c-6d334e90e2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-3bd68a6a-a59d-4b35-b66e-cc28281ff2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-9313d5c2-c19e-4883-b8cc-fc73f79e9f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948168535-172.17.0.17-1597115217672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-518e343c-70b6-48bc-b96d-60c2069c8f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-329ce05b-2398-4f89-945f-4faa13d1f78d,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-ad0bf308-3d47-4df1-b2a4-13e73a89c962,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-fd780ec2-e6fc-4b7e-8bd5-2c0724523308,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-8d75d966-d844-4e69-b873-7553c7fa3034,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-60020de6-4b44-4d0a-9611-988f0fb052aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-d156b258-e2e8-4cce-bec3-95d6bdcac582,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-6b0247d1-c231-499c-9da8-7250f0952873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948168535-172.17.0.17-1597115217672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-518e343c-70b6-48bc-b96d-60c2069c8f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-329ce05b-2398-4f89-945f-4faa13d1f78d,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-ad0bf308-3d47-4df1-b2a4-13e73a89c962,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-fd780ec2-e6fc-4b7e-8bd5-2c0724523308,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-8d75d966-d844-4e69-b873-7553c7fa3034,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-60020de6-4b44-4d0a-9611-988f0fb052aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-d156b258-e2e8-4cce-bec3-95d6bdcac582,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-6b0247d1-c231-499c-9da8-7250f0952873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694677637-172.17.0.17-1597115246075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-3618e686-acc1-4dd7-8cf0-1d0688f13d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-08d2fde7-427c-44c5-b9e9-d0d4d0b27f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-85ab9dad-dfe9-4b31-b09d-91ca1a0895da,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-b2c02af3-d40c-46d0-a878-3bb4abc66881,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-6b960a2f-9f71-431f-90df-b8cf1455787a,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-de5216bb-091b-43ad-8215-bd8c02a51e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-f2a6fcd8-7614-4c23-85ac-7f0fb99d93c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-9e76cc14-d932-4479-a9da-3c7ceb712942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694677637-172.17.0.17-1597115246075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-3618e686-acc1-4dd7-8cf0-1d0688f13d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-08d2fde7-427c-44c5-b9e9-d0d4d0b27f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-85ab9dad-dfe9-4b31-b09d-91ca1a0895da,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-b2c02af3-d40c-46d0-a878-3bb4abc66881,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-6b960a2f-9f71-431f-90df-b8cf1455787a,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-de5216bb-091b-43ad-8215-bd8c02a51e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-f2a6fcd8-7614-4c23-85ac-7f0fb99d93c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-9e76cc14-d932-4479-a9da-3c7ceb712942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591581608-172.17.0.17-1597115402672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44100,DS-e5c62e96-8c6e-4088-95fd-b17e295ce635,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-be8ca2af-6052-4bb4-afb4-2fb84721b836,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-68c66754-bcef-4a44-8798-94574943af2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-0329f128-c875-4faa-879f-73ebe656ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-b300743a-7389-43a1-932e-b98b026e681c,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-28334005-be5b-4a2d-bc59-2037e5922f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-6e9b3738-9a5e-42f5-b2a2-1100f2564c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-c10b3f3d-038f-4482-8922-b13da595f170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591581608-172.17.0.17-1597115402672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44100,DS-e5c62e96-8c6e-4088-95fd-b17e295ce635,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-be8ca2af-6052-4bb4-afb4-2fb84721b836,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-68c66754-bcef-4a44-8798-94574943af2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-0329f128-c875-4faa-879f-73ebe656ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-b300743a-7389-43a1-932e-b98b026e681c,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-28334005-be5b-4a2d-bc59-2037e5922f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-6e9b3738-9a5e-42f5-b2a2-1100f2564c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-c10b3f3d-038f-4482-8922-b13da595f170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034995926-172.17.0.17-1597115659679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-b7b88c18-1b40-4c64-89f4-5a0c8c69bcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-fa191ad4-a21b-4c4a-bcd8-fb46a3d059e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-79907300-58ab-4eb7-9beb-335e6e86212d,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-1d389d3d-7ea0-4ca2-8efc-35d7153ee02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-3dbc2eca-277a-45c0-9f7f-955cbdbbbad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-98e32be1-e1cd-46f8-85a5-a06da03b0450,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-5b903b09-0bc3-40fb-96ab-5a0d27f0fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-2a6e9c4e-f019-4fde-bf07-5ea79a1f3377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034995926-172.17.0.17-1597115659679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-b7b88c18-1b40-4c64-89f4-5a0c8c69bcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-fa191ad4-a21b-4c4a-bcd8-fb46a3d059e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-79907300-58ab-4eb7-9beb-335e6e86212d,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-1d389d3d-7ea0-4ca2-8efc-35d7153ee02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-3dbc2eca-277a-45c0-9f7f-955cbdbbbad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-98e32be1-e1cd-46f8-85a5-a06da03b0450,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-5b903b09-0bc3-40fb-96ab-5a0d27f0fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-2a6e9c4e-f019-4fde-bf07-5ea79a1f3377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994316272-172.17.0.17-1597115696845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33521,DS-cde8d533-1878-496a-96d7-4d4064eaee78,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-eae62263-1845-40e5-bf2e-623e8086d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-a2e83dd8-7d2b-43d3-a810-4bab1989cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-fc1bd86c-0117-4a2f-9192-5b28bc98ca66,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-17bcb992-ee8d-4e39-971f-44a248f035ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-f29afcd0-e723-40fb-b9da-96ecd23cb531,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-ad2f9c3e-9201-42bd-8f0e-39ecb1af465a,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-feef1ac2-9323-423e-bc5f-ab49a8d4fe19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994316272-172.17.0.17-1597115696845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33521,DS-cde8d533-1878-496a-96d7-4d4064eaee78,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-eae62263-1845-40e5-bf2e-623e8086d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-a2e83dd8-7d2b-43d3-a810-4bab1989cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-fc1bd86c-0117-4a2f-9192-5b28bc98ca66,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-17bcb992-ee8d-4e39-971f-44a248f035ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-f29afcd0-e723-40fb-b9da-96ecd23cb531,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-ad2f9c3e-9201-42bd-8f0e-39ecb1af465a,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-feef1ac2-9323-423e-bc5f-ab49a8d4fe19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493618523-172.17.0.17-1597115918730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-33257a86-d339-4cd1-be78-ea267df53d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-d0e21786-3b15-4c56-b996-00e152e0b88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-c606af79-3cc6-488d-860b-5f03941f5537,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-fe9edbcd-d21f-4091-bf35-3c827db0a23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-77d6e4ab-11f8-4977-ad65-f3f7b4b60546,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-ce389663-7061-4882-9ede-17da7c8d9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-8629f4fa-309b-440a-b67f-a8ee719be791,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-c8a0fe56-99b9-48d7-bee4-5fea99dd489a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493618523-172.17.0.17-1597115918730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-33257a86-d339-4cd1-be78-ea267df53d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-d0e21786-3b15-4c56-b996-00e152e0b88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-c606af79-3cc6-488d-860b-5f03941f5537,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-fe9edbcd-d21f-4091-bf35-3c827db0a23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-77d6e4ab-11f8-4977-ad65-f3f7b4b60546,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-ce389663-7061-4882-9ede-17da7c8d9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-8629f4fa-309b-440a-b67f-a8ee719be791,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-c8a0fe56-99b9-48d7-bee4-5fea99dd489a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969607415-172.17.0.17-1597115945140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-8d242801-015f-4240-b24b-4cab5b119ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-b7a7b918-977c-480b-8af7-e1ca6bb68409,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-4814a01b-b2ea-4c6a-aa0c-0b934b78ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-073d9eb8-e4be-4bdd-901a-cc11f6197f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-b23c07bd-04f2-45de-82f8-66e3e3c2989d,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-ba1b8672-b730-4551-b9a5-b08ba5675c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-fb245106-b1db-4e59-b57c-2c3882d46628,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-b51dd308-8007-4350-ba62-2af1296711d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969607415-172.17.0.17-1597115945140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-8d242801-015f-4240-b24b-4cab5b119ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-b7a7b918-977c-480b-8af7-e1ca6bb68409,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-4814a01b-b2ea-4c6a-aa0c-0b934b78ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-073d9eb8-e4be-4bdd-901a-cc11f6197f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-b23c07bd-04f2-45de-82f8-66e3e3c2989d,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-ba1b8672-b730-4551-b9a5-b08ba5675c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-fb245106-b1db-4e59-b57c-2c3882d46628,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-b51dd308-8007-4350-ba62-2af1296711d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702507756-172.17.0.17-1597116512395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38618,DS-dd410e08-21c0-4d2d-913f-ab4c827b2102,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-eafdf739-0322-4f86-8e8c-127cb96e20b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-414f3180-0e9f-4e09-80cc-59df40e3cdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-494f61a7-626f-44d5-9067-26b78fcf1a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-41cb5d02-c4f0-46c3-a3df-c4996f3db41f,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-e591b0a9-9871-413d-aa48-7d95255b33e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-d594320d-5306-43c1-8a5a-a3bd90630d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-b8911519-1977-4c7b-b55f-b50269a98020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702507756-172.17.0.17-1597116512395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38618,DS-dd410e08-21c0-4d2d-913f-ab4c827b2102,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-eafdf739-0322-4f86-8e8c-127cb96e20b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-414f3180-0e9f-4e09-80cc-59df40e3cdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-494f61a7-626f-44d5-9067-26b78fcf1a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-41cb5d02-c4f0-46c3-a3df-c4996f3db41f,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-e591b0a9-9871-413d-aa48-7d95255b33e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-d594320d-5306-43c1-8a5a-a3bd90630d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-b8911519-1977-4c7b-b55f-b50269a98020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384791196-172.17.0.17-1597116873623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41360,DS-75fdbb03-ce2a-4774-937a-2bab02670d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-61f9dde7-a449-4fd3-9008-67a071087843,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-380c3e3d-263b-4e6f-ad81-8f7a75c87ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-f7380bc1-b033-4f39-8fe0-08e317f97aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-d1e559d7-0001-4f5c-a80d-aabb54ee1f25,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-9202a7ee-9dba-4038-a61d-5728cf5e5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-d245d683-2ae7-4e00-814c-2162c98e0ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-176c77f6-9a78-40ab-b39f-c5e0d7075e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384791196-172.17.0.17-1597116873623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41360,DS-75fdbb03-ce2a-4774-937a-2bab02670d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-61f9dde7-a449-4fd3-9008-67a071087843,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-380c3e3d-263b-4e6f-ad81-8f7a75c87ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-f7380bc1-b033-4f39-8fe0-08e317f97aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-d1e559d7-0001-4f5c-a80d-aabb54ee1f25,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-9202a7ee-9dba-4038-a61d-5728cf5e5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-d245d683-2ae7-4e00-814c-2162c98e0ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-176c77f6-9a78-40ab-b39f-c5e0d7075e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365223749-172.17.0.17-1597117015369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45553,DS-53ccba9e-3d18-4dba-ba64-6b6479f72a29,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-5f923b6e-982e-4cf4-a405-316d0278314e,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-aeaec6f7-1ef5-47df-b7ef-09be42fa8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-e8a17902-6874-4f65-8d40-1033aeec5bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-9002269a-6557-45c8-ac89-956effc8c469,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-8cac3e7c-7751-4008-a842-28302cb8c318,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-4b47278a-9c24-4470-8170-3a4d83d5e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-3f6d5906-ac61-4520-b223-77fb08f0e8e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365223749-172.17.0.17-1597117015369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45553,DS-53ccba9e-3d18-4dba-ba64-6b6479f72a29,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-5f923b6e-982e-4cf4-a405-316d0278314e,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-aeaec6f7-1ef5-47df-b7ef-09be42fa8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-e8a17902-6874-4f65-8d40-1033aeec5bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-9002269a-6557-45c8-ac89-956effc8c469,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-8cac3e7c-7751-4008-a842-28302cb8c318,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-4b47278a-9c24-4470-8170-3a4d83d5e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-3f6d5906-ac61-4520-b223-77fb08f0e8e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357839327-172.17.0.17-1597117602631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35183,DS-09b7d3ad-fcaa-4fa8-8063-e749c4690402,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-03167007-74e7-4d4a-8d2e-224c6a79733a,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-1d0afd28-747c-47c0-b005-783f84cfde47,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-7191abae-a41c-4f18-a1b3-7a56e9a4f354,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-f8698274-300c-410d-85d2-107d2ea4ded0,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-b73bf14d-f39e-4a40-9036-b9c1e14e53ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-9a3aaedc-5022-4868-9c43-15edc1f6c6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-b25a0724-a651-4bc4-9647-8b135566a49e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357839327-172.17.0.17-1597117602631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35183,DS-09b7d3ad-fcaa-4fa8-8063-e749c4690402,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-03167007-74e7-4d4a-8d2e-224c6a79733a,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-1d0afd28-747c-47c0-b005-783f84cfde47,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-7191abae-a41c-4f18-a1b3-7a56e9a4f354,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-f8698274-300c-410d-85d2-107d2ea4ded0,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-b73bf14d-f39e-4a40-9036-b9c1e14e53ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-9a3aaedc-5022-4868-9c43-15edc1f6c6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-b25a0724-a651-4bc4-9647-8b135566a49e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5065
