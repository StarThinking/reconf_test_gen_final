reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433325274-172.17.0.7-1597095010945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-fec0335a-0354-4176-9e3a-0d5b14f563df,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-c085a175-fb2a-4296-a3a8-fbf555a06c57,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-f240ace0-30d8-4aaa-96f9-bae41f401bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-e5b49e80-d091-4f39-b74c-7bc10b986865,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-3b49d54a-be4e-4c64-9a38-3f4e3bf7aeae,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-3e4a681d-e8f5-4d44-bcbf-9ae6f1acddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-b35f25ca-1c82-4e02-aa2f-5b64f42d6047,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-f12b8c47-0691-4212-b040-61d02894aa02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433325274-172.17.0.7-1597095010945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-fec0335a-0354-4176-9e3a-0d5b14f563df,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-c085a175-fb2a-4296-a3a8-fbf555a06c57,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-f240ace0-30d8-4aaa-96f9-bae41f401bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-e5b49e80-d091-4f39-b74c-7bc10b986865,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-3b49d54a-be4e-4c64-9a38-3f4e3bf7aeae,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-3e4a681d-e8f5-4d44-bcbf-9ae6f1acddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-b35f25ca-1c82-4e02-aa2f-5b64f42d6047,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-f12b8c47-0691-4212-b040-61d02894aa02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404790213-172.17.0.7-1597095785484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-44b76903-a92c-4075-ba5d-3bade7e8de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-529eeb7d-cdd6-454d-bf89-86533ca7621a,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-229cff0c-3bee-42d4-994b-0ff01829d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-0089ac54-1b66-4d6f-a02b-903e41583382,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-03f4514b-9967-42a2-962c-996a6ced1204,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-ae080ae1-3de2-4387-998b-c99803635500,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-38a55ba3-0782-4b9f-b092-2beda65f4596,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-1907fb5c-ac83-438f-9888-87de62f10158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404790213-172.17.0.7-1597095785484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-44b76903-a92c-4075-ba5d-3bade7e8de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-529eeb7d-cdd6-454d-bf89-86533ca7621a,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-229cff0c-3bee-42d4-994b-0ff01829d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-0089ac54-1b66-4d6f-a02b-903e41583382,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-03f4514b-9967-42a2-962c-996a6ced1204,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-ae080ae1-3de2-4387-998b-c99803635500,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-38a55ba3-0782-4b9f-b092-2beda65f4596,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-1907fb5c-ac83-438f-9888-87de62f10158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312280367-172.17.0.7-1597096360393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35948,DS-ff1f140e-da76-4d8c-bb92-c33cd18b4f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-49305d16-32da-4971-b866-e8dbe7c3cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-5a9b0fc0-1a0d-486b-acce-51597ac4497e,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-3b67c243-3a39-41bd-826e-be3387ba7bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-529a8547-fbd0-4b5d-ac77-db4543b0707f,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-154f87ad-a16e-4331-9222-9c586be74d60,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-53f57520-6608-422a-a436-f216103f3bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-da373aaa-8933-44f8-be80-74bbc635f861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312280367-172.17.0.7-1597096360393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35948,DS-ff1f140e-da76-4d8c-bb92-c33cd18b4f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-49305d16-32da-4971-b866-e8dbe7c3cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-5a9b0fc0-1a0d-486b-acce-51597ac4497e,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-3b67c243-3a39-41bd-826e-be3387ba7bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-529a8547-fbd0-4b5d-ac77-db4543b0707f,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-154f87ad-a16e-4331-9222-9c586be74d60,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-53f57520-6608-422a-a436-f216103f3bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-da373aaa-8933-44f8-be80-74bbc635f861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6028060-172.17.0.7-1597096721549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-2a71a4d7-abd5-4283-9535-32f5f88f8e06,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-38f2b3e9-d4ce-42c3-b9a7-7b44c2944fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-022c3886-1e1d-45dd-a6f1-dd57c2116de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-3a319a70-94cc-4f42-9593-97ef29cc3295,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-56215f87-26f6-421d-8d00-5a3966abeb61,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-f916b572-a380-45be-8478-99f6c80dbd98,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-68d11aa3-b115-47a5-9c89-1879f199e4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-d016e496-3527-4365-a9db-7b985bdc1dd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6028060-172.17.0.7-1597096721549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-2a71a4d7-abd5-4283-9535-32f5f88f8e06,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-38f2b3e9-d4ce-42c3-b9a7-7b44c2944fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-022c3886-1e1d-45dd-a6f1-dd57c2116de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-3a319a70-94cc-4f42-9593-97ef29cc3295,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-56215f87-26f6-421d-8d00-5a3966abeb61,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-f916b572-a380-45be-8478-99f6c80dbd98,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-68d11aa3-b115-47a5-9c89-1879f199e4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-d016e496-3527-4365-a9db-7b985bdc1dd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157890122-172.17.0.7-1597097024690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40580,DS-4ae82e76-c1eb-42b8-85c8-c765b2dc550d,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-4824a19e-f0e7-4011-8468-efd14d3efdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-5ef619d0-2254-4c40-9d38-53198ce50c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-a7ed736e-54c9-4a7e-a7b1-d3667bdf7ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-a8aa382c-87b0-44b4-8314-750e1cb2aec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-86c16df1-1882-467c-9e7f-2ccbf387ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-2ffe7fd5-e7ad-469a-9a85-3b9c7042a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-c69bb903-ec16-4726-b119-06d453e8e1d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157890122-172.17.0.7-1597097024690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40580,DS-4ae82e76-c1eb-42b8-85c8-c765b2dc550d,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-4824a19e-f0e7-4011-8468-efd14d3efdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-5ef619d0-2254-4c40-9d38-53198ce50c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-a7ed736e-54c9-4a7e-a7b1-d3667bdf7ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-a8aa382c-87b0-44b4-8314-750e1cb2aec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-86c16df1-1882-467c-9e7f-2ccbf387ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-2ffe7fd5-e7ad-469a-9a85-3b9c7042a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-c69bb903-ec16-4726-b119-06d453e8e1d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010560468-172.17.0.7-1597097057495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38486,DS-bb1b3992-87d6-449b-9bba-a11f3c2412aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-67c5d531-cb52-42d7-8013-462470a3117f,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-c4790a91-0f8f-4629-8851-91fda53c3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-c9ce95a4-4c9e-46ee-a322-b8f1694d4bed,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-6efda935-6ec5-42fc-b4e3-237ae5570c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-26a6abfd-f174-4694-bbd1-7da444d5e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-79d4b094-9405-4a13-972d-fb8a6994ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-c48cb2d9-2b55-401a-bf7a-d884933658e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010560468-172.17.0.7-1597097057495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38486,DS-bb1b3992-87d6-449b-9bba-a11f3c2412aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-67c5d531-cb52-42d7-8013-462470a3117f,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-c4790a91-0f8f-4629-8851-91fda53c3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-c9ce95a4-4c9e-46ee-a322-b8f1694d4bed,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-6efda935-6ec5-42fc-b4e3-237ae5570c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-26a6abfd-f174-4694-bbd1-7da444d5e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-79d4b094-9405-4a13-972d-fb8a6994ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-c48cb2d9-2b55-401a-bf7a-d884933658e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997548466-172.17.0.7-1597098114842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46586,DS-d46c8133-25d3-48dc-9581-d5e3f8633b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-4d452777-13ff-43a6-a820-1fd41d2c3fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-1edd88ef-7a49-4c77-8daa-1c2b6b799028,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-61fda51b-102f-4498-8afc-0e30a7658887,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-46bd43c1-37fb-42d2-8a46-fb981bc92cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-1faf138a-77f1-4b8a-82dd-7e97ad06f975,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-60bff5ac-0091-4935-930d-6dc11a426adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-5488f7d7-5e70-47bc-a73d-ee706efcac73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997548466-172.17.0.7-1597098114842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46586,DS-d46c8133-25d3-48dc-9581-d5e3f8633b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-4d452777-13ff-43a6-a820-1fd41d2c3fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-1edd88ef-7a49-4c77-8daa-1c2b6b799028,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-61fda51b-102f-4498-8afc-0e30a7658887,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-46bd43c1-37fb-42d2-8a46-fb981bc92cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-1faf138a-77f1-4b8a-82dd-7e97ad06f975,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-60bff5ac-0091-4935-930d-6dc11a426adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-5488f7d7-5e70-47bc-a73d-ee706efcac73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377764785-172.17.0.7-1597098141457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-5d66f747-353c-4226-be6c-a34c44ea8901,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-4152a428-58c6-4f54-a841-7b038362f4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-27ddba6b-12fe-4295-9e3b-fb6ad8473976,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-c64a8b4b-6b51-40eb-9b60-4f62bf210761,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-0d90d2aa-f467-46d8-959d-78efa1413f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-eca31530-4282-4afd-80ad-929f12dd64e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-b95ca1b4-b463-4704-bbc5-94042edc7aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-0f25bd26-859a-4b27-b6e3-12a2e7d4132c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377764785-172.17.0.7-1597098141457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-5d66f747-353c-4226-be6c-a34c44ea8901,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-4152a428-58c6-4f54-a841-7b038362f4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-27ddba6b-12fe-4295-9e3b-fb6ad8473976,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-c64a8b4b-6b51-40eb-9b60-4f62bf210761,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-0d90d2aa-f467-46d8-959d-78efa1413f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-eca31530-4282-4afd-80ad-929f12dd64e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-b95ca1b4-b463-4704-bbc5-94042edc7aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-0f25bd26-859a-4b27-b6e3-12a2e7d4132c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948609029-172.17.0.7-1597098239340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-62fdcdcf-14e6-416d-863a-45e576c82291,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-a2504a1b-12c8-48f9-9234-c5cab3b0454c,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-66fcc7ea-9793-4f82-b7ad-a73957583840,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-c55dc48a-5944-4de1-acdd-3f3851b35a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-218995c6-a56a-48d1-8be2-b23bdf80f5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-603e17c4-760f-49dd-83f9-e7f7ccd44542,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-d6f12dc3-ad3f-4e01-9e79-1f51a6b1b368,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-61b148e1-3d63-4e85-824c-db3556f9652c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948609029-172.17.0.7-1597098239340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-62fdcdcf-14e6-416d-863a-45e576c82291,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-a2504a1b-12c8-48f9-9234-c5cab3b0454c,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-66fcc7ea-9793-4f82-b7ad-a73957583840,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-c55dc48a-5944-4de1-acdd-3f3851b35a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-218995c6-a56a-48d1-8be2-b23bdf80f5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-603e17c4-760f-49dd-83f9-e7f7ccd44542,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-d6f12dc3-ad3f-4e01-9e79-1f51a6b1b368,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-61b148e1-3d63-4e85-824c-db3556f9652c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238742510-172.17.0.7-1597098620373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-b2cacc6b-f32b-46b5-803b-da272ac28e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-2527b342-5be1-4f78-88cc-436b29b4d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-3b8455f7-b4e5-45fd-9234-5296c7476867,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-2ac43bdb-2860-4cf4-9f2c-b3d8fe8583ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-fc0aa1ed-e47b-4a89-be6e-4d97534bb63b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-521e845e-dd3c-40d2-97e3-645a29a4853a,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-a4993617-fe5e-4bd5-889e-1351de3180c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-6926044e-2f88-43e8-9450-8a7fe45148f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238742510-172.17.0.7-1597098620373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-b2cacc6b-f32b-46b5-803b-da272ac28e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-2527b342-5be1-4f78-88cc-436b29b4d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-3b8455f7-b4e5-45fd-9234-5296c7476867,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-2ac43bdb-2860-4cf4-9f2c-b3d8fe8583ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-fc0aa1ed-e47b-4a89-be6e-4d97534bb63b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-521e845e-dd3c-40d2-97e3-645a29a4853a,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-a4993617-fe5e-4bd5-889e-1351de3180c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-6926044e-2f88-43e8-9450-8a7fe45148f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022613022-172.17.0.7-1597098763329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37315,DS-d800784b-8a10-43a6-93ed-e2893e549cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-3ad73f05-559a-4ff7-89e8-329229994191,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-8b68a0f8-36cc-411e-9732-010cd0943a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-a158f7d2-7f53-4b3e-948f-b54d735c0b38,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-5a160ce9-5a6e-4b17-95da-e572290d7323,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-9e7f4079-a7e6-4980-b709-a68165071938,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-5fc25fd4-0522-4660-a248-65ee0a0b3795,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-7f6cbc82-2081-4575-bdb1-5967ebc068d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022613022-172.17.0.7-1597098763329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37315,DS-d800784b-8a10-43a6-93ed-e2893e549cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-3ad73f05-559a-4ff7-89e8-329229994191,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-8b68a0f8-36cc-411e-9732-010cd0943a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-a158f7d2-7f53-4b3e-948f-b54d735c0b38,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-5a160ce9-5a6e-4b17-95da-e572290d7323,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-9e7f4079-a7e6-4980-b709-a68165071938,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-5fc25fd4-0522-4660-a248-65ee0a0b3795,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-7f6cbc82-2081-4575-bdb1-5967ebc068d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5258
