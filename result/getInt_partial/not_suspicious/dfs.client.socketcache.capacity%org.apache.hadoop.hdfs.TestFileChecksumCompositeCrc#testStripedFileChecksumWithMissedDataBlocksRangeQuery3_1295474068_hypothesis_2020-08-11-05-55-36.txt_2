reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194315988-172.17.0.18-1597125356518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-0253f3c1-6cb7-4042-b36c-80b27029a7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-9f58bb99-b5f1-4f0a-9a81-ffc7a9e8dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-5ee4b414-6a9b-42c3-a83a-ca5178d0a8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-778fb2da-9c2f-4443-a9df-60dbe1b3541f,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-53368e31-d149-4901-a0bc-fb6b6e2fb623,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-90a24909-cf0b-4627-8a91-5c0aaa325682,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-39e1baaf-21b8-4f24-ac33-b0d47a607232,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-a0aaf769-80ef-47e5-9f24-2babe30dd8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194315988-172.17.0.18-1597125356518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-0253f3c1-6cb7-4042-b36c-80b27029a7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-9f58bb99-b5f1-4f0a-9a81-ffc7a9e8dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-5ee4b414-6a9b-42c3-a83a-ca5178d0a8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-778fb2da-9c2f-4443-a9df-60dbe1b3541f,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-53368e31-d149-4901-a0bc-fb6b6e2fb623,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-90a24909-cf0b-4627-8a91-5c0aaa325682,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-39e1baaf-21b8-4f24-ac33-b0d47a607232,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-a0aaf769-80ef-47e5-9f24-2babe30dd8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278609842-172.17.0.18-1597125969327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44197,DS-b6ad3afe-4ed6-4905-ad3d-b8db8173a89a,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-940cc5ff-9404-4af8-819e-cf1dfd2c5943,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-9f02ae6b-44b3-47b3-8eaa-bcc3b98cc425,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-fd08ab81-d432-4113-8d2d-01a2a12fde9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-722543c0-6ea6-4140-80ee-8f2d2c4ff960,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-88c0ced0-cc3b-4375-8713-098fc44b8e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-f2005bb8-4adf-47c0-895f-9a05adda4a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-97a32de4-4167-40b3-86a0-affc78e2829e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278609842-172.17.0.18-1597125969327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44197,DS-b6ad3afe-4ed6-4905-ad3d-b8db8173a89a,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-940cc5ff-9404-4af8-819e-cf1dfd2c5943,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-9f02ae6b-44b3-47b3-8eaa-bcc3b98cc425,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-fd08ab81-d432-4113-8d2d-01a2a12fde9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-722543c0-6ea6-4140-80ee-8f2d2c4ff960,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-88c0ced0-cc3b-4375-8713-098fc44b8e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-f2005bb8-4adf-47c0-895f-9a05adda4a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-97a32de4-4167-40b3-86a0-affc78e2829e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132805072-172.17.0.18-1597126004541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-6e216fee-b865-4596-a85e-8a4ed9dd80bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-d51cd212-1bb3-4ca3-b13d-29141a55929b,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-a9889f74-a1b1-4dc7-aa6c-a3ec604c0c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-54ed8dea-73d4-439b-8046-bbf469bb74f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-346a252a-a010-4eb4-93e5-8e59a29d62ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-6e70733e-5493-44e6-b91d-9495a197bd46,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-484b17dc-f2be-484a-b2a3-f875df4dce46,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-7dffabec-25fc-4cb3-9d45-54ba388a238c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132805072-172.17.0.18-1597126004541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-6e216fee-b865-4596-a85e-8a4ed9dd80bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-d51cd212-1bb3-4ca3-b13d-29141a55929b,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-a9889f74-a1b1-4dc7-aa6c-a3ec604c0c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-54ed8dea-73d4-439b-8046-bbf469bb74f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-346a252a-a010-4eb4-93e5-8e59a29d62ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-6e70733e-5493-44e6-b91d-9495a197bd46,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-484b17dc-f2be-484a-b2a3-f875df4dce46,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-7dffabec-25fc-4cb3-9d45-54ba388a238c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203146877-172.17.0.18-1597126257342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-a46d7da1-0a0e-4abc-8eee-59971d20fba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-10639da9-f006-459b-94bd-c7be3a2c99fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-1b460b3a-ae6e-4d86-b109-d81b80658092,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-7a4a0b60-4ab5-4696-8db4-177fa48b5833,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-7328a769-8aa0-406a-82a4-22b3b1f553cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-eb8a564a-985c-4015-a498-7c76171f3327,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-e1b6dfff-c2bd-4752-9000-522126145669,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-ab606ded-ffc5-4a1c-a72d-3aecb34d8084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203146877-172.17.0.18-1597126257342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-a46d7da1-0a0e-4abc-8eee-59971d20fba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-10639da9-f006-459b-94bd-c7be3a2c99fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-1b460b3a-ae6e-4d86-b109-d81b80658092,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-7a4a0b60-4ab5-4696-8db4-177fa48b5833,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-7328a769-8aa0-406a-82a4-22b3b1f553cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-eb8a564a-985c-4015-a498-7c76171f3327,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-e1b6dfff-c2bd-4752-9000-522126145669,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-ab606ded-ffc5-4a1c-a72d-3aecb34d8084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986664347-172.17.0.18-1597126334201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-3e1373cd-1993-4773-a59d-f93c15a7f5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-ab3cbaa5-7762-44bb-a5b8-380de35cf4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-91901df3-5726-4aef-a625-01b98ca8505d,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-5b9b02e6-2794-45ba-889f-102e79c15ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-a2fdd316-4c8f-4531-a406-c5915bee83dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-6ec1e2ee-6a68-420b-91b2-3e06d4f798e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-31d3d7d0-612f-4379-83f8-b688e542a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-616adb58-5534-42e0-bec0-52b47adc5356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986664347-172.17.0.18-1597126334201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-3e1373cd-1993-4773-a59d-f93c15a7f5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-ab3cbaa5-7762-44bb-a5b8-380de35cf4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-91901df3-5726-4aef-a625-01b98ca8505d,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-5b9b02e6-2794-45ba-889f-102e79c15ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-a2fdd316-4c8f-4531-a406-c5915bee83dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-6ec1e2ee-6a68-420b-91b2-3e06d4f798e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-31d3d7d0-612f-4379-83f8-b688e542a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-616adb58-5534-42e0-bec0-52b47adc5356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782539976-172.17.0.18-1597126722670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44018,DS-dcaf8ee9-77ce-4929-8b1e-f7348a82a012,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-f2204c36-c491-432a-99e1-125b0a580f39,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-a26c7047-c586-4c18-ac8f-8de7f7bb1ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-a2dc255e-93d8-48ef-aae2-55b63977739b,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-993e3257-f36b-4d81-9f52-78bcdb6df229,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-286d1c6e-2b27-4c29-ae17-88cfc6e5ed44,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-a64f16ed-083d-4fa8-8ae0-6dddc45f1ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-97a0a8a1-affb-473c-8c1f-44a6bd6b8c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782539976-172.17.0.18-1597126722670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44018,DS-dcaf8ee9-77ce-4929-8b1e-f7348a82a012,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-f2204c36-c491-432a-99e1-125b0a580f39,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-a26c7047-c586-4c18-ac8f-8de7f7bb1ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-a2dc255e-93d8-48ef-aae2-55b63977739b,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-993e3257-f36b-4d81-9f52-78bcdb6df229,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-286d1c6e-2b27-4c29-ae17-88cfc6e5ed44,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-a64f16ed-083d-4fa8-8ae0-6dddc45f1ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-97a0a8a1-affb-473c-8c1f-44a6bd6b8c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070127874-172.17.0.18-1597126831044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32932,DS-e65f17a6-e840-4c8e-8f85-6686be122e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-e1f62f5d-391e-4409-a67d-611acac3b8db,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-ed4c8b54-283a-4d67-9e52-3263512986ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-cc0b8214-b10e-4533-bdfd-f3db456348bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-f9834052-b18a-460b-b6ad-3a8a62d60208,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-342a69bd-ef06-4ed3-9bb0-65ddeeee3371,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-45176261-ed06-44e7-81d9-c234ae85478a,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-fca64f83-dc98-47c3-97cb-e3fb6be8a63e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070127874-172.17.0.18-1597126831044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32932,DS-e65f17a6-e840-4c8e-8f85-6686be122e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-e1f62f5d-391e-4409-a67d-611acac3b8db,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-ed4c8b54-283a-4d67-9e52-3263512986ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-cc0b8214-b10e-4533-bdfd-f3db456348bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-f9834052-b18a-460b-b6ad-3a8a62d60208,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-342a69bd-ef06-4ed3-9bb0-65ddeeee3371,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-45176261-ed06-44e7-81d9-c234ae85478a,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-fca64f83-dc98-47c3-97cb-e3fb6be8a63e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455471041-172.17.0.18-1597126976690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-003b0c6d-2044-4fe6-8210-5c66db898655,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-8294b455-e6ba-4091-bd8f-19ff88f1660a,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e087c8b2-2198-4fd3-9f1e-8a7fe962d140,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-31b9e8a6-9d63-4074-aac4-125428ea343c,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-b9ed0aa1-46ae-4f38-8428-0f09735acec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-e50aa5d3-d407-43f4-bc2b-f740c2336748,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-2916e02b-124a-4438-8b9a-94e8587c2f41,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-1e71dad6-83dc-40f8-9598-8ab6ea4b6fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455471041-172.17.0.18-1597126976690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-003b0c6d-2044-4fe6-8210-5c66db898655,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-8294b455-e6ba-4091-bd8f-19ff88f1660a,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e087c8b2-2198-4fd3-9f1e-8a7fe962d140,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-31b9e8a6-9d63-4074-aac4-125428ea343c,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-b9ed0aa1-46ae-4f38-8428-0f09735acec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-e50aa5d3-d407-43f4-bc2b-f740c2336748,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-2916e02b-124a-4438-8b9a-94e8587c2f41,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-1e71dad6-83dc-40f8-9598-8ab6ea4b6fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962850226-172.17.0.18-1597129759270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36255,DS-9adf0362-594f-49fc-9715-eb1ccf0e0cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-b5d68020-cffc-49f5-b501-0801d078de14,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b3245587-616a-471f-9928-83c395e4b046,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-1b22b9c2-d960-45da-8459-3cedc64a4f32,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-2497d386-7247-4040-ac87-144f382aa16a,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-0279ad95-ff9d-43cb-a311-e699e8b3b5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5c54241b-72ed-44e4-aa23-2e8e0f7fe4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-6fe6322d-0fc3-4a19-b143-4c701a3999d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962850226-172.17.0.18-1597129759270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36255,DS-9adf0362-594f-49fc-9715-eb1ccf0e0cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-b5d68020-cffc-49f5-b501-0801d078de14,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b3245587-616a-471f-9928-83c395e4b046,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-1b22b9c2-d960-45da-8459-3cedc64a4f32,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-2497d386-7247-4040-ac87-144f382aa16a,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-0279ad95-ff9d-43cb-a311-e699e8b3b5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5c54241b-72ed-44e4-aa23-2e8e0f7fe4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-6fe6322d-0fc3-4a19-b143-4c701a3999d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109710087-172.17.0.18-1597129795276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43243,DS-30fe20ba-7324-4d2d-bc5a-73f2309de4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-c7311282-5a11-4978-9f4e-0ca2465febb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-a13fc94a-4a12-4d7b-96cc-e03d4e6b2fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-f5a60741-02dd-45dc-b62f-650a85115fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-c9300dce-c0e9-4625-9722-b9e8155015ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-8147bd96-e267-44f1-93d5-22d9daf6eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-bf884a84-36cc-47ac-abc5-9340e1e8c329,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-2a700054-8f50-4f2b-be40-6f623fd5f36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109710087-172.17.0.18-1597129795276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43243,DS-30fe20ba-7324-4d2d-bc5a-73f2309de4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-c7311282-5a11-4978-9f4e-0ca2465febb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-a13fc94a-4a12-4d7b-96cc-e03d4e6b2fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-f5a60741-02dd-45dc-b62f-650a85115fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-c9300dce-c0e9-4625-9722-b9e8155015ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-8147bd96-e267-44f1-93d5-22d9daf6eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-bf884a84-36cc-47ac-abc5-9340e1e8c329,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-2a700054-8f50-4f2b-be40-6f623fd5f36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-524012423-172.17.0.18-1597129999240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45193,DS-0c522870-b814-40c9-b100-3a429aa665be,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-00a2f9fa-806e-4c99-b6e1-45c4e9d1e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-1b009109-e067-44d8-91f3-fa895565c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-d2bbb90f-3318-40cc-ab55-f0a4c18dab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-ac1bc13a-2830-4438-ba63-d1e350076b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-8595bd04-3ae7-4db6-a355-13b759e93020,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-efa7d10e-f041-47cf-a428-b15ee42b8318,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-5cea9507-3784-4532-98b2-9b6bb4d1b87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-524012423-172.17.0.18-1597129999240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45193,DS-0c522870-b814-40c9-b100-3a429aa665be,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-00a2f9fa-806e-4c99-b6e1-45c4e9d1e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-1b009109-e067-44d8-91f3-fa895565c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-d2bbb90f-3318-40cc-ab55-f0a4c18dab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-ac1bc13a-2830-4438-ba63-d1e350076b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-8595bd04-3ae7-4db6-a355-13b759e93020,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-efa7d10e-f041-47cf-a428-b15ee42b8318,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-5cea9507-3784-4532-98b2-9b6bb4d1b87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213482157-172.17.0.18-1597130475479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38515,DS-1064dd33-db03-4a92-80e2-e855620c1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-3763bcdb-001a-453f-951b-c5134b762de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-b6d0b24b-72fa-4aa8-b513-a46e5018e9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-d83b2fb5-8261-437a-b392-92acec17c350,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-69b3fa78-1f79-4f5c-b95d-f2dee4019d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-7a000452-51d2-49b6-b30a-e1cb9b96c224,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-aecc6d7b-a821-4a0c-add4-c98a3c656ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1899ae9b-91b7-44e8-ad8c-5877354f6b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213482157-172.17.0.18-1597130475479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38515,DS-1064dd33-db03-4a92-80e2-e855620c1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-3763bcdb-001a-453f-951b-c5134b762de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-b6d0b24b-72fa-4aa8-b513-a46e5018e9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-d83b2fb5-8261-437a-b392-92acec17c350,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-69b3fa78-1f79-4f5c-b95d-f2dee4019d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-7a000452-51d2-49b6-b30a-e1cb9b96c224,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-aecc6d7b-a821-4a0c-add4-c98a3c656ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1899ae9b-91b7-44e8-ad8c-5877354f6b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347756170-172.17.0.18-1597130510182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35638,DS-280ffc3e-8adf-423d-9eb6-a32887fcb969,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-b7d37334-5039-446a-adf5-c443ccc3a8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-a8e49b2a-d905-434e-b132-8b252f1cffb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-9d20f556-4c1a-4c89-ba98-a55fbea9b988,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-be33e165-0904-400e-9123-e165c0eb355a,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-e4dcbcd9-69cb-4d5e-9ff9-74722545764c,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-bdf5b9ac-437b-48f2-98d6-135dfc911676,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-4c9d4c95-5ecd-4a3b-b401-91ef472889d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347756170-172.17.0.18-1597130510182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35638,DS-280ffc3e-8adf-423d-9eb6-a32887fcb969,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-b7d37334-5039-446a-adf5-c443ccc3a8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-a8e49b2a-d905-434e-b132-8b252f1cffb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-9d20f556-4c1a-4c89-ba98-a55fbea9b988,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-be33e165-0904-400e-9123-e165c0eb355a,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-e4dcbcd9-69cb-4d5e-9ff9-74722545764c,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-bdf5b9ac-437b-48f2-98d6-135dfc911676,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-4c9d4c95-5ecd-4a3b-b401-91ef472889d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5410
