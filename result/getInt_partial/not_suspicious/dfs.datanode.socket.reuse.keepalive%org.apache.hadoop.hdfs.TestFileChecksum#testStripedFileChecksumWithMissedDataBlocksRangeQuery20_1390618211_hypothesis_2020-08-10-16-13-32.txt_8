reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149621913-172.17.0.9-1597076097161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34053,DS-77994fc9-88cd-48cf-b9ed-bbcd655664b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-fa012f8a-5328-4b9f-91fc-e7c06c002e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-d583ce51-df5a-4ce1-954d-68995c5294f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-da2d29cd-118b-4882-8627-8e7b93439907,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-805e4f1b-01d9-475f-a085-bc3547696ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-319b6be0-b123-4ee6-aa27-739a4cd86b30,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-769143f7-97f6-4795-8bac-e5f6430c9b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-577411e5-8a15-4568-a8d6-c1843f73e5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149621913-172.17.0.9-1597076097161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34053,DS-77994fc9-88cd-48cf-b9ed-bbcd655664b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-fa012f8a-5328-4b9f-91fc-e7c06c002e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-d583ce51-df5a-4ce1-954d-68995c5294f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-da2d29cd-118b-4882-8627-8e7b93439907,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-805e4f1b-01d9-475f-a085-bc3547696ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-319b6be0-b123-4ee6-aa27-739a4cd86b30,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-769143f7-97f6-4795-8bac-e5f6430c9b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-577411e5-8a15-4568-a8d6-c1843f73e5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950887239-172.17.0.9-1597076350156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33851,DS-063673eb-0b31-4244-8f4f-f3024f21b2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-6001c4f5-a25f-45a3-ab31-9d9fd0ba4e38,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-b8c7ff7b-2cfe-4677-bada-b2819167e07a,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-f7a955ae-40fd-4a3e-83b8-16e863d34079,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-2b6c8a5f-e841-4958-b639-fa54d7efb604,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-74e7f55c-6b4d-4796-bbb3-b2cfad9a1fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-d055db0f-d1b1-4e0c-8236-9b5c70d72dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-198bd642-45a3-4583-ae3f-d833f6009bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950887239-172.17.0.9-1597076350156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33851,DS-063673eb-0b31-4244-8f4f-f3024f21b2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-6001c4f5-a25f-45a3-ab31-9d9fd0ba4e38,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-b8c7ff7b-2cfe-4677-bada-b2819167e07a,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-f7a955ae-40fd-4a3e-83b8-16e863d34079,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-2b6c8a5f-e841-4958-b639-fa54d7efb604,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-74e7f55c-6b4d-4796-bbb3-b2cfad9a1fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-d055db0f-d1b1-4e0c-8236-9b5c70d72dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-198bd642-45a3-4583-ae3f-d833f6009bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782276912-172.17.0.9-1597076386240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-b4bd6f6a-387c-4ec6-9d43-a804bb08aa35,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-229c1576-dc2a-4173-b541-be5e52f3fe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-b361a458-18ab-4c83-9736-22e3972b0f47,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-0b479b30-f4cb-4a1b-96a1-ef2023e6e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-00f8283d-7133-46fc-bbd1-10872c1d91fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-4e86745e-d7b3-484e-8d5f-28ab0779f785,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-470c3849-922d-4156-a238-262c85374f84,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-465d4d16-9690-4126-bdf6-e1fb7d5ff881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782276912-172.17.0.9-1597076386240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-b4bd6f6a-387c-4ec6-9d43-a804bb08aa35,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-229c1576-dc2a-4173-b541-be5e52f3fe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-b361a458-18ab-4c83-9736-22e3972b0f47,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-0b479b30-f4cb-4a1b-96a1-ef2023e6e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-00f8283d-7133-46fc-bbd1-10872c1d91fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-4e86745e-d7b3-484e-8d5f-28ab0779f785,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-470c3849-922d-4156-a238-262c85374f84,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-465d4d16-9690-4126-bdf6-e1fb7d5ff881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103949634-172.17.0.9-1597076495599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36332,DS-e47174bd-009f-4482-be11-ab87686bc124,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-e6e81e38-57b0-45f9-9cdc-9dbce44a9b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-1c488dcf-7b4b-44ab-9e79-9ba2b31ea941,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-b4122340-ba4b-4185-856c-54efef9b9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-363993bb-95d9-47b4-b572-9e488a7b62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-226a0996-0cb1-4aed-b93f-9bc6ba7f42ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-a7973a57-3029-4832-a8ad-f6a8707900c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-3fd7dfd2-4a99-4d47-bc6c-872766ea540d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103949634-172.17.0.9-1597076495599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36332,DS-e47174bd-009f-4482-be11-ab87686bc124,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-e6e81e38-57b0-45f9-9cdc-9dbce44a9b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-1c488dcf-7b4b-44ab-9e79-9ba2b31ea941,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-b4122340-ba4b-4185-856c-54efef9b9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-363993bb-95d9-47b4-b572-9e488a7b62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-226a0996-0cb1-4aed-b93f-9bc6ba7f42ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-a7973a57-3029-4832-a8ad-f6a8707900c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-3fd7dfd2-4a99-4d47-bc6c-872766ea540d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690715923-172.17.0.9-1597076598296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-4d519a10-ce01-465e-aebd-b908171c63a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-1009357b-ab77-4107-8e26-185a6ab88209,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-9708bfbd-1bd4-4931-bdde-19e7d7ae843c,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-406759f7-67f7-490b-a9b5-f086f51c7f16,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-5d479ba6-8d71-4707-800b-1b558a736527,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-226978e0-ef60-4ab0-8f59-ca193c14277d,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-c55752ee-2a29-4ee2-8559-a3553303a193,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-033aa0b1-008c-459f-a1fe-44d8f3d927a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690715923-172.17.0.9-1597076598296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-4d519a10-ce01-465e-aebd-b908171c63a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-1009357b-ab77-4107-8e26-185a6ab88209,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-9708bfbd-1bd4-4931-bdde-19e7d7ae843c,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-406759f7-67f7-490b-a9b5-f086f51c7f16,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-5d479ba6-8d71-4707-800b-1b558a736527,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-226978e0-ef60-4ab0-8f59-ca193c14277d,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-c55752ee-2a29-4ee2-8559-a3553303a193,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-033aa0b1-008c-459f-a1fe-44d8f3d927a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172936169-172.17.0.9-1597076924453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35389,DS-98473eeb-b5a1-4923-85e3-8ee3b7b624b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-fc10c98d-8d74-4bdf-8650-d0025d4a94da,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-793d5d3c-cd42-4611-9310-e0c6f8430c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-78e0e50c-b27b-4666-b1d8-992885b97394,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-d50a02f4-81a3-40bc-a353-157a059ddb91,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-7cd2fce2-e97a-4466-bb4e-486cb97e6188,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-d9607bbe-af55-44a1-8ea7-467fc4e39c63,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-5242844c-6c4c-4dca-ad61-2998b44d9d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172936169-172.17.0.9-1597076924453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35389,DS-98473eeb-b5a1-4923-85e3-8ee3b7b624b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-fc10c98d-8d74-4bdf-8650-d0025d4a94da,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-793d5d3c-cd42-4611-9310-e0c6f8430c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-78e0e50c-b27b-4666-b1d8-992885b97394,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-d50a02f4-81a3-40bc-a353-157a059ddb91,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-7cd2fce2-e97a-4466-bb4e-486cb97e6188,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-d9607bbe-af55-44a1-8ea7-467fc4e39c63,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-5242844c-6c4c-4dca-ad61-2998b44d9d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305487540-172.17.0.9-1597076998743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-c40595bf-7c22-463b-8a6e-557fbb2d3906,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-c779f594-e36a-4903-8772-6c33f671c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-9c84b821-2e2b-4b10-bb21-62635293ac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-24c97d52-da85-4135-b485-a6c202c337fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-48c1be5f-1652-4a26-b0fb-cea0f40b875b,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-8379614f-5e77-4e8e-a143-53a5ec21224f,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-7888817d-0f1d-4349-b9ac-97d0fa077e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-384fa5a1-6d0d-460d-820c-bee87cb9d896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305487540-172.17.0.9-1597076998743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-c40595bf-7c22-463b-8a6e-557fbb2d3906,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-c779f594-e36a-4903-8772-6c33f671c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-9c84b821-2e2b-4b10-bb21-62635293ac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-24c97d52-da85-4135-b485-a6c202c337fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-48c1be5f-1652-4a26-b0fb-cea0f40b875b,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-8379614f-5e77-4e8e-a143-53a5ec21224f,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-7888817d-0f1d-4349-b9ac-97d0fa077e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-384fa5a1-6d0d-460d-820c-bee87cb9d896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87261883-172.17.0.9-1597077476614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37097,DS-af4635b4-60b3-4c2e-a565-408ccc02bb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-dc3656d9-e951-4d17-a04b-96e124b2ac6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-ddfb70ee-cc88-4ec2-8d25-61cea62f6992,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-4d408ef0-8b7f-4238-82b3-9480de4f0d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-141241c2-18c2-48ea-9fe5-c385ed624412,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-1e96f62b-3558-4815-a058-d6ae43d91a82,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-aae430c9-a78b-4363-bdd0-1d2c594f7c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-d1d26a24-d9e0-463e-a0f6-dc068d31e802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87261883-172.17.0.9-1597077476614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37097,DS-af4635b4-60b3-4c2e-a565-408ccc02bb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-dc3656d9-e951-4d17-a04b-96e124b2ac6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-ddfb70ee-cc88-4ec2-8d25-61cea62f6992,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-4d408ef0-8b7f-4238-82b3-9480de4f0d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-141241c2-18c2-48ea-9fe5-c385ed624412,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-1e96f62b-3558-4815-a058-d6ae43d91a82,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-aae430c9-a78b-4363-bdd0-1d2c594f7c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-d1d26a24-d9e0-463e-a0f6-dc068d31e802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163057431-172.17.0.9-1597077551070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38626,DS-9662e0dc-4be7-492f-b3f5-57417386547d,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-82d389a7-eed2-4843-9755-4c391e503f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-053cc6d3-7ae3-4841-957f-026278afa78b,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-6fd90622-c05d-4cd9-9058-8874add1516b,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-0705be16-cfae-490b-9697-81cc16ccaa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-0d3086f9-7052-4360-a8de-010187d01896,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-bc54064b-b042-4dbe-a49b-6382315315ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-103e2976-3da0-4ef6-84f5-a9e638fb5e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163057431-172.17.0.9-1597077551070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38626,DS-9662e0dc-4be7-492f-b3f5-57417386547d,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-82d389a7-eed2-4843-9755-4c391e503f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-053cc6d3-7ae3-4841-957f-026278afa78b,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-6fd90622-c05d-4cd9-9058-8874add1516b,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-0705be16-cfae-490b-9697-81cc16ccaa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-0d3086f9-7052-4360-a8de-010187d01896,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-bc54064b-b042-4dbe-a49b-6382315315ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-103e2976-3da0-4ef6-84f5-a9e638fb5e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166647582-172.17.0.9-1597077581599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36166,DS-726ee98e-b317-4841-b01e-78a553f3485f,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-e360195f-93d8-4c92-a148-799492ff41a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-7d450a61-9e76-41a0-bdc9-c2c9a328b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-79e75d9e-03be-4ed5-b1c2-4b657f97a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-e90adef0-7883-43a6-9f8b-3a0a5811621c,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-c11ce3e2-b351-4c9e-9a74-886f1597c59c,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-0c6abfce-cd69-43fb-9171-5b90bb22a8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-c642e0c9-152a-424f-ad44-2a121071f500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166647582-172.17.0.9-1597077581599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36166,DS-726ee98e-b317-4841-b01e-78a553f3485f,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-e360195f-93d8-4c92-a148-799492ff41a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-7d450a61-9e76-41a0-bdc9-c2c9a328b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-79e75d9e-03be-4ed5-b1c2-4b657f97a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-e90adef0-7883-43a6-9f8b-3a0a5811621c,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-c11ce3e2-b351-4c9e-9a74-886f1597c59c,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-0c6abfce-cd69-43fb-9171-5b90bb22a8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-c642e0c9-152a-424f-ad44-2a121071f500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726614211-172.17.0.9-1597077912783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-e0e253f6-00e8-4a56-931c-c05bab042e41,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-dfae1c37-e344-495d-b601-3543f3918995,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-4dbc36c6-c5aa-40dc-9e88-85904c45a351,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-6573dc38-040c-40b3-ae4e-0ad1c41bc014,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-07cbe759-259e-4d60-9f22-a417a2d5e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-90e85c39-693b-422f-a517-0b6f187fd7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-050ce4a4-bb60-4402-8177-a7e6998208ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-9e05cd36-462d-4fe5-b453-056692449310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726614211-172.17.0.9-1597077912783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-e0e253f6-00e8-4a56-931c-c05bab042e41,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-dfae1c37-e344-495d-b601-3543f3918995,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-4dbc36c6-c5aa-40dc-9e88-85904c45a351,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-6573dc38-040c-40b3-ae4e-0ad1c41bc014,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-07cbe759-259e-4d60-9f22-a417a2d5e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-90e85c39-693b-422f-a517-0b6f187fd7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-050ce4a4-bb60-4402-8177-a7e6998208ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-9e05cd36-462d-4fe5-b453-056692449310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-130540635-172.17.0.9-1597077946884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42100,DS-e494d729-978d-4ba6-8d4a-9f7f2f2eae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-74cd9c6a-6ac6-46da-bfd2-4df47ac85ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-c69b40d6-07da-498c-a0b2-9d5e4641e1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-441f140c-99c8-43cd-b472-59d27447ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-a1d0a860-82e0-4244-99b0-0b6c40386ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-d0ebcae5-9187-4805-8999-91cdfa4f2867,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-6e06dfcb-e295-4dd0-8813-1fb4ea44f942,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-f108a199-cf08-4339-ae7a-0a7be53b50c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-130540635-172.17.0.9-1597077946884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42100,DS-e494d729-978d-4ba6-8d4a-9f7f2f2eae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-74cd9c6a-6ac6-46da-bfd2-4df47ac85ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-c69b40d6-07da-498c-a0b2-9d5e4641e1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-441f140c-99c8-43cd-b472-59d27447ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-a1d0a860-82e0-4244-99b0-0b6c40386ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-d0ebcae5-9187-4805-8999-91cdfa4f2867,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-6e06dfcb-e295-4dd0-8813-1fb4ea44f942,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-f108a199-cf08-4339-ae7a-0a7be53b50c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047463056-172.17.0.9-1597077982358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-8af0a278-320a-42f7-bab5-2a03af972c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-e180b5a0-c16a-47f4-b28e-58a8542a17ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-86288391-d3f8-4994-9e80-1e6c246c3ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-287c923f-45e6-40cb-a9e8-2ee925af98dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-5ebcb65b-a1a6-416c-9e23-f1d3fb7d792f,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-1572db23-7d73-4d31-aa88-e11579132a29,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-4f2635eb-e798-4643-8e9f-706aac582595,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-b85d3c40-0e71-427d-8014-2d463f2517e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047463056-172.17.0.9-1597077982358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-8af0a278-320a-42f7-bab5-2a03af972c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-e180b5a0-c16a-47f4-b28e-58a8542a17ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-86288391-d3f8-4994-9e80-1e6c246c3ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-287c923f-45e6-40cb-a9e8-2ee925af98dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-5ebcb65b-a1a6-416c-9e23-f1d3fb7d792f,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-1572db23-7d73-4d31-aa88-e11579132a29,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-4f2635eb-e798-4643-8e9f-706aac582595,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-b85d3c40-0e71-427d-8014-2d463f2517e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-360234405-172.17.0.9-1597078209089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-f26d9b8f-6493-4175-b197-92527f54f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-4e7d7191-32ce-4fde-8300-f1c25c279a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-759c46ae-6ce6-4fd8-a9d9-ec8abea666d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-7fc37b2d-2b7b-4cd8-bedb-24babc044d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-a64ec299-c22c-4b3f-a837-7f6a1c55c0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-ea7c2c32-2529-4499-87f0-708bd3510b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-95f03224-122f-4965-89e4-69d6c539f2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-62d05666-8d96-490d-864f-05f494406bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-360234405-172.17.0.9-1597078209089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-f26d9b8f-6493-4175-b197-92527f54f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-4e7d7191-32ce-4fde-8300-f1c25c279a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-759c46ae-6ce6-4fd8-a9d9-ec8abea666d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-7fc37b2d-2b7b-4cd8-bedb-24babc044d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-a64ec299-c22c-4b3f-a837-7f6a1c55c0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-ea7c2c32-2529-4499-87f0-708bd3510b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-95f03224-122f-4965-89e4-69d6c539f2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-62d05666-8d96-490d-864f-05f494406bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437312549-172.17.0.9-1597079146085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-bcd9b382-28a8-4568-89d1-63714287fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-dd94d456-e7a4-43ec-8a5d-478df93b34b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-39e81c54-992e-4e69-a9da-4a0f28f25684,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-6b2b9965-95e7-450c-a2ab-9ed223e5b993,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-1ccab0e7-3ba6-450b-bded-6cfdf3a2d975,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-79f6aad5-063f-449d-aedf-1912feb6ff85,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-32d11959-924c-42a2-8e7d-d8039ddcb0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-95731da6-fbfe-4e19-8df3-0634603f7926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437312549-172.17.0.9-1597079146085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-bcd9b382-28a8-4568-89d1-63714287fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-dd94d456-e7a4-43ec-8a5d-478df93b34b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-39e81c54-992e-4e69-a9da-4a0f28f25684,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-6b2b9965-95e7-450c-a2ab-9ed223e5b993,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-1ccab0e7-3ba6-450b-bded-6cfdf3a2d975,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-79f6aad5-063f-449d-aedf-1912feb6ff85,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-32d11959-924c-42a2-8e7d-d8039ddcb0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-95731da6-fbfe-4e19-8df3-0634603f7926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106878780-172.17.0.9-1597079176430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-b59b0955-acbc-4ffd-9c1c-8359783038f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-96b2d31e-9792-46b4-8603-22f31749d55f,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-940e4630-9edb-4fa1-a468-69bf6c52ca6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-fd360252-efc9-4a4a-9fd4-08c737b4cecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-2caaa1b8-d87d-40c6-8054-8a78f603bf81,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-a30259bd-d76f-444d-8050-f5a5394fe160,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-60f977bd-c72c-4c4c-8fdb-0ec43f636665,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-478894fa-108d-442b-b446-24e577685d13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106878780-172.17.0.9-1597079176430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-b59b0955-acbc-4ffd-9c1c-8359783038f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-96b2d31e-9792-46b4-8603-22f31749d55f,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-940e4630-9edb-4fa1-a468-69bf6c52ca6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-fd360252-efc9-4a4a-9fd4-08c737b4cecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-2caaa1b8-d87d-40c6-8054-8a78f603bf81,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-a30259bd-d76f-444d-8050-f5a5394fe160,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-60f977bd-c72c-4c4c-8fdb-0ec43f636665,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-478894fa-108d-442b-b446-24e577685d13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060066899-172.17.0.9-1597079206662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37949,DS-8a3630e3-4584-4a4b-8a84-419957ac6b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-0961531b-f776-43ea-9cdf-c38078d13216,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-12ea2788-9a5a-4a41-892a-8f5c5e074055,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-477eb39b-082d-43ab-b94d-441255d812e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-f7766ae3-e272-4a3e-bf47-85eec4d4e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-3c8af694-93e2-4084-85a2-d7c6675a357a,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-831c670a-c15e-4689-85df-89975894f628,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-16e33105-5407-4ab7-b9a8-e5f532ae3fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060066899-172.17.0.9-1597079206662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37949,DS-8a3630e3-4584-4a4b-8a84-419957ac6b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-0961531b-f776-43ea-9cdf-c38078d13216,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-12ea2788-9a5a-4a41-892a-8f5c5e074055,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-477eb39b-082d-43ab-b94d-441255d812e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-f7766ae3-e272-4a3e-bf47-85eec4d4e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-3c8af694-93e2-4084-85a2-d7c6675a357a,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-831c670a-c15e-4689-85df-89975894f628,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-16e33105-5407-4ab7-b9a8-e5f532ae3fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225337605-172.17.0.9-1597079450434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-12e9505d-a5e2-4e44-ab50-f891c7a65331,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-9ec14826-240c-4fb8-ae1e-3e3257124758,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-f0f1a3ea-929a-4bcd-8ca0-b21932d32cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-c89ec9df-3c55-4454-8bcd-f2b7e8806c13,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-f6facd2f-4bc3-427b-b1a8-f9f837e29bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-80293585-8467-4ea5-aa83-c35ff7a4a575,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-bffc1c0a-d2b6-4835-a8e0-5fef44405d21,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-92b230dc-608a-4c91-bc65-2ee1474f0765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225337605-172.17.0.9-1597079450434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-12e9505d-a5e2-4e44-ab50-f891c7a65331,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-9ec14826-240c-4fb8-ae1e-3e3257124758,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-f0f1a3ea-929a-4bcd-8ca0-b21932d32cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-c89ec9df-3c55-4454-8bcd-f2b7e8806c13,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-f6facd2f-4bc3-427b-b1a8-f9f837e29bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-80293585-8467-4ea5-aa83-c35ff7a4a575,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-bffc1c0a-d2b6-4835-a8e0-5fef44405d21,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-92b230dc-608a-4c91-bc65-2ee1474f0765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632484480-172.17.0.9-1597079593058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-e44a4264-81f2-435c-90fa-d9ac03462409,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-79dc8ef7-7285-4195-97ee-aabedc8d1589,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-5b235b58-a3e7-4132-9d04-67e5f474f376,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-9b8d3496-28d4-4dc0-87df-30e47e6ae4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-4cade791-4467-49ce-9b90-9826e3e84280,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-2896ce58-4d1d-4fa1-9fd4-aa46dabe2840,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-d1993563-e9e6-45db-89be-434305a77d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-2dc7d5b8-09fe-4bc1-b5b9-c1847027464a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632484480-172.17.0.9-1597079593058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-e44a4264-81f2-435c-90fa-d9ac03462409,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-79dc8ef7-7285-4195-97ee-aabedc8d1589,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-5b235b58-a3e7-4132-9d04-67e5f474f376,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-9b8d3496-28d4-4dc0-87df-30e47e6ae4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-4cade791-4467-49ce-9b90-9826e3e84280,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-2896ce58-4d1d-4fa1-9fd4-aa46dabe2840,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-d1993563-e9e6-45db-89be-434305a77d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-2dc7d5b8-09fe-4bc1-b5b9-c1847027464a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659241277-172.17.0.9-1597079846547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-e28ecdc9-4345-472d-b350-d1bd2cb1df87,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-b8020e1c-54c7-48c7-8e19-998a02220c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-a7fe1d16-be1b-4b18-96b8-1b47a0725e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-466ecd14-1116-4221-a42b-3e7af7f7d947,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-53d8a850-d43d-4f5c-a918-25b8114b0a69,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-3b53dc93-a25c-4aac-8ba8-d81693f1f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-ba723278-2062-4e39-834c-d8ee7e6c74fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-12a10a06-1f52-40ee-af36-caf348c953b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659241277-172.17.0.9-1597079846547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-e28ecdc9-4345-472d-b350-d1bd2cb1df87,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-b8020e1c-54c7-48c7-8e19-998a02220c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-a7fe1d16-be1b-4b18-96b8-1b47a0725e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-466ecd14-1116-4221-a42b-3e7af7f7d947,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-53d8a850-d43d-4f5c-a918-25b8114b0a69,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-3b53dc93-a25c-4aac-8ba8-d81693f1f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-ba723278-2062-4e39-834c-d8ee7e6c74fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-12a10a06-1f52-40ee-af36-caf348c953b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103449470-172.17.0.9-1597080588458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-c1cb04cc-a660-45dd-ab3b-4798840aeb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-7f1a7179-f372-4c7d-ae21-198b79701db4,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-2e6f83d0-ce73-40fb-aa1e-177b32171715,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-6ff08e91-e4b3-4571-9f0f-e6a219910840,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-9a1ff0be-0a55-4279-85f1-7957d483ee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-cab810e1-4518-4cda-b523-2db5d13f8ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-200ca002-5c69-47e5-bf8e-b75f44103e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-791d423a-5a30-46c7-8fe2-dc01fe6d09b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103449470-172.17.0.9-1597080588458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-c1cb04cc-a660-45dd-ab3b-4798840aeb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-7f1a7179-f372-4c7d-ae21-198b79701db4,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-2e6f83d0-ce73-40fb-aa1e-177b32171715,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-6ff08e91-e4b3-4571-9f0f-e6a219910840,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-9a1ff0be-0a55-4279-85f1-7957d483ee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-cab810e1-4518-4cda-b523-2db5d13f8ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-200ca002-5c69-47e5-bf8e-b75f44103e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-791d423a-5a30-46c7-8fe2-dc01fe6d09b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1364231070-172.17.0.9-1597080803855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-29cd9c65-90bd-440b-a24c-d2691bb7d510,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-eb8b1bf9-ed18-46ca-93b0-0800329a3651,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-dfcddf49-f3a3-4222-a88e-1f1ec68b3965,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-c884abfc-effa-47df-93ca-3c27e636c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-63f91a7e-c6c8-4666-bec7-1ded5093d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-7b43b545-fa1a-4b82-9255-ab160de31cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-566d3674-da7c-4d35-a2ac-0f567b1373c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-69e94339-0202-4423-a19d-a2f0415fb4bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1364231070-172.17.0.9-1597080803855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-29cd9c65-90bd-440b-a24c-d2691bb7d510,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-eb8b1bf9-ed18-46ca-93b0-0800329a3651,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-dfcddf49-f3a3-4222-a88e-1f1ec68b3965,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-c884abfc-effa-47df-93ca-3c27e636c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-63f91a7e-c6c8-4666-bec7-1ded5093d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-7b43b545-fa1a-4b82-9255-ab160de31cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-566d3674-da7c-4d35-a2ac-0f567b1373c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-69e94339-0202-4423-a19d-a2f0415fb4bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668511145-172.17.0.9-1597080940270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40268,DS-828ed2fe-c5cb-45dd-8832-46e235556315,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-82faf659-f314-4666-857f-a3800555d974,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-ab60d1fa-afa3-4bb2-81f4-f845bbdfe0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-58e15199-e3c0-46a5-8f0e-326799d9c265,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-ef40a897-a1bc-4d79-ad29-2c2efbbaff02,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-41e23f91-acb4-4c07-8923-36c55c4eefb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-a834386d-2b6b-4c5b-a7af-561ae42b9c62,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-f5a3807b-3ec0-4424-91ee-920c63f12f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668511145-172.17.0.9-1597080940270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40268,DS-828ed2fe-c5cb-45dd-8832-46e235556315,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-82faf659-f314-4666-857f-a3800555d974,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-ab60d1fa-afa3-4bb2-81f4-f845bbdfe0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-58e15199-e3c0-46a5-8f0e-326799d9c265,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-ef40a897-a1bc-4d79-ad29-2c2efbbaff02,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-41e23f91-acb4-4c07-8923-36c55c4eefb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-a834386d-2b6b-4c5b-a7af-561ae42b9c62,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-f5a3807b-3ec0-4424-91ee-920c63f12f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354743162-172.17.0.9-1597081128052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35627,DS-cad3fb15-ee3a-4159-b3cd-a188ddf79a66,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-a016d95b-7cf8-4011-b0ec-35cca4ecaadb,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-6b4a0629-a12e-4ac7-9aae-cbd8e1e1a584,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-43c92631-a59a-4543-8655-071a2809d837,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-aeffb17a-68be-40d3-82f1-ec7941a1d3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-0e1ac185-7f40-449d-88e7-1797a780b288,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-1258c08e-e693-44cf-8c66-82e05c0b34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-76d39177-0913-42b2-a965-c09d596db800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354743162-172.17.0.9-1597081128052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35627,DS-cad3fb15-ee3a-4159-b3cd-a188ddf79a66,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-a016d95b-7cf8-4011-b0ec-35cca4ecaadb,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-6b4a0629-a12e-4ac7-9aae-cbd8e1e1a584,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-43c92631-a59a-4543-8655-071a2809d837,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-aeffb17a-68be-40d3-82f1-ec7941a1d3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-0e1ac185-7f40-449d-88e7-1797a780b288,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-1258c08e-e693-44cf-8c66-82e05c0b34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-76d39177-0913-42b2-a965-c09d596db800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5171
