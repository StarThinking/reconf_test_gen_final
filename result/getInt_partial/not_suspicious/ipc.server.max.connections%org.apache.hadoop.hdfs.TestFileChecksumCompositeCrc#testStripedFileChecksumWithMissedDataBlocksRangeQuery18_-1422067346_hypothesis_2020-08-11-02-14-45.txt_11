reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905362043-172.17.0.3-1597112412437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42595,DS-16c39ebf-c5bb-4410-ab20-97f0d762d722,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-ce55c81a-40c8-491b-8519-f9415580e6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-aefbcb32-0609-4a8a-9ff5-53f00a8e0d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-a0e9b3bf-2760-41c9-adce-3605102a3ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-2621c213-8ac7-4528-ad85-ab9a418e0f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-0e2bc656-9a36-4d08-a59c-b1e5afc8dd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-3333f280-ddd5-43bd-9e76-601a48630761,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-2d10f2e5-380d-4a9b-975e-d4820cee00ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905362043-172.17.0.3-1597112412437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42595,DS-16c39ebf-c5bb-4410-ab20-97f0d762d722,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-ce55c81a-40c8-491b-8519-f9415580e6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-aefbcb32-0609-4a8a-9ff5-53f00a8e0d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-a0e9b3bf-2760-41c9-adce-3605102a3ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-2621c213-8ac7-4528-ad85-ab9a418e0f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-0e2bc656-9a36-4d08-a59c-b1e5afc8dd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-3333f280-ddd5-43bd-9e76-601a48630761,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-2d10f2e5-380d-4a9b-975e-d4820cee00ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614221567-172.17.0.3-1597112693770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-8f990f0f-cfa2-4bfb-b07f-230ece248790,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-d37063a6-b633-46ad-a1a2-411d8e206bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-b697c0da-3f86-4d3a-9a45-2d8f12269484,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-20bf5be0-42da-4349-bf09-92158a585e32,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-5650cb36-cc12-4b80-89b5-085d24713627,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-96f3143b-2685-4c1d-9419-55dcff5edd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-a4b22a13-cc6e-4aa4-9b3b-6c0897cb3afa,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-0e6baf2b-9d32-4944-86f4-eb0c1d51a1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614221567-172.17.0.3-1597112693770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-8f990f0f-cfa2-4bfb-b07f-230ece248790,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-d37063a6-b633-46ad-a1a2-411d8e206bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-b697c0da-3f86-4d3a-9a45-2d8f12269484,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-20bf5be0-42da-4349-bf09-92158a585e32,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-5650cb36-cc12-4b80-89b5-085d24713627,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-96f3143b-2685-4c1d-9419-55dcff5edd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-a4b22a13-cc6e-4aa4-9b3b-6c0897cb3afa,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-0e6baf2b-9d32-4944-86f4-eb0c1d51a1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579210484-172.17.0.3-1597112967973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37166,DS-98a0239c-c8fd-4bfd-b19c-44dac5eae0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-d89ae429-e601-4681-a9ff-01c0a71f86eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-db2c91be-77dc-49dc-b092-dbbf269e03a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-84313900-a71f-48f1-967b-a1923326a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-a1190eab-db0b-4092-b3a4-13e6f2fd6b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-99034752-8587-448d-8ed3-27d9f7e03abd,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-3893b1f0-81c1-4cd0-a6fa-a6dec4af8841,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-c4f5d991-38db-4968-abad-d38f5cfe1409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579210484-172.17.0.3-1597112967973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37166,DS-98a0239c-c8fd-4bfd-b19c-44dac5eae0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-d89ae429-e601-4681-a9ff-01c0a71f86eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-db2c91be-77dc-49dc-b092-dbbf269e03a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-84313900-a71f-48f1-967b-a1923326a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-a1190eab-db0b-4092-b3a4-13e6f2fd6b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-99034752-8587-448d-8ed3-27d9f7e03abd,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-3893b1f0-81c1-4cd0-a6fa-a6dec4af8841,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-c4f5d991-38db-4968-abad-d38f5cfe1409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708650308-172.17.0.3-1597113590722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35021,DS-a9f719c0-628d-445b-b03f-bd3635e525e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5b35d177-fcd7-4969-bb08-ed6a6294190c,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-505f6466-3fc5-4c3a-96e9-8859c10db24a,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-73f6e4db-6ba7-4214-8f4d-db39904a596d,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-fe58746b-dbf9-4624-8a31-811cbbeda6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-1fd2e9fc-45c5-4dac-8dad-da2c4ab2caaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-3a76c679-ea2c-4fbc-b60e-6ea9cef6d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-2b8c1c3a-3e54-43f6-9cae-212ed5912135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708650308-172.17.0.3-1597113590722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35021,DS-a9f719c0-628d-445b-b03f-bd3635e525e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5b35d177-fcd7-4969-bb08-ed6a6294190c,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-505f6466-3fc5-4c3a-96e9-8859c10db24a,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-73f6e4db-6ba7-4214-8f4d-db39904a596d,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-fe58746b-dbf9-4624-8a31-811cbbeda6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-1fd2e9fc-45c5-4dac-8dad-da2c4ab2caaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-3a76c679-ea2c-4fbc-b60e-6ea9cef6d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-2b8c1c3a-3e54-43f6-9cae-212ed5912135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371829431-172.17.0.3-1597113795838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45026,DS-77c1969d-5c7b-4d37-97d6-b7f2c5187218,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-3dd5409a-9cb1-4adc-92ac-b8ed7a8262b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-19af3acf-5864-4f59-af69-afe38b404bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-1ae22488-d5f2-4a65-888a-e15316f0a791,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-5e2b26b2-8d80-4c83-8237-06f76636844c,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-cdc25373-938b-4439-88e3-b44a5fbe1440,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-c61867ae-ef87-44f4-8ff5-4e904abe2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-0a4e3292-edb9-478e-b858-73d4c89d2312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371829431-172.17.0.3-1597113795838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45026,DS-77c1969d-5c7b-4d37-97d6-b7f2c5187218,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-3dd5409a-9cb1-4adc-92ac-b8ed7a8262b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-19af3acf-5864-4f59-af69-afe38b404bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-1ae22488-d5f2-4a65-888a-e15316f0a791,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-5e2b26b2-8d80-4c83-8237-06f76636844c,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-cdc25373-938b-4439-88e3-b44a5fbe1440,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-c61867ae-ef87-44f4-8ff5-4e904abe2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-0a4e3292-edb9-478e-b858-73d4c89d2312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564460295-172.17.0.3-1597114011390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41939,DS-be6550ac-9cfe-49c2-8610-7908ce08c35e,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-c44824a3-8936-4c29-9c3b-5f8a2a886373,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-6e70496c-2b76-487a-aad5-eb2f36184515,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-ea3fd9de-737a-42e7-9890-ab556f1d6f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-84ab03c4-05a6-492c-9e3e-d2fc091db804,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-f5049760-f03c-4cbc-83ef-5e5093d313af,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-2dbf1425-1683-4b87-995c-689f9eb1645a,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-7e811dbe-0507-4173-a848-10e73dcd1935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564460295-172.17.0.3-1597114011390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41939,DS-be6550ac-9cfe-49c2-8610-7908ce08c35e,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-c44824a3-8936-4c29-9c3b-5f8a2a886373,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-6e70496c-2b76-487a-aad5-eb2f36184515,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-ea3fd9de-737a-42e7-9890-ab556f1d6f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-84ab03c4-05a6-492c-9e3e-d2fc091db804,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-f5049760-f03c-4cbc-83ef-5e5093d313af,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-2dbf1425-1683-4b87-995c-689f9eb1645a,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-7e811dbe-0507-4173-a848-10e73dcd1935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526507306-172.17.0.3-1597114428830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43364,DS-748563ca-d81b-477f-b834-0f427060e66c,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-b0b3f8f6-d921-42c1-8fb4-604fae10ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-99cbbf2d-8d6b-4b43-8b29-8e9112dbacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-f0305afb-7092-4bde-8c87-502e6cebd203,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-457902fb-cd04-448e-a385-0275bf5d2117,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-408f6144-12f8-4a0f-815e-765983485f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-e7ceafac-2193-40e5-b61d-3626c755bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-a1db00bf-b3a7-485d-91e9-55d73daba87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526507306-172.17.0.3-1597114428830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43364,DS-748563ca-d81b-477f-b834-0f427060e66c,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-b0b3f8f6-d921-42c1-8fb4-604fae10ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-99cbbf2d-8d6b-4b43-8b29-8e9112dbacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-f0305afb-7092-4bde-8c87-502e6cebd203,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-457902fb-cd04-448e-a385-0275bf5d2117,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-408f6144-12f8-4a0f-815e-765983485f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-e7ceafac-2193-40e5-b61d-3626c755bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-a1db00bf-b3a7-485d-91e9-55d73daba87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561116358-172.17.0.3-1597114461985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-ce1d876b-82f6-4b6f-8533-7b5bf7067c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-0cfe26e3-d682-4d97-a27f-90e875f88ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-0fe48b42-42de-4788-86ef-1390bf6daa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-d3f09b7e-60e3-45dd-8ced-83afd05dca98,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-038c7162-12eb-4986-bc69-5e5bc5caa20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-93bee331-93bd-43ea-8b17-b78d564e1779,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-83106ec0-1140-4221-b5a0-305db921cc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-b70a8bc9-24a7-4663-a693-121a890c0c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561116358-172.17.0.3-1597114461985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-ce1d876b-82f6-4b6f-8533-7b5bf7067c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-0cfe26e3-d682-4d97-a27f-90e875f88ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-0fe48b42-42de-4788-86ef-1390bf6daa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-d3f09b7e-60e3-45dd-8ced-83afd05dca98,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-038c7162-12eb-4986-bc69-5e5bc5caa20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-93bee331-93bd-43ea-8b17-b78d564e1779,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-83106ec0-1140-4221-b5a0-305db921cc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-b70a8bc9-24a7-4663-a693-121a890c0c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031826795-172.17.0.3-1597114708957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-65e9da09-beba-49ba-8eb1-6591a416bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-964cd65d-8051-4700-99fe-7678a1b901b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-d5bb3459-cc04-4cc9-baf5-20f4e094dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-e4a56c1b-4f72-4b79-9f70-3e5d1deab819,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-8efa6f1d-9d11-4961-baba-65949221ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-a5e44724-254d-4144-970e-6b3fd82aa8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-97e6eea1-68dc-4f6c-812f-d422a7706c14,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-1e63404b-6c9e-423c-863c-394fd195a17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031826795-172.17.0.3-1597114708957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-65e9da09-beba-49ba-8eb1-6591a416bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-964cd65d-8051-4700-99fe-7678a1b901b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-d5bb3459-cc04-4cc9-baf5-20f4e094dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-e4a56c1b-4f72-4b79-9f70-3e5d1deab819,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-8efa6f1d-9d11-4961-baba-65949221ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-a5e44724-254d-4144-970e-6b3fd82aa8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-97e6eea1-68dc-4f6c-812f-d422a7706c14,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-1e63404b-6c9e-423c-863c-394fd195a17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081432942-172.17.0.3-1597114815053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39423,DS-33254a82-ed39-459c-98ee-a118661484d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-9a076118-17bd-4681-acb5-558134903293,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-9de3bc39-d8bf-4f89-a281-39e1c93990e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-a6b6e8f4-7aef-433c-9e2b-bbb28455a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-98375f3f-6884-469f-9b45-8fea4d0db388,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-f738aaac-1d96-4f2c-8ab4-edeb05dc0336,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-aff960d8-75fd-45fa-999a-b007e1585c97,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-8b967dcf-e8c4-4001-ab52-d1388074071d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081432942-172.17.0.3-1597114815053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39423,DS-33254a82-ed39-459c-98ee-a118661484d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-9a076118-17bd-4681-acb5-558134903293,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-9de3bc39-d8bf-4f89-a281-39e1c93990e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-a6b6e8f4-7aef-433c-9e2b-bbb28455a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-98375f3f-6884-469f-9b45-8fea4d0db388,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-f738aaac-1d96-4f2c-8ab4-edeb05dc0336,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-aff960d8-75fd-45fa-999a-b007e1585c97,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-8b967dcf-e8c4-4001-ab52-d1388074071d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813821334-172.17.0.3-1597114851606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42631,DS-6bb63926-a814-40a7-8b65-2ce57e9bb414,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-2b5b1cb2-1ecf-4ebe-a6dd-b1594483a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-cfab2328-f195-41ef-b153-f344f6cd53a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-efda0008-41cd-45be-9e59-02f1243e44e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-267b4cb9-b90a-412d-9b46-cd41582c6591,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-19cea948-fbbd-43f0-ad3a-c522d099edd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-50a3fc80-0948-4ae3-9115-cd60380f3f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-4af0b1a6-00c6-4cca-851e-ee09d7377da4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813821334-172.17.0.3-1597114851606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42631,DS-6bb63926-a814-40a7-8b65-2ce57e9bb414,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-2b5b1cb2-1ecf-4ebe-a6dd-b1594483a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-cfab2328-f195-41ef-b153-f344f6cd53a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-efda0008-41cd-45be-9e59-02f1243e44e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-267b4cb9-b90a-412d-9b46-cd41582c6591,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-19cea948-fbbd-43f0-ad3a-c522d099edd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-50a3fc80-0948-4ae3-9115-cd60380f3f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-4af0b1a6-00c6-4cca-851e-ee09d7377da4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607581761-172.17.0.3-1597115051492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41595,DS-7b23f9d4-90cb-46c1-8eb0-35d5959f1243,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-fd488252-6340-4e13-8485-db1c02feef11,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-1eee0b57-af94-4251-b53f-aae16ca2bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-7a03e9b5-5d79-445c-9dbd-60bbcf0d883b,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-673811d4-7a40-4c31-a0e0-33ccb8181212,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-1a24a60f-b554-4ae7-a3ce-ba99495e6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-91336728-5909-4c03-8558-e03068c1615e,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-915c8f69-038c-4428-8c95-bb190edc1cb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607581761-172.17.0.3-1597115051492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41595,DS-7b23f9d4-90cb-46c1-8eb0-35d5959f1243,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-fd488252-6340-4e13-8485-db1c02feef11,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-1eee0b57-af94-4251-b53f-aae16ca2bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-7a03e9b5-5d79-445c-9dbd-60bbcf0d883b,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-673811d4-7a40-4c31-a0e0-33ccb8181212,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-1a24a60f-b554-4ae7-a3ce-ba99495e6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-91336728-5909-4c03-8558-e03068c1615e,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-915c8f69-038c-4428-8c95-bb190edc1cb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136212118-172.17.0.3-1597115090299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38549,DS-085d013b-81ac-47eb-9a84-8c118f0732d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-a4dd0084-a644-47f2-b2c2-8f15dc6aaea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-ad31d20e-f790-4b9e-8401-5e40af8f2912,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-a0cdcb49-4e10-4457-b6a0-cb75a9324aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-59af10be-ccf0-4cc6-8a85-60c7bd4e5675,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-dddc4f02-6690-406f-8c59-3ac990aa2809,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-8ddb295c-72c7-4a0b-afa8-659cb02dbe21,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-a529a754-f741-4df0-924f-3c12911a0fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136212118-172.17.0.3-1597115090299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38549,DS-085d013b-81ac-47eb-9a84-8c118f0732d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-a4dd0084-a644-47f2-b2c2-8f15dc6aaea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-ad31d20e-f790-4b9e-8401-5e40af8f2912,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-a0cdcb49-4e10-4457-b6a0-cb75a9324aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-59af10be-ccf0-4cc6-8a85-60c7bd4e5675,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-dddc4f02-6690-406f-8c59-3ac990aa2809,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-8ddb295c-72c7-4a0b-afa8-659cb02dbe21,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-a529a754-f741-4df0-924f-3c12911a0fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572981219-172.17.0.3-1597115427050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38291,DS-6ae042f8-2063-4b7d-806f-f9323868e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-23e5a48a-4ac0-44fe-963a-a4b7a6d1e30b,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-b0771bba-b951-45f2-a7bb-a377925949e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-5c05d1ea-d202-44a1-9fc4-1b77e3c186a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-92567775-4af4-4f61-b0f4-ad2cac76917f,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-cb48d984-359c-43f6-96f4-39c7a11d3134,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-af164b54-de27-42ea-8783-fe9fe65cbe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-e8281e44-9491-4eb8-ad05-92a98eac6b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572981219-172.17.0.3-1597115427050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38291,DS-6ae042f8-2063-4b7d-806f-f9323868e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-23e5a48a-4ac0-44fe-963a-a4b7a6d1e30b,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-b0771bba-b951-45f2-a7bb-a377925949e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-5c05d1ea-d202-44a1-9fc4-1b77e3c186a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-92567775-4af4-4f61-b0f4-ad2cac76917f,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-cb48d984-359c-43f6-96f4-39c7a11d3134,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-af164b54-de27-42ea-8783-fe9fe65cbe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-e8281e44-9491-4eb8-ad05-92a98eac6b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339557685-172.17.0.3-1597115839462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33926,DS-b5be02b4-f9c6-4dba-8d76-e8947c92ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-cacc3625-edc0-4500-93af-551df44c3532,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-19302df2-dcb2-409c-91d7-b6018ee206cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-74358699-624a-4968-a127-26777ef2ab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-e0737c3c-c2aa-465d-b856-632c3fa3ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-1de66176-a7fe-430a-98d2-6a499d9eeb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-f9859599-9e93-45bf-84fb-72735c193209,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-c79e82be-4f00-4003-bb93-12e71b0e6848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339557685-172.17.0.3-1597115839462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33926,DS-b5be02b4-f9c6-4dba-8d76-e8947c92ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-cacc3625-edc0-4500-93af-551df44c3532,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-19302df2-dcb2-409c-91d7-b6018ee206cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-74358699-624a-4968-a127-26777ef2ab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-e0737c3c-c2aa-465d-b856-632c3fa3ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-1de66176-a7fe-430a-98d2-6a499d9eeb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-f9859599-9e93-45bf-84fb-72735c193209,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-c79e82be-4f00-4003-bb93-12e71b0e6848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999160934-172.17.0.3-1597115882194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-2306acfc-e412-42d3-872f-f39706b3ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-637e57f3-e99e-4ad5-9e82-041ef249a679,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-6e6638e9-7cea-4597-95fb-584d2d107ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-3051cb88-8941-4a9d-9980-4ffe375ebf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-d0fb68ee-2428-4327-b391-92ee2e728180,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-821ff2e6-c853-4b74-b49e-167153498381,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-910f0d0c-011f-4013-b78f-2fd3f79206ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-ad3b221f-f7f2-4f78-b1b5-852736e33a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999160934-172.17.0.3-1597115882194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-2306acfc-e412-42d3-872f-f39706b3ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-637e57f3-e99e-4ad5-9e82-041ef249a679,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-6e6638e9-7cea-4597-95fb-584d2d107ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-3051cb88-8941-4a9d-9980-4ffe375ebf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-d0fb68ee-2428-4327-b391-92ee2e728180,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-821ff2e6-c853-4b74-b49e-167153498381,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-910f0d0c-011f-4013-b78f-2fd3f79206ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-ad3b221f-f7f2-4f78-b1b5-852736e33a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092891544-172.17.0.3-1597116252647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-af8deea6-f77d-4628-92bb-41c9cff98ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-83335b74-176d-4bb9-a1c3-abe789c5ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-914f9e00-91d0-4f52-b8bd-69a13675bc80,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-1850b441-3451-49dd-b814-92c4baf3c77a,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-cd0f1694-6a7d-4d4e-8425-a0dbeb16c7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-bb3a4363-1ad5-42f8-b10f-ba884a0b0bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-bc67eace-2d71-4b2e-9443-55f41098c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-09fc08c0-e180-4b78-9344-4f4362a0fe29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092891544-172.17.0.3-1597116252647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-af8deea6-f77d-4628-92bb-41c9cff98ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-83335b74-176d-4bb9-a1c3-abe789c5ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-914f9e00-91d0-4f52-b8bd-69a13675bc80,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-1850b441-3451-49dd-b814-92c4baf3c77a,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-cd0f1694-6a7d-4d4e-8425-a0dbeb16c7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-bb3a4363-1ad5-42f8-b10f-ba884a0b0bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-bc67eace-2d71-4b2e-9443-55f41098c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-09fc08c0-e180-4b78-9344-4f4362a0fe29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351849916-172.17.0.3-1597116583081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40915,DS-4ac32205-efae-469e-b58d-1c99ca3f71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-30b402fd-7119-418b-9893-f4a6c89a179c,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-5f0c6dcc-90f0-47ba-9c80-d602114229b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-820c3df3-cc20-45b4-836f-81f803330931,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-9038d351-82e1-48a7-9ba2-a8f8f22e42f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-1f24d008-e07d-4e27-ab52-e7b262b4e67b,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-2d575b0e-3cfd-4ef3-bf36-54d32e518630,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-59c68423-022b-4d2e-a2c6-70219c55ef07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351849916-172.17.0.3-1597116583081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40915,DS-4ac32205-efae-469e-b58d-1c99ca3f71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-30b402fd-7119-418b-9893-f4a6c89a179c,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-5f0c6dcc-90f0-47ba-9c80-d602114229b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-820c3df3-cc20-45b4-836f-81f803330931,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-9038d351-82e1-48a7-9ba2-a8f8f22e42f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-1f24d008-e07d-4e27-ab52-e7b262b4e67b,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-2d575b0e-3cfd-4ef3-bf36-54d32e518630,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-59c68423-022b-4d2e-a2c6-70219c55ef07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550074715-172.17.0.3-1597116913840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42912,DS-f8f09a50-a8b3-4902-8de5-a2905d6d001a,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-7eabff42-7911-49ca-9b70-ce6d58080c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-8e44a40b-8d6f-4806-8366-c649f661de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-6d965a7a-2d75-4df8-85d8-bb24adc20e64,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-77fe84f9-5a1c-4e60-808d-131c752a9580,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-6041a180-bc7b-4981-85b7-ce961152db98,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-9e469b13-41df-41ac-9f5e-fe341281f82d,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-147a1b86-5c0c-47ce-9717-794429978c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550074715-172.17.0.3-1597116913840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42912,DS-f8f09a50-a8b3-4902-8de5-a2905d6d001a,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-7eabff42-7911-49ca-9b70-ce6d58080c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-8e44a40b-8d6f-4806-8366-c649f661de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-6d965a7a-2d75-4df8-85d8-bb24adc20e64,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-77fe84f9-5a1c-4e60-808d-131c752a9580,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-6041a180-bc7b-4981-85b7-ce961152db98,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-9e469b13-41df-41ac-9f5e-fe341281f82d,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-147a1b86-5c0c-47ce-9717-794429978c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520496173-172.17.0.3-1597116947581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40114,DS-13132d1a-0589-4432-96f6-14db6a31ce57,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-9aa21ecd-3ab2-4ad8-8917-3060eaafac03,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-5b562bce-2577-4026-a610-4970ccfc3326,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-2b918604-67f8-4d21-b04e-720a6a11f8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-a1dbb5d5-0395-4193-987a-208199c7dc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-56dff2da-5994-430e-a22a-61e67b776f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-be0638b0-4c76-4dad-8180-5d89d1e7e540,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-8e8eac97-84a7-42db-8dae-50ab62204d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520496173-172.17.0.3-1597116947581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40114,DS-13132d1a-0589-4432-96f6-14db6a31ce57,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-9aa21ecd-3ab2-4ad8-8917-3060eaafac03,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-5b562bce-2577-4026-a610-4970ccfc3326,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-2b918604-67f8-4d21-b04e-720a6a11f8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-a1dbb5d5-0395-4193-987a-208199c7dc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-56dff2da-5994-430e-a22a-61e67b776f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-be0638b0-4c76-4dad-8180-5d89d1e7e540,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-8e8eac97-84a7-42db-8dae-50ab62204d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5402
