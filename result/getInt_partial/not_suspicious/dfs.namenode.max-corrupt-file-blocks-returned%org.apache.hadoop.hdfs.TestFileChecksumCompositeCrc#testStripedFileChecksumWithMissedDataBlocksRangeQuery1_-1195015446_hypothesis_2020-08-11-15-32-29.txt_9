reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751978229-172.17.0.21-1597160301281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41707,DS-7eedb6b9-75ce-4122-8704-9caa1f6ab69c,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-31360f35-8172-46b6-ab4e-6f3ab714f034,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-f19c7785-9e2c-4987-ab3d-d1cab84cb207,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-98f4971e-ea48-4c01-bc71-780cc7feddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-18c5c171-b10c-4b0a-ba82-5232e303e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-1ddb0727-f354-481d-b732-ba33d58e186e,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-8975676e-5906-4617-b5b0-03012426e8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-bbc6dd2a-9588-4d26-832c-b6021632b82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751978229-172.17.0.21-1597160301281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41707,DS-7eedb6b9-75ce-4122-8704-9caa1f6ab69c,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-31360f35-8172-46b6-ab4e-6f3ab714f034,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-f19c7785-9e2c-4987-ab3d-d1cab84cb207,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-98f4971e-ea48-4c01-bc71-780cc7feddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-18c5c171-b10c-4b0a-ba82-5232e303e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-1ddb0727-f354-481d-b732-ba33d58e186e,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-8975676e-5906-4617-b5b0-03012426e8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-bbc6dd2a-9588-4d26-832c-b6021632b82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244070781-172.17.0.21-1597161180229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34882,DS-74e60658-33d0-4f3d-9106-01cacb42d9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-6d7bcead-2f07-4941-84ff-a380b9d57675,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-49de1cab-6f78-474b-a5cc-866714602a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-caff9119-6940-4412-b88e-33a344e0301b,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-b6fdd5b8-7c65-426c-9a30-7647f8044867,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-3947af4a-1082-4682-a578-83fb8916816f,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-5cd48d55-5cc1-47bc-90fc-f23bb7748893,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-189cdd7c-b6e3-4d8b-96b4-80a64aba34b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244070781-172.17.0.21-1597161180229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34882,DS-74e60658-33d0-4f3d-9106-01cacb42d9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-6d7bcead-2f07-4941-84ff-a380b9d57675,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-49de1cab-6f78-474b-a5cc-866714602a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-caff9119-6940-4412-b88e-33a344e0301b,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-b6fdd5b8-7c65-426c-9a30-7647f8044867,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-3947af4a-1082-4682-a578-83fb8916816f,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-5cd48d55-5cc1-47bc-90fc-f23bb7748893,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-189cdd7c-b6e3-4d8b-96b4-80a64aba34b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146165399-172.17.0.21-1597161539907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-9c9da2ac-02dd-4dd5-90f9-e01548257d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-2b3f6561-0c4a-41c7-9353-a03db5afd658,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-28f2cf43-da9a-4603-af51-3cb2585b3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-ae458d29-7e59-4fcb-b23a-fdd58ab6a048,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-c37318aa-6f76-400c-8e5e-94d991071fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-f2a7091a-0672-42e4-a02c-59e51046b9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-e2f4862d-b893-435c-8143-dbeea3eb0340,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-8976e066-c733-4c80-8330-3964a9f87399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146165399-172.17.0.21-1597161539907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-9c9da2ac-02dd-4dd5-90f9-e01548257d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-2b3f6561-0c4a-41c7-9353-a03db5afd658,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-28f2cf43-da9a-4603-af51-3cb2585b3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-ae458d29-7e59-4fcb-b23a-fdd58ab6a048,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-c37318aa-6f76-400c-8e5e-94d991071fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-f2a7091a-0672-42e4-a02c-59e51046b9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-e2f4862d-b893-435c-8143-dbeea3eb0340,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-8976e066-c733-4c80-8330-3964a9f87399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526976699-172.17.0.21-1597161573104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-d85beae9-05f8-410e-966d-a640418d6d55,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-e5b16503-a801-4493-819b-2540de44d27f,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-759f94a7-98e8-4d9c-b5cf-f89c1d4e3152,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-593a4e9b-9621-4fe1-92d5-02326f7eddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-abb656b1-3e04-44e5-b6df-5b88b3e1c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-f0eb6b3a-f178-4f94-8265-705110c93bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-034e5479-7197-40b0-abab-34f6620584f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-880041ae-6d73-4897-a9c9-bf19be801e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526976699-172.17.0.21-1597161573104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-d85beae9-05f8-410e-966d-a640418d6d55,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-e5b16503-a801-4493-819b-2540de44d27f,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-759f94a7-98e8-4d9c-b5cf-f89c1d4e3152,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-593a4e9b-9621-4fe1-92d5-02326f7eddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-abb656b1-3e04-44e5-b6df-5b88b3e1c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-f0eb6b3a-f178-4f94-8265-705110c93bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-034e5479-7197-40b0-abab-34f6620584f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-880041ae-6d73-4897-a9c9-bf19be801e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634891006-172.17.0.21-1597162215995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35321,DS-19a5206b-3d35-4b79-9de3-b5579267950e,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-12402c7c-8291-46b4-895a-f6d33a863031,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-2c6e8322-c094-4d4d-a546-d2d473885f08,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-323ddb8c-8831-422a-9a66-d0c4cff8581b,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-332322b4-4312-4661-a8aa-6a34feca13dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-240a6f95-d4dd-4bc5-96d4-797e245e2eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-93ec585a-b2e5-461d-9d01-cec2bde8bb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-2047ce77-fd57-423b-b7df-128fe583fa0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634891006-172.17.0.21-1597162215995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35321,DS-19a5206b-3d35-4b79-9de3-b5579267950e,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-12402c7c-8291-46b4-895a-f6d33a863031,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-2c6e8322-c094-4d4d-a546-d2d473885f08,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-323ddb8c-8831-422a-9a66-d0c4cff8581b,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-332322b4-4312-4661-a8aa-6a34feca13dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-240a6f95-d4dd-4bc5-96d4-797e245e2eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-93ec585a-b2e5-461d-9d01-cec2bde8bb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-2047ce77-fd57-423b-b7df-128fe583fa0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593126548-172.17.0.21-1597162961493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38761,DS-d0221651-6008-46a6-9402-5d157901c857,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-a2d09913-aecc-4d95-b565-9c17b806f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-d5a5df65-2c9d-40c2-a845-5fa5a42c4f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-9595a32b-20f2-4ea1-a51b-858df3adb989,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-522d71a5-950e-40fe-92d8-3b5881981b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-a13c8aed-f56e-4878-b3cd-2f51a61ad986,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-cfeef2d3-3546-4300-b2c5-029d52001bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-4eccd187-f65c-45e9-ba3d-194bce1d24ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593126548-172.17.0.21-1597162961493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38761,DS-d0221651-6008-46a6-9402-5d157901c857,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-a2d09913-aecc-4d95-b565-9c17b806f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-d5a5df65-2c9d-40c2-a845-5fa5a42c4f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-9595a32b-20f2-4ea1-a51b-858df3adb989,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-522d71a5-950e-40fe-92d8-3b5881981b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-a13c8aed-f56e-4878-b3cd-2f51a61ad986,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-cfeef2d3-3546-4300-b2c5-029d52001bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-4eccd187-f65c-45e9-ba3d-194bce1d24ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774177813-172.17.0.21-1597163577131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35115,DS-973b3af1-e989-402e-aae7-9efd2bede0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-1b985d7a-23f0-420e-b761-968b34f04538,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-ee22f625-c32b-42d9-8830-7bb07184d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-52b85703-374f-45f9-8415-d5360fa93d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-78dec204-95ff-4e3b-a0da-21787d1d5f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-fbd2608d-7bca-408b-bf37-78ef43110b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-0c20c431-fe77-4876-9449-26d72bc1c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-4c5c80ff-e77f-4769-bafe-97010ed85b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774177813-172.17.0.21-1597163577131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35115,DS-973b3af1-e989-402e-aae7-9efd2bede0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-1b985d7a-23f0-420e-b761-968b34f04538,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-ee22f625-c32b-42d9-8830-7bb07184d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-52b85703-374f-45f9-8415-d5360fa93d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-78dec204-95ff-4e3b-a0da-21787d1d5f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-fbd2608d-7bca-408b-bf37-78ef43110b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-0c20c431-fe77-4876-9449-26d72bc1c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-4c5c80ff-e77f-4769-bafe-97010ed85b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567960844-172.17.0.21-1597163808119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41322,DS-cc8257f5-1f56-4d8e-8f25-01813f365e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-bab81584-096e-4d93-afe6-44578a4af44e,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-bd2799b4-81f9-42b4-93cb-5f98216d8129,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-827bfad8-2653-473e-84d2-8589b82de7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-15596c1b-1007-437c-90f8-b5986ad89cac,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-5d45f5d6-3b2d-4bd8-acd7-b5cc8513a018,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-86e0fca1-c721-457e-ad91-52aa76554069,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-71d6f7d5-3ffc-4d0e-9cad-e6f66531db98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567960844-172.17.0.21-1597163808119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41322,DS-cc8257f5-1f56-4d8e-8f25-01813f365e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-bab81584-096e-4d93-afe6-44578a4af44e,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-bd2799b4-81f9-42b4-93cb-5f98216d8129,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-827bfad8-2653-473e-84d2-8589b82de7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-15596c1b-1007-437c-90f8-b5986ad89cac,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-5d45f5d6-3b2d-4bd8-acd7-b5cc8513a018,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-86e0fca1-c721-457e-ad91-52aa76554069,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-71d6f7d5-3ffc-4d0e-9cad-e6f66531db98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993609073-172.17.0.21-1597164021537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45046,DS-08ac57ea-934f-4ef7-92b6-57ea9fea6038,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-ef83f9ee-5354-4606-845a-2f81842b09eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-7fced339-7544-4dae-b13f-a818d0c497a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-94d207b2-d2fe-4865-8b91-4d30a0756ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-71da04f2-2de4-4d6e-b41a-60621676021e,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-c5c63d79-116c-4cd2-944d-5dfae5f8ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-0dce34d3-8532-427b-9fd2-a947c0c880d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-3ae9d785-d19e-482f-aa03-88a3be8e9b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993609073-172.17.0.21-1597164021537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45046,DS-08ac57ea-934f-4ef7-92b6-57ea9fea6038,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-ef83f9ee-5354-4606-845a-2f81842b09eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-7fced339-7544-4dae-b13f-a818d0c497a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-94d207b2-d2fe-4865-8b91-4d30a0756ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-71da04f2-2de4-4d6e-b41a-60621676021e,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-c5c63d79-116c-4cd2-944d-5dfae5f8ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-0dce34d3-8532-427b-9fd2-a947c0c880d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-3ae9d785-d19e-482f-aa03-88a3be8e9b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192837511-172.17.0.21-1597164195289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-076211a5-4b36-409d-803e-73653f318c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-283ea737-b444-4c41-aff8-97a27370e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-b486212c-0e33-4a1c-ad5b-98826fb0cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-dc126da2-4306-4e19-859e-2286d5cbb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-bec50738-1615-4c9c-81c9-5c88a408c645,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-6e909435-1906-4e51-b4ba-3d84556f56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-c709aaab-abc5-4b6c-aeee-cfe28c231c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-d228d682-432f-4de1-b1f3-36a37768f96f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192837511-172.17.0.21-1597164195289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-076211a5-4b36-409d-803e-73653f318c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-283ea737-b444-4c41-aff8-97a27370e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-b486212c-0e33-4a1c-ad5b-98826fb0cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-dc126da2-4306-4e19-859e-2286d5cbb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-bec50738-1615-4c9c-81c9-5c88a408c645,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-6e909435-1906-4e51-b4ba-3d84556f56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-c709aaab-abc5-4b6c-aeee-cfe28c231c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-d228d682-432f-4de1-b1f3-36a37768f96f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097092054-172.17.0.21-1597164439809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34679,DS-5a3dbc83-81a2-4ffc-90fd-eec8a02de4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-987b1904-5c20-41a2-9079-b16aacef05b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-79f05ef2-2795-40af-ba4d-51a233e4786a,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-03e97f01-9f08-40a9-b43a-3eb758547f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-0923202b-1aef-417c-9092-2c76e64dc841,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-4b82293c-8c21-47a9-b33d-2a02c9d1628a,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-5c26f857-ea5e-4762-a662-c0b77dc0dcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-592e451e-074d-4e40-a9c2-c56e2f52c193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097092054-172.17.0.21-1597164439809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34679,DS-5a3dbc83-81a2-4ffc-90fd-eec8a02de4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-987b1904-5c20-41a2-9079-b16aacef05b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-79f05ef2-2795-40af-ba4d-51a233e4786a,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-03e97f01-9f08-40a9-b43a-3eb758547f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-0923202b-1aef-417c-9092-2c76e64dc841,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-4b82293c-8c21-47a9-b33d-2a02c9d1628a,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-5c26f857-ea5e-4762-a662-c0b77dc0dcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-592e451e-074d-4e40-a9c2-c56e2f52c193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470555042-172.17.0.21-1597164571992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-f0a16a8f-20e8-45b2-abbd-d570a5618d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-814b35fa-d002-4bee-aba8-2ad517ec340b,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-64a5b168-5c20-4d2f-8835-d8eadf3bc3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-f539f3d3-0239-4d26-9068-e5fa61303a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-1fbf619e-737a-4702-9c25-4fbdb393069f,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-c66af4f5-3ac7-4d79-9f6a-dbc6b2826db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-3c0854a9-36c4-4950-9375-087deb14ae29,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-859db953-b196-42dc-8a3d-4bd2b2b5c5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470555042-172.17.0.21-1597164571992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-f0a16a8f-20e8-45b2-abbd-d570a5618d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-814b35fa-d002-4bee-aba8-2ad517ec340b,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-64a5b168-5c20-4d2f-8835-d8eadf3bc3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-f539f3d3-0239-4d26-9068-e5fa61303a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-1fbf619e-737a-4702-9c25-4fbdb393069f,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-c66af4f5-3ac7-4d79-9f6a-dbc6b2826db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-3c0854a9-36c4-4950-9375-087deb14ae29,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-859db953-b196-42dc-8a3d-4bd2b2b5c5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922254815-172.17.0.21-1597164924854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44018,DS-31ab7533-cc8a-435f-a07a-ee055652d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-876a82e3-cde1-48af-a513-709fdbadcc84,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-5f023a73-7d86-4c44-a311-b89b8694037e,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-d57b8a2e-924c-4325-9ccc-741c15d8a2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-a7c9280c-34d6-4c18-9222-cc4b4a26b781,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-cf2f0859-2022-46ff-9d30-4955a657a46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-03726def-41f9-4d45-9421-250992f07e62,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-a04d7cfe-0987-4afe-bff7-b432ba5ecfa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922254815-172.17.0.21-1597164924854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44018,DS-31ab7533-cc8a-435f-a07a-ee055652d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-876a82e3-cde1-48af-a513-709fdbadcc84,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-5f023a73-7d86-4c44-a311-b89b8694037e,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-d57b8a2e-924c-4325-9ccc-741c15d8a2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-a7c9280c-34d6-4c18-9222-cc4b4a26b781,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-cf2f0859-2022-46ff-9d30-4955a657a46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-03726def-41f9-4d45-9421-250992f07e62,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-a04d7cfe-0987-4afe-bff7-b432ba5ecfa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5112
