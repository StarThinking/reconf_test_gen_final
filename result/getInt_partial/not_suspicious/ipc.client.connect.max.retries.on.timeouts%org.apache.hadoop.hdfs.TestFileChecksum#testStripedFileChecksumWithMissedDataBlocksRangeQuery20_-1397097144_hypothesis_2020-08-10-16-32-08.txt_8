reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673073699-172.17.0.4-1597077146137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-33addb30-818b-4c4d-9f7e-c7e70022dbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-f746e0bf-1019-4b67-ab9f-fc5d40072203,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-cace9858-4db8-4f27-abb2-5ed5a3776cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-79f6919f-c388-4867-89d1-2c39a26f591e,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-9ec2f891-17a1-4de1-917b-cbf0ca6c3845,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-4e656333-85dc-43af-99a3-3e14ae224f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-da139251-5ebe-4db3-afbe-d5b8240c1273,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-8a594468-4d09-4d0a-bea9-6cf98772d836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673073699-172.17.0.4-1597077146137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-33addb30-818b-4c4d-9f7e-c7e70022dbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-f746e0bf-1019-4b67-ab9f-fc5d40072203,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-cace9858-4db8-4f27-abb2-5ed5a3776cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-79f6919f-c388-4867-89d1-2c39a26f591e,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-9ec2f891-17a1-4de1-917b-cbf0ca6c3845,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-4e656333-85dc-43af-99a3-3e14ae224f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-da139251-5ebe-4db3-afbe-d5b8240c1273,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-8a594468-4d09-4d0a-bea9-6cf98772d836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4817759-172.17.0.4-1597077365909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33406,DS-41d4fcca-c6e5-4132-a8ac-c76bbc207bef,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-09ab53b3-7922-4ff5-b618-e81c5d8a35c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-fc59922a-7e31-420a-b14d-5e6d3bc26f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-8586ef73-4ac8-49f8-8613-f06ae08b45cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-21ea04a2-cf89-4ed2-8666-961f950196b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-cc96d491-3a04-421b-be53-2363883c1d80,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-0cdb0eeb-dbb2-4c3f-841b-205213f709bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-5a1e917a-8a96-4f38-9915-c66b59ebca21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4817759-172.17.0.4-1597077365909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33406,DS-41d4fcca-c6e5-4132-a8ac-c76bbc207bef,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-09ab53b3-7922-4ff5-b618-e81c5d8a35c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-fc59922a-7e31-420a-b14d-5e6d3bc26f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-8586ef73-4ac8-49f8-8613-f06ae08b45cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-21ea04a2-cf89-4ed2-8666-961f950196b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-cc96d491-3a04-421b-be53-2363883c1d80,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-0cdb0eeb-dbb2-4c3f-841b-205213f709bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-5a1e917a-8a96-4f38-9915-c66b59ebca21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855969945-172.17.0.4-1597078300096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-d47eeb67-a866-4f7a-87b0-64332c5f899b,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-6662f575-d90a-499c-8663-3ddf56394d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-ef73a942-4e4c-40c9-a53b-151499dfe66f,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-1002d915-35d2-4f2f-a569-c2531bd2ebc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-a00eb614-7609-4b5b-9534-eb670a36f3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-ba561200-9201-44f9-83e5-7fb4bc0d3bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-4491a1b5-2fc4-43f1-b250-4c56715cb67c,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-9602b68e-6412-4350-b9aa-3e3734abdf00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855969945-172.17.0.4-1597078300096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-d47eeb67-a866-4f7a-87b0-64332c5f899b,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-6662f575-d90a-499c-8663-3ddf56394d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-ef73a942-4e4c-40c9-a53b-151499dfe66f,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-1002d915-35d2-4f2f-a569-c2531bd2ebc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-a00eb614-7609-4b5b-9534-eb670a36f3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-ba561200-9201-44f9-83e5-7fb4bc0d3bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-4491a1b5-2fc4-43f1-b250-4c56715cb67c,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-9602b68e-6412-4350-b9aa-3e3734abdf00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747456893-172.17.0.4-1597078363838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-ad2c001e-d6ee-4352-9739-95b6d852b668,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-c064cb01-3d14-4ffd-845b-a8b036b03b02,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-49b563c3-4bce-4395-92e6-891919954853,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-c0b0ae7d-5579-4801-98e7-fc72bac9cbde,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-d88b05e5-136c-45c9-9f3a-d7a1f7fdc291,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-6015121a-0dca-4bd1-8994-0579a40450b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-5b79da8f-e5c8-481e-a457-a52189aefc86,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-6fccec30-5fcc-4383-8766-fd04560c8d54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747456893-172.17.0.4-1597078363838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-ad2c001e-d6ee-4352-9739-95b6d852b668,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-c064cb01-3d14-4ffd-845b-a8b036b03b02,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-49b563c3-4bce-4395-92e6-891919954853,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-c0b0ae7d-5579-4801-98e7-fc72bac9cbde,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-d88b05e5-136c-45c9-9f3a-d7a1f7fdc291,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-6015121a-0dca-4bd1-8994-0579a40450b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-5b79da8f-e5c8-481e-a457-a52189aefc86,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-6fccec30-5fcc-4383-8766-fd04560c8d54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451959117-172.17.0.4-1597079407770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-c4676919-ab0e-47ad-98f9-6e655080369b,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-6a88463a-0221-4fd2-9756-c1f26adbbbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-64782d8d-464c-449e-9982-649d19eae35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-f3b3a35d-c3f5-467d-bcb5-6aee576e0f47,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-fbeb46cf-c957-4129-920b-96eecff37713,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-984e8fe1-08d4-439d-b9b4-c83f3260e411,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-70532957-397d-4e04-9b25-ba759bce32c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-11957560-41b7-4237-83dd-bfef4f490d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451959117-172.17.0.4-1597079407770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-c4676919-ab0e-47ad-98f9-6e655080369b,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-6a88463a-0221-4fd2-9756-c1f26adbbbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-64782d8d-464c-449e-9982-649d19eae35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-f3b3a35d-c3f5-467d-bcb5-6aee576e0f47,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-fbeb46cf-c957-4129-920b-96eecff37713,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-984e8fe1-08d4-439d-b9b4-c83f3260e411,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-70532957-397d-4e04-9b25-ba759bce32c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-11957560-41b7-4237-83dd-bfef4f490d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239751603-172.17.0.4-1597079479877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44960,DS-2308e030-4fbe-4477-a3b8-ac0d2a88ec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-71cc826d-512e-41ea-9efc-5b68d2c5852b,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-426c04ec-8b91-41d1-afcd-f91c38e1e7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-c03b1686-ab41-4559-a6ed-8734b22bf791,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-df513014-435e-46d0-a619-3b6a8ab011d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-cc3c971b-8675-427d-8626-1e6eec27a296,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-06354b14-2296-40c6-9d83-86fb8fc8b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-4079dddf-cd83-4689-afa2-8d9eb37d2296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239751603-172.17.0.4-1597079479877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44960,DS-2308e030-4fbe-4477-a3b8-ac0d2a88ec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-71cc826d-512e-41ea-9efc-5b68d2c5852b,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-426c04ec-8b91-41d1-afcd-f91c38e1e7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-c03b1686-ab41-4559-a6ed-8734b22bf791,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-df513014-435e-46d0-a619-3b6a8ab011d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-cc3c971b-8675-427d-8626-1e6eec27a296,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-06354b14-2296-40c6-9d83-86fb8fc8b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-4079dddf-cd83-4689-afa2-8d9eb37d2296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131922633-172.17.0.4-1597079592250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-6685076d-3834-441a-a1c4-19d5683a0520,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6b08a1ae-69b3-4532-9547-06cbc4556eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-a7636dff-ff4c-4eaf-9581-6348c29500d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-18b040a7-a78f-4057-90e2-16e3a79d829d,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-84910cf0-ae7f-44b8-b406-11e91e1e00d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-b6005b9a-b194-476b-9e57-8b1a8501d795,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-882a5aab-66ca-4321-9011-4936f85ddc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-343320a1-59e0-4d5d-abad-5e0a72592fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131922633-172.17.0.4-1597079592250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-6685076d-3834-441a-a1c4-19d5683a0520,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6b08a1ae-69b3-4532-9547-06cbc4556eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-a7636dff-ff4c-4eaf-9581-6348c29500d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-18b040a7-a78f-4057-90e2-16e3a79d829d,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-84910cf0-ae7f-44b8-b406-11e91e1e00d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-b6005b9a-b194-476b-9e57-8b1a8501d795,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-882a5aab-66ca-4321-9011-4936f85ddc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-343320a1-59e0-4d5d-abad-5e0a72592fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459389144-172.17.0.4-1597080148790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-c03112be-8af0-4c0d-b310-c111408f52d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-e7334674-97c9-485c-b8f7-364be4c99599,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-977a6a8a-9844-4313-ae9a-2d2fa5d12b80,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-b8eb4052-f769-45e9-b717-3ba83cdad597,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-2d76ff7f-6524-4c62-b8e3-6dcb1310d5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-984fdec1-65ee-4736-8054-8c4d219e4485,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-b9e14d6a-72fd-4d9e-bfdd-f385ccb96d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-3de41be1-2c5e-4d4f-a64a-e28ecb4046c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459389144-172.17.0.4-1597080148790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-c03112be-8af0-4c0d-b310-c111408f52d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-e7334674-97c9-485c-b8f7-364be4c99599,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-977a6a8a-9844-4313-ae9a-2d2fa5d12b80,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-b8eb4052-f769-45e9-b717-3ba83cdad597,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-2d76ff7f-6524-4c62-b8e3-6dcb1310d5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-984fdec1-65ee-4736-8054-8c4d219e4485,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-b9e14d6a-72fd-4d9e-bfdd-f385ccb96d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-3de41be1-2c5e-4d4f-a64a-e28ecb4046c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851060659-172.17.0.4-1597080475407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40200,DS-c0a8de6a-2a1d-4fbb-b631-d0f979ef89a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-7e0ec62c-eafa-474e-9ab2-47f411f77fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-f5b8691c-413e-41a1-9ef4-6c2a653f7754,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-f1ae7c40-0b48-45fb-8f90-a474e6c76b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-2af52948-94b6-4a21-be66-9e5fb818b226,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-9dcaf973-c35d-4daf-b279-f2c452186d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-ea61c783-cc64-40e3-88a2-bebb757b15cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-f0058b0d-a6ee-4146-9733-4fee1268451e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851060659-172.17.0.4-1597080475407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40200,DS-c0a8de6a-2a1d-4fbb-b631-d0f979ef89a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-7e0ec62c-eafa-474e-9ab2-47f411f77fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-f5b8691c-413e-41a1-9ef4-6c2a653f7754,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-f1ae7c40-0b48-45fb-8f90-a474e6c76b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-2af52948-94b6-4a21-be66-9e5fb818b226,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-9dcaf973-c35d-4daf-b279-f2c452186d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-ea61c783-cc64-40e3-88a2-bebb757b15cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-f0058b0d-a6ee-4146-9733-4fee1268451e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835920407-172.17.0.4-1597080506799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41529,DS-f760d91f-8331-4f27-a047-c3a1f32e8221,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-f67ef283-66b2-45db-a029-d674d947116c,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-9ecf05a7-de98-482e-9f03-11ce7c7f347a,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-5e6ccd62-5e6d-467e-8dd2-4cfcecde038b,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-aa414e0d-1d71-4905-a5f2-53064f2fee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-2f4b4902-2c32-41ed-a261-222a08c099fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-77d1fe53-fe48-4380-a681-bd417de48c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-0c444775-3a12-4aa0-b24f-bf48e1e4b268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835920407-172.17.0.4-1597080506799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41529,DS-f760d91f-8331-4f27-a047-c3a1f32e8221,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-f67ef283-66b2-45db-a029-d674d947116c,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-9ecf05a7-de98-482e-9f03-11ce7c7f347a,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-5e6ccd62-5e6d-467e-8dd2-4cfcecde038b,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-aa414e0d-1d71-4905-a5f2-53064f2fee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-2f4b4902-2c32-41ed-a261-222a08c099fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-77d1fe53-fe48-4380-a681-bd417de48c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-0c444775-3a12-4aa0-b24f-bf48e1e4b268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785818563-172.17.0.4-1597080611847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-7f68b71d-696d-43dc-b497-08333174f3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-61484dfb-0014-4177-a559-453e0cc6f820,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-17b2574d-64c0-4159-b90c-de364a0193c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-907266e5-2873-4831-b7d3-4106eda5cd32,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-ec0c59bf-1b9b-4615-a9fb-6b646ce21ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-dd942e16-55d7-42ae-b0d4-4df2b74e797b,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-0a867070-23be-4a0a-aac9-8fdce427227e,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-a7275199-fdf8-44e9-8ec7-867f5291db3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785818563-172.17.0.4-1597080611847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-7f68b71d-696d-43dc-b497-08333174f3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-61484dfb-0014-4177-a559-453e0cc6f820,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-17b2574d-64c0-4159-b90c-de364a0193c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-907266e5-2873-4831-b7d3-4106eda5cd32,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-ec0c59bf-1b9b-4615-a9fb-6b646ce21ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-dd942e16-55d7-42ae-b0d4-4df2b74e797b,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-0a867070-23be-4a0a-aac9-8fdce427227e,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-a7275199-fdf8-44e9-8ec7-867f5291db3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99641938-172.17.0.4-1597081182063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-2959f653-2fd2-472b-b74f-63dd03b4eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-2271bcc2-e8f6-4b93-938f-89f628ba23bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-e4d5258b-7c52-4c37-b627-e7f1f082756a,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-e8a1dbc0-9270-4638-a173-b09f8019eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-de117243-1fa0-47b9-a8da-0bcfbd051126,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-cd5e4d50-391b-4012-9085-6a40f062371d,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-ffdece5e-412c-42e6-bb88-85422432ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-fc63563d-5cd9-403c-ad92-781452645b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99641938-172.17.0.4-1597081182063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-2959f653-2fd2-472b-b74f-63dd03b4eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-2271bcc2-e8f6-4b93-938f-89f628ba23bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-e4d5258b-7c52-4c37-b627-e7f1f082756a,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-e8a1dbc0-9270-4638-a173-b09f8019eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-de117243-1fa0-47b9-a8da-0bcfbd051126,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-cd5e4d50-391b-4012-9085-6a40f062371d,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-ffdece5e-412c-42e6-bb88-85422432ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-fc63563d-5cd9-403c-ad92-781452645b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958828496-172.17.0.4-1597081220693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40142,DS-12bd59e5-6e97-4f5b-ad7d-3e8f1a74eee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-712e9f63-582a-4dab-b443-d05fb496f750,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-87abbf91-5848-4829-b113-32758e50bd50,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-b6102bcc-8c04-457c-84bb-3373354dda32,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-0ae810a9-1c15-4ec4-a949-6f3cc7360460,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-81328909-dcbb-40b9-b55c-c7f02edeea75,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-2a779a2b-533e-4e83-b699-15a6bd5ba3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-13977ac0-ecfd-4612-bf83-8803ae2d0716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958828496-172.17.0.4-1597081220693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40142,DS-12bd59e5-6e97-4f5b-ad7d-3e8f1a74eee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-712e9f63-582a-4dab-b443-d05fb496f750,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-87abbf91-5848-4829-b113-32758e50bd50,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-b6102bcc-8c04-457c-84bb-3373354dda32,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-0ae810a9-1c15-4ec4-a949-6f3cc7360460,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-81328909-dcbb-40b9-b55c-c7f02edeea75,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-2a779a2b-533e-4e83-b699-15a6bd5ba3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-13977ac0-ecfd-4612-bf83-8803ae2d0716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358166592-172.17.0.4-1597081646160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37893,DS-ee121126-61f2-43e7-b024-a874af585747,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-db553a36-17ba-4881-b149-5786f18bca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-15ed0a1f-d049-4d83-ab2d-e07dd393e290,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-5f7e477f-f3b4-45a6-8912-781ce6ca7587,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-2a44430e-650e-4403-8fe0-8e139d73b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-5823c680-a0a7-45d0-8f5e-a1b8fe080ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-0ece6e00-c8d4-43f6-a1df-9e36653bff05,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-0bf6b988-271e-48b5-91f9-01a862c06a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358166592-172.17.0.4-1597081646160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37893,DS-ee121126-61f2-43e7-b024-a874af585747,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-db553a36-17ba-4881-b149-5786f18bca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-15ed0a1f-d049-4d83-ab2d-e07dd393e290,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-5f7e477f-f3b4-45a6-8912-781ce6ca7587,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-2a44430e-650e-4403-8fe0-8e139d73b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-5823c680-a0a7-45d0-8f5e-a1b8fe080ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-0ece6e00-c8d4-43f6-a1df-9e36653bff05,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-0bf6b988-271e-48b5-91f9-01a862c06a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311515087-172.17.0.4-1597082109911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-d83dc205-8468-4a27-9cb6-25003b54f595,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-b0f9c7c4-4b18-4fee-ac79-a3dddbddd853,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-32c63538-5fe2-4ab8-b021-556e71884958,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-f9322eaf-c058-448e-8750-1fef404d306a,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-11bfab6c-d9bd-4c43-a8f0-cefeadfa7488,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-e2975238-af84-4576-b130-9b5c12060756,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-6db2a916-fd1d-412b-8f26-1e2620aeb5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-ae3adba4-902e-4c9b-9ef9-cbff2d97fa4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311515087-172.17.0.4-1597082109911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-d83dc205-8468-4a27-9cb6-25003b54f595,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-b0f9c7c4-4b18-4fee-ac79-a3dddbddd853,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-32c63538-5fe2-4ab8-b021-556e71884958,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-f9322eaf-c058-448e-8750-1fef404d306a,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-11bfab6c-d9bd-4c43-a8f0-cefeadfa7488,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-e2975238-af84-4576-b130-9b5c12060756,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-6db2a916-fd1d-412b-8f26-1e2620aeb5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-ae3adba4-902e-4c9b-9ef9-cbff2d97fa4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105449874-172.17.0.4-1597082353251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42959,DS-02020454-8cf4-4214-ad94-60a707273794,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-71911abf-a915-4529-ab6a-63b6a54ee1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-9b7ffba1-b4b9-485f-b60b-a84cd0995b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-93b1ce07-08e9-44ec-ba2c-7c073ba15473,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-0d372c4f-e207-4de9-860e-710c92c8fab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-c7ab1191-1bc4-41b9-b21f-cfbde3636304,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-566ba0af-afa5-47d6-aada-7deae17df559,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-fd6633f8-184e-49d9-b237-bf0bfd74d0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105449874-172.17.0.4-1597082353251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42959,DS-02020454-8cf4-4214-ad94-60a707273794,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-71911abf-a915-4529-ab6a-63b6a54ee1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-9b7ffba1-b4b9-485f-b60b-a84cd0995b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-93b1ce07-08e9-44ec-ba2c-7c073ba15473,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-0d372c4f-e207-4de9-860e-710c92c8fab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-c7ab1191-1bc4-41b9-b21f-cfbde3636304,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-566ba0af-afa5-47d6-aada-7deae17df559,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-fd6633f8-184e-49d9-b237-bf0bfd74d0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5286
