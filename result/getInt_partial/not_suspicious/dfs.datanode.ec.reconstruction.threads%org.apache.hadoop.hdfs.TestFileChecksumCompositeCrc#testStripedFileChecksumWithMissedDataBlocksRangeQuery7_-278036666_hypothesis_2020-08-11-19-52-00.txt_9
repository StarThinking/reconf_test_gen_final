reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225879567-172.17.0.16-1597175536124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34796,DS-48672562-4b13-4be8-8bfc-2aff4693f79f,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-4ddfa555-7c84-4a5c-8ec9-cd35b3095f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-a3f4b95c-a81f-4acc-a4c3-7e34a33b1228,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-dcb9ce16-7213-4233-b7a6-0968f1f9a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-9c5847a2-60ea-49e5-b034-f13877034e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-19829599-61fc-4a3e-a467-47bd02561b15,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-fcf78509-b1ba-404a-8042-52521c6205cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-208ccad6-4dbf-4110-8ac5-2adbd12f1d6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225879567-172.17.0.16-1597175536124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34796,DS-48672562-4b13-4be8-8bfc-2aff4693f79f,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-4ddfa555-7c84-4a5c-8ec9-cd35b3095f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-a3f4b95c-a81f-4acc-a4c3-7e34a33b1228,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-dcb9ce16-7213-4233-b7a6-0968f1f9a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-9c5847a2-60ea-49e5-b034-f13877034e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-19829599-61fc-4a3e-a467-47bd02561b15,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-fcf78509-b1ba-404a-8042-52521c6205cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-208ccad6-4dbf-4110-8ac5-2adbd12f1d6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703271255-172.17.0.16-1597175649235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-c96d1db1-4ed9-4d8f-94f1-79b7b8db3886,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-90b39336-7700-4ee0-a7a0-fcf3b1005286,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-2953bd11-19db-42b6-a1be-acba96d45f35,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-f1091761-0739-4746-b9fb-d0add5239ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-fdee5982-5c62-4743-ba7d-95f82061f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-e685b508-16eb-4645-91ca-6b080a10d926,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-e285a32a-d443-40ca-aa6a-ff71cb444716,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-1fbb3894-c267-4e29-a5a4-9692cc9b15d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703271255-172.17.0.16-1597175649235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-c96d1db1-4ed9-4d8f-94f1-79b7b8db3886,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-90b39336-7700-4ee0-a7a0-fcf3b1005286,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-2953bd11-19db-42b6-a1be-acba96d45f35,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-f1091761-0739-4746-b9fb-d0add5239ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-fdee5982-5c62-4743-ba7d-95f82061f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-e685b508-16eb-4645-91ca-6b080a10d926,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-e285a32a-d443-40ca-aa6a-ff71cb444716,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-1fbb3894-c267-4e29-a5a4-9692cc9b15d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146564423-172.17.0.16-1597175793448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-e7b1b081-ffca-4b2b-8604-518e5cf69fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-5bce19ec-c4bc-49a1-8e2f-96f49c7ddc19,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-9f1bb1fa-8181-4ecc-897b-3195b64638c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-5ca400ea-a997-46ce-8d8d-34f943ec852b,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-46f5c718-8a03-4c8e-a313-5cfdcc6b1955,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-ae1385b4-bc05-45ef-95b2-531da5ae92ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-ae782b50-241a-4a28-a4af-a623003f2d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-42b3acba-5b1e-4af1-b354-6b618704f830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146564423-172.17.0.16-1597175793448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-e7b1b081-ffca-4b2b-8604-518e5cf69fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-5bce19ec-c4bc-49a1-8e2f-96f49c7ddc19,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-9f1bb1fa-8181-4ecc-897b-3195b64638c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-5ca400ea-a997-46ce-8d8d-34f943ec852b,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-46f5c718-8a03-4c8e-a313-5cfdcc6b1955,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-ae1385b4-bc05-45ef-95b2-531da5ae92ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-ae782b50-241a-4a28-a4af-a623003f2d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-42b3acba-5b1e-4af1-b354-6b618704f830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133772567-172.17.0.16-1597175874357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34249,DS-beee5d26-c331-4f74-b518-45e9ed744dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-81106725-f857-4c41-afc1-ed7f2b23c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-b2333c9b-dd70-4fa4-826b-408d44768f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-7d6b57b2-66e2-407b-ac19-ac964da8c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-d6a44777-0109-4202-a026-a95fb457ef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-fbdf1e02-92af-40fa-b911-b6b0d29f359c,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-0bf14817-0fc8-493c-bf32-2696577ec061,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-16aa9ff6-51b6-4dab-a106-d24841235d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133772567-172.17.0.16-1597175874357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34249,DS-beee5d26-c331-4f74-b518-45e9ed744dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-81106725-f857-4c41-afc1-ed7f2b23c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-b2333c9b-dd70-4fa4-826b-408d44768f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-7d6b57b2-66e2-407b-ac19-ac964da8c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-d6a44777-0109-4202-a026-a95fb457ef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-fbdf1e02-92af-40fa-b911-b6b0d29f359c,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-0bf14817-0fc8-493c-bf32-2696577ec061,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-16aa9ff6-51b6-4dab-a106-d24841235d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975971529-172.17.0.16-1597175974124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35840,DS-816ac510-6031-48d9-a968-32c20dc3867c,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-8caf781c-a471-42c8-a574-c0fc4413a17e,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-366d5aa6-8299-44ba-96d9-db0198ab750a,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-58dda4bd-fa5c-4c51-8117-2a6d3109eeea,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-52efab28-6b82-476a-af8f-17240ed90352,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-6b6aba17-2793-48eb-b832-50e90072a5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-52404adb-eaf6-4a1a-af80-db0478665544,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-4d6e357b-0bbc-469d-a383-0ad4d7187727,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975971529-172.17.0.16-1597175974124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35840,DS-816ac510-6031-48d9-a968-32c20dc3867c,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-8caf781c-a471-42c8-a574-c0fc4413a17e,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-366d5aa6-8299-44ba-96d9-db0198ab750a,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-58dda4bd-fa5c-4c51-8117-2a6d3109eeea,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-52efab28-6b82-476a-af8f-17240ed90352,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-6b6aba17-2793-48eb-b832-50e90072a5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-52404adb-eaf6-4a1a-af80-db0478665544,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-4d6e357b-0bbc-469d-a383-0ad4d7187727,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355144749-172.17.0.16-1597176262750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-3b38bab6-9abb-48ea-9929-f05b01d87ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-5258d072-2475-496a-b6f7-c236047491c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-b53c2f71-5485-412e-a71c-037a3bb26882,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-db268495-6d04-4520-96da-c9899c7cb99d,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-8fe5e732-2501-49cd-8a34-b3a58b71f7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-991e90b1-42f6-4c5c-bd4d-031ebdc32c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-53d35e0d-a7ad-4d78-95c6-9ecea817a117,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-609aba94-6db6-45e3-9f7f-bf3039b58791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355144749-172.17.0.16-1597176262750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-3b38bab6-9abb-48ea-9929-f05b01d87ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-5258d072-2475-496a-b6f7-c236047491c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-b53c2f71-5485-412e-a71c-037a3bb26882,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-db268495-6d04-4520-96da-c9899c7cb99d,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-8fe5e732-2501-49cd-8a34-b3a58b71f7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-991e90b1-42f6-4c5c-bd4d-031ebdc32c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-53d35e0d-a7ad-4d78-95c6-9ecea817a117,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-609aba94-6db6-45e3-9f7f-bf3039b58791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875711562-172.17.0.16-1597176413984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41656,DS-53355692-de53-43d6-98c9-96a94a73adf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-5e60ddc7-763c-479d-b1b4-a4aaa0d567a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-b1bbad45-479e-47ad-a4fa-19b9830b2678,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-593cb91f-7714-4ea8-8315-1eeb5b28d936,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-7f0a5ff7-6666-4d96-a410-511f94314a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-d918b543-4a66-480b-adef-a105edcb4983,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-9b2cf0e0-76b2-4422-832c-2b4877c6e4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-e04a1fe4-2938-4597-b804-31be9698e28e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875711562-172.17.0.16-1597176413984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41656,DS-53355692-de53-43d6-98c9-96a94a73adf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-5e60ddc7-763c-479d-b1b4-a4aaa0d567a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-b1bbad45-479e-47ad-a4fa-19b9830b2678,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-593cb91f-7714-4ea8-8315-1eeb5b28d936,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-7f0a5ff7-6666-4d96-a410-511f94314a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-d918b543-4a66-480b-adef-a105edcb4983,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-9b2cf0e0-76b2-4422-832c-2b4877c6e4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-e04a1fe4-2938-4597-b804-31be9698e28e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010525294-172.17.0.16-1597176443397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-cafab450-f52e-4099-bddd-b63dd4a1064d,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-a3c27e6c-4fe4-4b02-83fc-c83edb986b58,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-698c05af-6894-4ceb-8518-ad3c6e9c8a45,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8f7bc326-be4a-4db1-b168-eba120399b43,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-76020e9b-c1cc-4509-a8a8-c06d9b59e542,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-650d8157-5e68-4787-bb05-a8658217de43,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-39605d88-72df-4d34-a3c6-c5fdb0f29465,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-a27d2339-cced-4b01-a47f-1dd18db1cdcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010525294-172.17.0.16-1597176443397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-cafab450-f52e-4099-bddd-b63dd4a1064d,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-a3c27e6c-4fe4-4b02-83fc-c83edb986b58,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-698c05af-6894-4ceb-8518-ad3c6e9c8a45,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8f7bc326-be4a-4db1-b168-eba120399b43,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-76020e9b-c1cc-4509-a8a8-c06d9b59e542,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-650d8157-5e68-4787-bb05-a8658217de43,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-39605d88-72df-4d34-a3c6-c5fdb0f29465,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-a27d2339-cced-4b01-a47f-1dd18db1cdcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882659884-172.17.0.16-1597176745283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-9d3ff254-1480-4db7-b1f6-d67cd28b1fae,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-9a32c427-4ca5-4265-84ca-981feea4abfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-3ac6c0f2-6893-44cf-807b-943d6c686ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-767e20e7-81b1-48e7-abe7-b681b487124f,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-f0308314-b7a4-4b4d-8092-1ee005662d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-47740249-24ce-47ad-8be5-42c8151e022e,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-7bef9d2d-c728-4112-a2a9-23b428c4dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-a34b9758-2be9-4ae3-9389-d592c83fa3e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882659884-172.17.0.16-1597176745283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-9d3ff254-1480-4db7-b1f6-d67cd28b1fae,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-9a32c427-4ca5-4265-84ca-981feea4abfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-3ac6c0f2-6893-44cf-807b-943d6c686ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-767e20e7-81b1-48e7-abe7-b681b487124f,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-f0308314-b7a4-4b4d-8092-1ee005662d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-47740249-24ce-47ad-8be5-42c8151e022e,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-7bef9d2d-c728-4112-a2a9-23b428c4dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-a34b9758-2be9-4ae3-9389-d592c83fa3e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248987564-172.17.0.16-1597176777519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-d1db5c03-8749-46fd-be11-081690b50121,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-96ed63f9-c773-446d-820c-fc9f53d1e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-62d3e5b1-856c-4775-a5ec-44213e40aa28,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-2b1e6957-b824-4f81-a5e9-6d35842325a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-4d8a10d3-53a8-423b-abcc-01edd614d676,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-00061002-5c5c-4aeb-8b3b-5ceb41128791,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-5fdee36d-f315-42a3-9392-89c457b9f40d,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-31cd6175-9e30-4ddf-88d7-92c8032c5ccc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248987564-172.17.0.16-1597176777519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-d1db5c03-8749-46fd-be11-081690b50121,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-96ed63f9-c773-446d-820c-fc9f53d1e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-62d3e5b1-856c-4775-a5ec-44213e40aa28,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-2b1e6957-b824-4f81-a5e9-6d35842325a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-4d8a10d3-53a8-423b-abcc-01edd614d676,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-00061002-5c5c-4aeb-8b3b-5ceb41128791,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-5fdee36d-f315-42a3-9392-89c457b9f40d,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-31cd6175-9e30-4ddf-88d7-92c8032c5ccc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324339869-172.17.0.16-1597176959405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46714,DS-cedb61aa-3d17-4144-ab75-8c45aa2f9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-5e324cf6-e6c3-45ec-aa7c-2917a77d359a,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-ea5a2a3a-fc37-40c5-9014-851c820c6ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-2be48278-aa66-41b1-a8ae-ff8edd9f9dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-6cb1b37a-10aa-4e93-bd75-ffa3361d64b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-bd5083b5-4665-4e68-a654-c9e0deb344e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-3c0296d1-fb7d-4ba6-a2a1-75bb18602f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-6446d381-dd06-411a-9e12-56ec8ea5a079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324339869-172.17.0.16-1597176959405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46714,DS-cedb61aa-3d17-4144-ab75-8c45aa2f9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-5e324cf6-e6c3-45ec-aa7c-2917a77d359a,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-ea5a2a3a-fc37-40c5-9014-851c820c6ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-2be48278-aa66-41b1-a8ae-ff8edd9f9dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-6cb1b37a-10aa-4e93-bd75-ffa3361d64b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-bd5083b5-4665-4e68-a654-c9e0deb344e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-3c0296d1-fb7d-4ba6-a2a1-75bb18602f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-6446d381-dd06-411a-9e12-56ec8ea5a079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016113117-172.17.0.16-1597176989888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38699,DS-37fbbfbf-ed27-476b-bd1c-84bf625bc487,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-a2fbf64e-b664-4b3a-a4b2-ed7107522b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-c32ac23e-0747-4824-905b-3b5bf2aa85fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-13408d7e-290b-4688-b676-fc493c703ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-fdfb9f87-5a24-4764-ba8e-318a842709fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-64393bf2-92cc-4e82-87a6-bb35978c90b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-a45f0180-293d-47d8-a90a-82d519332ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-90af7640-2677-405b-945d-e7f6fc4c4561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016113117-172.17.0.16-1597176989888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38699,DS-37fbbfbf-ed27-476b-bd1c-84bf625bc487,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-a2fbf64e-b664-4b3a-a4b2-ed7107522b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-c32ac23e-0747-4824-905b-3b5bf2aa85fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-13408d7e-290b-4688-b676-fc493c703ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-fdfb9f87-5a24-4764-ba8e-318a842709fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-64393bf2-92cc-4e82-87a6-bb35978c90b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-a45f0180-293d-47d8-a90a-82d519332ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-90af7640-2677-405b-945d-e7f6fc4c4561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885499506-172.17.0.16-1597177133797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44711,DS-03bd4843-fe73-4ef5-9435-7dc323b6f4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-001f925d-0ce6-4b26-a7d8-ece075e8e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-d855910f-e48b-4644-bcf9-d123c6e2d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-959e115c-1a64-471d-afab-2cee7044991a,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-8cc49ece-0127-4a20-9d12-3fc870531062,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-21d6ce60-d807-4d25-88fd-36b6c43620fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-252158e9-6807-4583-be17-d1076cf511f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-e15f05c1-3a3a-4be6-9619-8b8576bf8ea5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885499506-172.17.0.16-1597177133797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44711,DS-03bd4843-fe73-4ef5-9435-7dc323b6f4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-001f925d-0ce6-4b26-a7d8-ece075e8e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-d855910f-e48b-4644-bcf9-d123c6e2d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-959e115c-1a64-471d-afab-2cee7044991a,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-8cc49ece-0127-4a20-9d12-3fc870531062,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-21d6ce60-d807-4d25-88fd-36b6c43620fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-252158e9-6807-4583-be17-d1076cf511f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-e15f05c1-3a3a-4be6-9619-8b8576bf8ea5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361773674-172.17.0.16-1597177345831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-544e92c4-49fa-49ad-8769-edca074af94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-dea19972-ea6a-4444-80d1-4a3b613fcf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-511677ae-e255-4bd9-894a-974eaa5869a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-402b2899-5122-4873-96db-1208a70c8f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-914501d3-181d-4af7-acc5-c14bdfcdafad,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-12a5fbd3-9602-4d9c-91da-9bc991a38f53,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-b32f14fb-32c7-4128-99cd-e53335c4e57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-957dfad7-6362-46a5-a299-5bb9c8b8dbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361773674-172.17.0.16-1597177345831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-544e92c4-49fa-49ad-8769-edca074af94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-dea19972-ea6a-4444-80d1-4a3b613fcf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-511677ae-e255-4bd9-894a-974eaa5869a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-402b2899-5122-4873-96db-1208a70c8f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-914501d3-181d-4af7-acc5-c14bdfcdafad,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-12a5fbd3-9602-4d9c-91da-9bc991a38f53,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-b32f14fb-32c7-4128-99cd-e53335c4e57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-957dfad7-6362-46a5-a299-5bb9c8b8dbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853702540-172.17.0.16-1597177378076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-59e21b06-75ed-4768-ad2b-be2c17a0095d,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-0af2ac1d-41a7-4b0b-a444-d7aa469fd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-af2fa04e-961d-4f8f-9779-fceff159786d,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-caf1a951-e3fa-4dd5-a88e-d220d1ff89a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-57150089-6be8-496d-b3dd-44ab65676667,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-6b0d3c8c-6026-408f-93ba-56cbd76f9005,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-2c2dd2f8-1fe3-4c8e-87f5-9a246a01380b,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-1daf135a-ba8a-4c30-b17c-cc71635da3c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853702540-172.17.0.16-1597177378076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-59e21b06-75ed-4768-ad2b-be2c17a0095d,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-0af2ac1d-41a7-4b0b-a444-d7aa469fd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-af2fa04e-961d-4f8f-9779-fceff159786d,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-caf1a951-e3fa-4dd5-a88e-d220d1ff89a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-57150089-6be8-496d-b3dd-44ab65676667,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-6b0d3c8c-6026-408f-93ba-56cbd76f9005,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-2c2dd2f8-1fe3-4c8e-87f5-9a246a01380b,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-1daf135a-ba8a-4c30-b17c-cc71635da3c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399620508-172.17.0.16-1597177587295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33762,DS-9d76cfae-9d99-42e7-b261-8720cdff7623,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-dd447e5c-dfd9-4ff8-8e3d-bcc96a608915,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-c34350cb-b534-4b56-b4dc-cca482f03673,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-efc963e1-a59f-468b-a591-583a8f68fcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-4ee0a158-3009-46d0-877d-dce71a119bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-f46a1fa4-ac6f-4e33-90bc-26bdf144a3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-565eb9c7-d923-4885-9960-f8edb4ced57d,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-1efd3de2-da77-4a3a-8dea-ea9964d90020,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399620508-172.17.0.16-1597177587295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33762,DS-9d76cfae-9d99-42e7-b261-8720cdff7623,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-dd447e5c-dfd9-4ff8-8e3d-bcc96a608915,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-c34350cb-b534-4b56-b4dc-cca482f03673,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-efc963e1-a59f-468b-a591-583a8f68fcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-4ee0a158-3009-46d0-877d-dce71a119bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-f46a1fa4-ac6f-4e33-90bc-26bdf144a3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-565eb9c7-d923-4885-9960-f8edb4ced57d,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-1efd3de2-da77-4a3a-8dea-ea9964d90020,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60916541-172.17.0.16-1597177700635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40289,DS-67346fb1-a26f-4604-82ae-b1e1c2923ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-287cad87-fcf8-4bef-828a-3935cd5cf300,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-d4f6e6a5-ce2b-4953-96bc-5f785f75acbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-41499513-d01f-4818-8050-c157c85fdb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-48b24ebf-a1aa-4f13-b594-f1b101916ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-7f382be6-ccaa-445b-9817-61790b4a6752,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-109b891f-6962-4ef5-8166-a76d1ff8bee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-a4e9563c-f27a-4a14-9933-132c36495750,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60916541-172.17.0.16-1597177700635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40289,DS-67346fb1-a26f-4604-82ae-b1e1c2923ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-287cad87-fcf8-4bef-828a-3935cd5cf300,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-d4f6e6a5-ce2b-4953-96bc-5f785f75acbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-41499513-d01f-4818-8050-c157c85fdb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-48b24ebf-a1aa-4f13-b594-f1b101916ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-7f382be6-ccaa-445b-9817-61790b4a6752,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-109b891f-6962-4ef5-8166-a76d1ff8bee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-a4e9563c-f27a-4a14-9933-132c36495750,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211761388-172.17.0.16-1597177898825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38118,DS-831f939c-3c15-4207-b64e-9f7eb52100ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-a744c016-7414-4c53-ad51-a2bf9e9c5373,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-f1ce0799-a0d8-4acd-a660-ee4a0003edb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-db9817e0-7b56-41e6-9f0e-854c3c4d610c,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-75eeb20f-5670-4eca-ab76-e31d18940d48,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-af92f9d4-f278-4100-bfac-7e11af0d16e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-3ab5f645-f01d-41bc-928c-e8cb97054c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-a8cb453b-157a-4366-b0b7-f3e689ba413a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211761388-172.17.0.16-1597177898825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38118,DS-831f939c-3c15-4207-b64e-9f7eb52100ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-a744c016-7414-4c53-ad51-a2bf9e9c5373,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-f1ce0799-a0d8-4acd-a660-ee4a0003edb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-db9817e0-7b56-41e6-9f0e-854c3c4d610c,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-75eeb20f-5670-4eca-ab76-e31d18940d48,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-af92f9d4-f278-4100-bfac-7e11af0d16e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-3ab5f645-f01d-41bc-928c-e8cb97054c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-a8cb453b-157a-4366-b0b7-f3e689ba413a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886783831-172.17.0.16-1597178038171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-d04b9bde-ec07-4360-8a8a-bda8315b89c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-9ca12a28-90cb-4868-bd5f-70999771e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-1660f1ff-45fe-4b99-9741-b74404d2e9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-6b5b84fe-ef36-4b4a-b094-af968a2d1615,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-61d0c249-30ec-42aa-a276-87783348fcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-4d7fbea4-127e-421f-9cf0-ccc69c2ea4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-45046bbc-3290-4942-8573-715f47e9a8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-c88ac210-21e1-4d59-8352-8b2998df0617,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886783831-172.17.0.16-1597178038171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-d04b9bde-ec07-4360-8a8a-bda8315b89c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-9ca12a28-90cb-4868-bd5f-70999771e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-1660f1ff-45fe-4b99-9741-b74404d2e9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-6b5b84fe-ef36-4b4a-b094-af968a2d1615,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-61d0c249-30ec-42aa-a276-87783348fcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-4d7fbea4-127e-421f-9cf0-ccc69c2ea4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-45046bbc-3290-4942-8573-715f47e9a8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-c88ac210-21e1-4d59-8352-8b2998df0617,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558154782-172.17.0.16-1597178072832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45435,DS-191fb094-12be-4dd8-a96d-0238707fec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-02b5889a-61e2-42d0-933a-2c76083c10e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-b90ee445-3f12-4414-9fdf-7f086e8a08a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-7d5cecb7-8cad-48bf-a1e1-9b4ab7bf5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-2064120d-33cf-4ac6-b732-1b3533404cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-8f8649a9-5d69-4e40-a927-fcb8e122d816,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-88dc71b2-93fd-4079-add0-2de2ac6289fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-84513c2c-c90b-4dea-b398-d25f511a0766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558154782-172.17.0.16-1597178072832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45435,DS-191fb094-12be-4dd8-a96d-0238707fec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-02b5889a-61e2-42d0-933a-2c76083c10e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-b90ee445-3f12-4414-9fdf-7f086e8a08a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-7d5cecb7-8cad-48bf-a1e1-9b4ab7bf5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-2064120d-33cf-4ac6-b732-1b3533404cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-8f8649a9-5d69-4e40-a927-fcb8e122d816,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-88dc71b2-93fd-4079-add0-2de2ac6289fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-84513c2c-c90b-4dea-b398-d25f511a0766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559035358-172.17.0.16-1597178349969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-ead577f3-b8fd-42b3-aa13-e863f12c7653,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-67805507-899b-4e4d-95d2-f8bcb3917b58,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-7baaffc8-9166-4ae6-a743-31bec0451602,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-2e209168-c868-4801-83af-6f332dc7fb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-5bae5e57-46a1-4702-ae31-2bdc6e887ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-30776c96-70dd-41d8-9a0b-012dcb456def,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-a8bde258-6e3d-4bad-b326-ad96fa5824df,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-8a749aca-36d8-4acd-8c0b-9fabfe33450c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559035358-172.17.0.16-1597178349969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-ead577f3-b8fd-42b3-aa13-e863f12c7653,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-67805507-899b-4e4d-95d2-f8bcb3917b58,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-7baaffc8-9166-4ae6-a743-31bec0451602,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-2e209168-c868-4801-83af-6f332dc7fb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-5bae5e57-46a1-4702-ae31-2bdc6e887ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-30776c96-70dd-41d8-9a0b-012dcb456def,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-a8bde258-6e3d-4bad-b326-ad96fa5824df,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-8a749aca-36d8-4acd-8c0b-9fabfe33450c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082792947-172.17.0.16-1597178807460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44858,DS-4c8ea502-f399-4d0b-b5bd-5d4df4d3a5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-f80e4404-3991-46e4-b5cf-c33abf40bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-ea911c03-42df-416b-839d-4f27b91fb13b,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-6c4ff4a5-8000-45ec-9f27-cc3bdcbda490,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-3225cb63-c26c-41ed-855b-e64b55e60a36,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-c2b83e51-271c-49c1-aaa9-5fcfc5444274,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-9ac6948e-c6d9-4b3b-892c-7e42f79814a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-b6855169-ba91-4aeb-97de-a84bee2d77df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082792947-172.17.0.16-1597178807460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44858,DS-4c8ea502-f399-4d0b-b5bd-5d4df4d3a5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-f80e4404-3991-46e4-b5cf-c33abf40bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-ea911c03-42df-416b-839d-4f27b91fb13b,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-6c4ff4a5-8000-45ec-9f27-cc3bdcbda490,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-3225cb63-c26c-41ed-855b-e64b55e60a36,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-c2b83e51-271c-49c1-aaa9-5fcfc5444274,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-9ac6948e-c6d9-4b3b-892c-7e42f79814a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-b6855169-ba91-4aeb-97de-a84bee2d77df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597572510-172.17.0.16-1597178904144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38001,DS-c4eeb253-6301-47fd-9009-7a8fad2d2f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-d07a0ff3-71fb-4f0d-9efd-9067a2088529,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-4022610a-2e1c-45ac-bb8f-4fd87c4259d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-a8815e66-311b-4b50-95c6-8c300a798671,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-0c20b818-5186-42d8-98a5-aa6d2be457df,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-6f82c2d3-9d34-4f0e-9c36-35188a4af69d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-0eadd321-da5e-415a-8ffd-2d0461ef12bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-9bb6f311-6f7a-42dd-b05b-90f494679388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597572510-172.17.0.16-1597178904144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38001,DS-c4eeb253-6301-47fd-9009-7a8fad2d2f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-d07a0ff3-71fb-4f0d-9efd-9067a2088529,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-4022610a-2e1c-45ac-bb8f-4fd87c4259d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-a8815e66-311b-4b50-95c6-8c300a798671,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-0c20b818-5186-42d8-98a5-aa6d2be457df,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-6f82c2d3-9d34-4f0e-9c36-35188a4af69d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-0eadd321-da5e-415a-8ffd-2d0461ef12bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-9bb6f311-6f7a-42dd-b05b-90f494679388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109620187-172.17.0.16-1597178941468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-11bc45c8-79ab-4218-95a0-b91877bf70d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-97a98e1b-46e0-42cc-8ffb-a54e0903e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-0eb0ddf0-b0dd-4bec-8adb-849c6f8c14d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-f8dc6ad1-0f46-4327-a7f5-9546dd0f0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-2756278f-6603-4bc2-8ff9-d1f0bb19b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-a711b759-df0f-4a5f-bf6d-2d874edbc9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-67ed4a38-e4ae-4191-b3f6-3b0b1857986f,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-74bad3c8-a18c-4d73-8b27-e3f22dfdb4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109620187-172.17.0.16-1597178941468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-11bc45c8-79ab-4218-95a0-b91877bf70d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-97a98e1b-46e0-42cc-8ffb-a54e0903e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-0eb0ddf0-b0dd-4bec-8adb-849c6f8c14d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-f8dc6ad1-0f46-4327-a7f5-9546dd0f0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-2756278f-6603-4bc2-8ff9-d1f0bb19b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-a711b759-df0f-4a5f-bf6d-2d874edbc9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-67ed4a38-e4ae-4191-b3f6-3b0b1857986f,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-74bad3c8-a18c-4d73-8b27-e3f22dfdb4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860508547-172.17.0.16-1597179245626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-c2e7f2be-4732-4da6-aa29-435a05b33713,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-94bbb89d-7899-438b-9eff-f44b2cb70cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-0edcba72-483b-444a-90d8-44295667c830,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-4e84e28e-d3a4-45bc-8b48-2317107dd562,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-8d092ad3-3223-45f7-b06c-624ddcc2d49d,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-520fcf29-35a7-41d4-ae4f-8b332ec97a92,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-9b97676a-44b7-41d6-bd94-d3ae8dea7089,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-df1e2e1a-af4c-4ad3-aecf-2ef34911303f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860508547-172.17.0.16-1597179245626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-c2e7f2be-4732-4da6-aa29-435a05b33713,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-94bbb89d-7899-438b-9eff-f44b2cb70cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-0edcba72-483b-444a-90d8-44295667c830,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-4e84e28e-d3a4-45bc-8b48-2317107dd562,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-8d092ad3-3223-45f7-b06c-624ddcc2d49d,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-520fcf29-35a7-41d4-ae4f-8b332ec97a92,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-9b97676a-44b7-41d6-bd94-d3ae8dea7089,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-df1e2e1a-af4c-4ad3-aecf-2ef34911303f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912193684-172.17.0.16-1597179352628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-3b6b2b27-fab2-497f-ad47-37a930c8bc78,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-e7b22e45-8e00-426a-8b6b-b4a464112fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-a48ec067-4b0c-41ee-9164-d1cf35bad311,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-71e61783-79c3-4f90-91bf-2fc0b14b4e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-8f334773-54df-4c28-97b1-145df8f61cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-af9804c1-d923-4355-8e55-99ab5a6a1a21,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-c644b4ce-75f0-4a7e-ac33-7cdf72d68956,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-de50cd64-10e7-465e-abc9-bd890caf85f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912193684-172.17.0.16-1597179352628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-3b6b2b27-fab2-497f-ad47-37a930c8bc78,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-e7b22e45-8e00-426a-8b6b-b4a464112fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-a48ec067-4b0c-41ee-9164-d1cf35bad311,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-71e61783-79c3-4f90-91bf-2fc0b14b4e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-8f334773-54df-4c28-97b1-145df8f61cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-af9804c1-d923-4355-8e55-99ab5a6a1a21,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-c644b4ce-75f0-4a7e-ac33-7cdf72d68956,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-de50cd64-10e7-465e-abc9-bd890caf85f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717557201-172.17.0.16-1597179504578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46044,DS-eb9fe4c5-5803-40ad-8371-9d2f426812f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-4a5bac61-ae50-4e7d-94b4-06604bf89dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-214c32df-eb29-4644-8232-cd51a0752b99,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-a8a0a278-1506-4970-83ba-8269ea139337,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-a33ce36c-a455-4e4c-ace4-27c5f41427e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-81923f44-e0c1-419d-9582-84cd776d5da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-48c839d2-0507-4608-b5e8-4e2696caedaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-6b059e3f-8835-441a-bdc8-06c5f062e110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717557201-172.17.0.16-1597179504578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46044,DS-eb9fe4c5-5803-40ad-8371-9d2f426812f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-4a5bac61-ae50-4e7d-94b4-06604bf89dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-214c32df-eb29-4644-8232-cd51a0752b99,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-a8a0a278-1506-4970-83ba-8269ea139337,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-a33ce36c-a455-4e4c-ace4-27c5f41427e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-81923f44-e0c1-419d-9582-84cd776d5da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-48c839d2-0507-4608-b5e8-4e2696caedaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-6b059e3f-8835-441a-bdc8-06c5f062e110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673533292-172.17.0.16-1597179697128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40027,DS-6e33558f-c3e5-4334-817d-076f9885cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-b799ccbe-e335-4f9b-85de-146922e3cc87,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-df010d16-d99c-455b-83e1-bc11d93d3202,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ccd6a0f8-4de8-4db7-8b8a-c2f0e6141cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-adfd0012-6c66-47ac-81c2-b4b451718427,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-e815f3fd-0ce5-4ab2-8c15-616d94ab42f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-9802c21a-4842-4a7f-a595-10baaf0a4bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-aa265e14-f7d4-4a00-9f14-12dd4e9e2ee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673533292-172.17.0.16-1597179697128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40027,DS-6e33558f-c3e5-4334-817d-076f9885cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-b799ccbe-e335-4f9b-85de-146922e3cc87,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-df010d16-d99c-455b-83e1-bc11d93d3202,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ccd6a0f8-4de8-4db7-8b8a-c2f0e6141cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-adfd0012-6c66-47ac-81c2-b4b451718427,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-e815f3fd-0ce5-4ab2-8c15-616d94ab42f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-9802c21a-4842-4a7f-a595-10baaf0a4bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-aa265e14-f7d4-4a00-9f14-12dd4e9e2ee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119178989-172.17.0.16-1597179729728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44177,DS-0d1e526a-d330-4f69-b123-1db9035fcc19,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-7583e688-a0cf-465e-92c3-9de8b671d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-f64bb643-1371-4837-9cc9-1e962bd8940d,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-b2ad47ec-bb65-45d4-b0be-a0e71468a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-c0d87b22-f433-4b05-8ac5-7222cc0ded53,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-d6de59bb-6460-491c-b9b8-7c21ee2465c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-417cf45b-e969-423d-b770-171f00d6db6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-ea08ffb2-86cc-48ea-8eaf-75a7813b1752,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119178989-172.17.0.16-1597179729728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44177,DS-0d1e526a-d330-4f69-b123-1db9035fcc19,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-7583e688-a0cf-465e-92c3-9de8b671d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-f64bb643-1371-4837-9cc9-1e962bd8940d,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-b2ad47ec-bb65-45d4-b0be-a0e71468a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-c0d87b22-f433-4b05-8ac5-7222cc0ded53,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-d6de59bb-6460-491c-b9b8-7c21ee2465c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-417cf45b-e969-423d-b770-171f00d6db6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-ea08ffb2-86cc-48ea-8eaf-75a7813b1752,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954962410-172.17.0.16-1597179995414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-82ecd390-5996-4c9e-a1f7-46996d95b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-bf3a67c2-6364-49da-bfdc-0b3c77ced23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-e8d3b9b6-9b87-493f-914c-7ef3747b622b,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-0e2c50c7-9e66-45b2-b9d9-6a85b69b600a,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-e8516525-b7b3-4783-b6b7-b48df954773e,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-12df0043-7834-40f6-9526-a37b24ba73e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-a1c15fa1-577e-48d2-ae6f-3d6447b86555,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-f569f780-2b8a-4fd6-aeba-e6c6affd16ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954962410-172.17.0.16-1597179995414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-82ecd390-5996-4c9e-a1f7-46996d95b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-bf3a67c2-6364-49da-bfdc-0b3c77ced23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-e8d3b9b6-9b87-493f-914c-7ef3747b622b,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-0e2c50c7-9e66-45b2-b9d9-6a85b69b600a,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-e8516525-b7b3-4783-b6b7-b48df954773e,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-12df0043-7834-40f6-9526-a37b24ba73e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-a1c15fa1-577e-48d2-ae6f-3d6447b86555,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-f569f780-2b8a-4fd6-aeba-e6c6affd16ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216635866-172.17.0.16-1597180339771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-5bb97c91-ef04-40c0-b58e-f5c14ce70d68,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-06c9a10f-a26e-42d8-baeb-70122707be25,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-8e5e6c0f-e69f-4356-98b6-d15c14131440,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-7d7ebfe3-3204-4762-aa80-e9320164679d,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-e02057cd-421a-4700-8752-5da8d284e7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-e7f16da5-e3f0-43b9-8b35-791f7c3b4a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-ee91d297-7244-4551-94b5-8347e8925493,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-dd11aa88-ff68-449a-9459-a57f6c0e50cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216635866-172.17.0.16-1597180339771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-5bb97c91-ef04-40c0-b58e-f5c14ce70d68,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-06c9a10f-a26e-42d8-baeb-70122707be25,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-8e5e6c0f-e69f-4356-98b6-d15c14131440,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-7d7ebfe3-3204-4762-aa80-e9320164679d,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-e02057cd-421a-4700-8752-5da8d284e7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-e7f16da5-e3f0-43b9-8b35-791f7c3b4a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-ee91d297-7244-4551-94b5-8347e8925493,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-dd11aa88-ff68-449a-9459-a57f6c0e50cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293319323-172.17.0.16-1597180372852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46584,DS-e0fb3a01-cc90-42e9-be4e-e3296992c1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-46215784-ea72-41b3-ade4-f7df6e85ec24,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-42f9f1b8-56ef-4344-b81c-0f13c041815e,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-e15f9069-0fda-444e-9690-bb364a664e33,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-8a87f9cd-0c27-446a-aede-c14332a35fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-a654c622-8f5e-4a9e-b88d-f5bc62517e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-ea2a30cd-d176-447b-85b0-07440d0a9aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-6cdb0fea-4e63-4a19-a18e-f48d9c0155bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293319323-172.17.0.16-1597180372852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46584,DS-e0fb3a01-cc90-42e9-be4e-e3296992c1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-46215784-ea72-41b3-ade4-f7df6e85ec24,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-42f9f1b8-56ef-4344-b81c-0f13c041815e,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-e15f9069-0fda-444e-9690-bb364a664e33,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-8a87f9cd-0c27-446a-aede-c14332a35fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-a654c622-8f5e-4a9e-b88d-f5bc62517e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-ea2a30cd-d176-447b-85b0-07440d0a9aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-6cdb0fea-4e63-4a19-a18e-f48d9c0155bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659821689-172.17.0.16-1597180435538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33517,DS-6f9d0ff2-5439-480f-9691-564fc352c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-edf3e11e-234b-4a7a-bf8a-ee5325040e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-d05214a8-8aec-4b1a-9596-ebe207553325,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-3f41ae71-234d-42b2-8d4c-015b078decc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-bf8b5ad4-74d1-400d-befd-214d76848ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-40c222c6-4e30-4f2d-ada0-25f2223f963e,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-2436625f-398e-457f-ac69-181ad34901a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-7fbd705a-4bdd-489d-8ee8-2a62ff894ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659821689-172.17.0.16-1597180435538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33517,DS-6f9d0ff2-5439-480f-9691-564fc352c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-edf3e11e-234b-4a7a-bf8a-ee5325040e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-d05214a8-8aec-4b1a-9596-ebe207553325,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-3f41ae71-234d-42b2-8d4c-015b078decc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-bf8b5ad4-74d1-400d-befd-214d76848ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-40c222c6-4e30-4f2d-ada0-25f2223f963e,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-2436625f-398e-457f-ac69-181ad34901a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-7fbd705a-4bdd-489d-8ee8-2a62ff894ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87353340-172.17.0.16-1597180469229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45811,DS-3b59a693-d86c-4156-9e24-c0af8f6d23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-32763dba-2d02-446d-a883-d654147b36be,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-56258bea-ae85-4870-896c-9cbe8cbc1241,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-88f811e0-5711-40b8-ae6d-db958ae52544,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-df297b49-dec6-44ef-b601-223c1219b759,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-4b6508fd-3cde-4b9b-9f76-a9b6ee39ef47,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-b0c10198-f12e-4749-9bd2-703beda9a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-4e280a6e-bbcf-433b-9eae-ba801f1ea46d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87353340-172.17.0.16-1597180469229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45811,DS-3b59a693-d86c-4156-9e24-c0af8f6d23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-32763dba-2d02-446d-a883-d654147b36be,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-56258bea-ae85-4870-896c-9cbe8cbc1241,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-88f811e0-5711-40b8-ae6d-db958ae52544,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-df297b49-dec6-44ef-b601-223c1219b759,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-4b6508fd-3cde-4b9b-9f76-a9b6ee39ef47,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-b0c10198-f12e-4749-9bd2-703beda9a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-4e280a6e-bbcf-433b-9eae-ba801f1ea46d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663825755-172.17.0.16-1597180609539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-b0dad8ab-2cfe-4d6e-9e9d-57588df9cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-082f703e-b700-4c3c-b52e-7e5d992d6c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-cae6b2a3-add1-49ab-982e-44ff67ef34ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-92810710-2379-4dbe-be16-ded8c64012f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-f3761451-5eeb-4741-b250-3b381da00c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-7a131bfe-cc56-4003-93e6-9352dd89713d,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-e0dfc96a-7901-450d-a761-ecb21fc94dec,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-af83ec8d-cb54-4522-9e41-c0ad7c6358db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663825755-172.17.0.16-1597180609539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-b0dad8ab-2cfe-4d6e-9e9d-57588df9cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-082f703e-b700-4c3c-b52e-7e5d992d6c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-cae6b2a3-add1-49ab-982e-44ff67ef34ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-92810710-2379-4dbe-be16-ded8c64012f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-f3761451-5eeb-4741-b250-3b381da00c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-7a131bfe-cc56-4003-93e6-9352dd89713d,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-e0dfc96a-7901-450d-a761-ecb21fc94dec,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-af83ec8d-cb54-4522-9e41-c0ad7c6358db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5212
