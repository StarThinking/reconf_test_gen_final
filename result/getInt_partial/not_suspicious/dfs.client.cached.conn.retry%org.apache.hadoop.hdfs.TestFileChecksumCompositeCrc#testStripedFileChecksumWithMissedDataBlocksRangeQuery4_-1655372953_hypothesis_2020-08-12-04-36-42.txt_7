reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820989534-172.17.0.12-1597207325682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-dae72be3-0b30-414c-955c-be3bc4d54f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-c2503509-17bd-41af-9416-f4be757d2739,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-6090f3b7-7f53-47fc-b40b-b2cb6dd2cef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-12e10a1f-4893-4011-b506-39da4973a677,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-bf8d19ed-a43b-4ddb-bd21-3a32d8ea16fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-c80eb30d-657b-42eb-aa42-fe3cd9b2debf,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-a466f97d-0198-4726-b441-6ee0edd6be66,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-ef062058-2983-4c91-a003-82a97d8a7202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820989534-172.17.0.12-1597207325682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-dae72be3-0b30-414c-955c-be3bc4d54f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-c2503509-17bd-41af-9416-f4be757d2739,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-6090f3b7-7f53-47fc-b40b-b2cb6dd2cef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-12e10a1f-4893-4011-b506-39da4973a677,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-bf8d19ed-a43b-4ddb-bd21-3a32d8ea16fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-c80eb30d-657b-42eb-aa42-fe3cd9b2debf,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-a466f97d-0198-4726-b441-6ee0edd6be66,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-ef062058-2983-4c91-a003-82a97d8a7202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987508863-172.17.0.12-1597207628019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34898,DS-019bf9ad-2cf1-4c87-b280-6d95c1253a98,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-d8fa8373-de55-4f0e-aff6-0911915c80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-4f84263a-9677-41b7-bbec-536d64b183f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-dd3df481-7d36-42a7-ad95-af2c7010234f,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-8c905245-ae29-4c46-a856-da0ab7a0ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-b6afe99e-e85e-4b2b-a191-4646456bc665,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-10cc44c1-6e58-4b33-814d-e480e820ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-85813727-ed78-4333-89e1-b89aa5fa240b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987508863-172.17.0.12-1597207628019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34898,DS-019bf9ad-2cf1-4c87-b280-6d95c1253a98,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-d8fa8373-de55-4f0e-aff6-0911915c80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-4f84263a-9677-41b7-bbec-536d64b183f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-dd3df481-7d36-42a7-ad95-af2c7010234f,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-8c905245-ae29-4c46-a856-da0ab7a0ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-b6afe99e-e85e-4b2b-a191-4646456bc665,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-10cc44c1-6e58-4b33-814d-e480e820ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-85813727-ed78-4333-89e1-b89aa5fa240b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140637814-172.17.0.12-1597208467200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-47c20581-4b5c-46ba-a8c3-95939d3129a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-996ca37f-2dfa-4e25-9605-c1181ca08b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-28945054-01c4-4100-8c26-a9293894655a,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-090b00f0-2572-4c0f-8947-f7b63c3edf84,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-bd539e78-7a05-4694-b1fa-a6b292389605,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-ba3a515f-f702-4a04-b6a0-72c85de1d1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-90ac074a-09e5-40a1-8f7b-8884fa5e1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-36364306-8da5-416b-ba0f-e1c44d66719c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140637814-172.17.0.12-1597208467200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-47c20581-4b5c-46ba-a8c3-95939d3129a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-996ca37f-2dfa-4e25-9605-c1181ca08b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-28945054-01c4-4100-8c26-a9293894655a,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-090b00f0-2572-4c0f-8947-f7b63c3edf84,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-bd539e78-7a05-4694-b1fa-a6b292389605,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-ba3a515f-f702-4a04-b6a0-72c85de1d1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-90ac074a-09e5-40a1-8f7b-8884fa5e1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-36364306-8da5-416b-ba0f-e1c44d66719c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960158974-172.17.0.12-1597208508046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-1ca371f6-46db-4551-8c3a-cd1bbd001447,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-21616250-94e9-40a7-bb66-55606d37b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-4bfc9e28-0346-4fa0-b4e8-4a3f531d98c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-94d7c942-77a9-4b84-9e53-8ad9a4e9feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-ec548582-953a-4225-959f-8d58e1965ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-0ed16539-87a7-4aec-8e68-4be139133757,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-c46249d9-cf65-42b1-84cd-f93f9ab64486,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-29ddb31b-e6d4-41bf-8e07-0403a6893328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960158974-172.17.0.12-1597208508046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-1ca371f6-46db-4551-8c3a-cd1bbd001447,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-21616250-94e9-40a7-bb66-55606d37b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-4bfc9e28-0346-4fa0-b4e8-4a3f531d98c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-94d7c942-77a9-4b84-9e53-8ad9a4e9feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-ec548582-953a-4225-959f-8d58e1965ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-0ed16539-87a7-4aec-8e68-4be139133757,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-c46249d9-cf65-42b1-84cd-f93f9ab64486,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-29ddb31b-e6d4-41bf-8e07-0403a6893328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027274136-172.17.0.12-1597208710214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-c9f211a0-5cf4-48fb-ba03-e80726579fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-69afa609-0d21-41f2-bd69-87c4d71bb329,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-a20a9278-192d-4b24-9752-6a1b8011a260,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-57414d58-f043-484d-9ac2-3bd648fd6fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-e598fc5d-3877-4576-a41d-4f90dddbc30e,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-7fb3a4ac-1506-4bd1-98d4-d9e8d27c39a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-65489f10-16a4-4fd8-a1fc-982c320bccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-29094bab-6190-4b41-ae25-36c714f4d988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027274136-172.17.0.12-1597208710214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-c9f211a0-5cf4-48fb-ba03-e80726579fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-69afa609-0d21-41f2-bd69-87c4d71bb329,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-a20a9278-192d-4b24-9752-6a1b8011a260,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-57414d58-f043-484d-9ac2-3bd648fd6fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-e598fc5d-3877-4576-a41d-4f90dddbc30e,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-7fb3a4ac-1506-4bd1-98d4-d9e8d27c39a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-65489f10-16a4-4fd8-a1fc-982c320bccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-29094bab-6190-4b41-ae25-36c714f4d988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288146631-172.17.0.12-1597209422252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33208,DS-2067a6bd-d88e-4ee4-8121-29cf5c9ae13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-a9517468-2606-4fbc-b7f8-b23d461375e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-c50eca3f-d981-48a1-8737-f01859b2a74f,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-07698f42-bfb9-4527-aaac-d6816ae45ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-75be47c5-2977-4391-a3b8-77949013be99,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-15e94212-3df8-46e8-9e85-cef2a152e302,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-403f9c2d-0524-4984-95d0-4c46b7b54600,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-b25d6212-1612-415f-a8f3-c9e930cda74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288146631-172.17.0.12-1597209422252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33208,DS-2067a6bd-d88e-4ee4-8121-29cf5c9ae13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-a9517468-2606-4fbc-b7f8-b23d461375e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-c50eca3f-d981-48a1-8737-f01859b2a74f,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-07698f42-bfb9-4527-aaac-d6816ae45ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-75be47c5-2977-4391-a3b8-77949013be99,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-15e94212-3df8-46e8-9e85-cef2a152e302,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-403f9c2d-0524-4984-95d0-4c46b7b54600,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-b25d6212-1612-415f-a8f3-c9e930cda74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70978998-172.17.0.12-1597209585204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-59676a32-33f2-445c-818f-ea3f58f4c728,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-a8387502-bfcc-4b7f-a798-c3cf718acdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-52584bef-386c-4eb1-b965-910c116e6936,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-0ff5d9e6-d1d7-4705-ba4b-8ba991bfb525,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-9c1e94c7-5075-4bd0-9459-dbe9866a1e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-6d7eddc3-ec4c-47aa-9995-dfe3b1c47dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-32ea211f-aec4-4eef-8f06-2381509822a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-470ef318-5299-4a12-a296-623ad18f2e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70978998-172.17.0.12-1597209585204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-59676a32-33f2-445c-818f-ea3f58f4c728,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-a8387502-bfcc-4b7f-a798-c3cf718acdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-52584bef-386c-4eb1-b965-910c116e6936,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-0ff5d9e6-d1d7-4705-ba4b-8ba991bfb525,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-9c1e94c7-5075-4bd0-9459-dbe9866a1e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-6d7eddc3-ec4c-47aa-9995-dfe3b1c47dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-32ea211f-aec4-4eef-8f06-2381509822a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-470ef318-5299-4a12-a296-623ad18f2e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203770124-172.17.0.12-1597209890141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36669,DS-1000ea9a-a7a7-49a3-86ed-644e198ac4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-f271639d-7bc6-42f8-b427-e8d15575fe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-e6677d07-5380-4801-a7e9-a67a29038ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-f9c7d7ac-bf36-48bd-986b-b8c13895447a,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-5fc3c4f0-a835-4568-be3b-f2943ecdac68,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-cf4ea389-a4e9-4878-9240-1f1c6c0bc23c,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-fd9b7436-4302-4046-a642-78ab74d3fba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-a573ab8d-2cd8-4286-97db-5c49e00a10f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203770124-172.17.0.12-1597209890141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36669,DS-1000ea9a-a7a7-49a3-86ed-644e198ac4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-f271639d-7bc6-42f8-b427-e8d15575fe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-e6677d07-5380-4801-a7e9-a67a29038ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-f9c7d7ac-bf36-48bd-986b-b8c13895447a,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-5fc3c4f0-a835-4568-be3b-f2943ecdac68,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-cf4ea389-a4e9-4878-9240-1f1c6c0bc23c,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-fd9b7436-4302-4046-a642-78ab74d3fba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-a573ab8d-2cd8-4286-97db-5c49e00a10f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790785069-172.17.0.12-1597210062150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-b0f34b37-4d82-4372-a98f-7e706fa24d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-a564349b-6ea5-4dd8-a041-3fe4d36266ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-52620825-1fd8-4b83-bc39-9d01ec897aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-a7f71753-070f-4a27-a852-bf1e6726efec,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-a98309b9-b4b6-4c22-addd-010e13198fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-f4a3c528-4258-4e3d-8956-6e860a3a5c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-8aa80e37-b20e-463c-8c69-bdea4788c6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-982ff7bd-bc73-4ace-a0a7-5077244f71aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790785069-172.17.0.12-1597210062150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-b0f34b37-4d82-4372-a98f-7e706fa24d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-a564349b-6ea5-4dd8-a041-3fe4d36266ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-52620825-1fd8-4b83-bc39-9d01ec897aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-a7f71753-070f-4a27-a852-bf1e6726efec,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-a98309b9-b4b6-4c22-addd-010e13198fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-f4a3c528-4258-4e3d-8956-6e860a3a5c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-8aa80e37-b20e-463c-8c69-bdea4788c6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-982ff7bd-bc73-4ace-a0a7-5077244f71aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035782559-172.17.0.12-1597210411264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-8acb8602-4df3-44bb-913b-b299bf1074d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-2c03571e-b241-4aec-9151-74bb73a09db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-d0b34fc8-1dbb-4097-a573-59d7f4f2dba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-57b5e8ff-c612-4e59-87ab-40df639567a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-5bde0f86-b07f-4227-aa5d-19ebe260ffc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-3c8b937e-d3bf-4ca6-ac86-023bc9361640,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-7b4c0580-2b70-4455-a3ad-0781ba65fec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-391cbb29-c4d1-4e46-8cd0-2e7bb9ad0add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035782559-172.17.0.12-1597210411264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-8acb8602-4df3-44bb-913b-b299bf1074d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-2c03571e-b241-4aec-9151-74bb73a09db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-d0b34fc8-1dbb-4097-a573-59d7f4f2dba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-57b5e8ff-c612-4e59-87ab-40df639567a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-5bde0f86-b07f-4227-aa5d-19ebe260ffc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-3c8b937e-d3bf-4ca6-ac86-023bc9361640,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-7b4c0580-2b70-4455-a3ad-0781ba65fec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-391cbb29-c4d1-4e46-8cd0-2e7bb9ad0add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926928909-172.17.0.12-1597210460867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-24c118c9-65a7-4048-bb6b-41ed8ee039ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-647e479f-5530-4c37-98ad-79786d9dc751,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-a45a36b2-f244-4c3b-8ef4-82d48c76a6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-6c8a9954-878c-4869-a917-4aebbb91d77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-8aa13e21-3770-4371-824f-7d82df8d5d27,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-b7727c51-20d9-41bb-afdc-b5fc14860946,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-1fb099a4-ef7d-4ee0-acb5-63e5ea21d446,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-0f4e3527-7ba0-49c9-ae96-3e6b84ecef67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926928909-172.17.0.12-1597210460867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-24c118c9-65a7-4048-bb6b-41ed8ee039ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-647e479f-5530-4c37-98ad-79786d9dc751,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-a45a36b2-f244-4c3b-8ef4-82d48c76a6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-6c8a9954-878c-4869-a917-4aebbb91d77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-8aa13e21-3770-4371-824f-7d82df8d5d27,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-b7727c51-20d9-41bb-afdc-b5fc14860946,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-1fb099a4-ef7d-4ee0-acb5-63e5ea21d446,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-0f4e3527-7ba0-49c9-ae96-3e6b84ecef67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630418125-172.17.0.12-1597210544211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-d5d4ce33-8632-42f8-85fa-dbc79734a934,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-18a2bc6b-807b-4e51-954e-c3b00bd9d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-2379f39a-70d1-447b-a676-e958e1423b31,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-cb2e8270-8373-457a-a8a3-152890944710,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-cb4058b2-0998-4bbe-bc96-0b8ea12c3581,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-3de542f3-f6df-4736-9f24-fdeb18b17eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-4bf5b648-38ed-436b-bf62-e062550eff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-edff3836-d01b-4a7b-8a11-dce74fe454d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630418125-172.17.0.12-1597210544211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-d5d4ce33-8632-42f8-85fa-dbc79734a934,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-18a2bc6b-807b-4e51-954e-c3b00bd9d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-2379f39a-70d1-447b-a676-e958e1423b31,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-cb2e8270-8373-457a-a8a3-152890944710,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-cb4058b2-0998-4bbe-bc96-0b8ea12c3581,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-3de542f3-f6df-4736-9f24-fdeb18b17eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-4bf5b648-38ed-436b-bf62-e062550eff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-edff3836-d01b-4a7b-8a11-dce74fe454d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56090974-172.17.0.12-1597210644969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-cf860903-1425-47d2-9492-916810c465a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-32f12e09-0b42-4d28-b00a-c252f70e99a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-42711cf8-3d2e-4f9f-95a3-eaf578d03ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-1ef3a734-c207-4aa4-9cea-b47a142fc4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-16008c99-159f-4a35-8b27-4c06e0587a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-d8178eac-8f57-49a9-8699-d668ea01bf05,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-bc491cf1-5118-4e9c-82b1-0329c4086fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-922d9caf-63f8-4756-923b-e727de1f8035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56090974-172.17.0.12-1597210644969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-cf860903-1425-47d2-9492-916810c465a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-32f12e09-0b42-4d28-b00a-c252f70e99a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-42711cf8-3d2e-4f9f-95a3-eaf578d03ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-1ef3a734-c207-4aa4-9cea-b47a142fc4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-16008c99-159f-4a35-8b27-4c06e0587a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-d8178eac-8f57-49a9-8699-d668ea01bf05,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-bc491cf1-5118-4e9c-82b1-0329c4086fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-922d9caf-63f8-4756-923b-e727de1f8035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451711173-172.17.0.12-1597210728051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-0610e34c-74a0-4493-baa5-0ebbf0d0a06e,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-0844f850-f76d-4723-a927-fef2ee958f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-6aadbf91-59b7-4ad6-8ee2-d9ee40bbca39,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-a3be0d6e-79b7-4084-8d58-998c937ae20b,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-5d8baa7c-53ab-4543-87cf-72f1113539f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-fbd1ef50-f161-40f0-8e0f-2cdaac0d21a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-0347da3e-4f2d-4919-84fe-5ee5c7bb42e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-e72a6138-9f7c-4b3b-91a8-c86a06bc3205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451711173-172.17.0.12-1597210728051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-0610e34c-74a0-4493-baa5-0ebbf0d0a06e,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-0844f850-f76d-4723-a927-fef2ee958f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-6aadbf91-59b7-4ad6-8ee2-d9ee40bbca39,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-a3be0d6e-79b7-4084-8d58-998c937ae20b,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-5d8baa7c-53ab-4543-87cf-72f1113539f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-fbd1ef50-f161-40f0-8e0f-2cdaac0d21a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-0347da3e-4f2d-4919-84fe-5ee5c7bb42e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-e72a6138-9f7c-4b3b-91a8-c86a06bc3205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4085
