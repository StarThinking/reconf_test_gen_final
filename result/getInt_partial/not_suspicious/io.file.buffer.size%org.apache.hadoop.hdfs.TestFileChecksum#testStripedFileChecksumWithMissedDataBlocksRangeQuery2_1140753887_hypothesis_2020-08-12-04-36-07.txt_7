reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186192364-172.17.0.13-1597206980838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43492,DS-9c94334d-2b4b-4784-ac55-45111a094b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-9d2cda63-028e-4683-aa0c-fa6293c4c27d,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-5c5b3f63-7c64-4bbf-8856-296cf49981d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-71499d17-d21a-441b-8c11-c57dad27cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-4ea29c7b-cab5-4e60-9c17-015dad891291,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-4525c2d8-5b52-40ce-85da-e1a377878ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-fde38863-aa97-4395-bef0-91dd8fb80933,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-7bb2da8a-dde2-452c-b723-bb45a48883bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186192364-172.17.0.13-1597206980838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43492,DS-9c94334d-2b4b-4784-ac55-45111a094b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-9d2cda63-028e-4683-aa0c-fa6293c4c27d,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-5c5b3f63-7c64-4bbf-8856-296cf49981d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-71499d17-d21a-441b-8c11-c57dad27cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-4ea29c7b-cab5-4e60-9c17-015dad891291,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-4525c2d8-5b52-40ce-85da-e1a377878ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-fde38863-aa97-4395-bef0-91dd8fb80933,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-7bb2da8a-dde2-452c-b723-bb45a48883bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119613661-172.17.0.13-1597207622886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43883,DS-391c96a4-445c-4986-8c8f-f36dbe9dcc67,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-52b5d33e-ee94-4e63-ad96-3b03d000cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-18bc7cf6-642d-43f6-bf35-229d67d623f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-1db44a54-6e72-4e9e-8d45-f013c6250cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-27de7256-6d93-4b39-a6a4-a6938ea5e2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-7e936b7c-d06a-4ccb-b181-5d76b71f1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-443e1862-2d51-48bc-85ca-64097439195a,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-f8fa4c08-4249-4f31-8d3c-2fab9061beb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119613661-172.17.0.13-1597207622886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43883,DS-391c96a4-445c-4986-8c8f-f36dbe9dcc67,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-52b5d33e-ee94-4e63-ad96-3b03d000cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-18bc7cf6-642d-43f6-bf35-229d67d623f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-1db44a54-6e72-4e9e-8d45-f013c6250cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-27de7256-6d93-4b39-a6a4-a6938ea5e2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-7e936b7c-d06a-4ccb-b181-5d76b71f1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-443e1862-2d51-48bc-85ca-64097439195a,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-f8fa4c08-4249-4f31-8d3c-2fab9061beb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560520017-172.17.0.13-1597207751329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-d66c89e1-4a86-40ad-b2bd-e93621702445,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-c08297f4-f95a-4cb4-bd50-db9e2eed176e,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-37ba1e71-3227-4436-92b4-18c4a89d1e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-c1303f2c-b0ab-420b-91a4-1ab6859f4193,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-89b217e9-4d42-48f2-8af4-bb8cc25c0859,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-ca269613-dcac-448f-b6ff-0a0fb9e35998,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-1d392d94-1ee3-4b66-b566-1faf4c7a54e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-b33af5a3-18e9-4d4e-9918-1411c4fdbf4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560520017-172.17.0.13-1597207751329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-d66c89e1-4a86-40ad-b2bd-e93621702445,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-c08297f4-f95a-4cb4-bd50-db9e2eed176e,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-37ba1e71-3227-4436-92b4-18c4a89d1e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-c1303f2c-b0ab-420b-91a4-1ab6859f4193,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-89b217e9-4d42-48f2-8af4-bb8cc25c0859,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-ca269613-dcac-448f-b6ff-0a0fb9e35998,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-1d392d94-1ee3-4b66-b566-1faf4c7a54e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-b33af5a3-18e9-4d4e-9918-1411c4fdbf4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732921302-172.17.0.13-1597207884203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38898,DS-a1f1220c-9ee2-4217-8bbb-90f6ff44be14,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-f7c09ad6-b51f-41f6-8c69-7f02e3a9e201,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-5c4dd62e-da94-45b4-a027-e34d09db34a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-9f359f6f-8970-4a99-8687-f0983348b473,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-b3d3bedf-d287-4248-b21c-6f9e46efc1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-7f3f9163-06c6-4ff6-94f3-c1cf9bfbe04c,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-80857a3e-cd84-45a1-b2c3-ea62000ba74e,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-6c9bbed3-02e5-4d96-9688-12006fc0bd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732921302-172.17.0.13-1597207884203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38898,DS-a1f1220c-9ee2-4217-8bbb-90f6ff44be14,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-f7c09ad6-b51f-41f6-8c69-7f02e3a9e201,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-5c4dd62e-da94-45b4-a027-e34d09db34a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-9f359f6f-8970-4a99-8687-f0983348b473,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-b3d3bedf-d287-4248-b21c-6f9e46efc1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-7f3f9163-06c6-4ff6-94f3-c1cf9bfbe04c,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-80857a3e-cd84-45a1-b2c3-ea62000ba74e,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-6c9bbed3-02e5-4d96-9688-12006fc0bd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679153604-172.17.0.13-1597208852025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-888d5703-aed5-4eb4-8a43-f9f2b6070aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-e9a13ce7-4e3e-47e7-929b-5c511b024664,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-5f4c5bc6-cf75-4049-b553-fcd72d7d9477,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-a20accb7-43af-40f5-bfc9-42e6ce4aa768,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-f3bb50a6-1eeb-44fd-aa49-570e29e34a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-41412f0d-c44c-4e5c-a647-e0e082ce2a40,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-df29186e-631a-4f83-bd8e-e17e062a3f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-69c6ecd1-ce7a-434d-a77d-6d88ff1cb358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679153604-172.17.0.13-1597208852025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-888d5703-aed5-4eb4-8a43-f9f2b6070aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-e9a13ce7-4e3e-47e7-929b-5c511b024664,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-5f4c5bc6-cf75-4049-b553-fcd72d7d9477,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-a20accb7-43af-40f5-bfc9-42e6ce4aa768,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-f3bb50a6-1eeb-44fd-aa49-570e29e34a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-41412f0d-c44c-4e5c-a647-e0e082ce2a40,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-df29186e-631a-4f83-bd8e-e17e062a3f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-69c6ecd1-ce7a-434d-a77d-6d88ff1cb358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225405320-172.17.0.13-1597208896518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45737,DS-d34ae608-d69e-4343-9800-05ec9490b16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-a21525d5-40df-46b7-bb63-39deeef22c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-042a4315-ab30-4b60-872b-e0dbe6c8b178,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-05063408-ca32-4eec-a11b-47a9acdd8278,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-6b303b3e-24c7-491d-a633-d05e4ba1df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-d3903c18-3df9-4e68-bbd7-ab59c2bff425,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-882e5786-6c63-4922-8aad-6be994683331,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-b88e2131-c148-4885-a9c1-bf92f2a07a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225405320-172.17.0.13-1597208896518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45737,DS-d34ae608-d69e-4343-9800-05ec9490b16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-a21525d5-40df-46b7-bb63-39deeef22c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-042a4315-ab30-4b60-872b-e0dbe6c8b178,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-05063408-ca32-4eec-a11b-47a9acdd8278,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-6b303b3e-24c7-491d-a633-d05e4ba1df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-d3903c18-3df9-4e68-bbd7-ab59c2bff425,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-882e5786-6c63-4922-8aad-6be994683331,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-b88e2131-c148-4885-a9c1-bf92f2a07a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663966325-172.17.0.13-1597209243803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35225,DS-1b753e99-4900-4db7-8ebf-b9cd98317e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-1d58d238-f5dc-47ec-9a0c-a3d8651159ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-a6cd2e78-0c43-44af-b803-e5d14ae158c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-6c89fc2e-6a63-4e90-95fe-66a810742e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-6ef1aa81-bb5c-466e-bed0-532a1e793f64,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-b82b5799-9f89-4b5f-aeef-dae299d64bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-3893001b-5eab-401a-bc9d-3bf2d2c7890c,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-1473a16b-be40-4448-939a-fe3e4744368c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663966325-172.17.0.13-1597209243803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35225,DS-1b753e99-4900-4db7-8ebf-b9cd98317e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-1d58d238-f5dc-47ec-9a0c-a3d8651159ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-a6cd2e78-0c43-44af-b803-e5d14ae158c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-6c89fc2e-6a63-4e90-95fe-66a810742e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-6ef1aa81-bb5c-466e-bed0-532a1e793f64,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-b82b5799-9f89-4b5f-aeef-dae299d64bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-3893001b-5eab-401a-bc9d-3bf2d2c7890c,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-1473a16b-be40-4448-939a-fe3e4744368c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709305324-172.17.0.13-1597209544753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37927,DS-dbbe6504-e17a-400b-af4b-2e1367f55766,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-8ca2329b-3e09-470f-87ba-6ff6f6329b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-bef04358-e2a8-487c-9ce9-e292bf00adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-392ac524-44d6-4147-a15f-3847ffb60ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-20bd1318-d401-4a57-b76f-d3738ec400e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-df261e74-b63c-4e81-9edc-c798fc03ca94,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-48d9408e-a876-4161-bffa-5586382df04d,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-4175d34c-e0fc-4228-bfc0-a9d1111d0179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709305324-172.17.0.13-1597209544753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37927,DS-dbbe6504-e17a-400b-af4b-2e1367f55766,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-8ca2329b-3e09-470f-87ba-6ff6f6329b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-bef04358-e2a8-487c-9ce9-e292bf00adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-392ac524-44d6-4147-a15f-3847ffb60ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-20bd1318-d401-4a57-b76f-d3738ec400e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-df261e74-b63c-4e81-9edc-c798fc03ca94,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-48d9408e-a876-4161-bffa-5586382df04d,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-4175d34c-e0fc-4228-bfc0-a9d1111d0179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222855150-172.17.0.13-1597209681458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41753,DS-7255670d-d88b-4161-9e26-9812989f2859,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-980c3b9a-e18b-4333-9cce-dc2899cad37c,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-b1198b57-13c9-4f87-938f-675160d237aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-7c3b3db1-f178-446d-93dd-10a186fc8587,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-680c7401-7fb3-4b51-8d9c-57221f661887,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-915b6560-a391-4333-8d4c-ab504f54576a,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-cdd0dde7-c558-4295-aa9c-4d5e4f0155ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-036613fc-9972-41de-a14e-31906409254d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222855150-172.17.0.13-1597209681458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41753,DS-7255670d-d88b-4161-9e26-9812989f2859,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-980c3b9a-e18b-4333-9cce-dc2899cad37c,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-b1198b57-13c9-4f87-938f-675160d237aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-7c3b3db1-f178-446d-93dd-10a186fc8587,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-680c7401-7fb3-4b51-8d9c-57221f661887,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-915b6560-a391-4333-8d4c-ab504f54576a,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-cdd0dde7-c558-4295-aa9c-4d5e4f0155ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-036613fc-9972-41de-a14e-31906409254d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539824140-172.17.0.13-1597209816036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-118ab9b5-2e6a-4eef-82c8-9f98c12b6727,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-753c422c-1dfb-4b41-8e7e-976ed9ec3e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-db42ceae-225b-4680-bbf1-45b5f720395b,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-41def7c1-734c-47a2-85dc-46018861a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-8d5da543-ea57-4156-9c01-a168ce309244,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-560d2434-97b4-4c5f-85d6-27796dee1b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-593cfb45-5b80-49de-a203-8aa4c86d24cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-22a1ae37-b278-4e5c-8340-1d4d1684f74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539824140-172.17.0.13-1597209816036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-118ab9b5-2e6a-4eef-82c8-9f98c12b6727,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-753c422c-1dfb-4b41-8e7e-976ed9ec3e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-db42ceae-225b-4680-bbf1-45b5f720395b,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-41def7c1-734c-47a2-85dc-46018861a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-8d5da543-ea57-4156-9c01-a168ce309244,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-560d2434-97b4-4c5f-85d6-27796dee1b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-593cfb45-5b80-49de-a203-8aa4c86d24cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-22a1ae37-b278-4e5c-8340-1d4d1684f74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806747832-172.17.0.13-1597209858923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39719,DS-fcc3443a-c8e9-412d-8f4c-5d3b07643052,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-6c7e27a0-4e6c-41a9-9043-def3c9a3a2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-aa04506a-2341-4e94-a96d-ff9fed55904b,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c537fd83-8b5c-412c-9d8b-23421abcdfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-e4e81494-bb56-4e25-9009-6bc7387375a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-46975a58-cda5-4ed1-a9c2-aca0272524a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-55007096-4287-48d0-a856-3a86a8de6c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-3b001e99-ab59-4dde-833d-3d814c49e8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806747832-172.17.0.13-1597209858923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39719,DS-fcc3443a-c8e9-412d-8f4c-5d3b07643052,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-6c7e27a0-4e6c-41a9-9043-def3c9a3a2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-aa04506a-2341-4e94-a96d-ff9fed55904b,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c537fd83-8b5c-412c-9d8b-23421abcdfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-e4e81494-bb56-4e25-9009-6bc7387375a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-46975a58-cda5-4ed1-a9c2-aca0272524a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-55007096-4287-48d0-a856-3a86a8de6c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-3b001e99-ab59-4dde-833d-3d814c49e8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449658646-172.17.0.13-1597210177821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-2a9ac2e9-02fc-4cb1-93c9-cb4b47af1802,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-830e3432-6696-4725-8fa1-c6bff9314d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-f441e159-593e-4d73-a7c6-660159423abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-3529f71d-4fb1-4c25-9db3-70cca4dc721d,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-2475aeb2-bad7-4fa6-bbb4-c7cead6b315c,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-a97993f7-551d-4391-9bac-26edd1dd25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-045140bb-57e9-4a42-bdd4-e7c7b15a8215,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-d1aaaae4-e52c-4394-a02c-c80f65e8f7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449658646-172.17.0.13-1597210177821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-2a9ac2e9-02fc-4cb1-93c9-cb4b47af1802,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-830e3432-6696-4725-8fa1-c6bff9314d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-f441e159-593e-4d73-a7c6-660159423abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-3529f71d-4fb1-4c25-9db3-70cca4dc721d,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-2475aeb2-bad7-4fa6-bbb4-c7cead6b315c,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-a97993f7-551d-4391-9bac-26edd1dd25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-045140bb-57e9-4a42-bdd4-e7c7b15a8215,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-d1aaaae4-e52c-4394-a02c-c80f65e8f7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743032196-172.17.0.13-1597210632026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45891,DS-074197d4-491e-4094-b283-9581cb7e5299,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-6e14f453-76bd-4bea-b419-687c97b77cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-bbfd2812-6345-4499-a56c-addf213c6b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-f50bed30-e859-4afb-84ad-8b8390c4ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-7f8979a3-13e4-40e9-a992-c37d31244451,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-e699de01-5e96-4528-a071-f3ecfe4d2b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-88b22b9a-534b-4023-83d5-b7b5f265b3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-65273304-0ffc-4d6b-bf62-39c3c20fcb38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743032196-172.17.0.13-1597210632026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45891,DS-074197d4-491e-4094-b283-9581cb7e5299,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-6e14f453-76bd-4bea-b419-687c97b77cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-bbfd2812-6345-4499-a56c-addf213c6b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-f50bed30-e859-4afb-84ad-8b8390c4ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-7f8979a3-13e4-40e9-a992-c37d31244451,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-e699de01-5e96-4528-a071-f3ecfe4d2b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-88b22b9a-534b-4023-83d5-b7b5f265b3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-65273304-0ffc-4d6b-bf62-39c3c20fcb38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415230944-172.17.0.13-1597211398610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-f97b080e-b662-4d5a-9352-56065f976855,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-f0c80730-8ce4-4269-91a8-94e253689fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-a3b5567d-4926-433b-af58-d3526aebb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-ea167cc2-3eb6-40d3-8f66-57b3c41e7695,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-7dc7586f-5f36-4b7d-9479-5584125cf8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-97ca5899-8832-441c-9972-1067074deed7,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-14a497a7-5450-4496-93c4-8d1c5a8c4613,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-afa556e9-3f55-4e4e-bb2f-c497d4b8fd46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415230944-172.17.0.13-1597211398610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-f97b080e-b662-4d5a-9352-56065f976855,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-f0c80730-8ce4-4269-91a8-94e253689fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-a3b5567d-4926-433b-af58-d3526aebb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-ea167cc2-3eb6-40d3-8f66-57b3c41e7695,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-7dc7586f-5f36-4b7d-9479-5584125cf8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-97ca5899-8832-441c-9972-1067074deed7,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-14a497a7-5450-4496-93c4-8d1c5a8c4613,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-afa556e9-3f55-4e4e-bb2f-c497d4b8fd46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225683815-172.17.0.13-1597211567698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46381,DS-0e6c839a-461c-4813-85a3-f20541ff2a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-77934b09-f0a9-4175-8e81-c8f2d02359bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-34f89e21-9b70-43e6-aa92-9aaaf9bb09f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-ac4bbf05-7e34-4c22-9f9d-3e63a929ee72,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-3655f3a1-819e-4890-aec9-940a64c8d5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-8c76ba25-ee14-4d8d-b7a4-7df6ccd4e76d,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-9b7e8efb-657c-42c2-a09b-40dfd12df618,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-12b0cdd9-4e5c-4fc0-9cf7-d7d197d5d93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225683815-172.17.0.13-1597211567698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46381,DS-0e6c839a-461c-4813-85a3-f20541ff2a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-77934b09-f0a9-4175-8e81-c8f2d02359bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-34f89e21-9b70-43e6-aa92-9aaaf9bb09f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-ac4bbf05-7e34-4c22-9f9d-3e63a929ee72,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-3655f3a1-819e-4890-aec9-940a64c8d5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-8c76ba25-ee14-4d8d-b7a4-7df6ccd4e76d,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-9b7e8efb-657c-42c2-a09b-40dfd12df618,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-12b0cdd9-4e5c-4fc0-9cf7-d7d197d5d93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971702305-172.17.0.13-1597211607565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-c38fd3d8-862a-4212-b81f-127046bf6cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-d3c2036c-b360-4848-9ea9-8c2005fdd4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-1e488033-9986-44cb-916f-594cfee190af,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-59581dbb-82f7-450f-b770-fe0a5a73c573,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-96019d09-1ef4-4402-b0f8-4cf79ac5e1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-b377027d-b37e-4c99-9557-13a83b09b01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-f2aeaac4-4635-480b-b48a-bfb635ddb0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-51e54867-32c3-4f95-af4d-81fbc9f089b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971702305-172.17.0.13-1597211607565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-c38fd3d8-862a-4212-b81f-127046bf6cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-d3c2036c-b360-4848-9ea9-8c2005fdd4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-1e488033-9986-44cb-916f-594cfee190af,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-59581dbb-82f7-450f-b770-fe0a5a73c573,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-96019d09-1ef4-4402-b0f8-4cf79ac5e1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-b377027d-b37e-4c99-9557-13a83b09b01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-f2aeaac4-4635-480b-b48a-bfb635ddb0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-51e54867-32c3-4f95-af4d-81fbc9f089b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963830024-172.17.0.13-1597212341941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-0222540f-c0a5-42b5-b2bb-312adbb2e41a,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-cdd8894f-f3a7-4756-8f1e-0948876ff7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-fff7e838-19ca-4462-83f4-1788c42a0837,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-6ce3a6f7-e144-40f6-a561-af0ef975202e,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-9ab31321-ab5a-4abe-b311-b95da55daa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-2a563d32-63b5-4ac6-bdd0-73bdc59ca907,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-3f89181d-ffc4-492b-803c-0b7fd7abce00,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-5f2542bf-9db9-4fe4-96f0-82e7251fe242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963830024-172.17.0.13-1597212341941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-0222540f-c0a5-42b5-b2bb-312adbb2e41a,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-cdd8894f-f3a7-4756-8f1e-0948876ff7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-fff7e838-19ca-4462-83f4-1788c42a0837,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-6ce3a6f7-e144-40f6-a561-af0ef975202e,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-9ab31321-ab5a-4abe-b311-b95da55daa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-2a563d32-63b5-4ac6-bdd0-73bdc59ca907,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-3f89181d-ffc4-492b-803c-0b7fd7abce00,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-5f2542bf-9db9-4fe4-96f0-82e7251fe242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6643
