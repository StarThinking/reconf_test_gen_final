reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185871557-172.17.0.17-1597148478653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37973,DS-bd399813-c49d-4bd5-9108-c9096fe2ef6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-9907840f-d0f7-4e73-b5d3-d6bcb4624584,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-55ba4df9-449f-407d-aa99-814f150192f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-35a30556-b48d-4687-882d-3c4c385d7b82,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-4f20d68a-105e-4fd9-8316-ac727c8359f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-15090129-3be1-42de-a989-b953b6639fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-78a71cd2-650c-40ea-be2d-3710bbc411e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-4280e885-8488-46e1-ab9e-c6ceda9c53b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185871557-172.17.0.17-1597148478653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37973,DS-bd399813-c49d-4bd5-9108-c9096fe2ef6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-9907840f-d0f7-4e73-b5d3-d6bcb4624584,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-55ba4df9-449f-407d-aa99-814f150192f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-35a30556-b48d-4687-882d-3c4c385d7b82,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-4f20d68a-105e-4fd9-8316-ac727c8359f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-15090129-3be1-42de-a989-b953b6639fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-78a71cd2-650c-40ea-be2d-3710bbc411e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-4280e885-8488-46e1-ab9e-c6ceda9c53b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645705711-172.17.0.17-1597148777770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-e6119616-edb9-4dd3-bf85-2419a00213bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-6edfd6df-97fe-4443-abac-0b89164689be,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-1a8f54dd-0330-473c-a862-e6654f8eb136,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-47d1b083-100d-45b9-a8f4-4e506a8e9263,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-51a7c895-e35e-44b3-a9ee-32947161421f,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-83a5ff37-01ce-4d18-b152-931829455a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-c33f05ff-6b59-4593-af21-56f47a7bcd83,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-f5f23c18-c319-45d0-8a74-c76f1d674c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645705711-172.17.0.17-1597148777770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-e6119616-edb9-4dd3-bf85-2419a00213bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-6edfd6df-97fe-4443-abac-0b89164689be,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-1a8f54dd-0330-473c-a862-e6654f8eb136,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-47d1b083-100d-45b9-a8f4-4e506a8e9263,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-51a7c895-e35e-44b3-a9ee-32947161421f,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-83a5ff37-01ce-4d18-b152-931829455a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-c33f05ff-6b59-4593-af21-56f47a7bcd83,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-f5f23c18-c319-45d0-8a74-c76f1d674c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471645239-172.17.0.17-1597148848463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43719,DS-e0098927-df20-4bcb-8734-0a0813028abb,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-bb0bd9a6-37b9-4812-a0f5-b3006b564339,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-bba3d4ee-1ad2-46fd-8de3-a5ed79b3a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-56a6bf54-2369-4646-94a3-561a8eb11a71,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-dc590139-7b36-4e51-bb0d-f284b0b11872,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-8ffbb8c0-e2a9-4c47-9ba3-bb5ff104544d,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-470936fe-5fd9-4e35-9e2e-471cc6e707f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-0c1fe707-3056-480a-aa4a-26cc4366072a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471645239-172.17.0.17-1597148848463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43719,DS-e0098927-df20-4bcb-8734-0a0813028abb,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-bb0bd9a6-37b9-4812-a0f5-b3006b564339,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-bba3d4ee-1ad2-46fd-8de3-a5ed79b3a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-56a6bf54-2369-4646-94a3-561a8eb11a71,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-dc590139-7b36-4e51-bb0d-f284b0b11872,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-8ffbb8c0-e2a9-4c47-9ba3-bb5ff104544d,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-470936fe-5fd9-4e35-9e2e-471cc6e707f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-0c1fe707-3056-480a-aa4a-26cc4366072a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28583846-172.17.0.17-1597149341108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-6ae781d6-a635-4f9b-9a1e-b951d6cfc93f,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-7f643253-8a37-465c-aa45-80cf6310f26a,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-0c5069c7-54db-42e9-af09-d9db1e6dc4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-27eca52b-72d9-497a-acbb-5cf06323886f,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-31475ba0-baf7-46b6-b069-c1eaea6e8d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-2c0820bd-a0f7-45dc-a68a-ba8cca9b1e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-b6de93f0-729a-4f65-acb0-eb7396afb671,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-43465c61-b468-47ef-895a-2b2b09221656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28583846-172.17.0.17-1597149341108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-6ae781d6-a635-4f9b-9a1e-b951d6cfc93f,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-7f643253-8a37-465c-aa45-80cf6310f26a,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-0c5069c7-54db-42e9-af09-d9db1e6dc4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-27eca52b-72d9-497a-acbb-5cf06323886f,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-31475ba0-baf7-46b6-b069-c1eaea6e8d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-2c0820bd-a0f7-45dc-a68a-ba8cca9b1e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-b6de93f0-729a-4f65-acb0-eb7396afb671,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-43465c61-b468-47ef-895a-2b2b09221656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567200275-172.17.0.17-1597149648841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39853,DS-f7a2191b-5620-4145-8a2e-a717f29abdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-ef5f3bc0-7f5b-45db-8934-61bb4b90e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-d7fbcc00-818e-4c7d-a902-65311a4e853e,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-03c5b3c2-920d-4939-99f5-4f3462dbb6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-61cf01d3-e105-40b5-be2d-2e18191c135d,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-59987beb-06e2-43bb-9782-9203326f5081,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-4743769d-efca-4424-b32f-d8d94b16f146,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-ab3bdb34-622d-42d4-afad-f292823d5621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567200275-172.17.0.17-1597149648841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39853,DS-f7a2191b-5620-4145-8a2e-a717f29abdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-ef5f3bc0-7f5b-45db-8934-61bb4b90e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-d7fbcc00-818e-4c7d-a902-65311a4e853e,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-03c5b3c2-920d-4939-99f5-4f3462dbb6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-61cf01d3-e105-40b5-be2d-2e18191c135d,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-59987beb-06e2-43bb-9782-9203326f5081,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-4743769d-efca-4424-b32f-d8d94b16f146,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-ab3bdb34-622d-42d4-afad-f292823d5621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356195017-172.17.0.17-1597149709538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-e268fdb2-ef26-4f03-9f4f-babeb05c16f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-2a1fcfb4-3d6f-4a15-ab38-5be68aea9d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-3e027ec8-afbb-4ab6-8af5-754f0cca281d,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-8143488a-0101-4bad-92e0-b30218c6e959,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-941931b9-aa50-4d6c-8675-be67be468016,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-f277dbfe-b21e-4fbc-83ae-8d02652edbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-aab7a3a1-4395-4be4-a188-b7150b24565a,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-1fc6aad5-a0fe-4114-8e8e-e215a2ce298b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356195017-172.17.0.17-1597149709538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-e268fdb2-ef26-4f03-9f4f-babeb05c16f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-2a1fcfb4-3d6f-4a15-ab38-5be68aea9d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-3e027ec8-afbb-4ab6-8af5-754f0cca281d,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-8143488a-0101-4bad-92e0-b30218c6e959,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-941931b9-aa50-4d6c-8675-be67be468016,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-f277dbfe-b21e-4fbc-83ae-8d02652edbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-aab7a3a1-4395-4be4-a188-b7150b24565a,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-1fc6aad5-a0fe-4114-8e8e-e215a2ce298b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742480796-172.17.0.17-1597149858276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40913,DS-28e6181f-f98a-411d-b050-96f6fbb31a78,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-14ddca6e-d901-4514-9916-b39e3db95c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-a0fa1ca6-e2d5-489e-9b70-40917fd516df,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-fb0a40d3-75d6-411d-8610-229210ee5437,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-2545582e-27a3-4100-8c1f-e699e23d5b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-7d96dd15-4897-4211-bb7f-68dc5d4f3fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-05d079e1-8e1e-4d40-9483-25f7bfc50d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-9e91c50d-3765-4724-897a-e334dbdafb28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742480796-172.17.0.17-1597149858276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40913,DS-28e6181f-f98a-411d-b050-96f6fbb31a78,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-14ddca6e-d901-4514-9916-b39e3db95c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-a0fa1ca6-e2d5-489e-9b70-40917fd516df,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-fb0a40d3-75d6-411d-8610-229210ee5437,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-2545582e-27a3-4100-8c1f-e699e23d5b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-7d96dd15-4897-4211-bb7f-68dc5d4f3fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-05d079e1-8e1e-4d40-9483-25f7bfc50d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-9e91c50d-3765-4724-897a-e334dbdafb28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708729644-172.17.0.17-1597150102105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44151,DS-96db1fd4-296f-4132-bd4b-8d87929d5191,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-c52c609c-7da7-4da1-a175-12ed8ed08193,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-1b5f28ab-8eb0-4ff2-a386-85660417e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-92126f5f-c48d-40e4-b91d-55645b26398e,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-ec301ff5-6568-4216-b6ff-518e81e6c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-f61b0834-b51a-4fa8-9234-b9f61e70bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-75e87f63-7fab-4367-9ccc-3677d479f431,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-648a4d36-3b0a-4e9a-92d9-594178e16952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708729644-172.17.0.17-1597150102105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44151,DS-96db1fd4-296f-4132-bd4b-8d87929d5191,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-c52c609c-7da7-4da1-a175-12ed8ed08193,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-1b5f28ab-8eb0-4ff2-a386-85660417e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-92126f5f-c48d-40e4-b91d-55645b26398e,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-ec301ff5-6568-4216-b6ff-518e81e6c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-f61b0834-b51a-4fa8-9234-b9f61e70bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-75e87f63-7fab-4367-9ccc-3677d479f431,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-648a4d36-3b0a-4e9a-92d9-594178e16952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378397436-172.17.0.17-1597150836848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35542,DS-8c8e0ee6-243c-44d3-ba25-b80fb072eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-e90bebc5-bba5-4ec4-96c8-7a73579e3ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-8c260198-3df9-4e95-8fff-1cc0751fd546,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-163d91ed-d148-497b-b268-6e469ff864ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-1cc82bd8-b0e5-4952-9162-69db1d01826d,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-1302f084-c840-47ce-8f96-5c110bdae760,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-47f9cb92-8341-428f-aabf-91565b541d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-398b4091-d4ee-4d4f-8bd2-a640ffa904f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378397436-172.17.0.17-1597150836848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35542,DS-8c8e0ee6-243c-44d3-ba25-b80fb072eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-e90bebc5-bba5-4ec4-96c8-7a73579e3ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-8c260198-3df9-4e95-8fff-1cc0751fd546,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-163d91ed-d148-497b-b268-6e469ff864ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-1cc82bd8-b0e5-4952-9162-69db1d01826d,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-1302f084-c840-47ce-8f96-5c110bdae760,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-47f9cb92-8341-428f-aabf-91565b541d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-398b4091-d4ee-4d4f-8bd2-a640ffa904f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514763780-172.17.0.17-1597151627435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45435,DS-de37789c-6449-4687-a7f9-ad26ec83cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-01a963d4-d640-477c-9158-e48bc2357ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-014fa214-62cc-4ebe-86f5-84f18d5fa446,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-8f8b4e12-4cf3-4e1b-8609-5ddf53f69f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-bb9016c8-a3cc-4bd8-9f13-cb73dc4afc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-70b066bf-25ba-4788-9675-4d030113412b,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-f1f8c75f-e5e7-45b8-a741-9022cdcbf4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-36be4a7f-d9f7-434e-8da5-a72ae77e4cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514763780-172.17.0.17-1597151627435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45435,DS-de37789c-6449-4687-a7f9-ad26ec83cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-01a963d4-d640-477c-9158-e48bc2357ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-014fa214-62cc-4ebe-86f5-84f18d5fa446,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-8f8b4e12-4cf3-4e1b-8609-5ddf53f69f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-bb9016c8-a3cc-4bd8-9f13-cb73dc4afc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-70b066bf-25ba-4788-9675-4d030113412b,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-f1f8c75f-e5e7-45b8-a741-9022cdcbf4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-36be4a7f-d9f7-434e-8da5-a72ae77e4cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579065142-172.17.0.17-1597151962463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44602,DS-38d05454-94dc-46ce-bcc2-810257af2f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-9e33f5a0-a0a7-441b-8a1b-6ebcc4af34d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-fdc2efd1-b1dd-42e8-8f55-15ce4e81e5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-67742abb-b7ad-40a7-aa7f-ecbc6b57cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-4390135e-c707-450f-9f54-4699692bb5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-12af3422-7382-4619-9e3d-883e24c0ea68,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-d38eb3fc-d9c7-45b1-9268-5fde4f1d671c,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-1350cd47-7bcc-4033-9c41-8a01df31fe8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579065142-172.17.0.17-1597151962463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44602,DS-38d05454-94dc-46ce-bcc2-810257af2f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-9e33f5a0-a0a7-441b-8a1b-6ebcc4af34d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-fdc2efd1-b1dd-42e8-8f55-15ce4e81e5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-67742abb-b7ad-40a7-aa7f-ecbc6b57cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-4390135e-c707-450f-9f54-4699692bb5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-12af3422-7382-4619-9e3d-883e24c0ea68,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-d38eb3fc-d9c7-45b1-9268-5fde4f1d671c,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-1350cd47-7bcc-4033-9c41-8a01df31fe8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 216000s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392608882-172.17.0.17-1597153279201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-e2ea9b1a-5007-4859-b816-9579e7fe4662,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-41bc4e17-e063-49ac-a611-b85e3ffe7488,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-ef248dc7-9841-42a1-9a0e-0c15d8d898ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-c235b81d-ced4-4ab7-8dd4-1092d59aae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-92f0bb37-7385-4acc-b416-15d6b9133335,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-a911460a-a4d7-47b3-9820-fa0d14aca4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-db54669f-828c-4b29-aed2-8bdd765f207b,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-0fec416c-4c42-499a-ab8c-66b8fdc39d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392608882-172.17.0.17-1597153279201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-e2ea9b1a-5007-4859-b816-9579e7fe4662,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-41bc4e17-e063-49ac-a611-b85e3ffe7488,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-ef248dc7-9841-42a1-9a0e-0c15d8d898ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-c235b81d-ced4-4ab7-8dd4-1092d59aae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-92f0bb37-7385-4acc-b416-15d6b9133335,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-a911460a-a4d7-47b3-9820-fa0d14aca4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-db54669f-828c-4b29-aed2-8bdd765f207b,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-0fec416c-4c42-499a-ab8c-66b8fdc39d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5488
