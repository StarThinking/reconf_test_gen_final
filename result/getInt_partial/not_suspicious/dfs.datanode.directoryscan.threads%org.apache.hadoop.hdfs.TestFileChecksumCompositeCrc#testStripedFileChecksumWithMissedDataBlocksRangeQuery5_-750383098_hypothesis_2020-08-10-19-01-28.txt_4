reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753073401-172.17.0.14-1597086309603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36041,DS-39c4eae6-7ad1-4fb1-b984-90ba04875868,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-31c9161d-9f65-4143-98de-9f0771a3e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-83785b35-54c7-47d1-b2b1-736a715f0673,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-37d5d4ae-7522-4a71-9b17-79d1542933f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-bcb3c69c-6922-443c-9771-fe86c1f6c8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-c9be9247-27b5-43d1-b796-63ebb8106f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-876fbd00-d013-4d2f-9777-620f48ee7d65,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-7c664c64-f49a-459d-ac10-ee40b9f9deee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753073401-172.17.0.14-1597086309603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36041,DS-39c4eae6-7ad1-4fb1-b984-90ba04875868,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-31c9161d-9f65-4143-98de-9f0771a3e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-83785b35-54c7-47d1-b2b1-736a715f0673,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-37d5d4ae-7522-4a71-9b17-79d1542933f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-bcb3c69c-6922-443c-9771-fe86c1f6c8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-c9be9247-27b5-43d1-b796-63ebb8106f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-876fbd00-d013-4d2f-9777-620f48ee7d65,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-7c664c64-f49a-459d-ac10-ee40b9f9deee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685716970-172.17.0.14-1597087052934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-0b519ea1-7a95-4aaf-9cd2-9ab2f21ab850,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-64a55553-a490-4ecc-82a5-b39bdd59c232,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-d5cd27e7-1721-42fd-b6a4-8621023e0a40,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-cd21ecad-b5f1-44e4-ae52-847ae4024cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-b4ed9f92-554e-47c7-8525-b47beec11a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-4705746c-55fb-498e-a832-57ccd53bdd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-ec0de960-e12c-4e4a-8036-e355f01be5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-9fd003f5-c8b4-4e69-bb20-248fdb4e5fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685716970-172.17.0.14-1597087052934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-0b519ea1-7a95-4aaf-9cd2-9ab2f21ab850,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-64a55553-a490-4ecc-82a5-b39bdd59c232,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-d5cd27e7-1721-42fd-b6a4-8621023e0a40,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-cd21ecad-b5f1-44e4-ae52-847ae4024cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-b4ed9f92-554e-47c7-8525-b47beec11a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-4705746c-55fb-498e-a832-57ccd53bdd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-ec0de960-e12c-4e4a-8036-e355f01be5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-9fd003f5-c8b4-4e69-bb20-248fdb4e5fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440172393-172.17.0.14-1597088007549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-7f7c103b-58ce-4e1f-b36b-31c511daa244,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-a5ef7d07-a0df-4565-984d-5051c75235ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-ea2e244b-7cea-40b2-ab38-a43eea600618,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-b80cdc99-7221-46de-b1c9-a51c54a6d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-2377afaa-69e5-44ac-9230-67b99440f375,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-7d0f8ecb-61a3-4e5b-9d00-11a87206ffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-fad0ac9c-713d-4492-9b10-12f91699f5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-f4373893-1716-4fe8-a959-728ab01e431e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440172393-172.17.0.14-1597088007549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-7f7c103b-58ce-4e1f-b36b-31c511daa244,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-a5ef7d07-a0df-4565-984d-5051c75235ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-ea2e244b-7cea-40b2-ab38-a43eea600618,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-b80cdc99-7221-46de-b1c9-a51c54a6d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-2377afaa-69e5-44ac-9230-67b99440f375,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-7d0f8ecb-61a3-4e5b-9d00-11a87206ffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-fad0ac9c-713d-4492-9b10-12f91699f5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-f4373893-1716-4fe8-a959-728ab01e431e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462395195-172.17.0.14-1597088114468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42723,DS-c6c3b1c4-62f3-49db-9402-1a124c676342,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-7e800e17-666e-424b-969e-60e6d355b9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-107cda98-094e-47da-911d-4e1fb72a63f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-9d0af5f0-f159-4024-95b1-73cf4bf1840f,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-f6bf6438-4a95-4ea8-b205-d6801c2be6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-a23dfb98-a945-4a9d-adf8-749cb1fe5478,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-15d50efc-035c-4086-b0e1-420d55b01296,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-913f6f95-fcbf-4f37-8be7-80d898ddb29a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462395195-172.17.0.14-1597088114468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42723,DS-c6c3b1c4-62f3-49db-9402-1a124c676342,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-7e800e17-666e-424b-969e-60e6d355b9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-107cda98-094e-47da-911d-4e1fb72a63f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-9d0af5f0-f159-4024-95b1-73cf4bf1840f,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-f6bf6438-4a95-4ea8-b205-d6801c2be6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-a23dfb98-a945-4a9d-adf8-749cb1fe5478,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-15d50efc-035c-4086-b0e1-420d55b01296,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-913f6f95-fcbf-4f37-8be7-80d898ddb29a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523884042-172.17.0.14-1597088440973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-75440963-5299-40e9-914c-284604ec2148,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-ef9e5c08-3dc6-4af0-a548-b508732c1680,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-73799dfa-f4d5-4248-95ae-7764c6f56562,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-0e64a0e3-ff82-4669-ac9b-4cd661653734,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-1c683c8c-2713-4933-9b92-316be371bbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-3f596c41-e6f1-47ad-80b3-b1ef5f431619,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-c9916905-2c78-4fe8-a595-3a338ba5c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-a8a0161c-bf09-4a1a-87a2-8fd26eb9de4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523884042-172.17.0.14-1597088440973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-75440963-5299-40e9-914c-284604ec2148,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-ef9e5c08-3dc6-4af0-a548-b508732c1680,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-73799dfa-f4d5-4248-95ae-7764c6f56562,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-0e64a0e3-ff82-4669-ac9b-4cd661653734,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-1c683c8c-2713-4933-9b92-316be371bbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-3f596c41-e6f1-47ad-80b3-b1ef5f431619,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-c9916905-2c78-4fe8-a595-3a338ba5c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-a8a0161c-bf09-4a1a-87a2-8fd26eb9de4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091152472-172.17.0.14-1597088939851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-e239e11e-3a0f-4480-a5e5-125ea2c00872,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-f241c584-8cd2-40e2-acd9-f359f1f68124,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-6f525489-09dd-4f8b-9055-965687d179b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-580723d8-9e8c-44e5-8dc0-aec0e31ab7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-5a415d11-fecd-4f2b-b8e2-80f09116a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-65126a1e-4d19-4425-9d3f-cb779ed46549,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-21c689a0-eed9-46c5-9b5e-3f1c808ce832,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-bb16250a-2cbe-43f7-ad4f-a68b26f36c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091152472-172.17.0.14-1597088939851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-e239e11e-3a0f-4480-a5e5-125ea2c00872,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-f241c584-8cd2-40e2-acd9-f359f1f68124,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-6f525489-09dd-4f8b-9055-965687d179b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-580723d8-9e8c-44e5-8dc0-aec0e31ab7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-5a415d11-fecd-4f2b-b8e2-80f09116a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-65126a1e-4d19-4425-9d3f-cb779ed46549,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-21c689a0-eed9-46c5-9b5e-3f1c808ce832,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-bb16250a-2cbe-43f7-ad4f-a68b26f36c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172195541-172.17.0.14-1597089017741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46843,DS-53b52a26-af2c-4549-ad51-28bfe911bf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-bae28655-6c60-4d96-82e3-98a708088d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-e33c39e1-2532-4ee8-8e50-ee99baa5771c,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-89a89f7a-6257-4755-96e0-c8a49be2892a,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-f7fbc925-de6f-43dc-a44d-7ffa90447ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-ad2a7716-dbf6-4423-a238-847e54a9e83e,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-4027205f-bc41-44f4-ae4c-115798dc3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-2a069f79-3888-431d-a55d-26d7ccf52505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172195541-172.17.0.14-1597089017741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46843,DS-53b52a26-af2c-4549-ad51-28bfe911bf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-bae28655-6c60-4d96-82e3-98a708088d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-e33c39e1-2532-4ee8-8e50-ee99baa5771c,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-89a89f7a-6257-4755-96e0-c8a49be2892a,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-f7fbc925-de6f-43dc-a44d-7ffa90447ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-ad2a7716-dbf6-4423-a238-847e54a9e83e,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-4027205f-bc41-44f4-ae4c-115798dc3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-2a069f79-3888-431d-a55d-26d7ccf52505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001061615-172.17.0.14-1597089164655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-f04cf243-14c3-4f08-9efc-05129dc61762,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b814fe1a-b67a-4aa7-b070-f2ff00a39e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-9cb2335d-d1c8-47dc-bf9a-44b965c0e994,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-31e46c7f-6cb0-4a20-a7a1-db8a5a85faea,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-8334f79c-d540-4753-bc6f-af382ff48b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-84304095-32aa-4e4e-a0b2-a9b053ab6f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-7131e6c4-d882-4a93-8d02-f02f3c0d3e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-73aea633-5ee5-40fd-b28f-db9fcec85689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001061615-172.17.0.14-1597089164655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-f04cf243-14c3-4f08-9efc-05129dc61762,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b814fe1a-b67a-4aa7-b070-f2ff00a39e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-9cb2335d-d1c8-47dc-bf9a-44b965c0e994,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-31e46c7f-6cb0-4a20-a7a1-db8a5a85faea,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-8334f79c-d540-4753-bc6f-af382ff48b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-84304095-32aa-4e4e-a0b2-a9b053ab6f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-7131e6c4-d882-4a93-8d02-f02f3c0d3e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-73aea633-5ee5-40fd-b28f-db9fcec85689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874747977-172.17.0.14-1597089397902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41582,DS-c7a16507-9674-44a7-a91a-91983d8a8a67,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-8813f9f5-f794-49fb-8fb1-3079e3a2737d,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-e7202d0e-2dd6-45df-935c-85fb87bc9620,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-4b10c89d-4359-4193-95bb-eb4d3d5d0cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-05ae3984-f8c6-4fb1-bf77-573cdfaf887f,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-6172e3c7-2c98-419d-bf10-6d8614992427,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-9a643107-9771-4ef2-9fac-747feb4ea041,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-6e2efe7e-39e2-4014-a801-10a54c938ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874747977-172.17.0.14-1597089397902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41582,DS-c7a16507-9674-44a7-a91a-91983d8a8a67,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-8813f9f5-f794-49fb-8fb1-3079e3a2737d,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-e7202d0e-2dd6-45df-935c-85fb87bc9620,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-4b10c89d-4359-4193-95bb-eb4d3d5d0cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-05ae3984-f8c6-4fb1-bf77-573cdfaf887f,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-6172e3c7-2c98-419d-bf10-6d8614992427,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-9a643107-9771-4ef2-9fac-747feb4ea041,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-6e2efe7e-39e2-4014-a801-10a54c938ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919692954-172.17.0.14-1597089940946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-c80b4030-80bc-4b06-82aa-e19b7cb2b102,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-f34efb19-2247-4eef-a094-0555e4f16b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-277d038e-d780-4556-91c1-f47a709ee324,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-1529a243-92e2-4837-8895-2a9ead1b2843,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-fe812a13-8485-4d31-bc73-e1d998f53914,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-1ff4afea-bec2-410e-9d38-fde873569141,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-381298c7-04f5-422a-aba7-ae3ae073a2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-568592ab-0fcb-43c8-85da-9a2ca19b045c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919692954-172.17.0.14-1597089940946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-c80b4030-80bc-4b06-82aa-e19b7cb2b102,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-f34efb19-2247-4eef-a094-0555e4f16b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-277d038e-d780-4556-91c1-f47a709ee324,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-1529a243-92e2-4837-8895-2a9ead1b2843,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-fe812a13-8485-4d31-bc73-e1d998f53914,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-1ff4afea-bec2-410e-9d38-fde873569141,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-381298c7-04f5-422a-aba7-ae3ae073a2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-568592ab-0fcb-43c8-85da-9a2ca19b045c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088923571-172.17.0.14-1597090652890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42750,DS-3d96f40b-7878-4961-887e-f680e69d81f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-67f23c1d-f65c-41a0-9932-d6d5e4f6e4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-9612102f-e975-4d05-bb26-50df2de44edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-e007e7e1-4619-4b93-830f-454c50ad934e,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-282862f3-6d92-4783-88d4-a4ebebfd00c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-c8d924dc-0376-4fec-821f-0b216fd03921,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-56283216-43f9-4948-8cf6-6509fa030269,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-63ee8154-b85b-47c2-8238-7d062b8693c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088923571-172.17.0.14-1597090652890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42750,DS-3d96f40b-7878-4961-887e-f680e69d81f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-67f23c1d-f65c-41a0-9932-d6d5e4f6e4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-9612102f-e975-4d05-bb26-50df2de44edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-e007e7e1-4619-4b93-830f-454c50ad934e,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-282862f3-6d92-4783-88d4-a4ebebfd00c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-c8d924dc-0376-4fec-821f-0b216fd03921,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-56283216-43f9-4948-8cf6-6509fa030269,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-63ee8154-b85b-47c2-8238-7d062b8693c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607460844-172.17.0.14-1597090931122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-47734cbc-0582-421f-aca5-cb6b4c9096ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-40f53390-3602-4bfd-a796-556ffe109903,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-be6d4d76-3271-4144-8f7c-99adf5dfb12a,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-f2e1bde0-2afe-442f-a7df-264973de609a,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-89d618ae-ac33-443c-a39f-43358e96ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-50be0c3b-91f4-4794-a58b-38938f113a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-848f10f4-c4ca-4515-b393-4797998b0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-1f7e98c4-4b84-4f22-a55d-08c0b92f00f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607460844-172.17.0.14-1597090931122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-47734cbc-0582-421f-aca5-cb6b4c9096ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-40f53390-3602-4bfd-a796-556ffe109903,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-be6d4d76-3271-4144-8f7c-99adf5dfb12a,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-f2e1bde0-2afe-442f-a7df-264973de609a,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-89d618ae-ac33-443c-a39f-43358e96ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-50be0c3b-91f4-4794-a58b-38938f113a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-848f10f4-c4ca-4515-b393-4797998b0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-1f7e98c4-4b84-4f22-a55d-08c0b92f00f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5170
