reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580493097-172.17.0.14-1597210583975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39466,DS-bf424b5d-5663-4729-a779-30a4d55cf420,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-efa6324c-8c6f-4624-8af1-661d39b5d132,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-8fb694b9-af41-4141-85c2-e7c2309aff54,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-254e7ad6-f84b-4a6e-8a86-ed547a366d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-d79a353b-0b25-478b-b7b4-f31812ccf516,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-02cae255-974d-4087-9fd2-dd69b311c124,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-93dc8d21-589d-44e0-89d1-fdbd2f8462a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-9344c2f6-3ef1-4a79-b7e7-5bcfebc52938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580493097-172.17.0.14-1597210583975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39466,DS-bf424b5d-5663-4729-a779-30a4d55cf420,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-efa6324c-8c6f-4624-8af1-661d39b5d132,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-8fb694b9-af41-4141-85c2-e7c2309aff54,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-254e7ad6-f84b-4a6e-8a86-ed547a366d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-d79a353b-0b25-478b-b7b4-f31812ccf516,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-02cae255-974d-4087-9fd2-dd69b311c124,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-93dc8d21-589d-44e0-89d1-fdbd2f8462a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-9344c2f6-3ef1-4a79-b7e7-5bcfebc52938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774468682-172.17.0.14-1597210691579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41842,DS-f98d0aa1-f66d-411e-9081-10c1789e517b,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-f58c9c6a-ad17-425b-8fa0-da1e5f0054db,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-b8ac6458-7d8b-4ac8-8624-4a2e266a86d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-96828ece-2cb6-44b4-8836-b35a3475db57,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-f52cb081-3c94-4510-8567-5b6563f11b97,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-88ce2364-bc89-43b3-9ba8-dd9fbbc39c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-6a7afba3-d556-4139-b5e2-38afa0745f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-ec525884-587e-4fc4-8cc4-90fcd6e2a385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774468682-172.17.0.14-1597210691579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41842,DS-f98d0aa1-f66d-411e-9081-10c1789e517b,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-f58c9c6a-ad17-425b-8fa0-da1e5f0054db,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-b8ac6458-7d8b-4ac8-8624-4a2e266a86d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-96828ece-2cb6-44b4-8836-b35a3475db57,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-f52cb081-3c94-4510-8567-5b6563f11b97,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-88ce2364-bc89-43b3-9ba8-dd9fbbc39c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-6a7afba3-d556-4139-b5e2-38afa0745f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-ec525884-587e-4fc4-8cc4-90fcd6e2a385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889436415-172.17.0.14-1597211481822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-1f2d2581-466f-4de0-9f99-76d7c09bf730,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-fdde788d-766c-4bf9-8d17-d34332fa84be,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-70ddcd21-2ebb-43b8-b8d4-0852a99edee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-5b52dabb-84fd-40a7-b31f-e3fd4289fede,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-1fa721f8-0a37-48e4-a338-ee5144a03422,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-39de79a8-be7e-4c81-aa74-3ceaf360d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-b5232804-ef73-4cf9-9a5b-dd63d9765b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-50bddcdc-6117-4566-a20c-77b8ee6db17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889436415-172.17.0.14-1597211481822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-1f2d2581-466f-4de0-9f99-76d7c09bf730,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-fdde788d-766c-4bf9-8d17-d34332fa84be,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-70ddcd21-2ebb-43b8-b8d4-0852a99edee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-5b52dabb-84fd-40a7-b31f-e3fd4289fede,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-1fa721f8-0a37-48e4-a338-ee5144a03422,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-39de79a8-be7e-4c81-aa74-3ceaf360d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-b5232804-ef73-4cf9-9a5b-dd63d9765b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-50bddcdc-6117-4566-a20c-77b8ee6db17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663929725-172.17.0.14-1597212215607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-61737013-4a73-4fda-88df-43868646fc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-943b3e8d-fef2-44b8-9e54-ed6bc035269e,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-df63608b-808e-4dc1-a551-035ab8b8061c,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-f592d54c-7d34-4844-9463-5415919bbd98,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-387eb8aa-775d-4211-a669-16c36a619e31,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-3e5dc2b1-f0ec-417c-a2ce-8458401fe954,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-72710cf1-9195-478b-9d24-f1b017f163ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-17c754ef-5a20-43f5-8971-45df9512dea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663929725-172.17.0.14-1597212215607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-61737013-4a73-4fda-88df-43868646fc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-943b3e8d-fef2-44b8-9e54-ed6bc035269e,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-df63608b-808e-4dc1-a551-035ab8b8061c,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-f592d54c-7d34-4844-9463-5415919bbd98,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-387eb8aa-775d-4211-a669-16c36a619e31,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-3e5dc2b1-f0ec-417c-a2ce-8458401fe954,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-72710cf1-9195-478b-9d24-f1b017f163ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-17c754ef-5a20-43f5-8971-45df9512dea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449175512-172.17.0.14-1597212662657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38093,DS-4ce56869-a3b6-4d8f-b65b-593f0555701c,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-4406754a-8e5b-4217-8b85-1650a1010727,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-d8ef3e77-99f2-4591-94df-147bf1bfe5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-4886148c-08f5-4dbb-8406-1394c663c219,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-492dce27-c500-40c4-9041-84714beda8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-e4186f0c-425e-4a6a-9158-de0170fb61e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-7c6921ae-14ee-4bb0-b86e-eaae26132bca,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-1d8d06fe-1705-4c86-878a-2b28c35ecf7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449175512-172.17.0.14-1597212662657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38093,DS-4ce56869-a3b6-4d8f-b65b-593f0555701c,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-4406754a-8e5b-4217-8b85-1650a1010727,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-d8ef3e77-99f2-4591-94df-147bf1bfe5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-4886148c-08f5-4dbb-8406-1394c663c219,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-492dce27-c500-40c4-9041-84714beda8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-e4186f0c-425e-4a6a-9158-de0170fb61e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-7c6921ae-14ee-4bb0-b86e-eaae26132bca,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-1d8d06fe-1705-4c86-878a-2b28c35ecf7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003175142-172.17.0.14-1597212695532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-864aa171-3dd3-4186-b736-deb66a1ef6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-7b8f2f8b-0222-4d4b-a030-a28076161589,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-62a5fe4a-e434-4745-bd8e-559d2b8455be,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-93908734-ce3a-4741-8c22-bd6ee8f94a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-9ceac7cf-9972-41b5-8f02-4ebff27f7a50,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-46235fc4-f92d-4b8f-a3fd-a1738c5d9a23,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-95b2281a-2456-4ec9-87be-6b15c5981bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-1f79356d-5fd1-41d3-b8ee-10537ecd32c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003175142-172.17.0.14-1597212695532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-864aa171-3dd3-4186-b736-deb66a1ef6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-7b8f2f8b-0222-4d4b-a030-a28076161589,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-62a5fe4a-e434-4745-bd8e-559d2b8455be,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-93908734-ce3a-4741-8c22-bd6ee8f94a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-9ceac7cf-9972-41b5-8f02-4ebff27f7a50,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-46235fc4-f92d-4b8f-a3fd-a1738c5d9a23,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-95b2281a-2456-4ec9-87be-6b15c5981bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-1f79356d-5fd1-41d3-b8ee-10537ecd32c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789669195-172.17.0.14-1597213575616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45060,DS-c394cb86-a388-4c0b-ae49-a9f90d0ece4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-8b51e9d9-19eb-4b47-9b00-47b3898ac2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-0f92d763-336c-4101-a8ff-ba987509b712,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-c990f840-652c-44d9-98ee-31f776aa4117,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-59bcd541-dc3f-4f90-a7e9-cfd810eb2fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-307131ce-6812-43dd-8244-6ff45e7515c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-fc0ff353-fc7d-4d5c-8ba5-c9e7fb872078,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-93c0ed25-f6d7-444d-8c34-f2c40ce9cf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789669195-172.17.0.14-1597213575616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45060,DS-c394cb86-a388-4c0b-ae49-a9f90d0ece4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-8b51e9d9-19eb-4b47-9b00-47b3898ac2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-0f92d763-336c-4101-a8ff-ba987509b712,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-c990f840-652c-44d9-98ee-31f776aa4117,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-59bcd541-dc3f-4f90-a7e9-cfd810eb2fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-307131ce-6812-43dd-8244-6ff45e7515c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-fc0ff353-fc7d-4d5c-8ba5-c9e7fb872078,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-93c0ed25-f6d7-444d-8c34-f2c40ce9cf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985734883-172.17.0.14-1597213613302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-77b5a896-41d1-4606-93a1-6bd73877ecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-45625a57-78cb-4899-90ae-9e319a9032bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-961d60a7-7348-448d-8e0e-a5a4a47fc93f,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-2faa2034-b788-4804-98f8-4d742913b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-766c5895-05bd-40dc-9574-5bf67f3844bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-657165e7-87d4-4175-893d-607dc3a8e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-43ec69ef-0269-4435-a949-c799329eb964,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-71365c2b-d56b-4c59-8181-1040b01fbb89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985734883-172.17.0.14-1597213613302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-77b5a896-41d1-4606-93a1-6bd73877ecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-45625a57-78cb-4899-90ae-9e319a9032bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-961d60a7-7348-448d-8e0e-a5a4a47fc93f,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-2faa2034-b788-4804-98f8-4d742913b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-766c5895-05bd-40dc-9574-5bf67f3844bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-657165e7-87d4-4175-893d-607dc3a8e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-43ec69ef-0269-4435-a949-c799329eb964,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-71365c2b-d56b-4c59-8181-1040b01fbb89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835328601-172.17.0.14-1597213981691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-dbc50dff-8c61-48f2-8ad5-46d7037db545,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-aa310894-4884-4d99-a93b-e63d153dab5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-8c73b6ca-f8e7-442f-9da4-92c33a6b92ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-c94700a2-beb9-4470-beb5-4179b9cca631,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-e77b6f27-06fa-4e41-8992-0655e28e1e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-db6d65e7-9200-4076-a2d1-80d1f92a7791,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-d9d05766-b189-41b8-8d4b-173091581888,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-f0a7a434-c8a5-4d8c-8c68-01a2ace299d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835328601-172.17.0.14-1597213981691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-dbc50dff-8c61-48f2-8ad5-46d7037db545,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-aa310894-4884-4d99-a93b-e63d153dab5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-8c73b6ca-f8e7-442f-9da4-92c33a6b92ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-c94700a2-beb9-4470-beb5-4179b9cca631,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-e77b6f27-06fa-4e41-8992-0655e28e1e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-db6d65e7-9200-4076-a2d1-80d1f92a7791,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-d9d05766-b189-41b8-8d4b-173091581888,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-f0a7a434-c8a5-4d8c-8c68-01a2ace299d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599682085-172.17.0.14-1597214289743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37109,DS-53724911-bf04-4cb1-a755-ab5a3e9041d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-4b1a6168-429a-4756-9945-d727c9601d06,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-538decb4-3eb1-4ad7-8292-d9718b5e2038,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-557efcac-e925-4442-9849-0d37eeeef3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-3a330cc5-386c-4ade-b5d8-60e9caa5129f,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-6ea8343c-3c82-4d9f-bc97-a1e392601944,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-4b411693-cc92-4b7a-bc4a-7d7463c85daf,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-f1b1b8b5-bfaa-463f-a34c-d9b676a243d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599682085-172.17.0.14-1597214289743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37109,DS-53724911-bf04-4cb1-a755-ab5a3e9041d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-4b1a6168-429a-4756-9945-d727c9601d06,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-538decb4-3eb1-4ad7-8292-d9718b5e2038,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-557efcac-e925-4442-9849-0d37eeeef3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-3a330cc5-386c-4ade-b5d8-60e9caa5129f,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-6ea8343c-3c82-4d9f-bc97-a1e392601944,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-4b411693-cc92-4b7a-bc4a-7d7463c85daf,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-f1b1b8b5-bfaa-463f-a34c-d9b676a243d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902171117-172.17.0.14-1597214329318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41868,DS-969f231c-eadf-4216-aff9-f7041b2f1947,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-19b503e8-23a9-48be-b20f-5e22919427f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-1abf886b-fbf9-42e5-86e4-769e8986a7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-62d0a909-6276-41c7-9638-bac3d88c18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-c3c97327-e750-4ace-8656-fb74ce029587,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-4749ade4-5676-4b7c-8117-67b52a704995,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-52462c52-890f-45a8-bebe-a794b938b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-9af3df54-9f61-4fdd-8667-b43da9976966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902171117-172.17.0.14-1597214329318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41868,DS-969f231c-eadf-4216-aff9-f7041b2f1947,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-19b503e8-23a9-48be-b20f-5e22919427f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-1abf886b-fbf9-42e5-86e4-769e8986a7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-62d0a909-6276-41c7-9638-bac3d88c18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-c3c97327-e750-4ace-8656-fb74ce029587,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-4749ade4-5676-4b7c-8117-67b52a704995,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-52462c52-890f-45a8-bebe-a794b938b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-9af3df54-9f61-4fdd-8667-b43da9976966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540062098-172.17.0.14-1597214405800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37691,DS-81ccf434-3900-4145-bfd7-e3b690f3602a,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-f3ab4e52-a0f1-43d7-8d89-843550db5b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-573f528a-b9b3-4a75-b12b-159b61d24bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-f8f71503-2102-4f1e-a745-98c1d7b2b7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-3e707d7d-73a3-45e8-831c-edd45c9550c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-19d93bd9-c206-4a89-bea2-84ccc0ebf8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-15bc53f3-6ed7-4a2e-9fa5-f642fe0c0b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-4cb2a00e-62d4-42ce-ae96-0384d465c013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540062098-172.17.0.14-1597214405800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37691,DS-81ccf434-3900-4145-bfd7-e3b690f3602a,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-f3ab4e52-a0f1-43d7-8d89-843550db5b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-573f528a-b9b3-4a75-b12b-159b61d24bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-f8f71503-2102-4f1e-a745-98c1d7b2b7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-3e707d7d-73a3-45e8-831c-edd45c9550c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-19d93bd9-c206-4a89-bea2-84ccc0ebf8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-15bc53f3-6ed7-4a2e-9fa5-f642fe0c0b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-4cb2a00e-62d4-42ce-ae96-0384d465c013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619037813-172.17.0.14-1597214740437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-c1aff2de-5ca9-4164-978c-8f0882811976,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-a12236f2-bf71-4a23-9c20-5691bffe4c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-ea8240d1-fae8-47e4-b2c8-5057fb024cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-400fa3e1-feb5-4028-abde-97fc8297b5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-84116599-eec2-401b-8078-59795de7e220,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-cc9929f3-5b7b-435e-b459-7b8b4015abd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-3caa7710-9a16-4313-bd26-0ed0869f5672,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-6ba18d1c-6461-4378-b3db-f17b6e0d3824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619037813-172.17.0.14-1597214740437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-c1aff2de-5ca9-4164-978c-8f0882811976,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-a12236f2-bf71-4a23-9c20-5691bffe4c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-ea8240d1-fae8-47e4-b2c8-5057fb024cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-400fa3e1-feb5-4028-abde-97fc8297b5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-84116599-eec2-401b-8078-59795de7e220,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-cc9929f3-5b7b-435e-b459-7b8b4015abd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-3caa7710-9a16-4313-bd26-0ed0869f5672,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-6ba18d1c-6461-4378-b3db-f17b6e0d3824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91131221-172.17.0.14-1597215094530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-ec360abd-4c7a-446b-8327-7c44f90b6d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-bbbf7946-988a-492a-923e-4b01361e186e,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-102bc3a6-4dc6-4ef6-a4a4-f27e6cd9b901,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-c6d4ed6a-9b45-4ed4-8d69-a9903f22ba28,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-070b7e76-fdb0-4a1e-b9a9-43e906d42916,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-64ae7fbd-3887-4ae0-894e-5887d7ab0d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-7e870d05-ecf2-448a-9bec-de59dacabbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-eee38181-98a1-4dba-9873-b41557fa5aba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91131221-172.17.0.14-1597215094530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-ec360abd-4c7a-446b-8327-7c44f90b6d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-bbbf7946-988a-492a-923e-4b01361e186e,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-102bc3a6-4dc6-4ef6-a4a4-f27e6cd9b901,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-c6d4ed6a-9b45-4ed4-8d69-a9903f22ba28,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-070b7e76-fdb0-4a1e-b9a9-43e906d42916,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-64ae7fbd-3887-4ae0-894e-5887d7ab0d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-7e870d05-ecf2-448a-9bec-de59dacabbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-eee38181-98a1-4dba-9873-b41557fa5aba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877142522-172.17.0.14-1597215242861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-4c2f15e4-912d-4d1c-9b2d-ce8003c97e07,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-f376163b-8ba7-4ce6-8b52-080eb7ea6659,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-f065f339-fdc6-4f2a-94e2-00d515782895,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-2fcdbda5-e555-433a-a423-f9be71758350,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-c94f28ea-c55d-49cb-a853-4386200e4276,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-d65386ed-cce1-4e03-8a16-3d104804127b,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-7504cf20-1a73-40b9-b7a4-94fd21e94bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-8ee6da2c-c0ad-44f7-846d-5a242421cf7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877142522-172.17.0.14-1597215242861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-4c2f15e4-912d-4d1c-9b2d-ce8003c97e07,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-f376163b-8ba7-4ce6-8b52-080eb7ea6659,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-f065f339-fdc6-4f2a-94e2-00d515782895,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-2fcdbda5-e555-433a-a423-f9be71758350,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-c94f28ea-c55d-49cb-a853-4386200e4276,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-d65386ed-cce1-4e03-8a16-3d104804127b,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-7504cf20-1a73-40b9-b7a4-94fd21e94bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-8ee6da2c-c0ad-44f7-846d-5a242421cf7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181832339-172.17.0.14-1597215478248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41731,DS-c03c7c2a-100b-408f-bfb9-a53ca416043f,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-531c4546-91ef-4ca6-8dec-eb49d0642835,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-36a4bc48-6726-4786-8aaf-6bebe26a6332,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-6e6ee197-2987-423f-99ea-4b1cf7b0348f,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-0122c80d-d1e9-4613-a45d-30de42d0c7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-411ff416-20c8-4171-966e-41c2bb3769c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-8f173a74-77f3-4391-a465-e97fabd609bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-a4ce1ab0-87e7-4f4b-9ad6-c156926e689b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181832339-172.17.0.14-1597215478248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41731,DS-c03c7c2a-100b-408f-bfb9-a53ca416043f,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-531c4546-91ef-4ca6-8dec-eb49d0642835,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-36a4bc48-6726-4786-8aaf-6bebe26a6332,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-6e6ee197-2987-423f-99ea-4b1cf7b0348f,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-0122c80d-d1e9-4613-a45d-30de42d0c7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-411ff416-20c8-4171-966e-41c2bb3769c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-8f173a74-77f3-4391-a465-e97fabd609bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-a4ce1ab0-87e7-4f4b-9ad6-c156926e689b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5563
