reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602467173-172.17.0.14-1597175278667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39824,DS-36ed3840-446c-4206-9ad2-1ae81ef39342,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-6f09969e-1859-4d80-9723-9f23537364dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-93393c31-b054-4963-b20a-25bfa730485b,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-1e52c03e-0757-4d5c-a7e2-1c7b85d4fbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-e9361968-35f3-47df-858f-d5ffb1a82818,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-0c4c5ae9-fdcf-4e82-9756-978c931c555d,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-2811f17e-da5b-4814-9a2d-6f2bf42a6823,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-76d7d55d-77bb-41b8-8652-e920eaeb7f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602467173-172.17.0.14-1597175278667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39824,DS-36ed3840-446c-4206-9ad2-1ae81ef39342,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-6f09969e-1859-4d80-9723-9f23537364dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-93393c31-b054-4963-b20a-25bfa730485b,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-1e52c03e-0757-4d5c-a7e2-1c7b85d4fbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-e9361968-35f3-47df-858f-d5ffb1a82818,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-0c4c5ae9-fdcf-4e82-9756-978c931c555d,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-2811f17e-da5b-4814-9a2d-6f2bf42a6823,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-76d7d55d-77bb-41b8-8652-e920eaeb7f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149980781-172.17.0.14-1597175344494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38652,DS-b38da858-1b39-4f80-9237-ca3ea375efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-d89091df-8d14-405f-8783-fdb676429071,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-f53f3608-e570-4957-8192-c65969fbca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-eb8507cc-7fe2-46c5-9414-b86a263fad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-cac2c391-1ea1-4a5d-9c89-6e0b05c4d535,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-b4b4da52-65b6-44cc-834b-e0962e9f5a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-c4065c14-4a40-4d79-83b5-f6906ad3dbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-92f9d5d5-3223-4183-b6d2-bf5c99277630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149980781-172.17.0.14-1597175344494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38652,DS-b38da858-1b39-4f80-9237-ca3ea375efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-d89091df-8d14-405f-8783-fdb676429071,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-f53f3608-e570-4957-8192-c65969fbca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-eb8507cc-7fe2-46c5-9414-b86a263fad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-cac2c391-1ea1-4a5d-9c89-6e0b05c4d535,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-b4b4da52-65b6-44cc-834b-e0962e9f5a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-c4065c14-4a40-4d79-83b5-f6906ad3dbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-92f9d5d5-3223-4183-b6d2-bf5c99277630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601924225-172.17.0.14-1597175591137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42429,DS-cfbcd676-7ab2-4d9e-8e23-9c767af5e287,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-ed9a64a7-0c1c-46e3-9075-ad1a4b0671d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-d74619e5-6f97-49a2-bf5d-f1d6e7ada903,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-eb407a4b-6c2a-42e4-ae97-18c910a36aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-52fa3561-cad5-41c9-8a3f-59d23aa9e6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-db060e81-0b19-44a0-a96c-f4b9d5462124,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-f7d90796-ebed-4ad2-9062-9cddc2ded5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-91c025b3-c909-4bcd-934b-e191e8a4871c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601924225-172.17.0.14-1597175591137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42429,DS-cfbcd676-7ab2-4d9e-8e23-9c767af5e287,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-ed9a64a7-0c1c-46e3-9075-ad1a4b0671d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-d74619e5-6f97-49a2-bf5d-f1d6e7ada903,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-eb407a4b-6c2a-42e4-ae97-18c910a36aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-52fa3561-cad5-41c9-8a3f-59d23aa9e6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-db060e81-0b19-44a0-a96c-f4b9d5462124,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-f7d90796-ebed-4ad2-9062-9cddc2ded5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-91c025b3-c909-4bcd-934b-e191e8a4871c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805159003-172.17.0.14-1597175725722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-c1bc77ad-3cab-4c5b-96e8-43a54dc1e4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-a7fd5cc3-2858-43f8-be86-6fc58d4bc5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-5808fc6c-6266-4510-b8cf-2010063605ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-7f852abe-b43d-453d-a2ba-cca2a51bd9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-caac9e69-be19-42dc-a4fe-502a1ca0aae7,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-b2447ec0-1281-4753-8b71-40282b38620a,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-aff9bd9d-cd31-40c8-bb2e-cd3eaacbfe07,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-a5664014-c693-4ac1-b35d-d6105de1be0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805159003-172.17.0.14-1597175725722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-c1bc77ad-3cab-4c5b-96e8-43a54dc1e4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-a7fd5cc3-2858-43f8-be86-6fc58d4bc5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-5808fc6c-6266-4510-b8cf-2010063605ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-7f852abe-b43d-453d-a2ba-cca2a51bd9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-caac9e69-be19-42dc-a4fe-502a1ca0aae7,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-b2447ec0-1281-4753-8b71-40282b38620a,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-aff9bd9d-cd31-40c8-bb2e-cd3eaacbfe07,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-a5664014-c693-4ac1-b35d-d6105de1be0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286714608-172.17.0.14-1597176231871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37393,DS-87a9673f-1681-4e2d-a196-1ee6adba797b,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-66c643b4-4255-4a40-a89b-06c073905617,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-42fc1cba-3354-40f7-b468-d3158cd3e61c,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-36916a86-6412-4bfb-ab0c-0ea50a334a12,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-4f96c940-1d21-452f-8f54-412cb194e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-f2bce13e-2441-4d47-afc8-567584131ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-9318f45b-904d-4e23-8705-326fe3471f69,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-6fa88b3a-13fd-4ff0-be8c-d5ed8e0461bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286714608-172.17.0.14-1597176231871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37393,DS-87a9673f-1681-4e2d-a196-1ee6adba797b,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-66c643b4-4255-4a40-a89b-06c073905617,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-42fc1cba-3354-40f7-b468-d3158cd3e61c,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-36916a86-6412-4bfb-ab0c-0ea50a334a12,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-4f96c940-1d21-452f-8f54-412cb194e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-f2bce13e-2441-4d47-afc8-567584131ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-9318f45b-904d-4e23-8705-326fe3471f69,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-6fa88b3a-13fd-4ff0-be8c-d5ed8e0461bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635038870-172.17.0.14-1597176260588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38849,DS-8bff0d90-eaa8-49fd-b55a-fe13a9028c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-ca915b9d-12f3-41e6-a75d-bf6517c2e600,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-77262e2c-8a0c-486f-8485-39846713fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-cf7750ae-4c6d-4ce6-b705-f663e833f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-89515711-20b5-4e3e-a10c-48c8284327a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-92d2a658-1651-414f-8708-8d92a4037c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-34af8727-9caa-4bef-8382-b56f80be5e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-7287e08b-f946-4b60-a270-22866e346754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635038870-172.17.0.14-1597176260588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38849,DS-8bff0d90-eaa8-49fd-b55a-fe13a9028c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-ca915b9d-12f3-41e6-a75d-bf6517c2e600,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-77262e2c-8a0c-486f-8485-39846713fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-cf7750ae-4c6d-4ce6-b705-f663e833f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-89515711-20b5-4e3e-a10c-48c8284327a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-92d2a658-1651-414f-8708-8d92a4037c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-34af8727-9caa-4bef-8382-b56f80be5e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-7287e08b-f946-4b60-a270-22866e346754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757677307-172.17.0.14-1597176327784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-2889f043-d625-45a1-b760-a18147310f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-fd578fa0-959f-4b01-b796-03b4bd78d466,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-dedd128e-abd2-47fb-83e0-96bc45b0e7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-23f14008-f26f-48da-86fc-c5395b2863a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-fa221e09-dbcd-408f-92e5-36b81d4e3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-b9b0d25c-6468-4ac2-be7b-5482264aaad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-3f829459-32dc-4716-b2f1-b4406a7efff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-bb2109ef-edc6-47d7-8a61-0c6da11eedb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757677307-172.17.0.14-1597176327784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-2889f043-d625-45a1-b760-a18147310f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-fd578fa0-959f-4b01-b796-03b4bd78d466,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-dedd128e-abd2-47fb-83e0-96bc45b0e7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-23f14008-f26f-48da-86fc-c5395b2863a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-fa221e09-dbcd-408f-92e5-36b81d4e3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-b9b0d25c-6468-4ac2-be7b-5482264aaad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-3f829459-32dc-4716-b2f1-b4406a7efff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-bb2109ef-edc6-47d7-8a61-0c6da11eedb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910056910-172.17.0.14-1597176553160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-6bd877b0-e7b1-428e-bf5d-40463d565017,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-f860ab30-6a8c-437a-ba9e-b1321a282aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-4548140f-519b-4684-84c6-cd7faa6c1519,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-178cee3b-6061-4a3a-a04e-6159326e9a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-e1eb37cd-abc5-48d3-a408-b71730f6d708,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-e5de7511-b51d-48f6-aa80-d68a15f3dd37,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1f83ecc2-c560-40d7-b165-a1ab33d37a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-9257d06e-8fd6-4afa-a699-d3ccebb54c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910056910-172.17.0.14-1597176553160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-6bd877b0-e7b1-428e-bf5d-40463d565017,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-f860ab30-6a8c-437a-ba9e-b1321a282aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-4548140f-519b-4684-84c6-cd7faa6c1519,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-178cee3b-6061-4a3a-a04e-6159326e9a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-e1eb37cd-abc5-48d3-a408-b71730f6d708,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-e5de7511-b51d-48f6-aa80-d68a15f3dd37,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1f83ecc2-c560-40d7-b165-a1ab33d37a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-9257d06e-8fd6-4afa-a699-d3ccebb54c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951528596-172.17.0.14-1597177032085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37429,DS-98722a76-833b-4792-81f7-44396a0f5adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-c45e65a9-be80-4d7a-b914-0b4ed84130c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-4a7acbce-5254-4523-bc58-414cf462fa97,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-68b8def3-37ff-484e-b725-b12cc179f03b,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-4b35ee79-f916-46fb-b766-2b7de4b6afd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-49b61e46-d8ce-4192-bef5-dfadbf816fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-aed23df3-c7f7-4c52-a86a-b395cd589ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-2f8d40bb-8d9d-48c6-94b0-c7c72334c984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951528596-172.17.0.14-1597177032085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37429,DS-98722a76-833b-4792-81f7-44396a0f5adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-c45e65a9-be80-4d7a-b914-0b4ed84130c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-4a7acbce-5254-4523-bc58-414cf462fa97,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-68b8def3-37ff-484e-b725-b12cc179f03b,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-4b35ee79-f916-46fb-b766-2b7de4b6afd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-49b61e46-d8ce-4192-bef5-dfadbf816fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-aed23df3-c7f7-4c52-a86a-b395cd589ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-2f8d40bb-8d9d-48c6-94b0-c7c72334c984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559534987-172.17.0.14-1597177157339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42388,DS-db26fb08-26ba-40b2-ace5-ca1a8d915a23,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-be715244-16e6-4ee4-84cc-836365a9a07e,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-d3947f4f-a372-4085-a4f0-5d6d0997beb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-5e3a9325-6f32-4810-98bd-c0723a8cee64,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-891618b7-5adb-460f-8484-82c2f48826b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-5686abab-9cf5-47bb-bd63-8eeffa4fbecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-ec4e343a-4bb8-42e1-9a55-ef41364e1f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-6a1e647a-849a-4251-9f3b-aa3f44abd376,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559534987-172.17.0.14-1597177157339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42388,DS-db26fb08-26ba-40b2-ace5-ca1a8d915a23,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-be715244-16e6-4ee4-84cc-836365a9a07e,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-d3947f4f-a372-4085-a4f0-5d6d0997beb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-5e3a9325-6f32-4810-98bd-c0723a8cee64,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-891618b7-5adb-460f-8484-82c2f48826b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-5686abab-9cf5-47bb-bd63-8eeffa4fbecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-ec4e343a-4bb8-42e1-9a55-ef41364e1f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-6a1e647a-849a-4251-9f3b-aa3f44abd376,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049312793-172.17.0.14-1597177248303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-985f2c8f-3357-41fa-83e6-895c78565227,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-7c23bcc5-f709-4647-b51e-1d1d3e5c6905,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-9c2aa47b-6d62-460c-a049-7f586b86e5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-b0036e3b-3597-4bf6-a2f9-9bf5cf853137,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-71602e25-30e1-4027-b29d-206fe375ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-f902bf73-18d7-447e-8d67-666b71d9437f,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-cc220c64-845c-4b7b-a834-286d0a6e1892,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-6818be1d-96e3-4afc-80c8-cb84ef7c250e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049312793-172.17.0.14-1597177248303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-985f2c8f-3357-41fa-83e6-895c78565227,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-7c23bcc5-f709-4647-b51e-1d1d3e5c6905,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-9c2aa47b-6d62-460c-a049-7f586b86e5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-b0036e3b-3597-4bf6-a2f9-9bf5cf853137,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-71602e25-30e1-4027-b29d-206fe375ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-f902bf73-18d7-447e-8d67-666b71d9437f,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-cc220c64-845c-4b7b-a834-286d0a6e1892,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-6818be1d-96e3-4afc-80c8-cb84ef7c250e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996635395-172.17.0.14-1597177607381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-15a218d2-2999-4a19-ba0c-68d8e3206a29,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-180645dd-f881-4bef-9db1-d774c3d7003b,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-3931a19d-a2f7-4085-808a-eac3dfc8551c,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-802a6689-87f5-4530-9446-cf3f9581b8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-486f0742-fba0-4373-98a1-70a90b3b893d,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-d6888328-48ba-4861-8ccf-1dd77199a675,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-d6ef6608-205c-478c-be41-4c77e84cd844,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-b9a31d1b-0732-4973-ae51-04d9dcc4648c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996635395-172.17.0.14-1597177607381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-15a218d2-2999-4a19-ba0c-68d8e3206a29,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-180645dd-f881-4bef-9db1-d774c3d7003b,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-3931a19d-a2f7-4085-808a-eac3dfc8551c,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-802a6689-87f5-4530-9446-cf3f9581b8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-486f0742-fba0-4373-98a1-70a90b3b893d,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-d6888328-48ba-4861-8ccf-1dd77199a675,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-d6ef6608-205c-478c-be41-4c77e84cd844,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-b9a31d1b-0732-4973-ae51-04d9dcc4648c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40326915-172.17.0.14-1597177785655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-2217bfa2-0513-4b45-97a3-6a7c50ea1ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-57bea85b-6fea-449e-9da7-6963ef42b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-1f7bf414-69c0-4140-937b-efd4da5d876c,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-2d46bc59-8718-469d-a575-6c71c65dc91f,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-5dfef672-26c7-416a-a262-0a30a90eca85,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-2270af95-5ed4-4b17-9863-d94df8778bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-5b6ae2da-f507-46b4-866a-dc6ba78d8127,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-f5ad0728-acad-4cf0-8ad3-953961246651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40326915-172.17.0.14-1597177785655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-2217bfa2-0513-4b45-97a3-6a7c50ea1ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-57bea85b-6fea-449e-9da7-6963ef42b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-1f7bf414-69c0-4140-937b-efd4da5d876c,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-2d46bc59-8718-469d-a575-6c71c65dc91f,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-5dfef672-26c7-416a-a262-0a30a90eca85,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-2270af95-5ed4-4b17-9863-d94df8778bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-5b6ae2da-f507-46b4-866a-dc6ba78d8127,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-f5ad0728-acad-4cf0-8ad3-953961246651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239000434-172.17.0.14-1597177948728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41755,DS-2f910b29-b433-4284-929c-aec7e530bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-80e8d88a-628e-4796-a439-d9e69f138826,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-fd1f714e-8dd1-4d81-ae4e-8255d32407c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-b5dcf19b-2608-4a63-a97c-27528c88370f,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-c7fa29ea-8319-4658-ae0f-73dd5526af2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-b216a577-2346-4c6e-adcf-253940d7120a,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-e6d785f4-5d0d-49e7-847a-a17af40b9c95,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-9b2a48e9-524c-4d6a-9625-b9c67d4082ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239000434-172.17.0.14-1597177948728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41755,DS-2f910b29-b433-4284-929c-aec7e530bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-80e8d88a-628e-4796-a439-d9e69f138826,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-fd1f714e-8dd1-4d81-ae4e-8255d32407c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-b5dcf19b-2608-4a63-a97c-27528c88370f,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-c7fa29ea-8319-4658-ae0f-73dd5526af2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-b216a577-2346-4c6e-adcf-253940d7120a,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-e6d785f4-5d0d-49e7-847a-a17af40b9c95,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-9b2a48e9-524c-4d6a-9625-b9c67d4082ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650902935-172.17.0.14-1597178002856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41350,DS-4b57c7f4-ab48-4b4a-9d6d-3e19cd001513,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-b712e3ae-1093-45eb-b5e0-36c74dc4c700,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-b54a8f1f-949e-4217-83b6-569f7220d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-fbdbb682-2159-4c52-923c-f5263f4e52e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-0bf4053a-01ee-4922-9b97-42e05aef175f,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-190f3acb-40e1-477c-8dad-2741a5db13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-1bef15da-e521-43c2-af8e-11fed88529f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-71e04be0-144b-4461-8b1a-8d87ee1c598d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650902935-172.17.0.14-1597178002856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41350,DS-4b57c7f4-ab48-4b4a-9d6d-3e19cd001513,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-b712e3ae-1093-45eb-b5e0-36c74dc4c700,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-b54a8f1f-949e-4217-83b6-569f7220d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-fbdbb682-2159-4c52-923c-f5263f4e52e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-0bf4053a-01ee-4922-9b97-42e05aef175f,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-190f3acb-40e1-477c-8dad-2741a5db13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-1bef15da-e521-43c2-af8e-11fed88529f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-71e04be0-144b-4461-8b1a-8d87ee1c598d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454642305-172.17.0.14-1597178384484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35888,DS-9c642e3f-6a16-4ec1-b69b-01113ce291d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-a7d17716-6fee-4e3c-912a-4945b3885ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-30186b27-bc70-4cde-8b20-48bbf516c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-4fb23d89-6a5c-4cbf-990d-10fd96ecbf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-ff6ee350-da01-43f4-899e-cdddbc36852f,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-d40c2f27-f07b-4957-bc32-cca0de601717,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-b28ec687-8fff-475e-971d-0d4ff2b3f954,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-b85c03df-e70a-4f53-b398-fb8a35760caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454642305-172.17.0.14-1597178384484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35888,DS-9c642e3f-6a16-4ec1-b69b-01113ce291d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-a7d17716-6fee-4e3c-912a-4945b3885ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-30186b27-bc70-4cde-8b20-48bbf516c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-4fb23d89-6a5c-4cbf-990d-10fd96ecbf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-ff6ee350-da01-43f4-899e-cdddbc36852f,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-d40c2f27-f07b-4957-bc32-cca0de601717,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-b28ec687-8fff-475e-971d-0d4ff2b3f954,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-b85c03df-e70a-4f53-b398-fb8a35760caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327073698-172.17.0.14-1597178503839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38792,DS-e5332c16-064e-49b5-8679-01853522b855,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-90b6deec-e752-400d-814a-3296d653cc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-5c232c64-0f76-44fa-8058-3c024d77130f,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-bc8c4f49-8ee3-4388-ab9a-d49a21fbf1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-f1db3591-af60-4216-b23d-8e66c31c7a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-043b94af-9d7b-4371-847c-bec5b011c345,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-b4d56e30-7585-4fc1-a53d-f1703decf957,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-2c1e2a43-b3a2-4ec8-8014-6adef855bf50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327073698-172.17.0.14-1597178503839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38792,DS-e5332c16-064e-49b5-8679-01853522b855,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-90b6deec-e752-400d-814a-3296d653cc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-5c232c64-0f76-44fa-8058-3c024d77130f,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-bc8c4f49-8ee3-4388-ab9a-d49a21fbf1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-f1db3591-af60-4216-b23d-8e66c31c7a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-043b94af-9d7b-4371-847c-bec5b011c345,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-b4d56e30-7585-4fc1-a53d-f1703decf957,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-2c1e2a43-b3a2-4ec8-8014-6adef855bf50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105734672-172.17.0.14-1597178576031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-c22b122d-2e5b-4594-9733-40d3c236e458,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-3c1589cc-9391-4d79-8235-b72b405c6560,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-ae5c5bea-98b5-4982-b017-b8ceafbf3a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-e1d15183-619f-4ef0-8936-b205a037f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-16d65d7b-1380-4cee-a9b9-1ba9b0b8cac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-90849d6d-6dd8-40d9-b9cb-6a975fca445d,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-600d85bc-da1e-424c-a8c9-cb998c967c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-1205a3bc-e017-4184-a9dd-0afe1ed61688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105734672-172.17.0.14-1597178576031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-c22b122d-2e5b-4594-9733-40d3c236e458,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-3c1589cc-9391-4d79-8235-b72b405c6560,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-ae5c5bea-98b5-4982-b017-b8ceafbf3a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-e1d15183-619f-4ef0-8936-b205a037f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-16d65d7b-1380-4cee-a9b9-1ba9b0b8cac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-90849d6d-6dd8-40d9-b9cb-6a975fca445d,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-600d85bc-da1e-424c-a8c9-cb998c967c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-1205a3bc-e017-4184-a9dd-0afe1ed61688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310923637-172.17.0.14-1597178607871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35666,DS-534a108e-45f8-40db-a907-3d98d603c440,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-a6e97c16-fbd1-44a5-991b-7f69a25e381d,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-a94224b9-02c7-4e1e-9da2-57ee5bac1b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-527fc837-e985-4376-8785-b252fb524f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-b0c0bb0f-3e0c-499c-8a60-89571ac2413c,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-99283159-2f7a-47db-a995-5ec182e991cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-77e5cdfa-a1b2-4c4e-8e5e-dc2eec08a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a56879aa-1a13-48c6-9117-bef077c62e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310923637-172.17.0.14-1597178607871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35666,DS-534a108e-45f8-40db-a907-3d98d603c440,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-a6e97c16-fbd1-44a5-991b-7f69a25e381d,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-a94224b9-02c7-4e1e-9da2-57ee5bac1b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-527fc837-e985-4376-8785-b252fb524f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-b0c0bb0f-3e0c-499c-8a60-89571ac2413c,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-99283159-2f7a-47db-a995-5ec182e991cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-77e5cdfa-a1b2-4c4e-8e5e-dc2eec08a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a56879aa-1a13-48c6-9117-bef077c62e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743334400-172.17.0.14-1597178702573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-760db447-2a67-487a-a510-1439489853f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-d075281c-2cb4-448a-8619-70d08f62c10f,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-d8a5079a-85f7-4e42-bca9-c1ff44e71a21,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-2c496ab6-714a-451c-9348-1feb87efa2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-d950124a-63fc-4e6e-a67a-89214c0afdef,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-4639facc-ec68-475c-82f1-1738e0156a91,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-47737f4c-97b8-4551-bc08-595cab8bc530,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-caebe3d9-020a-4429-adb0-2c6266178673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743334400-172.17.0.14-1597178702573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-760db447-2a67-487a-a510-1439489853f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-d075281c-2cb4-448a-8619-70d08f62c10f,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-d8a5079a-85f7-4e42-bca9-c1ff44e71a21,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-2c496ab6-714a-451c-9348-1feb87efa2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-d950124a-63fc-4e6e-a67a-89214c0afdef,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-4639facc-ec68-475c-82f1-1738e0156a91,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-47737f4c-97b8-4551-bc08-595cab8bc530,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-caebe3d9-020a-4429-adb0-2c6266178673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474501119-172.17.0.14-1597179000743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-ad9986fd-5245-4cdb-8dad-731c40f7ec06,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-ca540ea4-848b-4873-87bc-07e8191b03cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-34e905bb-a49b-4819-8c2d-54d84a770e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-3acf0c09-83bb-476c-93e4-15d226c7f493,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-49af125f-a2f3-43c3-a894-f996692ee1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-8e7b180e-5a77-4ea9-a8cc-76ff3c991162,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-485db2dc-a38c-497c-995f-ade37087047b,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-6226781b-d8c1-46b2-bea5-ba1c323e1037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474501119-172.17.0.14-1597179000743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-ad9986fd-5245-4cdb-8dad-731c40f7ec06,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-ca540ea4-848b-4873-87bc-07e8191b03cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-34e905bb-a49b-4819-8c2d-54d84a770e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-3acf0c09-83bb-476c-93e4-15d226c7f493,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-49af125f-a2f3-43c3-a894-f996692ee1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-8e7b180e-5a77-4ea9-a8cc-76ff3c991162,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-485db2dc-a38c-497c-995f-ade37087047b,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-6226781b-d8c1-46b2-bea5-ba1c323e1037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833982973-172.17.0.14-1597179091252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43624,DS-2706931f-aa2b-4c62-be03-3b61b71d2303,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-2193a3c2-361f-4eaa-82ee-398af6953acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-10f7eafe-2e62-4c65-96e0-ddf2d019ebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-28a95e09-de4c-4329-949d-d60760c0bb33,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-09a1cfe0-cccb-4aaa-a7f1-db3ce88eb0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-c82e79d8-1280-4590-81e6-5830cb6efeea,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-a04f84ad-739a-4e6a-ace5-0168d539563b,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-56f7efba-5f9d-410d-a34f-967c1d453f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833982973-172.17.0.14-1597179091252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43624,DS-2706931f-aa2b-4c62-be03-3b61b71d2303,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-2193a3c2-361f-4eaa-82ee-398af6953acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-10f7eafe-2e62-4c65-96e0-ddf2d019ebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-28a95e09-de4c-4329-949d-d60760c0bb33,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-09a1cfe0-cccb-4aaa-a7f1-db3ce88eb0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-c82e79d8-1280-4590-81e6-5830cb6efeea,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-a04f84ad-739a-4e6a-ace5-0168d539563b,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-56f7efba-5f9d-410d-a34f-967c1d453f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118215252-172.17.0.14-1597179326645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-e8630f1d-00fb-43b5-8618-059afd30e600,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-4f4967b4-b2a8-4067-a0f7-df7797444d27,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-749a2220-950d-4c8c-91b9-4533aa8e910d,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-5351ff97-f2ee-4614-a7ff-59a64cd03c99,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-8dd0fabf-5ef3-4a22-ae5d-f059656937b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-fe867deb-dbee-4052-a49b-51d17f7f11b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-f0e6965b-14d4-46d5-bea2-e1525ca9fdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-d41e8983-de17-4468-864e-ec3e862a162f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118215252-172.17.0.14-1597179326645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-e8630f1d-00fb-43b5-8618-059afd30e600,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-4f4967b4-b2a8-4067-a0f7-df7797444d27,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-749a2220-950d-4c8c-91b9-4533aa8e910d,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-5351ff97-f2ee-4614-a7ff-59a64cd03c99,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-8dd0fabf-5ef3-4a22-ae5d-f059656937b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-fe867deb-dbee-4052-a49b-51d17f7f11b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-f0e6965b-14d4-46d5-bea2-e1525ca9fdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-d41e8983-de17-4468-864e-ec3e862a162f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775626931-172.17.0.14-1597179610916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-78f1476c-4b34-4a41-b6fe-5803c414f150,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-31116996-c55b-4886-b072-ac57e97c3f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-cbfa8a4b-ebc5-498e-b4fa-ef1cc11ad603,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-d0c9adab-99e2-4107-a1bf-c7124d340704,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-0c45037b-faa6-4e92-8d40-5fcad42b75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-a1342d86-c759-425e-bb72-5c5a91a32a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-de9affb2-0026-4bd5-8cc4-f63a1770650e,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-6b3bc6db-0660-4d0d-98f8-a854fffeda42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775626931-172.17.0.14-1597179610916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-78f1476c-4b34-4a41-b6fe-5803c414f150,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-31116996-c55b-4886-b072-ac57e97c3f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-cbfa8a4b-ebc5-498e-b4fa-ef1cc11ad603,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-d0c9adab-99e2-4107-a1bf-c7124d340704,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-0c45037b-faa6-4e92-8d40-5fcad42b75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-a1342d86-c759-425e-bb72-5c5a91a32a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-de9affb2-0026-4bd5-8cc4-f63a1770650e,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-6b3bc6db-0660-4d0d-98f8-a854fffeda42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011621293-172.17.0.14-1597179773666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-d9b99e65-0344-426f-8c75-4d82b8aa8546,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-962ec314-ac0b-4218-8e08-ab6f06c5e285,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-a2df12bb-6267-4813-aa86-1afca4cb7f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-bdc25904-c7f0-4f42-995a-e94a24130c23,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-ea786a01-2e9c-4c48-9494-af71ebb0c6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-670f643b-4a0a-4e87-b9d1-9313b92b5391,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-4641682d-d456-409c-83d6-e4987c00df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-e2518449-441d-4164-b0bb-f7a427ea63fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011621293-172.17.0.14-1597179773666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-d9b99e65-0344-426f-8c75-4d82b8aa8546,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-962ec314-ac0b-4218-8e08-ab6f06c5e285,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-a2df12bb-6267-4813-aa86-1afca4cb7f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-bdc25904-c7f0-4f42-995a-e94a24130c23,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-ea786a01-2e9c-4c48-9494-af71ebb0c6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-670f643b-4a0a-4e87-b9d1-9313b92b5391,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-4641682d-d456-409c-83d6-e4987c00df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-e2518449-441d-4164-b0bb-f7a427ea63fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4697
