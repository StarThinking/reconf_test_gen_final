reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069528807-172.17.0.16-1597136340693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-c564cc7f-d7c7-4d8c-a194-0764c60891bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-9d62aee2-9e57-4a48-9d9f-278ea29908e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-5e9f5d5a-f163-4b5d-a5e4-f6ac2e9b8c42,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-8aa99047-89c7-4fc2-9d66-666521677d50,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-8469438c-f841-44be-b9e1-adca7720f549,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-4fcac5a7-ae15-45af-b4ab-3b46c3c0a385,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-59a751ce-ca28-4a84-95c4-4b520bb7cf83,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-ae55a834-82a6-4020-8392-258ecc6d30d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069528807-172.17.0.16-1597136340693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-c564cc7f-d7c7-4d8c-a194-0764c60891bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-9d62aee2-9e57-4a48-9d9f-278ea29908e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-5e9f5d5a-f163-4b5d-a5e4-f6ac2e9b8c42,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-8aa99047-89c7-4fc2-9d66-666521677d50,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-8469438c-f841-44be-b9e1-adca7720f549,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-4fcac5a7-ae15-45af-b4ab-3b46c3c0a385,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-59a751ce-ca28-4a84-95c4-4b520bb7cf83,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-ae55a834-82a6-4020-8392-258ecc6d30d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614650872-172.17.0.16-1597136393164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-029df344-cced-4b18-92e1-1f0cb0fcbd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-bb21d24c-0dbd-48d9-ab18-420b738de63f,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-9ffc5bfa-e956-4208-952f-27bfada1dc98,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-33d3619e-8f7e-4989-be61-359b77800b15,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-6a586a69-a1f3-4b16-9eb9-70f44b8c69be,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-6b8baa13-c203-4664-9689-a31cfd568b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-24db20d0-48c4-4a8b-8784-18120255ed5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-a538fce5-0fff-47ed-ab11-926ce068c934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614650872-172.17.0.16-1597136393164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-029df344-cced-4b18-92e1-1f0cb0fcbd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-bb21d24c-0dbd-48d9-ab18-420b738de63f,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-9ffc5bfa-e956-4208-952f-27bfada1dc98,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-33d3619e-8f7e-4989-be61-359b77800b15,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-6a586a69-a1f3-4b16-9eb9-70f44b8c69be,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-6b8baa13-c203-4664-9689-a31cfd568b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-24db20d0-48c4-4a8b-8784-18120255ed5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-a538fce5-0fff-47ed-ab11-926ce068c934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153384937-172.17.0.16-1597136437697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-4ec3c67d-4e55-431a-84a2-9163221627c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-39ffcec1-a2a6-4408-bf41-f5a2f6917121,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-d3db08f5-b4c8-4f60-b47d-eb661240f51d,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-ff9ab4f1-d735-4eb0-9ea6-7cf1afb022bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-cdef0603-b1be-489d-9e94-02d16bff7290,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-0cac8238-530f-4866-b401-40e1eaecad91,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-7141596b-82ae-4464-b3ac-bdb36855553d,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-dd388d68-d3fd-40c4-8235-318e0bcdfbea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153384937-172.17.0.16-1597136437697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-4ec3c67d-4e55-431a-84a2-9163221627c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-39ffcec1-a2a6-4408-bf41-f5a2f6917121,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-d3db08f5-b4c8-4f60-b47d-eb661240f51d,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-ff9ab4f1-d735-4eb0-9ea6-7cf1afb022bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-cdef0603-b1be-489d-9e94-02d16bff7290,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-0cac8238-530f-4866-b401-40e1eaecad91,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-7141596b-82ae-4464-b3ac-bdb36855553d,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-dd388d68-d3fd-40c4-8235-318e0bcdfbea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051175683-172.17.0.16-1597136731193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43123,DS-bdd9a3e7-74b9-4329-8dbf-d75a719f627d,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-a6d39ae6-17d2-4c38-a5b3-af471aead0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-6f496d63-a0e3-4306-9d49-c75fe161b062,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-ca567ce9-0fe1-4f03-9452-336a1fff73a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-612ff0ea-fd22-4b60-85b1-49d065af5db6,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-e253bec0-d3e1-4c05-901e-8be574161699,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-84e87d2c-3b94-4e0e-a2b9-3f5958cd95e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-4dd5cd06-fda7-4eb3-bfc3-55d4e7a2b221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051175683-172.17.0.16-1597136731193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43123,DS-bdd9a3e7-74b9-4329-8dbf-d75a719f627d,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-a6d39ae6-17d2-4c38-a5b3-af471aead0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-6f496d63-a0e3-4306-9d49-c75fe161b062,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-ca567ce9-0fe1-4f03-9452-336a1fff73a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-612ff0ea-fd22-4b60-85b1-49d065af5db6,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-e253bec0-d3e1-4c05-901e-8be574161699,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-84e87d2c-3b94-4e0e-a2b9-3f5958cd95e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-4dd5cd06-fda7-4eb3-bfc3-55d4e7a2b221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994827673-172.17.0.16-1597136775799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34720,DS-302672c5-7b61-42a7-b6c4-5ff83b373d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-61264e5f-4880-4971-8c21-32764e1b7be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-48c9da3c-d3c3-4851-8a5c-e02b839d8de6,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-bbd37437-a45b-4465-98ce-6ea586742888,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-cb0d8386-a215-4117-907f-7887a412376c,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-d13c8bf8-f595-4831-9c49-afe1a2b79697,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-052195f7-ff2c-43c1-b108-624d62e1960c,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-072d9aeb-3517-442e-b7fe-f43a36c00557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994827673-172.17.0.16-1597136775799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34720,DS-302672c5-7b61-42a7-b6c4-5ff83b373d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-61264e5f-4880-4971-8c21-32764e1b7be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-48c9da3c-d3c3-4851-8a5c-e02b839d8de6,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-bbd37437-a45b-4465-98ce-6ea586742888,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-cb0d8386-a215-4117-907f-7887a412376c,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-d13c8bf8-f595-4831-9c49-afe1a2b79697,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-052195f7-ff2c-43c1-b108-624d62e1960c,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-072d9aeb-3517-442e-b7fe-f43a36c00557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709396726-172.17.0.16-1597136855433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-ff584ba8-b0f3-46a6-b67a-92106bce6d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-b7ca6933-7ca4-4cf2-9024-9a2c07b57ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-0fe61f5d-7220-41a9-86b2-2a597ab5a430,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-42f45cae-df87-4526-ace1-142286a00916,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-d770dd77-bd6c-4618-bbe6-a8cd7295fdda,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-db32e592-b7d4-4bc9-b42b-821441281301,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-5c99f496-ac61-4dcb-a324-ebc1c7972795,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-9b46d553-9e76-4828-b607-9cf624914b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709396726-172.17.0.16-1597136855433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-ff584ba8-b0f3-46a6-b67a-92106bce6d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-b7ca6933-7ca4-4cf2-9024-9a2c07b57ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-0fe61f5d-7220-41a9-86b2-2a597ab5a430,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-42f45cae-df87-4526-ace1-142286a00916,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-d770dd77-bd6c-4618-bbe6-a8cd7295fdda,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-db32e592-b7d4-4bc9-b42b-821441281301,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-5c99f496-ac61-4dcb-a324-ebc1c7972795,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-9b46d553-9e76-4828-b607-9cf624914b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190839047-172.17.0.16-1597137457793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-22da29b4-a67e-45d3-9f3d-9d125c1ea4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-94593270-f07d-48fc-bf47-ba98de727e00,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-015e91f5-4800-4b4c-9766-4dc5ce4ec440,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-18af3889-5a7c-4f61-8028-cab91564a6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-80bfaab8-8517-48f1-801d-f1b63fdd280b,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-9f19b64e-3411-4f83-9a08-d843c5c2d989,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-af74f07d-83b3-4db5-8d8a-cddc3a163357,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-3ab750b7-f605-4a32-b9b3-51fe51e79b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190839047-172.17.0.16-1597137457793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-22da29b4-a67e-45d3-9f3d-9d125c1ea4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-94593270-f07d-48fc-bf47-ba98de727e00,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-015e91f5-4800-4b4c-9766-4dc5ce4ec440,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-18af3889-5a7c-4f61-8028-cab91564a6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-80bfaab8-8517-48f1-801d-f1b63fdd280b,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-9f19b64e-3411-4f83-9a08-d843c5c2d989,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-af74f07d-83b3-4db5-8d8a-cddc3a163357,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-3ab750b7-f605-4a32-b9b3-51fe51e79b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753437326-172.17.0.16-1597137599510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-144091a2-a1a4-4823-93f8-91a04b600c38,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-9ea50c65-575b-42c0-b92b-7e3dc1375227,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-531101d6-8077-4437-980e-8947525cb4db,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-f5226078-7ce9-4514-8dbf-5cde1d942673,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-57e68f90-f197-466a-bd7f-464905eee8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-5a069efe-ec87-4d9c-92b7-58ac8f3a141e,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-01120c86-92e4-4fff-b25d-2ab927300f63,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-fe3f8f0e-f77f-4016-83bf-f16b9fdf2900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753437326-172.17.0.16-1597137599510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-144091a2-a1a4-4823-93f8-91a04b600c38,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-9ea50c65-575b-42c0-b92b-7e3dc1375227,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-531101d6-8077-4437-980e-8947525cb4db,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-f5226078-7ce9-4514-8dbf-5cde1d942673,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-57e68f90-f197-466a-bd7f-464905eee8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-5a069efe-ec87-4d9c-92b7-58ac8f3a141e,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-01120c86-92e4-4fff-b25d-2ab927300f63,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-fe3f8f0e-f77f-4016-83bf-f16b9fdf2900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000489622-172.17.0.16-1597137683589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32900,DS-875e57a4-9162-40db-8a46-f2dff629c256,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-cb2d0cd4-dabd-48fa-9b9b-e696a0e0fb75,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-7c62fc6b-269e-4773-8e22-e438f55e118f,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-48f366c8-57e2-41df-b85b-e2623883c077,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-349924bc-589c-4888-a778-4f1f584d931b,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-6e901507-b1d2-4416-b2bc-90e2416a7907,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-6411795e-d764-4910-9d24-b39810995aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-36701b64-6960-41bf-8e9e-e894520c5525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000489622-172.17.0.16-1597137683589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32900,DS-875e57a4-9162-40db-8a46-f2dff629c256,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-cb2d0cd4-dabd-48fa-9b9b-e696a0e0fb75,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-7c62fc6b-269e-4773-8e22-e438f55e118f,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-48f366c8-57e2-41df-b85b-e2623883c077,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-349924bc-589c-4888-a778-4f1f584d931b,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-6e901507-b1d2-4416-b2bc-90e2416a7907,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-6411795e-d764-4910-9d24-b39810995aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-36701b64-6960-41bf-8e9e-e894520c5525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730614562-172.17.0.16-1597137725218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-7b70eb4d-f65c-4582-b614-5547dba297b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-0da3aa17-9246-46b3-84e8-fd14607e5fab,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-51b647ee-1a84-442b-bc18-96dd2ba54c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-4fc98902-acc7-4b06-824c-c7aa503034b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-d0446a89-7571-4754-a996-0a78f8f86cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-b0ffffc2-cfc5-446b-a0dc-623246c5fee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-64330929-be88-4c09-95a0-3442c71cb609,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-ebeb8cd8-d731-43ee-9ec0-c28762b09148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730614562-172.17.0.16-1597137725218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-7b70eb4d-f65c-4582-b614-5547dba297b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-0da3aa17-9246-46b3-84e8-fd14607e5fab,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-51b647ee-1a84-442b-bc18-96dd2ba54c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-4fc98902-acc7-4b06-824c-c7aa503034b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-d0446a89-7571-4754-a996-0a78f8f86cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-b0ffffc2-cfc5-446b-a0dc-623246c5fee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-64330929-be88-4c09-95a0-3442c71cb609,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-ebeb8cd8-d731-43ee-9ec0-c28762b09148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962652249-172.17.0.16-1597138020428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-06e6ae15-10ef-4543-9a33-0d0b3314fcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-7fa694a2-e7ac-4100-b14e-218c004be1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-80ddfdd3-6a82-4b95-a904-0c6fbf7f9368,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-2ce8ea17-61c3-449e-ba65-09ad2d8e5c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-1953299f-9cae-4aa0-ab7b-1af534654f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-362b98e0-5821-4de0-a2b2-d74a8ea59749,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-38be30e5-ba9a-4b59-84aa-017205341cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-e7670ad2-2c2e-41e1-b006-544bcfa058c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962652249-172.17.0.16-1597138020428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-06e6ae15-10ef-4543-9a33-0d0b3314fcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-7fa694a2-e7ac-4100-b14e-218c004be1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-80ddfdd3-6a82-4b95-a904-0c6fbf7f9368,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-2ce8ea17-61c3-449e-ba65-09ad2d8e5c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-1953299f-9cae-4aa0-ab7b-1af534654f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-362b98e0-5821-4de0-a2b2-d74a8ea59749,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-38be30e5-ba9a-4b59-84aa-017205341cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-e7670ad2-2c2e-41e1-b006-544bcfa058c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845609471-172.17.0.16-1597138063400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36997,DS-49b852bc-21a5-45e3-ab00-3933e60a0799,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-75d5f7ac-7505-450e-ada0-7792e61889c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-33dd7323-67a3-4c93-8dec-036f7d5b4271,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-29cf6a5b-acbe-41a2-8f04-f9b1333bebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-2ff2874f-09ee-44ba-8959-2b929a783607,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-a38d0347-8082-408c-b2d6-61dad1e38099,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-fbfd9753-4c54-422a-80b5-673a4e1408bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-6c056579-4e79-4acd-9b19-ca3980534349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845609471-172.17.0.16-1597138063400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36997,DS-49b852bc-21a5-45e3-ab00-3933e60a0799,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-75d5f7ac-7505-450e-ada0-7792e61889c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-33dd7323-67a3-4c93-8dec-036f7d5b4271,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-29cf6a5b-acbe-41a2-8f04-f9b1333bebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-2ff2874f-09ee-44ba-8959-2b929a783607,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-a38d0347-8082-408c-b2d6-61dad1e38099,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-fbfd9753-4c54-422a-80b5-673a4e1408bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-6c056579-4e79-4acd-9b19-ca3980534349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274834269-172.17.0.16-1597138640104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37384,DS-c9581a5f-52e8-403a-a864-ba6b56185d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-e4287736-2e86-4af2-901a-65759e60358a,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-1658ee73-fcb8-4371-8cb2-b197c7e3f659,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-2646ae8c-6d25-4ea3-a846-dda1273dde75,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-f979adc9-5a20-4fdb-9490-c6f8caba0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-eef8ea11-0b24-4bf6-b4f8-2f7f94b5dc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-63f392e6-8543-40b5-b102-3e25bbdcd25f,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-21c0b349-2acf-4d35-b040-4e16494743d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274834269-172.17.0.16-1597138640104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37384,DS-c9581a5f-52e8-403a-a864-ba6b56185d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-e4287736-2e86-4af2-901a-65759e60358a,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-1658ee73-fcb8-4371-8cb2-b197c7e3f659,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-2646ae8c-6d25-4ea3-a846-dda1273dde75,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-f979adc9-5a20-4fdb-9490-c6f8caba0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-eef8ea11-0b24-4bf6-b4f8-2f7f94b5dc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-63f392e6-8543-40b5-b102-3e25bbdcd25f,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-21c0b349-2acf-4d35-b040-4e16494743d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897465382-172.17.0.16-1597139236722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34747,DS-2a89b2f8-b39e-4f45-8b79-e2ea1058590b,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-461854a8-8297-4df9-8aba-67e8de640694,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-9f6b2b8c-eb02-436e-898c-a7103b706879,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-2ae6d942-5d2e-4f78-a1da-064694af9606,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-d262964a-c376-4473-8464-e4eb39e7c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-c9a01f50-f4ee-49be-9c4b-ea69b65f7a44,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-f2a09275-50e3-42a4-9ad3-95d242870788,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-da5048ed-2555-4f1e-b1a5-5184d427bf1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897465382-172.17.0.16-1597139236722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34747,DS-2a89b2f8-b39e-4f45-8b79-e2ea1058590b,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-461854a8-8297-4df9-8aba-67e8de640694,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-9f6b2b8c-eb02-436e-898c-a7103b706879,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-2ae6d942-5d2e-4f78-a1da-064694af9606,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-d262964a-c376-4473-8464-e4eb39e7c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-c9a01f50-f4ee-49be-9c4b-ea69b65f7a44,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-f2a09275-50e3-42a4-9ad3-95d242870788,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-da5048ed-2555-4f1e-b1a5-5184d427bf1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730642721-172.17.0.16-1597140222012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-abb6c286-53d5-4f7f-be16-65cc15f5bf85,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-dfd71b85-3bd1-4ebe-b7be-287c2856418e,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-d53dec82-6c7e-40b3-8cb5-c557c73df7da,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-b23d53a5-89fd-4fc0-8843-e582803ffba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-e25de9de-f0fc-4656-a34d-599bc6fe1dce,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-385d48f0-b626-4ef2-9bc7-5528ca393ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-048777ea-5a28-4d68-9cb0-d2625a6bd817,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-1e66456f-9297-4eae-a0cf-9ae5e59aa77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730642721-172.17.0.16-1597140222012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-abb6c286-53d5-4f7f-be16-65cc15f5bf85,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-dfd71b85-3bd1-4ebe-b7be-287c2856418e,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-d53dec82-6c7e-40b3-8cb5-c557c73df7da,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-b23d53a5-89fd-4fc0-8843-e582803ffba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-e25de9de-f0fc-4656-a34d-599bc6fe1dce,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-385d48f0-b626-4ef2-9bc7-5528ca393ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-048777ea-5a28-4d68-9cb0-d2625a6bd817,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-1e66456f-9297-4eae-a0cf-9ae5e59aa77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424087339-172.17.0.16-1597141192604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-e594479a-e859-4d82-8fa8-3082af6188fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-e4a253a6-9cea-4571-819d-0e483ff3ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-057a73eb-0f17-43ba-a991-949dd5ae38dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-da3ea377-246b-4038-8ee8-5cfe67e28f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-797a9e22-dd94-4a93-a8e8-fb1b9b44df3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-42617ed2-387e-4600-a1ce-6b0cc89c88f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-66aced7a-ed11-4e01-97e0-1b80cee3c69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-7df166bc-55e8-41c7-a046-7ec3c01aac75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424087339-172.17.0.16-1597141192604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-e594479a-e859-4d82-8fa8-3082af6188fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-e4a253a6-9cea-4571-819d-0e483ff3ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-057a73eb-0f17-43ba-a991-949dd5ae38dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-da3ea377-246b-4038-8ee8-5cfe67e28f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-797a9e22-dd94-4a93-a8e8-fb1b9b44df3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-42617ed2-387e-4600-a1ce-6b0cc89c88f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-66aced7a-ed11-4e01-97e0-1b80cee3c69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-7df166bc-55e8-41c7-a046-7ec3c01aac75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914486729-172.17.0.16-1597141229061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38411,DS-d2b7d5fd-98b1-448c-b826-e91469e90cac,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-610f98e1-2bb1-4120-9375-73522ea414ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-bf9f2e64-9475-4fed-8485-1c09222a1372,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-33090990-b424-463a-bc72-679e6a4d4597,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-59a1c9b7-ed88-430b-8f39-681ce7631cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-47a267eb-3dde-44d0-979c-ae299bab14fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-be6a3179-ea21-4a49-993f-18a7c6b89506,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-d1ceb564-7ce1-42eb-bb60-8a80145c89b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914486729-172.17.0.16-1597141229061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38411,DS-d2b7d5fd-98b1-448c-b826-e91469e90cac,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-610f98e1-2bb1-4120-9375-73522ea414ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-bf9f2e64-9475-4fed-8485-1c09222a1372,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-33090990-b424-463a-bc72-679e6a4d4597,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-59a1c9b7-ed88-430b-8f39-681ce7631cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-47a267eb-3dde-44d0-979c-ae299bab14fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-be6a3179-ea21-4a49-993f-18a7c6b89506,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-d1ceb564-7ce1-42eb-bb60-8a80145c89b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359354316-172.17.0.16-1597141999975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-560d0f58-2459-4dc0-8f66-8f5640197e11,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-77c3eedb-8e9f-408c-a6db-2d7a211051aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-cc779d7e-46a7-47d6-abb6-8c78137fc394,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-2e2aa91d-4749-4bbf-8dcb-6bab1d1b5897,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-4f657c0a-23a3-460b-9aba-2b29b2e3bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-e25e2785-79b0-4381-939a-fd361f966b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-d62af162-a7e4-410a-b141-5e82133e02b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-df98e4e6-ac08-42b5-bdeb-908bdc25ee6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359354316-172.17.0.16-1597141999975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-560d0f58-2459-4dc0-8f66-8f5640197e11,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-77c3eedb-8e9f-408c-a6db-2d7a211051aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-cc779d7e-46a7-47d6-abb6-8c78137fc394,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-2e2aa91d-4749-4bbf-8dcb-6bab1d1b5897,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-4f657c0a-23a3-460b-9aba-2b29b2e3bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-e25e2785-79b0-4381-939a-fd361f966b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-d62af162-a7e4-410a-b141-5e82133e02b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-df98e4e6-ac08-42b5-bdeb-908bdc25ee6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119388884-172.17.0.16-1597142174194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36266,DS-30f359e2-5f35-403e-b7b1-96feca6544bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-590cfba2-a993-4b1a-883c-f57c0818a03d,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-7bb3619e-9e70-4494-b50e-c3f30d9f8857,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-37552fc4-82a9-4310-832c-cd86b93b4ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-dc656578-1412-4b8d-93c4-092a6f02afd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-abb52fba-74f1-43c4-83cb-c358480ed02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-14296092-2b4a-4016-ac9f-84639b8b6547,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-0f0fe720-64cf-4ced-8b2e-cf924810f200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119388884-172.17.0.16-1597142174194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36266,DS-30f359e2-5f35-403e-b7b1-96feca6544bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-590cfba2-a993-4b1a-883c-f57c0818a03d,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-7bb3619e-9e70-4494-b50e-c3f30d9f8857,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-37552fc4-82a9-4310-832c-cd86b93b4ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-dc656578-1412-4b8d-93c4-092a6f02afd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-abb52fba-74f1-43c4-83cb-c358480ed02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-14296092-2b4a-4016-ac9f-84639b8b6547,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-0f0fe720-64cf-4ced-8b2e-cf924810f200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907047369-172.17.0.16-1597142365082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33718,DS-31b1d0a4-1f95-4a7d-88de-5849445abf97,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-de6bec03-c1ae-460d-852a-3b52a81059ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-c5a902c4-b1f7-4895-a3b2-59f53de19664,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-96535eee-2ee9-4299-853c-93f22e644574,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-7d4e1dbf-bb68-4c4a-822b-53be1b9870d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-de7e4363-2a8e-4022-9d49-9576e9670f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-5311ed33-6d9e-4e2b-aaf1-6b75980a3f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-2300367b-26b6-4ba9-ac21-1ae463f9450f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907047369-172.17.0.16-1597142365082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33718,DS-31b1d0a4-1f95-4a7d-88de-5849445abf97,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-de6bec03-c1ae-460d-852a-3b52a81059ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-c5a902c4-b1f7-4895-a3b2-59f53de19664,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-96535eee-2ee9-4299-853c-93f22e644574,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-7d4e1dbf-bb68-4c4a-822b-53be1b9870d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-de7e4363-2a8e-4022-9d49-9576e9670f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-5311ed33-6d9e-4e2b-aaf1-6b75980a3f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-2300367b-26b6-4ba9-ac21-1ae463f9450f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6734
