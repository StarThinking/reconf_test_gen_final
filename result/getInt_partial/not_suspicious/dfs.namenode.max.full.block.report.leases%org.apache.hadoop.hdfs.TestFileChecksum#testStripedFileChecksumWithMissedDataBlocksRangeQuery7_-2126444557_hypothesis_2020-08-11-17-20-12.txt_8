reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736324279-172.17.0.3-1597166466578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42670,DS-ed58c5c0-791c-4a4a-a2bd-01f08a62a367,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-d5d636d4-3abe-465b-8113-89d9c768ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-0faa2174-2974-48fd-990d-361391c85af8,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-a1e8e402-89f0-4ebd-8fff-9517fa8facb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-fee3cffb-4fb6-436c-9541-077afd1a10bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-35916d94-887f-406f-b32c-8339b4481023,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-1d343c38-410e-4bef-9c99-69f1a9d1f345,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-06862878-0dcf-498a-b328-de10d2e47181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736324279-172.17.0.3-1597166466578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42670,DS-ed58c5c0-791c-4a4a-a2bd-01f08a62a367,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-d5d636d4-3abe-465b-8113-89d9c768ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-0faa2174-2974-48fd-990d-361391c85af8,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-a1e8e402-89f0-4ebd-8fff-9517fa8facb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-fee3cffb-4fb6-436c-9541-077afd1a10bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-35916d94-887f-406f-b32c-8339b4481023,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-1d343c38-410e-4bef-9c99-69f1a9d1f345,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-06862878-0dcf-498a-b328-de10d2e47181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356525198-172.17.0.3-1597166506702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-4e972ec9-eb77-433a-962f-0a1cb0f533f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-ce40603e-c9b7-4ac6-aa1f-6504f4d958f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-fd1cd0e7-6a47-4480-872c-7e334f9a99f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-156d7d30-808b-4ab6-990b-112fc46f82a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-9b8bdc81-240b-4abb-9d2c-82058949f63e,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-d3fb3bc4-e108-4e7d-9b1e-ad76d5093819,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-5dadbad4-e5df-45d7-9c42-f23f685e06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-117be710-0101-46ab-a47f-bdf43d60c524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356525198-172.17.0.3-1597166506702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-4e972ec9-eb77-433a-962f-0a1cb0f533f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-ce40603e-c9b7-4ac6-aa1f-6504f4d958f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-fd1cd0e7-6a47-4480-872c-7e334f9a99f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-156d7d30-808b-4ab6-990b-112fc46f82a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-9b8bdc81-240b-4abb-9d2c-82058949f63e,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-d3fb3bc4-e108-4e7d-9b1e-ad76d5093819,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-5dadbad4-e5df-45d7-9c42-f23f685e06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-117be710-0101-46ab-a47f-bdf43d60c524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323769997-172.17.0.3-1597166795543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39047,DS-8cb74f4a-166b-4f7f-b996-96d39fba657b,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-0fb0f851-bbff-483b-8927-6f4711fd2de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-6da5ddab-7d4a-47b9-a46d-1a3fd7ef1524,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-f990a22c-9c37-4532-af5e-97d673ef7622,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-49966dc3-2f12-4d50-810b-1e9fa30d2e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-ae893c50-186c-4eff-8ecf-7ec7b161c9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-e640fd40-931e-414f-b8de-7d143ad79bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-2f1387aa-1ae1-4985-9d38-3d83a2c18c4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323769997-172.17.0.3-1597166795543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39047,DS-8cb74f4a-166b-4f7f-b996-96d39fba657b,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-0fb0f851-bbff-483b-8927-6f4711fd2de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-6da5ddab-7d4a-47b9-a46d-1a3fd7ef1524,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-f990a22c-9c37-4532-af5e-97d673ef7622,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-49966dc3-2f12-4d50-810b-1e9fa30d2e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-ae893c50-186c-4eff-8ecf-7ec7b161c9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-e640fd40-931e-414f-b8de-7d143ad79bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-2f1387aa-1ae1-4985-9d38-3d83a2c18c4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108606812-172.17.0.3-1597167044015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36646,DS-f3e88608-ee88-4bea-8c9e-56d2818dc542,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-6f8498a0-942f-4c0b-9f07-2cfa4bd8a5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-8c03cdcf-c526-4aeb-bff5-d8141a7f0929,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-6c5e52a5-8914-476a-bac0-546cc7efbbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-f881754c-2009-4a98-95f0-b50a104c1add,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-4726c184-568f-4028-b10d-fd65a57c25f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-cc3a783e-94f7-462f-ad49-87f345729383,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-098686b8-4ca3-463f-99d3-6684046b469a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108606812-172.17.0.3-1597167044015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36646,DS-f3e88608-ee88-4bea-8c9e-56d2818dc542,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-6f8498a0-942f-4c0b-9f07-2cfa4bd8a5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-8c03cdcf-c526-4aeb-bff5-d8141a7f0929,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-6c5e52a5-8914-476a-bac0-546cc7efbbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-f881754c-2009-4a98-95f0-b50a104c1add,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-4726c184-568f-4028-b10d-fd65a57c25f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-cc3a783e-94f7-462f-ad49-87f345729383,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-098686b8-4ca3-463f-99d3-6684046b469a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556279251-172.17.0.3-1597167366058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42285,DS-28ecef64-f40f-4b8e-b0f9-eb9865e1e15c,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-dfc9324e-c08f-4930-98a7-f91dc35b2478,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-06138815-5e13-4d03-8f3b-df3193a4ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-8725b303-7abb-4274-adc3-d7b0ad3280f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-2f15ab7b-d0ce-430c-8259-a3718e28ee92,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-d2289d4c-bff8-4731-a30d-0a39c903c6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-0f10c459-e070-442a-8f98-923cf4fe21ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-1dc468ef-0ce0-4dd8-b23f-995c78b2e26d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556279251-172.17.0.3-1597167366058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42285,DS-28ecef64-f40f-4b8e-b0f9-eb9865e1e15c,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-dfc9324e-c08f-4930-98a7-f91dc35b2478,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-06138815-5e13-4d03-8f3b-df3193a4ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-8725b303-7abb-4274-adc3-d7b0ad3280f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-2f15ab7b-d0ce-430c-8259-a3718e28ee92,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-d2289d4c-bff8-4731-a30d-0a39c903c6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-0f10c459-e070-442a-8f98-923cf4fe21ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-1dc468ef-0ce0-4dd8-b23f-995c78b2e26d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791754023-172.17.0.3-1597167550353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36848,DS-4a76b43a-b418-4ffe-bd18-dcc0493d7691,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-1cf95e49-9572-4697-b73d-9f5dba099a51,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-d57d7556-f06b-4360-b33b-650320015b07,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-10f03f14-3e0b-486e-a54a-651b8fb89d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-69037a03-95d4-47b4-bb58-4e5c2412ead4,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-a43de9e6-73c5-4fdd-9f13-5af2d13a3578,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-502df377-dcfb-4542-9d0c-727ec1d65968,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-532b803a-0c48-478b-a8c0-8ce424544eba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791754023-172.17.0.3-1597167550353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36848,DS-4a76b43a-b418-4ffe-bd18-dcc0493d7691,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-1cf95e49-9572-4697-b73d-9f5dba099a51,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-d57d7556-f06b-4360-b33b-650320015b07,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-10f03f14-3e0b-486e-a54a-651b8fb89d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-69037a03-95d4-47b4-bb58-4e5c2412ead4,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-a43de9e6-73c5-4fdd-9f13-5af2d13a3578,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-502df377-dcfb-4542-9d0c-727ec1d65968,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-532b803a-0c48-478b-a8c0-8ce424544eba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702430755-172.17.0.3-1597167820899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-2b96901e-757a-45bd-a9e8-2cc621082aac,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-e85791b2-0c8b-41f6-abe9-27d9e0b594ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-b11cff73-991b-48e7-b18b-be2c8e0c7296,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-254e0a28-6207-4245-842b-a3a60d39c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-0acd4e4b-964d-4308-9983-81a0eb748199,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-7e4d716e-dbd8-4759-92f1-b471581f3b48,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-cd815cd9-3f4b-4801-9b27-514f52481e10,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-ccb03b17-f4e4-444c-b4c0-aa0089759051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702430755-172.17.0.3-1597167820899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-2b96901e-757a-45bd-a9e8-2cc621082aac,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-e85791b2-0c8b-41f6-abe9-27d9e0b594ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-b11cff73-991b-48e7-b18b-be2c8e0c7296,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-254e0a28-6207-4245-842b-a3a60d39c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-0acd4e4b-964d-4308-9983-81a0eb748199,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-7e4d716e-dbd8-4759-92f1-b471581f3b48,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-cd815cd9-3f4b-4801-9b27-514f52481e10,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-ccb03b17-f4e4-444c-b4c0-aa0089759051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023921732-172.17.0.3-1597167927368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37954,DS-d959cddc-567b-4171-85ce-102fb5b21589,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-8feaeef4-fcbb-4f5e-98a0-f8c1ec42fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-b8fda5e8-338e-4b6f-a5aa-1b6f1595cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ebeeeffc-9349-4e79-85b7-35a3e1db87f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-21317a80-94cc-4e9f-a813-eb09685b6db8,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-00993a70-56e1-4e2c-87e6-36d10527a620,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-1652fea9-4618-4c2f-b20f-2ffcc1cc49be,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-456cd593-77fd-496b-b5ea-84c275070808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023921732-172.17.0.3-1597167927368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37954,DS-d959cddc-567b-4171-85ce-102fb5b21589,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-8feaeef4-fcbb-4f5e-98a0-f8c1ec42fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-b8fda5e8-338e-4b6f-a5aa-1b6f1595cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ebeeeffc-9349-4e79-85b7-35a3e1db87f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-21317a80-94cc-4e9f-a813-eb09685b6db8,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-00993a70-56e1-4e2c-87e6-36d10527a620,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-1652fea9-4618-4c2f-b20f-2ffcc1cc49be,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-456cd593-77fd-496b-b5ea-84c275070808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280464134-172.17.0.3-1597168025747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41556,DS-791bd910-7566-4e09-978a-efe6fbc9dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-b3c464e3-3045-47b6-bd42-75dae0dd7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-030ba8fd-dfa6-4bc3-8994-2f8fdf684c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-17b8d6be-adf2-4686-9a18-0a1572c17e09,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-c674ac41-35ff-469d-ae61-3ef761ca5907,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-ba911628-7a0c-4789-8666-b16ac2ae9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-43dba814-29d7-4ea6-9854-115fa96d61ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-d4443bbb-5ef6-4b12-8281-0498037ce12f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280464134-172.17.0.3-1597168025747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41556,DS-791bd910-7566-4e09-978a-efe6fbc9dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-b3c464e3-3045-47b6-bd42-75dae0dd7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-030ba8fd-dfa6-4bc3-8994-2f8fdf684c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-17b8d6be-adf2-4686-9a18-0a1572c17e09,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-c674ac41-35ff-469d-ae61-3ef761ca5907,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-ba911628-7a0c-4789-8666-b16ac2ae9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-43dba814-29d7-4ea6-9854-115fa96d61ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-d4443bbb-5ef6-4b12-8281-0498037ce12f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607450247-172.17.0.3-1597168129703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44581,DS-8f8cd54c-0780-43c0-91c0-471b875c8412,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-cf6b8a39-ff28-4281-a26c-e00ee53f03eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-4a6f4b66-0565-403c-ab94-2f481a30badb,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-fd2d6915-69e1-433d-a94d-2726fe9b9ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-91274f2c-55dc-48d2-8184-6fa018bb042e,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-59e338ce-7cb7-408c-b868-f060ed77ac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-8b989629-445b-4229-b5dd-b961ef58e62f,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-54288e1a-7b92-4b70-8045-dbb739f68010,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607450247-172.17.0.3-1597168129703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44581,DS-8f8cd54c-0780-43c0-91c0-471b875c8412,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-cf6b8a39-ff28-4281-a26c-e00ee53f03eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-4a6f4b66-0565-403c-ab94-2f481a30badb,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-fd2d6915-69e1-433d-a94d-2726fe9b9ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-91274f2c-55dc-48d2-8184-6fa018bb042e,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-59e338ce-7cb7-408c-b868-f060ed77ac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-8b989629-445b-4229-b5dd-b961ef58e62f,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-54288e1a-7b92-4b70-8045-dbb739f68010,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205449337-172.17.0.3-1597168382484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-67b2f76d-5967-4b3a-8bb0-5528d80508b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-b926f7ce-9149-4e2c-b8bc-6b77d2178154,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-4a2e6156-054a-468d-a05e-9363c17242d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-5a4ef4a7-cb29-4e0a-b896-32449cc6a778,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-5fd77af4-ad26-40b4-ab4a-fc6c7f3ffbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-c5be59db-ae75-4112-a7a7-297fa8383018,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-c0502325-25ec-42fe-b87b-6cf74a0a4eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-c29d931c-ace5-449a-b00d-f0127ca28ed4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205449337-172.17.0.3-1597168382484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-67b2f76d-5967-4b3a-8bb0-5528d80508b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-b926f7ce-9149-4e2c-b8bc-6b77d2178154,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-4a2e6156-054a-468d-a05e-9363c17242d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-5a4ef4a7-cb29-4e0a-b896-32449cc6a778,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-5fd77af4-ad26-40b4-ab4a-fc6c7f3ffbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-c5be59db-ae75-4112-a7a7-297fa8383018,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-c0502325-25ec-42fe-b87b-6cf74a0a4eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-c29d931c-ace5-449a-b00d-f0127ca28ed4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211623341-172.17.0.3-1597168489546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34173,DS-3ec1479e-fbba-4405-bed2-951ba5a6b6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-2d806768-d33f-4fac-8d1f-e82e15ce9bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-0f0b0860-09b0-440a-88e3-e9e9f3460a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-2080bb62-2077-40ce-92e2-b7562ac64882,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-ef57b401-a582-4d09-89c1-e555388c1bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-f4a70b92-c9f8-4386-b025-deacae2bc623,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-0cf15ed7-d63a-40fb-bf75-0ca084c6cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-6d5f793a-0483-4c9f-9d70-7763bcfdf187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211623341-172.17.0.3-1597168489546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34173,DS-3ec1479e-fbba-4405-bed2-951ba5a6b6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-2d806768-d33f-4fac-8d1f-e82e15ce9bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-0f0b0860-09b0-440a-88e3-e9e9f3460a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-2080bb62-2077-40ce-92e2-b7562ac64882,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-ef57b401-a582-4d09-89c1-e555388c1bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-f4a70b92-c9f8-4386-b025-deacae2bc623,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-0cf15ed7-d63a-40fb-bf75-0ca084c6cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-6d5f793a-0483-4c9f-9d70-7763bcfdf187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781191770-172.17.0.3-1597168553682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40072,DS-c66a7619-d6f3-445b-8aaf-15ae3f34461f,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-b24ed30c-77a6-4958-b686-d2416dc2c900,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-8a951ace-e6f8-4bd6-a3be-dc535999a1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-ce7f54b4-20dd-4be3-9a85-780cd2825151,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-c88d3046-1b23-4a12-bb63-1dd94efd683a,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-c7a101dc-abbb-4b5c-a1a2-c9f62820e6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-ffde1a15-2e5a-4cc1-9f15-a88418a427de,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-db096f51-4e7b-48f6-b832-2f4d82d1afda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781191770-172.17.0.3-1597168553682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40072,DS-c66a7619-d6f3-445b-8aaf-15ae3f34461f,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-b24ed30c-77a6-4958-b686-d2416dc2c900,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-8a951ace-e6f8-4bd6-a3be-dc535999a1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-ce7f54b4-20dd-4be3-9a85-780cd2825151,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-c88d3046-1b23-4a12-bb63-1dd94efd683a,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-c7a101dc-abbb-4b5c-a1a2-c9f62820e6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-ffde1a15-2e5a-4cc1-9f15-a88418a427de,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-db096f51-4e7b-48f6-b832-2f4d82d1afda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669281682-172.17.0.3-1597168717986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-dcdc3414-acb7-466a-9958-218f79d828da,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-881eb8ff-343f-45f1-8ecc-b2922d116e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-2f12157b-2678-42bb-a885-091cf33be167,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-5761c9a2-33b8-478c-a2de-d066741299f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-ebb8c41e-9ba4-4f5e-988e-37f65a046934,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-bdd43593-2011-4df8-bac7-f7508e1e2f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-63b94c34-0f4c-4d9b-a0c2-066cf0bdcefc,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-dc97fc89-4d22-4d90-a34c-a7192752cf08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669281682-172.17.0.3-1597168717986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-dcdc3414-acb7-466a-9958-218f79d828da,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-881eb8ff-343f-45f1-8ecc-b2922d116e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-2f12157b-2678-42bb-a885-091cf33be167,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-5761c9a2-33b8-478c-a2de-d066741299f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-ebb8c41e-9ba4-4f5e-988e-37f65a046934,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-bdd43593-2011-4df8-bac7-f7508e1e2f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-63b94c34-0f4c-4d9b-a0c2-066cf0bdcefc,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-dc97fc89-4d22-4d90-a34c-a7192752cf08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451536858-172.17.0.3-1597168749793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-bae81afb-d6d7-48a4-80f8-cc3755089e75,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-98025ccb-a4c2-4b14-ada9-175b0b4b45f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-2c6650fd-f260-4a0d-9341-f430a4e4333e,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-4c193e40-3c9b-48e1-aad2-c7022bfd5d02,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-e5471147-0575-45b1-904a-3ea49ab88740,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-361a6f66-21ad-4f30-a203-b2ca7e4925ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-91377cbf-6a6f-4790-8f53-fc7e9bfd3293,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-79da6944-f801-4e33-a6f4-88b4ae2fa0c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451536858-172.17.0.3-1597168749793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-bae81afb-d6d7-48a4-80f8-cc3755089e75,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-98025ccb-a4c2-4b14-ada9-175b0b4b45f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-2c6650fd-f260-4a0d-9341-f430a4e4333e,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-4c193e40-3c9b-48e1-aad2-c7022bfd5d02,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-e5471147-0575-45b1-904a-3ea49ab88740,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-361a6f66-21ad-4f30-a203-b2ca7e4925ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-91377cbf-6a6f-4790-8f53-fc7e9bfd3293,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-79da6944-f801-4e33-a6f4-88b4ae2fa0c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875899985-172.17.0.3-1597168850768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40663,DS-887f6659-6c62-4dff-8252-a4fa6af4e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-0d124599-22b4-469f-98a5-42d0a1b1236a,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-3b2b9562-3c5d-4650-b9a2-c94f7f2647d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-335418e8-ca30-4b3b-ac1b-d4a04c7e6807,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-e807f546-6dd6-4e5e-b160-623da5ab8ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-1d830985-8730-4aff-a85e-1e0a448081c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-44fd7965-bc62-4652-bb29-3d9e04871959,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-dcc6e2e5-c038-48e4-a506-da60a2ca65b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875899985-172.17.0.3-1597168850768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40663,DS-887f6659-6c62-4dff-8252-a4fa6af4e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-0d124599-22b4-469f-98a5-42d0a1b1236a,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-3b2b9562-3c5d-4650-b9a2-c94f7f2647d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-335418e8-ca30-4b3b-ac1b-d4a04c7e6807,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-e807f546-6dd6-4e5e-b160-623da5ab8ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-1d830985-8730-4aff-a85e-1e0a448081c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-44fd7965-bc62-4652-bb29-3d9e04871959,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-dcc6e2e5-c038-48e4-a506-da60a2ca65b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30232211-172.17.0.3-1597168948228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-5cbd48b2-ba5c-4c8e-a4dd-af304e4f84e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-dd7a8ae6-0177-4209-a432-a98ed7d0dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-136563d2-620b-42d5-bd8d-0fb4549ae4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-e92713b1-afaa-46a9-8911-3b75945736ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-c41f574b-2f76-441b-9cd1-74133222da5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-e6aa91aa-5361-4057-89fc-49c7ee834c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-5190dbef-ee5d-41e0-b0ec-8f5fdfbe1310,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-812f8886-d88f-416d-80b0-7d0e2801bf7f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30232211-172.17.0.3-1597168948228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-5cbd48b2-ba5c-4c8e-a4dd-af304e4f84e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-dd7a8ae6-0177-4209-a432-a98ed7d0dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-136563d2-620b-42d5-bd8d-0fb4549ae4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-e92713b1-afaa-46a9-8911-3b75945736ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-c41f574b-2f76-441b-9cd1-74133222da5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-e6aa91aa-5361-4057-89fc-49c7ee834c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-5190dbef-ee5d-41e0-b0ec-8f5fdfbe1310,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-812f8886-d88f-416d-80b0-7d0e2801bf7f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720014208-172.17.0.3-1597169106222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-afc93eb5-f075-4437-936a-061cecd6d673,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-4408c2cc-a34b-4025-ad1b-aa04a947409a,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-aa98f493-0d00-4b05-b17a-63d58e090a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-0d95e85f-0d8f-4d13-981a-5743c809b8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-d81283a8-5fac-4e74-a8e1-f023e16d6cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-62f88c93-c3e4-4e12-889a-712ba83b85dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-e9f61106-45db-4168-8d1c-9b1c825c87bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-d59aa2c5-4680-4ab5-978e-1b7841de98d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720014208-172.17.0.3-1597169106222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-afc93eb5-f075-4437-936a-061cecd6d673,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-4408c2cc-a34b-4025-ad1b-aa04a947409a,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-aa98f493-0d00-4b05-b17a-63d58e090a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-0d95e85f-0d8f-4d13-981a-5743c809b8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-d81283a8-5fac-4e74-a8e1-f023e16d6cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-62f88c93-c3e4-4e12-889a-712ba83b85dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-e9f61106-45db-4168-8d1c-9b1c825c87bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-d59aa2c5-4680-4ab5-978e-1b7841de98d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410585799-172.17.0.3-1597169172333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-6da81f83-082c-427d-ae24-58fb125b548c,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-5bdc23d3-11df-4810-a29f-169fe119c7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-6068fcf0-7e41-4446-89d2-f55ec06bfec5,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-ba698b94-71c3-4fed-8387-2e50fa723e47,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-21bcae72-6a96-4e7a-b1f8-fbc5ee1d1c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-32f8863a-7f74-456d-a9a0-65659cd5e801,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-22eff581-ae09-4597-bbab-3c1cd437c39b,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-27873dae-5339-47cb-bbd6-86409d88a3c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410585799-172.17.0.3-1597169172333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-6da81f83-082c-427d-ae24-58fb125b548c,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-5bdc23d3-11df-4810-a29f-169fe119c7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-6068fcf0-7e41-4446-89d2-f55ec06bfec5,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-ba698b94-71c3-4fed-8387-2e50fa723e47,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-21bcae72-6a96-4e7a-b1f8-fbc5ee1d1c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-32f8863a-7f74-456d-a9a0-65659cd5e801,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-22eff581-ae09-4597-bbab-3c1cd437c39b,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-27873dae-5339-47cb-bbd6-86409d88a3c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011475439-172.17.0.3-1597169255310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-b95b5a7f-500d-4935-8814-5e12fb450615,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-aacb00dc-5807-4d41-a2e0-d27b5d9dcbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-be62755e-778f-4ce3-bf0a-e8384f9d9133,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-4fd590c3-6997-4a11-947b-eeb14153dd31,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-d9125734-5548-4a52-aaac-d9a061dd2512,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-a3596e58-f838-4b51-b43f-d8a82b8fc583,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-405c35e5-0d37-4524-9d68-3c10a2fde8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-3edec190-2fc3-4622-9fee-65725fe550b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011475439-172.17.0.3-1597169255310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-b95b5a7f-500d-4935-8814-5e12fb450615,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-aacb00dc-5807-4d41-a2e0-d27b5d9dcbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-be62755e-778f-4ce3-bf0a-e8384f9d9133,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-4fd590c3-6997-4a11-947b-eeb14153dd31,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-d9125734-5548-4a52-aaac-d9a061dd2512,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-a3596e58-f838-4b51-b43f-d8a82b8fc583,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-405c35e5-0d37-4524-9d68-3c10a2fde8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-3edec190-2fc3-4622-9fee-65725fe550b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350647348-172.17.0.3-1597169291515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-c5691790-b6d6-4066-b92e-28a08f6ffe40,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-b04997c2-5e35-4437-aae6-694b79826085,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-2b0b8a02-e396-47b5-bf74-87d766c01553,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-fbfe31d4-d7e1-4265-b40b-53c2d17158de,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-d92766fe-8f7f-4961-8238-7e949a844ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-919a70e1-ded0-4ce8-97fa-8762558bf8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-7c8d3319-c87f-4837-99b0-bd3041ce0a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-8aa2e4ec-e5fa-4752-ac84-196bd602032e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350647348-172.17.0.3-1597169291515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-c5691790-b6d6-4066-b92e-28a08f6ffe40,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-b04997c2-5e35-4437-aae6-694b79826085,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-2b0b8a02-e396-47b5-bf74-87d766c01553,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-fbfe31d4-d7e1-4265-b40b-53c2d17158de,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-d92766fe-8f7f-4961-8238-7e949a844ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-919a70e1-ded0-4ce8-97fa-8762558bf8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-7c8d3319-c87f-4837-99b0-bd3041ce0a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-8aa2e4ec-e5fa-4752-ac84-196bd602032e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95703124-172.17.0.3-1597169328783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42204,DS-649450d4-2dcb-4508-a629-1af84b62bd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-2f3dd6fc-2861-48ef-bc0e-6f0b8e3661a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-ebca01b6-dd92-4888-b1a2-cba0e0fed354,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-5b0a1cc6-4eef-4322-be7d-d195a955e167,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-b5edb2bb-ea65-41ea-947c-3ad6b636c247,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-cd9e0b43-c2d3-4343-93e2-019d8c3d624e,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-d64bb56e-07f8-4d13-b81f-1c35afe9aa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-1c054876-6e45-42b5-b2a0-00a4555f4b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95703124-172.17.0.3-1597169328783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42204,DS-649450d4-2dcb-4508-a629-1af84b62bd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-2f3dd6fc-2861-48ef-bc0e-6f0b8e3661a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-ebca01b6-dd92-4888-b1a2-cba0e0fed354,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-5b0a1cc6-4eef-4322-be7d-d195a955e167,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-b5edb2bb-ea65-41ea-947c-3ad6b636c247,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-cd9e0b43-c2d3-4343-93e2-019d8c3d624e,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-d64bb56e-07f8-4d13-b81f-1c35afe9aa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-1c054876-6e45-42b5-b2a0-00a4555f4b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130400325-172.17.0.3-1597169450336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-6522cab9-c087-4ce6-bbb9-0e09f9db4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-eb1bcb4b-9f2d-4055-baa2-fd3a7ab87211,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-2c830966-9e0d-4faa-a269-379d2b271ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-1e7665e8-6924-4698-8715-92be47218119,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-8ef036ee-e981-4882-99e2-a889f528d837,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-fd6970db-92d9-4a78-bce3-4214946eed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-ce6a598e-0163-4bd8-9380-d7cc9f51d262,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-82dfb2b9-0f8c-4583-8728-8e3b89c3ffb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130400325-172.17.0.3-1597169450336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-6522cab9-c087-4ce6-bbb9-0e09f9db4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-eb1bcb4b-9f2d-4055-baa2-fd3a7ab87211,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-2c830966-9e0d-4faa-a269-379d2b271ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-1e7665e8-6924-4698-8715-92be47218119,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-8ef036ee-e981-4882-99e2-a889f528d837,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-fd6970db-92d9-4a78-bce3-4214946eed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-ce6a598e-0163-4bd8-9380-d7cc9f51d262,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-82dfb2b9-0f8c-4583-8728-8e3b89c3ffb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951177719-172.17.0.3-1597169877495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-a25dc702-df0d-468c-bf1a-e12490306c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-019e2193-15bc-42c5-9931-1784ce857c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-8af5d6cc-3d1e-4227-9509-93a6f6a95a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-871efbaf-adf6-48d4-84fc-47fe6b394680,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-411885a1-1b93-4dc3-aa2c-6a9f70b4a6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-de1df43b-799a-4e69-9bc7-2bc5d95a8924,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-08309c52-3056-4f6b-848a-a1eb4c85c68a,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-a434cf9a-11e8-4389-8710-a447625a04aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951177719-172.17.0.3-1597169877495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-a25dc702-df0d-468c-bf1a-e12490306c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-019e2193-15bc-42c5-9931-1784ce857c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-8af5d6cc-3d1e-4227-9509-93a6f6a95a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-871efbaf-adf6-48d4-84fc-47fe6b394680,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-411885a1-1b93-4dc3-aa2c-6a9f70b4a6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-de1df43b-799a-4e69-9bc7-2bc5d95a8924,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-08309c52-3056-4f6b-848a-a1eb4c85c68a,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-a434cf9a-11e8-4389-8710-a447625a04aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602090603-172.17.0.3-1597170173005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37710,DS-eaa3bf40-7a38-4aa3-b909-7ff2abb0c1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-19a1cef1-cc46-4fa3-b064-dd99f286b482,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-9dda29cb-27b0-452e-a3ec-36c357b2995e,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-8cecbe75-9ad5-4cbb-b7a2-0a8325947865,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-250ad6f3-5182-4a77-809e-217dcc9a36d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-471dd33e-8837-417e-9e95-561b62431674,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-62eda6af-cb1c-4547-86fd-42d73c9507b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-07915965-0fb9-4b77-92e1-f092739b2d40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602090603-172.17.0.3-1597170173005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37710,DS-eaa3bf40-7a38-4aa3-b909-7ff2abb0c1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-19a1cef1-cc46-4fa3-b064-dd99f286b482,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-9dda29cb-27b0-452e-a3ec-36c357b2995e,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-8cecbe75-9ad5-4cbb-b7a2-0a8325947865,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-250ad6f3-5182-4a77-809e-217dcc9a36d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-471dd33e-8837-417e-9e95-561b62431674,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-62eda6af-cb1c-4547-86fd-42d73c9507b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-07915965-0fb9-4b77-92e1-f092739b2d40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078813658-172.17.0.3-1597170392650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-96568ee3-e126-45b3-8d0a-dc30e2f32588,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-1f39bc8d-9f2a-4c08-b643-6a8cf449f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-d0b963c4-a05a-44d5-a52d-106eb8f8762d,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-ee96e872-b88e-435a-a2e3-7cbaeba673dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-37993f2d-1857-4eab-8c09-b85b639c3abd,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-ecc3a04a-3db6-43c2-bcba-87196209acc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-d9096bcf-a62e-4aa1-a2a0-bcc3e1c9b489,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-0f81ac36-2a63-4935-a7f4-0249e5657ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078813658-172.17.0.3-1597170392650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-96568ee3-e126-45b3-8d0a-dc30e2f32588,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-1f39bc8d-9f2a-4c08-b643-6a8cf449f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-d0b963c4-a05a-44d5-a52d-106eb8f8762d,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-ee96e872-b88e-435a-a2e3-7cbaeba673dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-37993f2d-1857-4eab-8c09-b85b639c3abd,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-ecc3a04a-3db6-43c2-bcba-87196209acc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-d9096bcf-a62e-4aa1-a2a0-bcc3e1c9b489,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-0f81ac36-2a63-4935-a7f4-0249e5657ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643663292-172.17.0.3-1597170438406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36766,DS-92007bfb-914b-4122-98f3-9e5d1fdc5eef,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-ccbb5ddd-223a-4d8f-af35-9b6e206ecebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-9d597ba1-88f2-4a10-91aa-17229e0d7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-bf1ecef9-65be-4874-b748-c340fca0af9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-a54a2f31-625c-48ea-98fb-42abaea9856d,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-2cd6375f-8084-41f5-a546-c12fecbc598e,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-66dabb5f-ac87-4a07-91fb-717d0c0250a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-36f933c8-25d0-4c76-99d8-43d21923caf1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643663292-172.17.0.3-1597170438406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36766,DS-92007bfb-914b-4122-98f3-9e5d1fdc5eef,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-ccbb5ddd-223a-4d8f-af35-9b6e206ecebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-9d597ba1-88f2-4a10-91aa-17229e0d7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-bf1ecef9-65be-4874-b748-c340fca0af9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-a54a2f31-625c-48ea-98fb-42abaea9856d,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-2cd6375f-8084-41f5-a546-c12fecbc598e,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-66dabb5f-ac87-4a07-91fb-717d0c0250a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-36f933c8-25d0-4c76-99d8-43d21923caf1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302655474-172.17.0.3-1597170654834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-8d2e0298-773b-4573-9a58-3b276a057077,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-0ae94b8d-ea0d-41f5-bdf7-a82b9be65e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-cc5c273b-25b4-4b16-9ba0-a5f6e4fcc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-56302a22-e5b5-4e65-9049-ae7affa4c3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-57e079f7-6c97-4127-8766-ba37d8654566,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-74542d4a-f4f6-48fa-b6a5-0e241c22e9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-0c754d4b-731b-4c9d-9be7-e0f7da188dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-ad74897d-7ebd-408a-b80a-4dbd50e846bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302655474-172.17.0.3-1597170654834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-8d2e0298-773b-4573-9a58-3b276a057077,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-0ae94b8d-ea0d-41f5-bdf7-a82b9be65e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-cc5c273b-25b4-4b16-9ba0-a5f6e4fcc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-56302a22-e5b5-4e65-9049-ae7affa4c3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-57e079f7-6c97-4127-8766-ba37d8654566,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-74542d4a-f4f6-48fa-b6a5-0e241c22e9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-0c754d4b-731b-4c9d-9be7-e0f7da188dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-ad74897d-7ebd-408a-b80a-4dbd50e846bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400903859-172.17.0.3-1597170685861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-259839b4-8d51-4540-bd4c-2c33451c89cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-b54df372-0ecf-4af6-a6b3-47555bf81187,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-77d9da67-d5f1-49f3-990b-4039f1e8e6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-1a5e1a7d-e155-45c3-b088-410fd3420ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-dbdfbb93-378d-4b41-937d-3ce7b710e7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-79a9d28f-c537-48b5-b268-da25c2b47bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-2c511710-e3ee-4826-907b-65ee80d5722d,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c24fd1c8-84a0-42e6-93ac-cba0878dd643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400903859-172.17.0.3-1597170685861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-259839b4-8d51-4540-bd4c-2c33451c89cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-b54df372-0ecf-4af6-a6b3-47555bf81187,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-77d9da67-d5f1-49f3-990b-4039f1e8e6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-1a5e1a7d-e155-45c3-b088-410fd3420ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-dbdfbb93-378d-4b41-937d-3ce7b710e7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-79a9d28f-c537-48b5-b268-da25c2b47bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-2c511710-e3ee-4826-907b-65ee80d5722d,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c24fd1c8-84a0-42e6-93ac-cba0878dd643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773631173-172.17.0.3-1597170720085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-81f1f272-dd5c-49c6-81fb-d1a07a5dd4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-4965e7be-7011-4712-91ee-c92da009e701,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-cc281805-6ec3-41a6-83c7-4da06cb2b998,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-70cdc5dd-c0a4-41e8-8ee4-d45c98530019,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-f0187274-842d-484f-b835-66180f8d4f95,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-2a3d1e53-5672-40e5-8ecb-c32d2a8b7a97,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-0a511918-a4ce-48d1-8199-d69116fced10,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-5c5891ca-6dec-4909-a42e-f5b5ac4227d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773631173-172.17.0.3-1597170720085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-81f1f272-dd5c-49c6-81fb-d1a07a5dd4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-4965e7be-7011-4712-91ee-c92da009e701,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-cc281805-6ec3-41a6-83c7-4da06cb2b998,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-70cdc5dd-c0a4-41e8-8ee4-d45c98530019,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-f0187274-842d-484f-b835-66180f8d4f95,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-2a3d1e53-5672-40e5-8ecb-c32d2a8b7a97,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-0a511918-a4ce-48d1-8199-d69116fced10,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-5c5891ca-6dec-4909-a42e-f5b5ac4227d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106623692-172.17.0.3-1597170794363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42721,DS-c49cdf9b-9686-45a6-92c1-9a272c783ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-cc548a67-56ff-4159-b4a4-c7eaa11d0369,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-a3f54897-bf79-4ff6-a599-c4f60d14c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-524228e9-a38b-4cec-a857-652fc6a53cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-70cf0d8d-4f29-47b0-8d7a-b601be49fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-3f305a2d-b91a-479c-897d-b73218b7f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-288a78f4-a631-4428-9a4c-554bd0d07762,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-7c28cb3e-97aa-4a9c-aa5d-3fedc8b3519f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106623692-172.17.0.3-1597170794363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42721,DS-c49cdf9b-9686-45a6-92c1-9a272c783ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-cc548a67-56ff-4159-b4a4-c7eaa11d0369,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-a3f54897-bf79-4ff6-a599-c4f60d14c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-524228e9-a38b-4cec-a857-652fc6a53cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-70cf0d8d-4f29-47b0-8d7a-b601be49fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-3f305a2d-b91a-479c-897d-b73218b7f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-288a78f4-a631-4428-9a4c-554bd0d07762,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-7c28cb3e-97aa-4a9c-aa5d-3fedc8b3519f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574800703-172.17.0.3-1597170865105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44956,DS-faed7564-9a8c-49cd-89f2-993905c4a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-b9572324-e7a0-4ead-927d-fc35b7fbdbef,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-b4a1b136-e037-4d35-90d1-25885e29de0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-8513d7a3-7a76-435f-8219-448b51868be7,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-1e494293-589f-4cdc-b241-d5fadd1b60d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-cdb438e3-6da9-44a4-818e-26759f6ac276,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-b0a96cbf-db87-4c9f-bc33-0fcf25d593fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-c8cf912c-515a-406f-8717-e1abcdf9ae3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574800703-172.17.0.3-1597170865105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44956,DS-faed7564-9a8c-49cd-89f2-993905c4a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-b9572324-e7a0-4ead-927d-fc35b7fbdbef,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-b4a1b136-e037-4d35-90d1-25885e29de0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-8513d7a3-7a76-435f-8219-448b51868be7,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-1e494293-589f-4cdc-b241-d5fadd1b60d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-cdb438e3-6da9-44a4-818e-26759f6ac276,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-b0a96cbf-db87-4c9f-bc33-0fcf25d593fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-c8cf912c-515a-406f-8717-e1abcdf9ae3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732795005-172.17.0.3-1597170901003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33881,DS-3d7bc712-d96f-4916-b981-f78de1cfe56a,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-5413a478-53a3-4fed-b865-a59058f12587,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-12e55724-436f-4e27-bdce-527eb764be66,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-71fc4eea-d402-4c83-9ed4-7c46415ce9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-46d9ab46-ce4f-44ef-8e65-9295b2f4a955,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-6b830df0-387a-4684-854c-fd3171c753fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-521d1884-271d-47ac-b1e1-f509a756ce60,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-9e09cd20-0c3b-448f-aa2d-9317c518eaec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732795005-172.17.0.3-1597170901003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33881,DS-3d7bc712-d96f-4916-b981-f78de1cfe56a,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-5413a478-53a3-4fed-b865-a59058f12587,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-12e55724-436f-4e27-bdce-527eb764be66,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-71fc4eea-d402-4c83-9ed4-7c46415ce9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-46d9ab46-ce4f-44ef-8e65-9295b2f4a955,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-6b830df0-387a-4684-854c-fd3171c753fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-521d1884-271d-47ac-b1e1-f509a756ce60,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-9e09cd20-0c3b-448f-aa2d-9317c518eaec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464742639-172.17.0.3-1597171041026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43269,DS-f684f48e-e286-4141-89dd-38f7a892ef12,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-384131d0-e0db-4625-a45b-d4412c1f4c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-eddcc4fa-d450-4ce1-b0ab-cd680223b7da,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-e2560a80-de74-4b0c-9d0f-ad064d3294a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-3de00c5c-d373-4d10-a792-612cecb5f08e,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-0279e6ba-e1f2-482b-8789-4f8d6b12a51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-e4e3c7a9-398a-4eff-865b-89eef7890795,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-083ac58f-b151-43c4-8cfe-dad43641f0d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464742639-172.17.0.3-1597171041026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43269,DS-f684f48e-e286-4141-89dd-38f7a892ef12,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-384131d0-e0db-4625-a45b-d4412c1f4c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-eddcc4fa-d450-4ce1-b0ab-cd680223b7da,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-e2560a80-de74-4b0c-9d0f-ad064d3294a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-3de00c5c-d373-4d10-a792-612cecb5f08e,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-0279e6ba-e1f2-482b-8789-4f8d6b12a51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-e4e3c7a9-398a-4eff-865b-89eef7890795,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-083ac58f-b151-43c4-8cfe-dad43641f0d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325935421-172.17.0.3-1597171200997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34752,DS-093e66d9-a0d2-4829-8458-5248a1fed635,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-fbf0c983-52ae-49ce-b87c-772fbefecb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-7205900f-e001-4a9a-af20-d8a6781e8877,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-9a092533-5215-4d85-b0a6-e577a4206bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-99fe1a72-936e-414d-964d-fc7f07834c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-3490bb17-3173-4cfa-a170-ef36a18ca90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-925a4f4a-c3f7-4ae4-b366-b2a0013a87f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-e2b3d2e6-86ea-4ee1-80aa-528269d1ae72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325935421-172.17.0.3-1597171200997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34752,DS-093e66d9-a0d2-4829-8458-5248a1fed635,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-fbf0c983-52ae-49ce-b87c-772fbefecb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-7205900f-e001-4a9a-af20-d8a6781e8877,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-9a092533-5215-4d85-b0a6-e577a4206bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-99fe1a72-936e-414d-964d-fc7f07834c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-3490bb17-3173-4cfa-a170-ef36a18ca90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-925a4f4a-c3f7-4ae4-b366-b2a0013a87f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-e2b3d2e6-86ea-4ee1-80aa-528269d1ae72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394003995-172.17.0.3-1597171363391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-4c6dbbcb-d05e-44c4-982c-d150cab5e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-af320b90-e467-49a1-bfa4-b202406f5f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-36121407-5b82-46a7-9526-1ae27373d2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-84ab872f-c241-480e-a838-03880e578152,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-7eeacd77-44c9-4eb0-9b9b-f3c9c5215781,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-73dd9a46-8313-4102-89ea-63b1716a084b,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-2446e8f1-2489-4aac-9e4d-ed5d28acb0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-6c0324e0-5883-4813-ba18-ca42a286f243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394003995-172.17.0.3-1597171363391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-4c6dbbcb-d05e-44c4-982c-d150cab5e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-af320b90-e467-49a1-bfa4-b202406f5f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-36121407-5b82-46a7-9526-1ae27373d2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-84ab872f-c241-480e-a838-03880e578152,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-7eeacd77-44c9-4eb0-9b9b-f3c9c5215781,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-73dd9a46-8313-4102-89ea-63b1716a084b,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-2446e8f1-2489-4aac-9e4d-ed5d28acb0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-6c0324e0-5883-4813-ba18-ca42a286f243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5252
